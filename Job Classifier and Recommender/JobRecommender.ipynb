{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "q_RXws5u-xwv"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer\n",
        "import nltk\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company</th>\n",
              "      <th>job-title</th>\n",
              "      <th>job-description</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AppZen</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>It ProfessionalsGrowing AI dvlpmt co seeks Dat...</td>\n",
              "      <td>Entry level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Patterned Learning AI</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>REMOTE (US/Canada Residing people only, with w...</td>\n",
              "      <td>Entry level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Patterned Learning AI</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>REMOTE (US/Canada Residing people only, with w...</td>\n",
              "      <td>Entry level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SynergisticIT</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>SYNERGISTICIT wants every candidate to know th...</td>\n",
              "      <td>Entry level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Perfect Snacks</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Company DescriptionWho We Are...Based in sunny...</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>Tutor Intelligence</td>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>We encourage people of all backgrounds and ide...</td>\n",
              "      <td>Not Applicable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371</th>\n",
              "      <td>Diverse Lynx</td>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>Job DescriptionJob Role : Software Engineer (P...</td>\n",
              "      <td>Entry level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1372</th>\n",
              "      <td>SynergisticIT</td>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>SYNERGISTICIT wants every candidate to know th...</td>\n",
              "      <td>Entry level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373</th>\n",
              "      <td>SynergisticIT</td>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>SYNERGISTICIT wants every candidate to know th...</td>\n",
              "      <td>Entry level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1374</th>\n",
              "      <td>Enolink</td>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>Our mission is to bring the power of AI to hea...</td>\n",
              "      <td>Employment type\\n        \\n\\n          Full-time</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1173 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    company                  job-title  \\\n",
              "0                    AppZen             Data Scientist   \n",
              "1     Patterned Learning AI             Data Scientist   \n",
              "2     Patterned Learning AI             Data Scientist   \n",
              "3             SynergisticIT             Data Scientist   \n",
              "4            Perfect Snacks             Data Scientist   \n",
              "...                     ...                        ...   \n",
              "1370     Tutor Intelligence  Machine Learning Engineer   \n",
              "1371           Diverse Lynx  Machine Learning Engineer   \n",
              "1372          SynergisticIT  Machine Learning Engineer   \n",
              "1373          SynergisticIT  Machine Learning Engineer   \n",
              "1374                Enolink  Machine Learning Engineer   \n",
              "\n",
              "                                        job-description  \\\n",
              "0     It ProfessionalsGrowing AI dvlpmt co seeks Dat...   \n",
              "1     REMOTE (US/Canada Residing people only, with w...   \n",
              "2     REMOTE (US/Canada Residing people only, with w...   \n",
              "3     SYNERGISTICIT wants every candidate to know th...   \n",
              "4     Company DescriptionWho We Are...Based in sunny...   \n",
              "...                                                 ...   \n",
              "1370  We encourage people of all backgrounds and ide...   \n",
              "1371  Job DescriptionJob Role : Software Engineer (P...   \n",
              "1372  SYNERGISTICIT wants every candidate to know th...   \n",
              "1373  SYNERGISTICIT wants every candidate to know th...   \n",
              "1374  Our mission is to bring the power of AI to hea...   \n",
              "\n",
              "                                                 level  \n",
              "0                                          Entry level  \n",
              "1                                          Entry level  \n",
              "2                                          Entry level  \n",
              "3                                          Entry level  \n",
              "4                                     Mid-Senior level  \n",
              "...                                                ...  \n",
              "1370                                    Not Applicable  \n",
              "1371                                       Entry level  \n",
              "1372                                       Entry level  \n",
              "1373                                       Entry level  \n",
              "1374  Employment type\\n        \\n\\n          Full-time  \n",
              "\n",
              "[1173 rows x 4 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv(\"dataJobs.csv\")\n",
        "df=df.dropna()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_descriptions = df[\"job-description\"].tolist()\n",
        "job_titles = df[\"job-title\"].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\aswat\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\aswat\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\aswat\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('stopwords')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "ps = nltk.PorterStemmer()\n",
        "words = set(nltk.corpus.words.words())\n",
        "\n",
        "def clean_message(message):\n",
        "    message = message.lower()\n",
        "    message = re.sub(r\"http\\S+\", \"\", message)\n",
        "    message = re.sub(r\"www.\\S+\", \"\", message)\n",
        "    message = bert_tokenizer.tokenize(message)\n",
        "    message_links_removed = \"\".join([char for char in message if char not in string.punctuation])\n",
        "    message_cleaned = \" \".join([word for word in re.split('\\W+', message_links_removed)\n",
        "        if word not in stopword])\n",
        "    message = \" \".join([wn.lemmatize(word) for word in re.split('\\W+', message_cleaned)])\n",
        "    return message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_descriptions=[clean_message(x) for x in job_descriptions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(job_descriptions, job_titles, test_size=0.2, random_state=42)\n",
        "cv = CountVectorizer()\n",
        "X_train = cv.fit_transform(X_train)\n",
        "X_test=cv.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z_tZFQrKSTi",
        "outputId": "30f87399-c2e1-403b-9ac0-2c4e5ad26d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8297872340425532\n"
          ]
        }
      ],
      "source": [
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(\"Accuracy:\", accuracy_nb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "de5G5L8Z23lI",
        "outputId": "1ebb8a5e-3aec-4848-b2fb-6580d07b1360"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred_nb, labels=nb.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Compter Vision Engineer\",\"Data Analytics\",\"Data Engineer\",\"Data Scientist\",\"Machine Learning Engineer\"])\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvxRX6I3KVaD",
        "outputId": "ff82eb3d-86b5-4b6f-ca70-b1c6bbc39896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8553191489361702\n"
          ]
        }
      ],
      "source": [
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "print(\"Accuracy:\", accuracy_gb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "OvQvpElo4hjB",
        "outputId": "04a5d1e0-7993-4c10-f29e-59fe71be0464"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred_gb, labels=gb.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Compter Vision Engineer\",\"Data Analytics\",\"Data Engineer\",\"Data Scientist\",\"Machine Learning Engineer\"])\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MjJ3sLaKhlV",
        "outputId": "0c9c224c-6317-43ad-b4c3-49f4a7597562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8680851063829788\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy:\", accuracy_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "tbqDuNnN4o9h",
        "outputId": "be9618df-f97a-4936-9c56-790cd98b6fc0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred_rf, labels=rf.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Compter Vision Engineer\",\"Data Analytics\",\"Data Engineer\",\"Data Scientist\",\"Machine Learning Engineer\"])\n",
        "disp.plot()\n",
        "plt.title(\"Confusion Matrix of Random Forest\")\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Rotate y-axis labels by 45 degrees\n",
        "plt.yticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "goy4kDao4v35",
        "outputId": "bbd5cd99-2f09-43ee-c527-bd6f746351ea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred_lr, labels=lr.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Compter Vision Engineer\",\"Data Analytics\",\"Data Engineer\",\"Data Scientist\",\"Machine Learning Engineer\"])\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nzpyq_MKswo",
        "outputId": "55d64a3f-9cce-4e8e-c3cc-9da838f9f111"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aswat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8382978723404255\n",
            "Jaccard Index: 0.7231739891314359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aswat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svm = LinearSVC(max_iter=2000)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"Accuracy:\", accuracy_svm)\n",
        "from sklearn.metrics import jaccard_score\n",
        "jaccard_similarity = jaccard_score(y_pred_svm, y_test,average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "a0TBl-2j44J7",
        "outputId": "bcfadbc7-51cb-4cf2-c481-7611e67e73ee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred_svm, labels=svm.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Compter Vision Engineer\",\"Data Analytics\",\"Data Engineer\",\"Data Scientist\",\"Machine Learning Engineer\"])\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gvAhhoW9cxdt",
        "outputId": "d9b0d3a7-31c4-4aeb-a078-c40204c801d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "x=[\"Niave Bayes\",\"Gradient Boost\",\"Random Forest\",\"Logistic Regression\",\"Support Vector Machine\"]\n",
        "y=[accuracy_nb,accuracy_gb,accuracy_rf,accuracy_lr,accuracy_svm]\n",
        "# creating the bar plot\n",
        "plt.bar(x, y, color ='blue',\n",
        "        width = 0.4)\n",
        "plt.yticks(np.arange(0, 1, step=0.05))\n",
        "plt.xlabel(\"Classifier\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracies of the Classifiers\")\n",
        "for i in range(len(x)):\n",
        "     plt.text(i, y[i], round(y[i],3), ha = 'center')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"It ProfessionalsGrowing AI dvlpmt co seeks Data Scientists (NLP) [50] w/ base pay $130,450-$170K/yr. Deg'd/exp'd In-house FT great compens/benefitsSend resume to AppZen, San Jose, CA 50@AppZen.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Scientist (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job RequirementsM.S. or PhD in Data Science/Electrical Engineering/Computer ScienceExperience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlySpecial Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Data Scientist , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job RequirementsM.S. or PhD in Data Science/Electrical Engineering/Computer ScienceExperience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlySpecial Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Entry Level Data Scientist with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionWho We Are...Based in sunny San Diego, Perfect Snacks is the company behind The Original Refrigerated Protein Bar. Offering a line of products that boast whole food ingredients and clean food credentials, Perfect Snacks is sold online and in more than 35,000 retailers nationwide. Now more than a decade since its inception, the brand has experienced rapid growth in the last few years, as consumers flock to the fridge for fresher options. Our success is attributed to the people behind the brand, who share in our family's mission: 'To nourish worldkind with a hug, good vibes and a delicious dose of fresh whole food nutrition. To us, that’s the recipe to make life a little more, well, perfect.'Who Are We Looking For...The Data Scientist will support the Sales Operations team, as well as the broader organization, with a focus on effective data management, optimization, and cohesive reporting. This will require frequent coordination and collaboration with both internal & external team members.Job DescriptionEssential Duties:Primary database developer – design and build SQL database to house all data necessary to populate internal revenue and forecast reporting. Lead project to replicate best in class customer reporting currently in place (UNFI, KEHE, WFM) for additional customers:Walmart, Sam’s, Target, etc. (some currently provided by brokers)Be the company expert on Power BI, report availability and manage distribution of reportsMaintain current PowerBI dashboards - UNFI, KeHE, WFMLead project to automate refresh of daily revenue reportingOwn Power BI reporting of syndicated data (Nielsen, Spins) – maintain/refresh monthly current reporting, make modifications and develop new reporting as neededAid in the implementation and management of new Demand Planning system with a focus on integration into NetSuite ERP systemAssist in development of new Power BI trade/net sales/P&LAccepts responsibility for the organizational goals by taking ownership of new and different duties and identifying new opportunities within the Sales Operations team. Lead effort to gather and systematically organize customer/distributor specific data reports (WFM, Dora’s, Dot, Etc.) QualificationsSkills / Qualification / Education:Bachelor’s degree and +7 years in CPG or related field preferred with focus on business intelligenceExpert level knowledge of SQL, writing queries, developing databases, etc. Experience using Microsoft Stack (Outlook, Excel, Power BI, etc.)Experience using data visualization tools (i.e. Power BI, Tableau)Ability to manage multiple projects and deadlines simultaneouslyHigh attention to detail and passion for data integrityAbility to work across multiple data sources to provide a holistic perspectiveAbility to influence decision making across multiple levels and functions of an organization to drive resultsExcellent organizational skills and time management abilitiesAbility to make decisions and work with little supervisionAbility to work under pressure and balance multiple tasksAdditional InformationCompensation: $90-100k/ Year (DOE)Bonus / Benefits / Vacation / 401k EligibleThis role can be remote, however aplicant must live in the United StatesGot what it takes to join the Perfect Snacks family? We want to hear from you!We will only consider candidates who provide a resume and answer the below questions: Why do you want to join the Perfect Snacks family/brand? What excites you about this role? Where are you located?www.perfectsnacks.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"CFD Research Corporation has an immediate need for a Data Scientist. This individual will support customer site work in Huntsville, AL. The Data Scientist will develop and apply interdisciplinary methods, algorithms, statistics, and research techniques in the development of data-driven solutions to extract knowledge, provide insights, and present information from data in various structures and unstructured forms. Performs advanced data analysis of heterogeneous datasets and systems Assists in the development of data products, reports, dashboards or other display techniques Evaluates data, algorithms, and their interaction to improve algorithm performance Assists with data modeling and data virtualization and writing code to preprocess and clean dataBasic Qualifications Minimum degree required is a Bachelor's in a STEM field or equivalent Minimum of 2 years of related experience Knowledge of advanced machine learning (ML) and data science techniques and tools Working knowledge of current operating systems and programming languagesOther Qualifications Experience with Deep Learning, Advanced Analytics, Neo4j, MongoDB, ArangoDB, SQL and NoSQL databases Programming experience in Python, R, Julia, TensorFlow, CUDA, JavaScript, Scala, Java, Unix/Linux, C, C++About CFD Research: Since its inception in 1987, CFD Research has worked with government agencies, businesses, and academia to provide innovative solutions within the Aerospace & Defense, Biomedical & Life Sciences, and Energy & Materials industries. Over the years CFD Research has earned multiple national awards for successful application and commercialization of innovative technology prototypes, multi-physics simulation software, multi-disciplinary analyses, and expert support services. CFD Research's impressive three-year growth rate was high enough to recognize the company in the Inc. Magazine's 5000 for the second year in a row.Benefits: CFD Research offers competitive salaries and excellent employee benefits, including an employer matching 401(k) and Employee Stock Ownership Plan (ESOP). CFD Research offers a highly competitive insurance package, including medical, vision, and dental insurance. We offer company paid leave, long-term disability, accidental death and dismemberment, and life insurance. Performance appraisals occur twice a year and pay increases are based upon corporate goals, personal development, performance, and outstanding achievements. In addition, group and individual bonuses are awarded for exceptional performance.CFD Research is an EO employer - Veterans/Disabled and other protected categoriesJob Posted by ApplicantPro\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title: Data ScientistLocation: 100% remoteDuration: 18 monthsJob DescriptionThe Microsoft Mixed Reality team works with big data. You will join the Hololens Product Integrity Group as we outline our next generation data analytics architecture, allowing us to monitor product quality, apply correlation and understanding to device measurements, and deploy new test coverage for the product.ExperienceAn Engineering B.S. with Data Science/Analytics experience, a grounding in statistics and analysis.Skills: JMP, PowerBI/ DAX Formulas, SQL manipulation, regression analysis. Also interesting: R, Python, Tableau or similar graphical reporting tools.Network infrastructure and experience architecting Azure based systems is also a plus.SkillsThis role involves H/W and Software background which allows the measurement of how the network performs.Candidate must be US Citizen or Green card holder.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Role : Data ScientistLocation : Remote (CST)(Contrect)Job DescriptionMandatory Skill : AI Cognitive AgencyManage GCP platform data loads in and out of the platform or within hybrid environmentTake offline models data scientists build and turn them into a real machine learning production systemDevelop and deploy scalable tools and services for our clients to handle machine learning training and inferenceDesign the data pipelines and engineering infrastructure to support internal clients- enterprise machine learning systems at scaleIdentify and evaluate new technologies to improve performance, maintainability, and reliability of our clients' machine learning systemsApply software engineering rigor and best practices to machine learning, including CI/CD, automation, etc.Support model development, with an emphasis on auditability, versioning, and data securityFacilitate the development and deployment of proof-of-concept machine learning systemsCommunication and requirements from various stake holders to build final requirements and track progressQualificationsExperience building end-to-end systems as a GCP Platform Engineer, ML DevOps Engineer, or Data Engineer (or equivalent)MLOps within the enterprise CI/CD process for ML modelsExperience deploying ML APIs in production environments in GCP using GKEExperience in using GCP Vertex AI for ML and BigQueryKnowledge in Terraform and Containers technologiesExperience writing data processing jobs using GCP Dataflow and DataprocExperience setting up ML model monitoring and autoscaling for ML prediction jobsStrong software engineering skills in complex, multi-language systemsFluency in Python and comfort with Linux administrationExperience working with cloud computing and database systems and cloud based various data formats NOSQL/HDFSExperience building custom integrations between cloud-based systems using APIsExperience developing and maintaining ML systems built with open source toolsExperience developing with containers and Kubernetes in cloud computing environmentsFamiliarity with one or more data-oriented workflow orchestration frameworks (KubeFlow, Airflow, Argo, etc.)Ability to translate business needs to technical requirementsStrong understanding of software testing, benchmarking, and continuous integrationExposure to machine learning methodology and best practicesExperience in deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Position: Data ScientistLocation: Elk Grove, CA (Day 1st Onsite)ContractThe data scientist role willUse SQL to access data and build tablesUse topic modeling (or a similar NLP methodology) to process survey commentsUse Tableau to share results of NLP modelingPSRTEK is a reputed technology recruitment and IT staffing brand with a global footprint and an admired client base. As an ideas and innovation powerhouse with a culture of excellence, we bring remarkable expertise and deliver powerfully transformative results.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"PacArctic,LLC, a Koniag Government Services company, is seeking an experienced Jr Data Scientist with a Secret Clearance to support PAC and our government customer in Washington, DC.We offer competitive compensation and an extraordinary benefits package including health, dental and vision insurance, 401K with company matching, flexible spending accounts, paid holidays, three weeks paid time off, and more.Essential Functions, Responsibilities & Duties may include, but are not limited to: Support research, analysis, and tracking OBO's HR function milestones and metrics. Using data collected in the study, assist the government to identify findings and recommendations of this assessment that will streamline the customer's functions/products, maximize efficiencies, and provide a concrete structural blueprint for the delivery of HR services in a cost-effective manner that optimizes the customer's long and short-term service goals. Recommendations as needed for project data visualizations. Support the government to analyze the data collected outputs throughout the different methodologies. Support data analysis and development of data sets for functional and performance analytics; turning data into value for IT solutions. Create data visualizations to communicate IT findings which enhance business functions. Support a wide variety of analytical techniques used to determine and communicate trends and patterns, fill gaps in information and project events, identify anomalies, ascribe meaning to events or information from disparate sources, and develop defensible judgments and conclusions based on accepted research and analytical methodologies.Work Experience, Knowledge, Skills & Abilities Able to obtain and maintain a Top-Secret clearance. Experience in statistical analysis and data mining Knowledgeable in Eclipse IDE, PyCharm, Java, Rstudio, Microsoft SQL, Python Knowledge of data management concepts, principles, and methods for database logical and physical design, development, and maintenance of information management systems. Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Highly developed oral and written communication skills required to present findings or translate the data into an understandable document. Must be skilled and able to prepare and present highly complex matters, material, and/or issues to others. Bachelor's degree in data science strongly preferred. Two years of professional experience required.Working Environment & ConditionsThis job operates in a professional office environment and has a noise level of mostly low to moderate. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines. This position is primarily indoors, consistent with a standard office position and has a noise level of mostly low to moderate. The incumbent is required to stand, walk; sit; use hands to finger, handle, or feel objects, tools, or controls; reach with hands and arms; talk and hear. The workload may require the incumbent to sit for extended periods of time. The incumbent must be able to read, do simple math calculations and withstand moderate amounts of stress. The incumbent must occasionally lift and/or move up to 25 lbs. Specific vision abilities required by the job include close vision, distance vision, color vision, depth perception, and the ability to adjust focus.Our Equal Employment Opportunity PolicyThe company is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, sex, sexual orientation, gender, or gender identity (except where gender is a bona fide occupational qualification), national origin, age, disability, military/veteran status, marital status, genetic information, or any other factor protected by law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits and all other privileges, terms, and conditions of employment.The company is dedicated to seeking all qualified applicants. If you require accommodation to navigate or to apply for a position on our website, please contact Heaven Wood via e-mail at accommodations@koniag-gs.com or by calling 703-488-9377 to request accommodation.Koniag Government Services (KGS) is an Alaska Native Owned corporation supporting the values and traditions of our native communities through an agile employee and corporate culture that delivers Enterprise Solutions, Professional Services and Operational Management to Federal Government Agencies. As a wholly owned subsidiary of Koniag, we apply our proven commercial solutions to a deep knowledge of Defense and Civilian missions to provide forward leaning technical, professional, and operational solutions. KGS enables successful mission outcomes for our customers through solution-oriented business partnerships and a commitment to exceptional service delivery. We ensure long-term success with a continuous improvement approach while balancing the collective interests of our customers, employees, and native communities. For more information, please visit www.koniag-gs.com.Equal Opportunity Employer/Veterans/Disabled. Shareholder Preference in accordance with Public Law 88-352\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Deep Learning Engineer - (CNN/RNN)AboutTrilogy Innovations is seeking a highly skilled Deep Learning Engineer / CNN Architect to join our team. The successful candidate will be responsible for designing, implementing, and optimizing deep learning models using Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Convolutional Recurrent Neural Networks (RCNN) for various applications such as image recognition, waveform analysis, and natural language processing.Telework: 100% remote supportFull-time (W2) Employment Benefits: Health, vision/dental, life/disability, 401(k) + matchPerks: 100% coverage of professional development, phone/internet reimbursements & bonus programsRequirementsMaster's or Ph.D. degree in Computer Science or related field.5+ years of experience in developing and implementing deep learning models.Strong understanding of Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Convolutional Recurrent Neural Networks (RCNN).Experience working with large datasets.Strong programming skills in Python, TensorFlow, and PyTorch.Experience with VGG16 and EfficientNet is highly desired.Experience working with embedded systems is a plus.ResponsibilitiesDesign, develop, and implement deep learning models using CNN, RNN, and RCNN for various applications.Work with large data sets to preprocess, clean, and prepare data for model training.Create datasets for training and testing.Train machine learning models and validate their accuracy, and deploy validated models into production.Optimize models for performance and accuracy, and fine-tune hyperparameters to achieve optimal results.Stay up to date with the latest developments in deep learning techniques and technology.Provide technical guidance and support to other team members.Why work for Trilogy Innovations?Professional Development Programs for all employeesUp to $150/month towards your phone and internet services per monthReferral Bonus Programs (Employees & Business Development)401(k) with company matchComprehensive medical, vision and dental insurance; life/disability insurance coverageHealth Spending Account (HSA)www.trilogyit.comTrilogy Innovations, Inc. is a minority-owned (8a) and HUBZone certified systems and software engineering company that delivers superior technical solutions across private and public sectors. Since 2010, our talented personnel have successfully provided Innovative IT solutions across government agencies such as the FBI, U.S. Air Force, NASA, Department of Education, Department of Energy, U.S. Coast Guard, SOCOM, and private industries in Oil & Gas, and Land Management Services.Trilogy Innovations, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"This role is only available for W2 or 1099 individual.  100% Remote WorkLocation: Remote anywhere in the USContract to Hire our client is adamant about finding a long term fit. No difference between contract and FTE,  100% will convert.  Job Description: Our client is currently looking for a Data Scientist. We are working with a Director in the Machine Learning & Data Science in our client's cyber division.Our client hosts a true Big Data environment (Petabytes of data stored, and processing daily upwards of 235 billion market events). You will be tasked with researching and helping construct some of the most important machine learning models that protect our stock and bond markets.Our client is looking to incorporate anomaly detection/data science technology in their cyber environment to identify abnormal behavior.Our client is looking for someone with a great deal of intellectual curiosity, experience in a data science environment, who want to be very hands on and technical (coding and mathematical/research analysis is required).Minimum QualificationsPhD preferred, Master's required Computer Science, Math, Statistics, Physics and/or Electrical Engineering must have the mathematical background to apply mathematical analysis to data and determine relationships4+ years of experience in Data Science, Big Data, AI/Client and/or software/data engineeringExpertise in programming with PythonStrong SQL querying skillsExperience in Big Data environments and in a data science practiceKeen ability to research data and identify relationships (this is 85% of the job)Data science experienceHave worked on building and maintaining Machine Learning modelsExperience with PySpark and PyTorchMust have strong communication skillsPreferred:Coding experience with SparkBig Data engineering experienceAWS experienceExperience executing sophisticated SQL queries for backend, data testing.Powered by JazzHRb8OFsmkPmt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Iron EagleX is a veteran owned defense contracting company based in Tampa, FL.It is our mission to provide solutions to the most challenging technical problems facing the Department of Defense while simultaneously making a positive impact on our employees and community.Job DescriptionThe Data Scientist will support the United States Special Operations Command (USSOCOM) Chief Data Office (CDO) and be responsible for designing, implementing, and maintaining a data pipeline. Additionally, the Data Scientist shall interpret and analyze complex sets of data and plan, execute, and manage ML projects with cloud-native platforms and advanced ML solutions. They will leverage multiple methodologies such as data mining, natural language programming, and machine learning.Job Duties Include (but Not Limited To)Interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific methodCoordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the dataExperiment against data points, provide information based on experiment results, and provide previously undiscovered solutions to command data challengesCoordinate with Data Engineers to build data environments providing data identified by other data professionalsApply and develop scientific methodology, statistics, and algorithms to discover and frame relevant problems, hypotheses, and opportunitiesDevelop predictive and prescriptive modeling, natural language processing (NLP), Robotic Process Automation (RPA), text mining and processing, clustering, forecasting methods, and other advanced statistical techniquesDesign and automate processes to facilitate the manipulation and analysis of dataManage and integrate data across dissimilar data sets and analyze large-scale structured and unstructured dataUse frameworks to conduct large-scale data processingPerform statistical modeling and create data visualizations Research, design, and implement algorithms to solve complex problemsProgram using R, Python (NumPy, SciPy, Pandas) or similar analytical languagesPerform data engineering, data processing, and modeling techniques using cloud-based data management, data science, and ML platforms Communicate complex concepts and hypothesis to a non-technical audience through digital storytellingRequired Skills & ExperienceMinimum of 1-year of Data Science experience is required:Proficient with one or more programming languages (Java, C++, Python, R, etc.):Proficient in Agile Development and Git Operations: Demonstrated experience applying data science methods to real-world data problems:MUST BE US CITIZENDesired SkillsExperience working with the Department of DefenseEducation & CertificationsBachelors in Stem field or Master’s Degree in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fields:Security ClearanceActive TS/SCI Clearance is requiredBenefitsNational Health, vision and dental plans20 days of PTO and 11 paid holidaysLife InsuranceShort – and long-term disability plans401(K) retirement planIncentive and recognition programsRelocation opportunitiesIron EagleX is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, among other things, or status as a qualified individual with disability.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'About Us\\xa0\\xa0DeepLogica is a proprietary AI platform that empowers clients’ existing processes and systems to redefine eCommerce delivery. We utilize machine learning models to accurately predict supply chain events, provide actionable business insights and ultimately enhance the buying experience.\\xa0\\xa0About The Role\\xa0\\xa0We’re looking for a talented Data Scientist who is passionate about data, learning, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\\xa0A varied skill set, creativity, flexibility, and positive team attitude are high priorities. \\xa0Main Responsibilities\\xa0\\xa0In collaboration with the other members of your team and your supervisor you will be in charge or participate in the following activities:\\xa0Collecting, cleaning, and transforming large datasets for downstream processing.\\xa0Design accurate and scalable prediction algorithmsDevelop statistical and machine learning models to extract insights and predictions from data.\\xa0Visualize and present findings to stakeholders in a clear and concise manner.\\xa0Collaborate with cross-functional teams to identify business problems that can be solved using data.\\xa0Design experiments to test hypotheses and improve models.\\xa0Assist Data Engineering team members in building and deploying data pipelines and scalable infrastructure to support data analysis.\\xa0Ensure ethical use of data and compliance with privacy regulations.\\xa0Continuously monitor and evaluate the performance of models and adjusting as needed\\xa0Required Education, Qualifications and Experience\\xa0Bachelors or Masters degree in operations research, computer science, software engineering, or a related field\\xa0\\xa02-3 years of experience in quantitative analytics of data modeling.\\xa0Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)Passionate self-starter, able to prioritize tasks and manage time effectively.\\xa0Ability to take ownership of tasks to ensure high quality and successful on-time completion.\\xa0\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Location Lawrenceville, New Jersey 08648Role is 100% onsite.Junior (0-3 Yrs.)DescriptionLeads discovery and optimization (LDO) is a diverse group of scientists and engineers, providing critical assay information to therapeutic research centers (TRCs) throughout research and early development (R&ED). We are seeking a highly motivated and innovative data scientist to join the data science and advanced analytics team within LDO until the end of 2023. The individual will develop a machine learning and Bayesian statistics-based approach to model assay variability using medium to high throughput screening datasets. The individual will work in a highly dynamic environment at the center of the R&ED drug discovery engine to develop cutting edge tools applied to complex drug discovery problems.Roles and ResponsibilitiesWrite python scripts to enable rapid cleaning and analysis of medium and high throughput datasetsUtilize machine learning (ML) approaches to generate small molecules featuresUtilize Bayesian statistics approaches to estimate uncertainties in assay datasets, based on results on above ML outputsWrite and document programming code (python preferred) to facilitate data preparation / cleaning, model development, and evaluationProduce high quality scripts, documentation, and processing pipeline by the end of 2023Create deployable version of processing pipeline for near term use as a stand-alone application and ultimately future integration with enterprise suiteQualificationsPh.D. in quantitative sciences/engineering (computer science, mathematics, statistics, or engineering)5+ years of relevant professional experience with a proven track record in machine learning and data science experience in drug discovery machine learning is desirable but not requiredStrong knowledge of one or more scripting programming languages, with a focus on machine learning (e.g., Python (preferred), R, Matlab, C/C++)Experience utilizing molecular features of small molecules in machine learning modelsExperience with the use and application of Bayesian statistics and simulation methods in generating probabilistic outcomesAble to extract information from databases using a variety of software packages (e.g., Oracle SQL developer)Ability to build and maintain databases aligned with enterprise solutions is desirable but not requiredStrong analytical and problem solving skills to understand technical business problems and implement solutionsAbility to work effectively on matrixed teams to collaboratively solve challenging problems, while also able to work independently with minimal resourcesHas good interpersonal, communication, writing and organizational skillsStrong preference for on-site presence to enable colocation with data science team\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Junior Data Scientist (Remote) with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Associate, Data ScienceNew York, United States of AmericaWhat You Will Be DoingUSA Job Function Description:Designs and monitors control systems which ensure the integrity and security of data and for advising on the optimal use of the organization's computing resources.Assesses the completeness, accuracy, validity and efficiency of information processing, business and application systems, reviews the operations, systems software, systems development and security of the organization's computing environment, and recommends appropriate software and hardware acquisitions.Essential Functions/Responsibility StatementsTranslates business queries into actionable and commercial insights leveraging unstructured data and statistically robust techniques.Drives cross functional analytics projects from beginning to end: builds relationships with partner teams, frames and structures questions, collects and analyzes data, and summarizes key insights in support of decision making.Works with engineers to evangelize data best practices and implement analytics solutions.Evaluation and discovery of alternative data vendors including ability to quantifiably validate external algorithms and apply insights to commercially driven use cases.Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.Education: Bachelor's Degree or equivalent work experienceWork Experience: 5-9 years ; Data mining/advanced analytics applied to large-scale data-intensive projects.Skills And AbilitiesKnowledge of the principles of machine earning, classification models, time series regression and stochastic statistics to deliver improved business performanceDemonstrated experience with SQL, R or a comparable programming language (such as Python, SAS, SPSS, or MATLAB)Demonstrated ability to communicate complex concepts.Strong quantitative and problem solving skills with focus hypothesis formulation and testing.Strong evidence of leveraging analytics to drive business results.Strong project management skills.Individually motivated and possess sound judgment, integrity, and a solid work ethic.Diversity & EEO Statements: At Santander, we value and respect differences in our workforce and strive to increase the diversity of our teams. We actively encourage everyone to apply.Santander is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, genetics, disability, age, veteran status or any other characteristic protected by law.Working Conditions: Frequent Minimal physical effort such as sitting, standing and walking. Occasional moving and lifting equipment and furniture is required to support onsite and offsite meeting setup and teardown. Physically capable of lifting up to fifty pounds, able to bend, kneel, climb ladders.Employer Rights: Employer Rights: This job description does not list all of the job duties of the job. You may be asked by your supervisors or managers to perform other duties. You may be evaluated in part based upon your performance of the tasks listed in this job description. The employer has the right to revise this job description at any time. This job description is not a contract for employment and either you or the employer may terminate at any time for any reason.For NYC Job Applicants: The base annual salary range for this position is $41,600-$172,500.The exact compensation may vary based on skills, experience, training, licensure and certifications and location.Masters of Science (MS) EnglishPrimary Location: New York, NY, Madison Ave CorpOther Locations: New York-New YorkOrganization: Banco Santander S.A.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'HiSatyam this side. We do have a new an excellent opportunity for you. This opportunity is a full time onsite position as Data Scientist.  Please have a look at the job description below and let me know if you or someone you know is interested in this role. You can mail me at satyam@extendinfosys.com.Job Title Data ScientistLocation Santa Clara, CAJob Type Full TimeJob DescriptionData Scientist -- Computer Vision Solid knowledge of various Image Filtering, Binary Morphology, Perspective / Affine transformation, Edge Detection, and Tracking. Machine Learning: Regression, Unsupervised Learning, PCA Nice but not necessary to have HDR, Panorama, and deep Learning object detectionThanksSatyam Prajapati | Technical Recruiter| Extend Information SystemsCell: (571) 547-2880Email: satyam@extendinfosys.comAddress: 44258 Mercure Circle, UNIT 102 A, Sterling VA, USA - 20166Web:www.extendinfosys.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Summary This position is located in the Office of Nuclear Reactor Regulation (NRR), Embark Venture Studio (EVS) and Office of Nuclear Material Safety and Safeguards (NMSS), Program Management, Policy Development, and Analysis Staff (PMDA). This position is Bargaining Unit with the National Treasury Employees Union, Chapter 20This position is not subject to Confidential Financial Disclosure reporting requirements. This position is subject to security ownership restriction reporting requirements. Responsibilities The incumbent serves as a Data Scientist with specific technical expertise. Duties include but are not limited to: data mining/data analysis methods (e.g., data cleansing, data management, analytics, visualization, and engineering), modeling (e.g., model selection, training, evaluation, and tuning), mathematics, statistics, and artificial intelligence to collect, analyze, and interpret large datasets. collection and maintenance of data, data analytics, development of methodological approaches, study design, development of data strategies and data policies, and advanced written, verbal, and visual communications of study/analysis output. provides direction and scientific expertise to a wide range of highly complex, highly visible initiatives and projects. leads and/or consults with cross-functional teams to develop data-driven solutions that address NRC's program and business challenges. leverages data visualization tools (e.g., Tableau, Power BI) to visualize and analyze data in support of metrics, trend analysis, and other reports and projects. utilizes scripting languages (such as JavaScript, Java, Python) to create predictive models to drive data-driven decision-making and automate existing processes. analyzes management information requirements to develop program or administrative reporting systems including the systems specifications, data gathering and analytical techniques, and systems evaluation methodology. leads the development and implementation of mathematical, and/or statistical (e.g., regression, classification, resampling, statistical tests, and proper usage) techniques and concepts that are applicable to data management, analysis, regulatory issues, and program oversight, including understanding the issues and limitations of these techniques. Requirements Conditions of Employment U.S. Citizenship Required This is a Drug Testing position. Background investigation leading to a clearance is required for new hires. To ensure compliance with an applicable preliminary nationwide injunction, which may be supplemented, modified, or vacated, depending on the course of ongoing litigation, the NRC will take no action to implement or enforce the COVID-19 vaccination requirement pursuant to Executive Order 14043 on Requiring Coronavirus Disease 2019 Vaccination for Federal Employees. Therefore, to the extent that an NRC job announcement includes the requirement that applicants must be fully vaccinated against COVID-19 pursuant to Executive Order 14043, that requirement does not currently apply. You must meet the qualifications for this position by no later than 30 calendar days after the closing date of this announcement and before placement in the position. Qualifications The ideal candidate will be able to demonstrate the following:Demonstrated knowledge of and experience in developing data analytics/science related products (e.g. machine learning, natural language processing, robotics process automation, and artificial intelligence) and applied programming or data manipulation with a programing language (e.g., Python; R; SQL; or equivalent) to analyze large volumes of data to build and enhance products, processes, and systems. Demonstrated knowledge and experience in identifying problematic issues and reporting discrepancies and providing appropriate recommendations to leadership.Demonstrated ability to establish and maintain effective work relationships with peers, management, and personnel of other U.S. government agencies, equivalent industry organizations, or international organizations.Demonstrated ability to effectively communicate technical information both orally and in writing.Knowledge of regulatory programs, policies, guidance, and support activities. In order to qualify for this position, you must have at least one year of specialized experience at the next lower grade level in the Federal service or equivalent experience in the private or public sector. SPECIALIZED EXPERIENCE is defined as experience performing data acquisition, data cleansing, and data visualization with tools such as Tableau and Power BI; having familiarity with data discovery to take an unknown data set and extract meaning; possessing effective software development skills and understanding scripting languages; and exhibiting excellent skills related to written and oral communications, organization, problem solving, and the ability to work independently and collaboratively in a team environment. A description of how you possess the specialized experience as well as how you meet the qualifications desired in an ideal candidate must be addressed in your resume. Education Basic Requirements: Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. or Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience. Additional Information The duty location of this position is Rockville, MD. In general, employees are expected to be in the office at a minimum of 4 days per pay period**. Telework schedules, including full-time telework, are approved, on a case-by-case basis. If selected, telework will be determined in accordance with Agency policy and the Collective Bargaining Agreement, if applicable.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About the Role:We are looking for a highly analytical, data obsessed Data Scientist to join our growing company. The ideal candidate will work cross functionally to develop, maintain and implement predictive models that will provide actionable insights to inform key business decisions. This role will sit within our Product Team and report to our Senior Director, Product Analytics.What you'll be doing:Think critically and leverage data to test and iterate on new product features and business strategiesDeﬁne and implement client usage, churn, retention, and other key metricsBuild and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scaleQuery databases from multiple marketing and product sources and create usable KPI dashboardsSetup analytical framework for user journeys and lifecycle marketing funnelsStatistical modeling:Support business objectives through statistical modeling through the prediction of main KPIs such as churn, retention and LTVDesign, implement and maintain machine learning models to automate and optimize marketing, operations, and customer experienceA/B testing and causal modelingCommunication & Teamwork:Collaborate with stakeholders across the companyFull-stack data science analysis and present insights to both the data science team and internal company stakeholders. Minimum Qualifications:Bachelor's degree in computer science, mathematics, data science, engineering or a closely related field2+ years as a Data Scientist (Business Intelligence) involving data extraction, analysis, and statistical modelingExcellent problem solving skills with keen attention to detail Ability to communicate complex data insights to both technical and non-technical audience, including senior leadership Experience in product, wellness or healthcare company preferred Evidenced proﬁciency in skills listed by at 3 months experience in each:Python, SQL, git, and common data science and machine learning libraries (pandas, sklearn, etc.)Understanding of data visualization best practices, proﬁcient with BI Platforms (Looker, Tableau)This role offers a remote and/or hybrid work environment, but we would prefer candidates located in the NYC and NJ area.Salary Range: $115,000 to $120,000 + equity & benefits. The base pay is one component of Nanit's total compensation package, which may also include access to healthcare benefits, a 401(k) plan, short-term and long-term disability coverage, and basic life insurance. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About ZeppZepp (NYSE: ZEPP) is one of the world’s largest smart wearable technology companies. With Zepp’s proven AI algorithms, massive data sets and analytical capabilities, global distribution channels, and demonstrated success launching international products in the health tech space, the Global Engineering team in Vancouver plays a vital role in our aggressive global market-share expansion strategy.The Ideal Candidate: We are looking for a Data Scientist to join our team developing the next generation of algorithms to measure and understand the health of the human body, more importantly, provide actionable guidance to users to improve their well-being. The ideal candidate should have industry experience, specializing in algorithms, data science, deep learning or signal processing. With an advanced degree in Data Science/Electrical Engineering/Applied Science/Computer Science/Biomedical Engineering/Physiology/Sleep Science or Sport Science, the successful candidate will be a creative problem-solver and fast learner, with a passion for applying research and designing impactful products. The Role: the Data Scientist for Zepp Health will work with our global R&D team (US, Canada, and Beijing) to push the limits of healthcare applications with wearable devices and sensors. This role has a particular emphasis on applied machine learning, where you will have the opportunity to experiment and adapt state-of-the-art architectures to high impact problems in human health that can be deployed across millions of devices. Responsibilities include:Use machine learning and state-of-the-art deep learning to research and model physiological dataDesign for deployment across multiple platforms: cloud, mobile, and wearable devicesAssist in designing and implementing experiments to collect data from company product and prototypesQualifications/Requirements:M.S. or PhD in Data Science/Electrical Engineering/Applied Physics/Biomedical Engineering/Computer ScienceAt least 2 years of industry experience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlyZepp Health is an Equal Opportunity employer and welcomes everyone to our team. If you need reasonable accommodation at any point in the application or interview process, please let us know. In your application, please feel free to note which pronouns you use (for example: she/her/hers, he/him/his, they/them/theirs, etc).\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Data Scientist , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job RequirementsM.S. or PhD in Data Science/Electrical Engineering/Computer ScienceExperience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlySpecial Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Company DescriptionWho We Are...Based in sunny San Diego, Perfect Snacks is the company behind The Original Refrigerated Protein Bar. Offering a line of products that boast whole food ingredients and clean food credentials, Perfect Snacks is sold online and in more than 35,000 retailers nationwide. Now more than a decade since its inception, the brand has experienced rapid growth in the last few years, as consumers flock to the fridge for fresher options. Our success is attributed to the people behind the brand, who share in our family's mission: 'To nourish worldkind with a hug, good vibes and a delicious dose of fresh whole food nutrition. To us, that’s the recipe to make life a little more, well, perfect.'Who Are We Looking For...The Data Scientist will support the Sales Operations team, as well as the broader organization, with a focus on effective data management, optimization, and cohesive reporting. This will require frequent coordination and collaboration with both internal & external team members.Job DescriptionEssential Duties:Primary database developer – design and build SQL database to house all data necessary to populate internal revenue and forecast reporting. Lead project to replicate best in class customer reporting currently in place (UNFI, KEHE, WFM) for additional customers:Walmart, Sam’s, Target, etc. (some currently provided by brokers)Be the company expert on Power BI, report availability and manage distribution of reportsMaintain current PowerBI dashboards - UNFI, KeHE, WFMLead project to automate refresh of daily revenue reportingOwn Power BI reporting of syndicated data (Nielsen, Spins) – maintain/refresh monthly current reporting, make modifications and develop new reporting as neededAid in the implementation and management of new Demand Planning system with a focus on integration into NetSuite ERP systemAssist in development of new Power BI trade/net sales/P&LAccepts responsibility for the organizational goals by taking ownership of new and different duties and identifying new opportunities within the Sales Operations team. Lead effort to gather and systematically organize customer/distributor specific data reports (WFM, Dora’s, Dot, Etc.) QualificationsSkills / Qualification / Education:Bachelor’s degree and +7 years in CPG or related field preferred with focus on business intelligenceExpert level knowledge of SQL, writing queries, developing databases, etc. Experience using Microsoft Stack (Outlook, Excel, Power BI, etc.)Experience using data visualization tools (i.e. Power BI, Tableau)Ability to manage multiple projects and deadlines simultaneouslyHigh attention to detail and passion for data integrityAbility to work across multiple data sources to provide a holistic perspectiveAbility to influence decision making across multiple levels and functions of an organization to drive resultsExcellent organizational skills and time management abilitiesAbility to make decisions and work with little supervisionAbility to work under pressure and balance multiple tasksAdditional InformationCompensation: $90-100k/ Year (DOE)Bonus / Benefits / Vacation / 401k EligibleThis role can be remote, however aplicant must live in the United StatesGot what it takes to join the Perfect Snacks family? We want to hear from you!We will only consider candidates who provide a resume and answer the below questions: Why do you want to join the Perfect Snacks family/brand? What excites you about this role? Where are you located?www.perfectsnacks.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Our client, one of the top 5 Employers in DFW, is seeking to add a Data Scientist / Data Analyst to their growing team. BECOME A PART OF HEALTHCARE IMPROVEMENT, using your strong analytical skills!HYBRID - EXTREMELY FLEXIBLE REMOTE SCHEDULE!!! EXCELLENT OPPORTUNITY to use your FINANCIAL ANALYSIS BACKGROUND in SUPPORT OF IMPROVING PATIENT HEALTHCARE!What you will do:Conduct program or project analysis using statistical techniques to prove or disprove efficacy of the projects, tying in sources from the EMR, Supply Chain, Finance, Patient Experience, and third-party sources.Create Analytical and forecasting studies for C-Level Executives.With minimal guidance, manipulates and joins data from multiple sources into population set for comparative analysis using a SQL or No-SQL tool approaches.Deliver actionable insights with data to propose operational or process changes.Identify key driver of desired outcomes both known and unknown at the start of the analysis. Explain the analysis to key stakeholdersDelivers presentations to upper leadership on findings through graphical displays, and ability to tell the story through data and examples.Here’s What You NeedEducationBachelor's Degree Statistics, Data Science, Finance, Engineering, Information Technology, or equivalent (required) ANDMaster's Degree Statistics, Data Science, Finance, Engineering, Information Technology, or equivalent. Will accept additional experience in lieu a Master's degree.Experience2 Years with a Bachelor's degree: 2 years in analytics - Financial or Healthcare Industry.With a Master's degree: Financial Modeling and Analysis.Experience working in healthcare or related field preferredSkills Strong Analytical Skills and ability to provide solutions through data analysis. Experience with Financial Modeling. Experience with any Visualization software - Power BI, Tableau, Cognos, Excel. Exceptional communication skills to develop and present dashboards.EXCELLENT BENEFITS, LONG-TERM GROWTH POTENTIAL, HEALTHCARE INDUSTRY, APPLY TODAY!For immediate consideration send your resume to: cmartinez@r2now.com\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"It ProfessionalsGrowing AI dvlpmt co seeks Data Scientists (NLP) [50] w/ base pay $130,450-$170K/yr. Deg'd/exp'd In-house FT great compens/benefitsSend resume to AppZen, San Jose, CA 50@AppZen.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title: Data ScientistLocation: 100% remoteDuration: 18 monthsJob DescriptionThe Microsoft Mixed Reality team works with big data. You will join the Hololens Product Integrity Group as we outline our next generation data analytics architecture, allowing us to monitor product quality, apply correlation and understanding to device measurements, and deploy new test coverage for the product.ExperienceAn Engineering B.S. with Data Science/Analytics experience, a grounding in statistics and analysis.Skills: JMP, PowerBI/ DAX Formulas, SQL manipulation, regression analysis. Also interesting: R, Python, Tableau or similar graphical reporting tools.Network infrastructure and experience architecting Azure based systems is also a plus.SkillsThis role involves H/W and Software background which allows the measurement of how the network performs.Candidate must be US Citizen or Green card holder.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Role : Data ScientistLocation : Remote (CST)(Contrect)Job DescriptionMandatory Skill : AI Cognitive AgencyManage GCP platform data loads in and out of the platform or within hybrid environmentTake offline models data scientists build and turn them into a real machine learning production systemDevelop and deploy scalable tools and services for our clients to handle machine learning training and inferenceDesign the data pipelines and engineering infrastructure to support internal clients- enterprise machine learning systems at scaleIdentify and evaluate new technologies to improve performance, maintainability, and reliability of our clients' machine learning systemsApply software engineering rigor and best practices to machine learning, including CI/CD, automation, etc.Support model development, with an emphasis on auditability, versioning, and data securityFacilitate the development and deployment of proof-of-concept machine learning systemsCommunication and requirements from various stake holders to build final requirements and track progressQualificationsExperience building end-to-end systems as a GCP Platform Engineer, ML DevOps Engineer, or Data Engineer (or equivalent)MLOps within the enterprise CI/CD process for ML modelsExperience deploying ML APIs in production environments in GCP using GKEExperience in using GCP Vertex AI for ML and BigQueryKnowledge in Terraform and Containers technologiesExperience writing data processing jobs using GCP Dataflow and DataprocExperience setting up ML model monitoring and autoscaling for ML prediction jobsStrong software engineering skills in complex, multi-language systemsFluency in Python and comfort with Linux administrationExperience working with cloud computing and database systems and cloud based various data formats NOSQL/HDFSExperience building custom integrations between cloud-based systems using APIsExperience developing and maintaining ML systems built with open source toolsExperience developing with containers and Kubernetes in cloud computing environmentsFamiliarity with one or more data-oriented workflow orchestration frameworks (KubeFlow, Airflow, Argo, etc.)Ability to translate business needs to technical requirementsStrong understanding of software testing, benchmarking, and continuous integrationExposure to machine learning methodology and best practicesExperience in deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Position: Data ScientistLocation: Elk Grove, CA (Day 1st Onsite)ContractThe data scientist role willUse SQL to access data and build tablesUse topic modeling (or a similar NLP methodology) to process survey commentsUse Tableau to share results of NLP modelingPSRTEK is a reputed technology recruitment and IT staffing brand with a global footprint and an admired client base. As an ideas and innovation powerhouse with a culture of excellence, we bring remarkable expertise and deliver powerfully transformative results.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Are you seeking to grow and enhance your technical career to new heights, in a full-time, W-2 opportunity?What if an organization existed solely for the purpose of investing in YOU, being of service to YOU, showing you how, and supporting you every step of the way?Is a customized and personalized approach to your learning journey, career development, and overall ability to maximize your earning potential important to you?Let’s make it happen – together!What’s In It For YOU:Full Time, W-2 Employment, with Free, Paid 6-8 Week Training in Data Science (an Industry-Proof Technology) at Our HeadquartersComplete and Total Support to Secure and Maintain End-Client Projects, Post TrainingPaid Corporate-Sponsored Housing During Above-Mentioned TrainingRelocation Assistance for Training and All Projects, as NeededCompetitive, Industry-Leading Full Health Benefits (Medical, Dental, Vision)401K Eligibility Post 1 Year with CompanyWork Visa Sponsorship for Foreign NationalsA Chance for Nationwide TravelCompany-sponsored Technical Certifications, as Necessary, per TechnologyLearn to Become a Best-in-Class Engineer, Developer, and ConsultantDevelopment in Proven Soft Skills and Interviewing Skills MethodsAn Expert Technical Engineer Development ProgramProject Deliverable Support, Once on ProjectExposure to a Breadth and Depth of Best-Practice Production Environments, Code Bases, and Tech Stacks with 100s of Industry-Leading End ClientsHelp our end clients across multiple states design, architect, test, deploy, maintain, document, and scale upwardWho We Are:We\\'re a top-tier IT consulting firm, providing best-in-class Data Science solutions for companies across finance, energy, ecomm, logistics, travel, retail, entertainment, auto, and healthcare, specifically for our many end clients, including Microsoft, Google, Johnson and Johnson, Fannie Mae, Walmart, PayPal, T-Mobile, McDonalds, CVS, Verizon, Charter, Nike, Dell, Wells Fargo, Capital One, Charles Schwab, and many more.Yes! This means you, too, will have these types of well-known, industry-leading end-client experiences in your repertoire after coming on board with us!We\\'re a people development firm (that’s mean YOU!). When you join our family, you come to us with the required foundational technical skills, coding ability, educational degree, and general understanding that will serve as a foundation to learning Data Science. We’re then going to mentor, develop, and train you, as mentioned above, to learn Data Science, so you can then provide consultative services to our end clients!Some of Our HighlightsOur Expertise: IT consultative services and quality engineer development through recruiting, hiring, and coaching our consultants (that’s YOU!)Longevity: 25+ years\\' of combined domestic and international experienceDepth: Hundreds of Fortune 1000, 500, and innovative start-up end clients with 1000s of successfully completed and on-going projects across the US, EU, and UKGlobal: Employee work force is diverse, spanning across 4 continents of North America, Europe, South America, and AsiaGrowth and Innovation: Active monitoring and measurement of the market across all technological sectors to adapt to and implement what\\'s \"next”How We Will Help YouTeach and Develop: We will instruct and train you in Data Science to become a best-in-class consultant through our proven method and program, capable of delivering end-client deliverables, in our paid, 6-8-week training courseCustom Support: Several teams ready to collaborate with you in a custom-tailored way: Development Managers, Tech Subject Manager Experts, Project Deliverable Support, Teachers, Interview Coaches, Client Placement Specialists, Immigration Specialists (for our foreign national candidates)Project Placement: Personalized market-expertise team to enable your ability to secure and maintain a project with our myriad end clientsCareer Growth: We will help you gain the necessary industry experience to drive and propel your technical profession forwardWhat You Bring to the RoleMaster\\'s degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, PhD is preferred. Alternatively, Bachelor’s Degree with at least 2 years’ experience as a Data Analyst, Data Scientist, or Research Assistant6+ years of experience working in a corporate environment within ITStrong Proficiency in Python or Java programming language, or expertise with functional/object- oriented programmingAbility to translate objectives to a project plan with milestones, and resource/technology requirements, and teach, lead, and manage projects/people/clients to successful executionAbility to work across multiple engagements with clients to assess needs, provide assistance, and resolve problems, using structured problem solving and communication to both technical and non- technical audiencesAvailability to travel (80% after Training portion) and live in the U.SStrong English written and verbal communication skillsNice-to-Have:Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environmentExperience in machine learning, artificial intelligence and/or artificial neural networksProficiency in applying various mathematical and statistical models to include, but not limited to: discrete event simulation, factor analysis, genetic algorithms, Bayesian probability models, hidden Markov models, sensitivity analysis, sampling, probability, multivariate data analysis, regression, PCA, time-series analysisBroad understanding of databases (e.g. SQL, NoSQL, Lucene, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, and/or Hive)Experience with visualization software (Tableau, D3, MicroStrategy, PowerBI)Experience delivering solutions in an Agile environmentExperience with Tensorflow, Theano or KerasPortfolio of public & private data science projects you’re proud of (GitHub, Kaggle, DrivenData, etc.)Publications in peer-reviewed journalsOther programming languages such as Scala, Java, RGet to Know Us Our blog and testimonials speak for themselves, they are a great way to get to know us even more and underscore what we can offer you, as well!Instagram: https://www.instagram.com/enhanceitcommunity/ LinkedIn: https://www.linkedin.com/company/enhance-it-com/?viewAsMember=true Website: https://www.enhanceit.com YouTube: https://www.youtube.com/channel/UCYBe7WrZ8lM3MJInS1ZczvQ Facebook: https://www.facebook.com/enhanceitcommunity\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Allozymes is a deep tech company based in Singapore. We are revolutionising the way industry uses enzymes for manufacturing chemicals and natural compounds. Our rapid discovery and evolution of custom-designed enzymes enables breakthrough developments for sustainable production of ingredients for pharmaceuticals, cosmetics, chemical, food and beverages.We’re hiring a highly capable Machine Learning Engineer into our Data team. This team is responsible for developing and implementing state-of-the-art approaches for evolving enzymes and microbes to enhance the production of chemicals and natural compounds. The engineer will integrate the development of our cloud-based artificial intelligence platform for enhancing Allozymes’ enzyme optimization capabilities. Working in a highly collaborative and dynamic environment, this role has the opportunity to interact with other scientists, automation and process engineers to achieve these goals. Responsibilities:Contribute to the design and improvement of Allozymes cloud-based AI platform.Scope project requirements, assess data quality, process data and perform feature engineering.Build, train and deploy ML/DL models, using state-of-the-art technologies and proprietary data to accurately perform predictions and generate new, high performing, enzymes.Perform model evaluation and statistical analysis to improve model quality.Enhance the performance and deployment environment of implemented solutions.Qualifications:MS or PhD in mathematics, statistics, computer science, engineering or a related quantitative field with a focus on AI and Machine Learning.2+ years of relevant industry experience.Expertise in building, training and deploying Machine and Deep Learning models.Proficiency in Python.Expertise in using ML/DS specific python libraries (Pandas, Numpy, Scipy, Scikit-learn, PyTorch, Keras).Experience with ML life-cycle management and code/data version control tools.Familiarity working with Cloud computing.Ability to work in a fast-paced, collaborative and cross-functional environment and communicate results effectively to management.Experience with supervised and unsupervised learning algorithms, clustering, feature selection methods, evaluation, dimensionality reduction, Bayesian inference, hyper-parameter tuning and model optimization is a plusExperience with Language models, Encoders, Transformers, Attention, Generative models and GANs is a plusExperience in biology, bioinformatics or computational biology.Experience using AWS/SageMaker is a plusExperience with containers and container orchestration tools is a plusExperience writing production-ready code (version-controlled, scalable, well-documented, testable, deployment-ready) is a plusNumber of Vacancies: 1\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and that to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Ideal candidate traits🧠 Previously scaled ML systems to 1M + users📑 Willing to go deep in the weeds on research & development⚙️ Cares a Ton About How Backend Systems Work💨 Has worked on large systems but executes like a startup, fast, ships and iteratesPowered by JazzHRkSUPOAkuhD\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"About the Role:We are looking for a highly analytical, data obsessed Data Scientist to join our growing company. The ideal candidate will work cross functionally to develop, maintain and implement predictive models that will provide actionable insights to inform key business decisions. This role will sit within our Product Team and report to our Senior Director, Product Analytics.What you'll be doing:Think critically and leverage data to test and iterate on new product features and business strategiesDeﬁne and implement client usage, churn, retention, and other key metricsBuild and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scaleQuery databases from multiple marketing and product sources and create usable KPI dashboardsSetup analytical framework for user journeys and lifecycle marketing funnelsStatistical modeling:Support business objectives through statistical modeling through the prediction of main KPIs such as churn, retention and LTVDesign, implement and maintain machine learning models to automate and optimize marketing, operations, and customer experienceA/B testing and causal modelingCommunication & Teamwork:Collaborate with stakeholders across the companyFull-stack data science analysis and present insights to both the data science team and internal company stakeholders. Minimum Qualifications:Bachelor's degree in computer science, mathematics, data science, engineering or a closely related field2+ years as a Data Scientist (Business Intelligence) involving data extraction, analysis, and statistical modelingExcellent problem solving skills with keen attention to detail Ability to communicate complex data insights to both technical and non-technical audience, including senior leadership Experience in product, wellness or healthcare company preferred Evidenced proﬁciency in skills listed by at 3 months experience in each:Python, SQL, git, and common data science and machine learning libraries (pandas, sklearn, etc.)Understanding of data visualization best practices, proﬁcient with BI Platforms (Looker, Tableau)This role offers a remote and/or hybrid work environment, but we would prefer candidates located in the NYC and NJ area.Salary Range: $115,000 to $120,000 + equity & benefits. The base pay is one component of Nanit's total compensation package, which may also include access to healthcare benefits, a 401(k) plan, short-term and long-term disability coverage, and basic life insurance. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Entry Level Data Scientist with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Data Scientist , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job RequirementsM.S. or PhD in Data Science/Electrical Engineering/Computer ScienceExperience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlySpecial Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Entry Level Data Scientist with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionWho We Are...Based in sunny San Diego, Perfect Snacks is the company behind The Original Refrigerated Protein Bar. Offering a line of products that boast whole food ingredients and clean food credentials, Perfect Snacks is sold online and in more than 35,000 retailers nationwide. Now more than a decade since its inception, the brand has experienced rapid growth in the last few years, as consumers flock to the fridge for fresher options. Our success is attributed to the people behind the brand, who share in our family's mission: 'To nourish worldkind with a hug, good vibes and a delicious dose of fresh whole food nutrition. To us, that’s the recipe to make life a little more, well, perfect.'Who Are We Looking For...The Data Scientist will support the Sales Operations team, as well as the broader organization, with a focus on effective data management, optimization, and cohesive reporting. This will require frequent coordination and collaboration with both internal & external team members.Job DescriptionEssential Duties:Primary database developer – design and build SQL database to house all data necessary to populate internal revenue and forecast reporting. Lead project to replicate best in class customer reporting currently in place (UNFI, KEHE, WFM) for additional customers:Walmart, Sam’s, Target, etc. (some currently provided by brokers)Be the company expert on Power BI, report availability and manage distribution of reportsMaintain current PowerBI dashboards - UNFI, KeHE, WFMLead project to automate refresh of daily revenue reportingOwn Power BI reporting of syndicated data (Nielsen, Spins) – maintain/refresh monthly current reporting, make modifications and develop new reporting as neededAid in the implementation and management of new Demand Planning system with a focus on integration into NetSuite ERP systemAssist in development of new Power BI trade/net sales/P&LAccepts responsibility for the organizational goals by taking ownership of new and different duties and identifying new opportunities within the Sales Operations team. Lead effort to gather and systematically organize customer/distributor specific data reports (WFM, Dora’s, Dot, Etc.) QualificationsSkills / Qualification / Education:Bachelor’s degree and +7 years in CPG or related field preferred with focus on business intelligenceExpert level knowledge of SQL, writing queries, developing databases, etc. Experience using Microsoft Stack (Outlook, Excel, Power BI, etc.)Experience using data visualization tools (i.e. Power BI, Tableau)Ability to manage multiple projects and deadlines simultaneouslyHigh attention to detail and passion for data integrityAbility to work across multiple data sources to provide a holistic perspectiveAbility to influence decision making across multiple levels and functions of an organization to drive resultsExcellent organizational skills and time management abilitiesAbility to make decisions and work with little supervisionAbility to work under pressure and balance multiple tasksAdditional InformationCompensation: $90-100k/ Year (DOE)Bonus / Benefits / Vacation / 401k EligibleThis role can be remote, however aplicant must live in the United StatesGot what it takes to join the Perfect Snacks family? We want to hear from you!We will only consider candidates who provide a resume and answer the below questions: Why do you want to join the Perfect Snacks family/brand? What excites you about this role? Where are you located?www.perfectsnacks.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Position: Data ScientistLocation: Elk Grove, CA (Day 1st Onsite)ContractThe data scientist role willUse SQL to access data and build tablesUse topic modeling (or a similar NLP methodology) to process survey commentsUse Tableau to share results of NLP modelingPSRTEK is a reputed technology recruitment and IT staffing brand with a global footprint and an admired client base. As an ideas and innovation powerhouse with a culture of excellence, we bring remarkable expertise and deliver powerfully transformative results.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role is only available for W2 or 1099 individual.  100% Remote WorkLocation: Remote anywhere in the USContract to Hire our client is adamant about finding a long term fit. No difference between contract and FTE,  100% will convert.  Job Description: Our client is currently looking for a Data Scientist. We are working with a Director in the Machine Learning & Data Science in our client's cyber division.Our client hosts a true Big Data environment (Petabytes of data stored, and processing daily upwards of 235 billion market events). You will be tasked with researching and helping construct some of the most important machine learning models that protect our stock and bond markets.Our client is looking to incorporate anomaly detection/data science technology in their cyber environment to identify abnormal behavior.Our client is looking for someone with a great deal of intellectual curiosity, experience in a data science environment, who want to be very hands on and technical (coding and mathematical/research analysis is required).Minimum QualificationsPhD preferred, Master's required Computer Science, Math, Statistics, Physics and/or Electrical Engineering must have the mathematical background to apply mathematical analysis to data and determine relationships4+ years of experience in Data Science, Big Data, AI/Client and/or software/data engineeringExpertise in programming with PythonStrong SQL querying skillsExperience in Big Data environments and in a data science practiceKeen ability to research data and identify relationships (this is 85% of the job)Data science experienceHave worked on building and maintaining Machine Learning modelsExperience with PySpark and PyTorchMust have strong communication skillsPreferred:Coding experience with SparkBig Data engineering experienceAWS experienceExperience executing sophisticated SQL queries for backend, data testing.Powered by JazzHRb8OFsmkPmt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Deep Learning Engineer - (CNN/RNN)AboutTrilogy Innovations is seeking a highly skilled Deep Learning Engineer / CNN Architect to join our team. The successful candidate will be responsible for designing, implementing, and optimizing deep learning models using Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Convolutional Recurrent Neural Networks (RCNN) for various applications such as image recognition, waveform analysis, and natural language processing.Telework: 100% remote supportFull-time (W2) Employment Benefits: Health, vision/dental, life/disability, 401(k) + matchPerks: 100% coverage of professional development, phone/internet reimbursements & bonus programsRequirementsMaster's or Ph.D. degree in Computer Science or related field.5+ years of experience in developing and implementing deep learning models.Strong understanding of Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Convolutional Recurrent Neural Networks (RCNN).Experience working with large datasets.Strong programming skills in Python, TensorFlow, and PyTorch.Experience with VGG16 and EfficientNet is highly desired.Experience working with embedded systems is a plus.ResponsibilitiesDesign, develop, and implement deep learning models using CNN, RNN, and RCNN for various applications.Work with large data sets to preprocess, clean, and prepare data for model training.Create datasets for training and testing.Train machine learning models and validate their accuracy, and deploy validated models into production.Optimize models for performance and accuracy, and fine-tune hyperparameters to achieve optimal results.Stay up to date with the latest developments in deep learning techniques and technology.Provide technical guidance and support to other team members.Why work for Trilogy Innovations?Professional Development Programs for all employeesUp to $150/month towards your phone and internet services per monthReferral Bonus Programs (Employees & Business Development)401(k) with company matchComprehensive medical, vision and dental insurance; life/disability insurance coverageHealth Spending Account (HSA)www.trilogyit.comTrilogy Innovations, Inc. is a minority-owned (8a) and HUBZone certified systems and software engineering company that delivers superior technical solutions across private and public sectors. Since 2010, our talented personnel have successfully provided Innovative IT solutions across government agencies such as the FBI, U.S. Air Force, NASA, Department of Education, Department of Energy, U.S. Coast Guard, SOCOM, and private industries in Oil & Gas, and Land Management Services.Trilogy Innovations, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About Us\\xa0\\xa0DeepLogica is a proprietary AI platform that empowers clients’ existing processes and systems to redefine eCommerce delivery. We utilize machine learning models to accurately predict supply chain events, provide actionable business insights and ultimately enhance the buying experience.\\xa0\\xa0About The Role\\xa0\\xa0We’re looking for a talented Data Scientist who is passionate about data, learning, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\\xa0A varied skill set, creativity, flexibility, and positive team attitude are high priorities. \\xa0Main Responsibilities\\xa0\\xa0In collaboration with the other members of your team and your supervisor you will be in charge or participate in the following activities:\\xa0Collecting, cleaning, and transforming large datasets for downstream processing.\\xa0Design accurate and scalable prediction algorithmsDevelop statistical and machine learning models to extract insights and predictions from data.\\xa0Visualize and present findings to stakeholders in a clear and concise manner.\\xa0Collaborate with cross-functional teams to identify business problems that can be solved using data.\\xa0Design experiments to test hypotheses and improve models.\\xa0Assist Data Engineering team members in building and deploying data pipelines and scalable infrastructure to support data analysis.\\xa0Ensure ethical use of data and compliance with privacy regulations.\\xa0Continuously monitor and evaluate the performance of models and adjusting as needed\\xa0Required Education, Qualifications and Experience\\xa0Bachelors or Masters degree in operations research, computer science, software engineering, or a related field\\xa0\\xa02-3 years of experience in quantitative analytics of data modeling.\\xa0Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)Passionate self-starter, able to prioritize tasks and manage time effectively.\\xa0Ability to take ownership of tasks to ensure high quality and successful on-time completion.\\xa0\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This job was posted by https://www.azjobconnection.gov : For more information, please see: https://www.azjobconnection.gov/jobs/5810394Special InformationThis position is subject to the availability of funding. The incumbent is not eligible for Service Professional non-renewal notice, or Classified Staff layoff or recall status.This position is eligible forhybrid workwhich allows the incumbent to complete their work at both an NAU site, campus, or facilityandat a non-centralized site with or without accommodation; ORThis position is eligible forremote workwhich allows the incumbent to complete their work at a location other than an NAU site, campus, or facility with or without accommodation. The incumbent may occasionally work in a shared site, but primarily will work elsewhere.FEWSION Lab is also hiring for a Postdoctoral Scholar (Job ID 607147),a Software Systems Engineer, Intermediate or Senior (Job ID 607151), and anOpen Rank Research Professor (Job ID 607158).Job DescriptionFlagstaff is not only home to Northern Arizona University but is known as Arizona\\\\'s outdoor playground due to its four-season outdoor recreation opportunities such as skiing, hiking, boating, and off-roading with nearby access to other world-class outdoor destinations such as Utah, the Colorado Rockies, Sonoran Desert, and the Grand Canyon. Employee benefit packages include a 75% discount on in-state tuition for dependents that can be applied at any of the three State universities, a generous defined-benefit pension, and exceptional health insurance plans. The public university system of Arizona provides excellent work-life balance and job security in an inclusive and diverse work environment.NAU currently seeks aData Scientist, Intermediate or Data Scientist, Seniorto join a team of dozens of engineers and scientists leading a large multi-year research project focused on supply chain and critical infrastructure resilience and data science (FEWSION, https://fewsion.us). The work focused on applied research and innovation with both public-serving and commercial use cases.This position is part of a cluster hire that includes software engineering, data science, postdoctoral, graduate research assistant, and research-track faculty positions; please consider applying for multiple positions as appropriate. This position allows negotiable flexibility in work location, with residence in Arizona and in-person work at the NAU campus in Flagstaff on multiple days per month preferred.Data Scientist work involves data science, modeling, data pipeline development, data discovery, supply chain analysis, network analysis, AI/ML modeling, statistical modeling, network modeling, timeseries forecasting, network modeling, and quantitative analysis of supply chains and critical infrastructures using both sensitive and open source data and related scientific workflow development, and documentation, in support of the FEWSION project and (as needed) other research projects in the School of Informatics Computing and Cyber Systems (SICCS) at NAU. At the senior rank this position will involve technical leadership of a small team of staff and students in the completion of data science tasks. Familiarity with spatio-temporal, remote sensing, and GIS sources open-source computing practices, cloud solutions, HPC, scientific modeling methods, operational AI/ML methods implementation, and security practices for proprietary or sensitive data sources is preferredMinimum QualificationsData Scientist, IntermediateBachelors Degree in computer science, Civil Engineering, Economics, Data Science, Statistics, or a related field, AND2-4 years of research experience; ORAny combination of relevant education and experience may be substituted for the educational requirement on a year-for-year basis Data Scientist, SeniorMaster\\\\'s Degree in Computer Science, Civil Engineering, Economics, Data Science, Statistics, or a related field, AND4-6 years of research experience; ORAny combination of relevant education and experience may be substituted for the educational requirement on a year-for-year basis.Preferred QualificationsData Scientist, IntermediateDemonstrated experience with data analysis, AI/ML, timeseries modeling, GIS, anomaly or change detection, network flow modeling, data visualization, handling sensitive or secure data sources, and scientific writing and communication in the context of supply chain and/or critical infrastructure data.Data Scientist, SeniorDemonstrated experience with data analysis, AI/ML, timeseries modeling, GIS, anomaly or change detection, network flow modeling, data visualization, handling sensitive or secure data sources, and scientific writing and communication in the context of supply chain and/or critical infrastructure data.Demonstrated experience with technical leadership of a small team of staff and students in the\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Junior Data Scientist (Remote) with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and that to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Associate, Data ScienceNew York, United States of AmericaWhat You Will Be DoingUSA Job Function Description:Designs and monitors control systems which ensure the integrity and security of data and for advising on the optimal use of the organization's computing resources.Assesses the completeness, accuracy, validity and efficiency of information processing, business and application systems, reviews the operations, systems software, systems development and security of the organization's computing environment, and recommends appropriate software and hardware acquisitions.Essential Functions/Responsibility StatementsTranslates business queries into actionable and commercial insights leveraging unstructured data and statistically robust techniques.Drives cross functional analytics projects from beginning to end: builds relationships with partner teams, frames and structures questions, collects and analyzes data, and summarizes key insights in support of decision making.Works with engineers to evangelize data best practices and implement analytics solutions.Evaluation and discovery of alternative data vendors including ability to quantifiably validate external algorithms and apply insights to commercially driven use cases.Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.Education: Bachelor's Degree or equivalent work experienceWork Experience: 5-9 years ; Data mining/advanced analytics applied to large-scale data-intensive projects.Skills And AbilitiesKnowledge of the principles of machine earning, classification models, time series regression and stochastic statistics to deliver improved business performanceDemonstrated experience with SQL, R or a comparable programming language (such as Python, SAS, SPSS, or MATLAB)Demonstrated ability to communicate complex concepts.Strong quantitative and problem solving skills with focus hypothesis formulation and testing.Strong evidence of leveraging analytics to drive business results.Strong project management skills.Individually motivated and possess sound judgment, integrity, and a solid work ethic.Diversity & EEO Statements: At Santander, we value and respect differences in our workforce and strive to increase the diversity of our teams. We actively encourage everyone to apply.Santander is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, genetics, disability, age, veteran status or any other characteristic protected by law.Working Conditions: Frequent Minimal physical effort such as sitting, standing and walking. Occasional moving and lifting equipment and furniture is required to support onsite and offsite meeting setup and teardown. Physically capable of lifting up to fifty pounds, able to bend, kneel, climb ladders.Employer Rights: Employer Rights: This job description does not list all of the job duties of the job. You may be asked by your supervisors or managers to perform other duties. You may be evaluated in part based upon your performance of the tasks listed in this job description. The employer has the right to revise this job description at any time. This job description is not a contract for employment and either you or the employer may terminate at any time for any reason.For NYC Job Applicants: The base annual salary range for this position is $41,600-$172,500.The exact compensation may vary based on skills, experience, training, licensure and certifications and location.Masters of Science (MS) EnglishPrimary Location: New York, NY, Madison Ave CorpOther Locations: New York-New YorkOrganization: Banco Santander S.A.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'HiSatyam this side. We do have a new an excellent opportunity for you. This opportunity is a full time onsite position as Data Scientist.  Please have a look at the job description below and let me know if you or someone you know is interested in this role. You can mail me at satyam@extendinfosys.com.Job Title Data ScientistLocation Santa Clara, CAJob Type Full TimeJob DescriptionData Scientist -- Computer Vision Solid knowledge of various Image Filtering, Binary Morphology, Perspective / Affine transformation, Edge Detection, and Tracking. Machine Learning: Regression, Unsupervised Learning, PCA Nice but not necessary to have HDR, Panorama, and deep Learning object detectionThanksSatyam Prajapati | Technical Recruiter| Extend Information SystemsCell: (571) 547-2880Email: satyam@extendinfosys.comAddress: 44258 Mercure Circle, UNIT 102 A, Sterling VA, USA - 20166Web:www.extendinfosys.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Summary This position is located in the Office of Nuclear Reactor Regulation (NRR), Embark Venture Studio (EVS) and Office of Nuclear Material Safety and Safeguards (NMSS), Program Management, Policy Development, and Analysis Staff (PMDA). This position is Bargaining Unit with the National Treasury Employees Union, Chapter 20This position is not subject to Confidential Financial Disclosure reporting requirements. This position is subject to security ownership restriction reporting requirements. Responsibilities The incumbent serves as a Data Scientist with specific technical expertise. Duties include but are not limited to: data mining/data analysis methods (e.g., data cleansing, data management, analytics, visualization, and engineering), modeling (e.g., model selection, training, evaluation, and tuning), mathematics, statistics, and artificial intelligence to collect, analyze, and interpret large datasets. collection and maintenance of data, data analytics, development of methodological approaches, study design, development of data strategies and data policies, and advanced written, verbal, and visual communications of study/analysis output. provides direction and scientific expertise to a wide range of highly complex, highly visible initiatives and projects. leads and/or consults with cross-functional teams to develop data-driven solutions that address NRC's program and business challenges. leverages data visualization tools (e.g., Tableau, Power BI) to visualize and analyze data in support of metrics, trend analysis, and other reports and projects. utilizes scripting languages (such as JavaScript, Java, Python) to create predictive models to drive data-driven decision-making and automate existing processes. analyzes management information requirements to develop program or administrative reporting systems including the systems specifications, data gathering and analytical techniques, and systems evaluation methodology. leads the development and implementation of mathematical, and/or statistical (e.g., regression, classification, resampling, statistical tests, and proper usage) techniques and concepts that are applicable to data management, analysis, regulatory issues, and program oversight, including understanding the issues and limitations of these techniques. Requirements Conditions of Employment U.S. Citizenship Required This is a Drug Testing position. Background investigation leading to a clearance is required for new hires. To ensure compliance with an applicable preliminary nationwide injunction, which may be supplemented, modified, or vacated, depending on the course of ongoing litigation, the NRC will take no action to implement or enforce the COVID-19 vaccination requirement pursuant to Executive Order 14043 on Requiring Coronavirus Disease 2019 Vaccination for Federal Employees. Therefore, to the extent that an NRC job announcement includes the requirement that applicants must be fully vaccinated against COVID-19 pursuant to Executive Order 14043, that requirement does not currently apply. You must meet the qualifications for this position by no later than 30 calendar days after the closing date of this announcement and before placement in the position. Qualifications The ideal candidate will be able to demonstrate the following:Demonstrated knowledge of and experience in developing data analytics/science related products (e.g. machine learning, natural language processing, robotics process automation, and artificial intelligence) and applied programming or data manipulation with a programing language (e.g., Python; R; SQL; or equivalent) to analyze large volumes of data to build and enhance products, processes, and systems. Demonstrated knowledge and experience in identifying problematic issues and reporting discrepancies and providing appropriate recommendations to leadership.Demonstrated ability to establish and maintain effective work relationships with peers, management, and personnel of other U.S. government agencies, equivalent industry organizations, or international organizations.Demonstrated ability to effectively communicate technical information both orally and in writing.Knowledge of regulatory programs, policies, guidance, and support activities. In order to qualify for this position, you must have at least one year of specialized experience at the next lower grade level in the Federal service or equivalent experience in the private or public sector. SPECIALIZED EXPERIENCE is defined as experience performing data acquisition, data cleansing, and data visualization with tools such as Tableau and Power BI; having familiarity with data discovery to take an unknown data set and extract meaning; possessing effective software development skills and understanding scripting languages; and exhibiting excellent skills related to written and oral communications, organization, problem solving, and the ability to work independently and collaboratively in a team environment. A description of how you possess the specialized experience as well as how you meet the qualifications desired in an ideal candidate must be addressed in your resume. Education Basic Requirements: Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. or Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience. Additional Information The duty location of this position is Rockville, MD. In general, employees are expected to be in the office at a minimum of 4 days per pay period**. Telework schedules, including full-time telework, are approved, on a case-by-case basis. If selected, telework will be determined in accordance with Agency policy and the Collective Bargaining Agreement, if applicable.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About the Role:We are looking for a highly analytical, data obsessed Data Scientist to join our growing company. The ideal candidate will work cross functionally to develop, maintain and implement predictive models that will provide actionable insights to inform key business decisions. This role will sit within our Product Team and report to our Senior Director, Product Analytics.What you'll be doing:Think critically and leverage data to test and iterate on new product features and business strategiesDeﬁne and implement client usage, churn, retention, and other key metricsBuild and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scaleQuery databases from multiple marketing and product sources and create usable KPI dashboardsSetup analytical framework for user journeys and lifecycle marketing funnelsStatistical modeling:Support business objectives through statistical modeling through the prediction of main KPIs such as churn, retention and LTVDesign, implement and maintain machine learning models to automate and optimize marketing, operations, and customer experienceA/B testing and causal modelingCommunication & Teamwork:Collaborate with stakeholders across the companyFull-stack data science analysis and present insights to both the data science team and internal company stakeholders. Minimum Qualifications:Bachelor's degree in computer science, mathematics, data science, engineering or a closely related field2+ years as a Data Scientist (Business Intelligence) involving data extraction, analysis, and statistical modelingExcellent problem solving skills with keen attention to detail Ability to communicate complex data insights to both technical and non-technical audience, including senior leadership Experience in product, wellness or healthcare company preferred Evidenced proﬁciency in skills listed by at 3 months experience in each:Python, SQL, git, and common data science and machine learning libraries (pandas, sklearn, etc.)Understanding of data visualization best practices, proﬁcient with BI Platforms (Looker, Tableau)This role offers a remote and/or hybrid work environment, but we would prefer candidates located in the NYC and NJ area.Salary Range: $115,000 to $120,000 + equity & benefits. The base pay is one component of Nanit's total compensation package, which may also include access to healthcare benefits, a 401(k) plan, short-term and long-term disability coverage, and basic life insurance. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Map Employment Opportunities Login Dayton, OH, USA 75000-110000 Salary Full TimeSURVICE Engineering offers a total rewards package to include competitive salaries, comprehensive insurance options, paid time off, 401k, profit sharing, flexible spending, tuition reimbursement.Email Me Similar JobsEmail Me This JobJoin Us in Making a Difference in the Lives of Those Defending Our Nation!Why SURVICE?Come join the SURVICE Engineering mission to protect, enhance, and enable those who defend the United States. Since 1981, we have supported the DoD community, as well as Homeland Security, advanced technologies, environmental, and commercial markets. Our employees have backgrounds in engineering, physics, mathematics, chemistry, computer science, acquisition, technical writing, training, and other technical and administrative fields. And many of our personnel have DoD and/or operational military experience. If you're looking for a challenging and rewarding career with a leading organization, come see what we can offer you!PositionData Scientist Location:Dayton, Ohio Security Clearance:Active Clearance or Eligible to Obtain -U.S. citizenship required Salary: $75,000 - $110,000 Travel:Up to 10% Benefits:SURVICE Engineering offers a total rewards package to include competitive salaries, comprehensive insurance options, paid time off, 401k, profit sharing, flexible spending, tuition reimbursement.Position SummarySURVICE Engineeringis currently seeking aData Scientistto support several Air Force Research Laboratory (AFRL) programs. You will accelerate your career and become an integral team member within the defense community.Primary Duties And Responsibilities Develop quantitative and qualitative data analysis and reporting of patterns, insights, discriminators, and trends to decision-makers Collect, aggregate, standardize and analyze data from multiple internal and external sources to drive insights into military utility performance Produce actionable reports that show key performance discriminators, quantify areas of uncertainty, and identify areas of improvement into current operations Use analytics and metrics to improve Concept of Employments (CONEMPS) as well as Tactics, Training, and Procedures (TTPs)Minimum Qualifications Bachelor's Degree in social science or technical field of study and 3-5+ years of relevant experience. Exceptional candidates with less experience will be considered. Candidates are not required to possess all qualifications; if you possess some of the desired qualifications, please apply.Desired Experience Strong analytical, inference, critical thinking, and creative problem-solving skills Strong communication and writing skills Practical knowledge of Department of Defense (DoD) aircraft and weapon systems Experience drawing qualitative insights and manipulating quantitative data (using Excel, Python, MATLAB, R, or similar data analysis tool) Experience with data science and visualization tools, such as R Shiny/RStudio, Tableau, JMP/JMP Pro, and/or similar Demonstrated ability to work independently and in a small team environment Demonstrated ability to participate in small, dynamic teams and deliver products exceeding customer expectationsAbout UsSURVICE Engineering is a nationally recognized, single-source engineering service provider for Government and Industry organizations involved in all phases of the systems engineering process. Our employees are our most valuable asset, and they are proud to have supported the development, testing, analysis, and modeling and simulation (M&S) of many of the major U.S. air, land, and sea combat systems in the field today. They have also contributed their expertise to other vital national defense programs and technologies that involve survivability, cybersecurity, information technology/management, software engineering, unmanned aerial systems (UASs), and metrology/reverse engineering.SURVICE is subject to Executive Order 14042 (Ensuring Adequate COVID Safety Protocols for Federal Contractors and Subcontractors) and the applicable Safer Federal Workforce Taskforce Guidance. Therefore, continued employment will be contingent upon compliance with these requirements in the event they become enforceable.SURVICE Engineering is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. VEVRAA Federal Contractor.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionWho We Are...Based in sunny San Diego, Perfect Snacks is the company behind The Original Refrigerated Protein Bar. Offering a line of products that boast whole food ingredients and clean food credentials, Perfect Snacks is sold online and in more than 35,000 retailers nationwide. Now more than a decade since its inception, the brand has experienced rapid growth in the last few years, as consumers flock to the fridge for fresher options. Our success is attributed to the people behind the brand, who share in our family's mission: 'To nourish worldkind with a hug, good vibes and a delicious dose of fresh whole food nutrition. To us, that’s the recipe to make life a little more, well, perfect.'Who Are We Looking For...The Data Scientist will support the Sales Operations team, as well as the broader organization, with a focus on effective data management, optimization, and cohesive reporting. This will require frequent coordination and collaboration with both internal & external team members.Job DescriptionEssential Duties:Primary database developer – design and build SQL database to house all data necessary to populate internal revenue and forecast reporting. Lead project to replicate best in class customer reporting currently in place (UNFI, KEHE, WFM) for additional customers:Walmart, Sam’s, Target, etc. (some currently provided by brokers)Be the company expert on Power BI, report availability and manage distribution of reportsMaintain current PowerBI dashboards - UNFI, KeHE, WFMLead project to automate refresh of daily revenue reportingOwn Power BI reporting of syndicated data (Nielsen, Spins) – maintain/refresh monthly current reporting, make modifications and develop new reporting as neededAid in the implementation and management of new Demand Planning system with a focus on integration into NetSuite ERP systemAssist in development of new Power BI trade/net sales/P&LAccepts responsibility for the organizational goals by taking ownership of new and different duties and identifying new opportunities within the Sales Operations team. Lead effort to gather and systematically organize customer/distributor specific data reports (WFM, Dora’s, Dot, Etc.) QualificationsSkills / Qualification / Education:Bachelor’s degree and +7 years in CPG or related field preferred with focus on business intelligenceExpert level knowledge of SQL, writing queries, developing databases, etc. Experience using Microsoft Stack (Outlook, Excel, Power BI, etc.)Experience using data visualization tools (i.e. Power BI, Tableau)Ability to manage multiple projects and deadlines simultaneouslyHigh attention to detail and passion for data integrityAbility to work across multiple data sources to provide a holistic perspectiveAbility to influence decision making across multiple levels and functions of an organization to drive resultsExcellent organizational skills and time management abilitiesAbility to make decisions and work with little supervisionAbility to work under pressure and balance multiple tasksAdditional InformationCompensation: $90-100k/ Year (DOE)Bonus / Benefits / Vacation / 401k EligibleThis role can be remote, however aplicant must live in the United StatesGot what it takes to join the Perfect Snacks family? We want to hear from you!We will only consider candidates who provide a resume and answer the below questions: Why do you want to join the Perfect Snacks family/brand? What excites you about this role? Where are you located?www.perfectsnacks.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Our client, one of the top 5 Employers in DFW, is seeking to add a Data Scientist / Data Analyst to their growing team. BECOME A PART OF HEALTHCARE IMPROVEMENT, using your strong analytical skills!HYBRID - EXTREMELY FLEXIBLE REMOTE SCHEDULE!!! EXCELLENT OPPORTUNITY to use your FINANCIAL ANALYSIS BACKGROUND in SUPPORT OF IMPROVING PATIENT HEALTHCARE!What you will do:Conduct program or project analysis using statistical techniques to prove or disprove efficacy of the projects, tying in sources from the EMR, Supply Chain, Finance, Patient Experience, and third-party sources.Create Analytical and forecasting studies for C-Level Executives.With minimal guidance, manipulates and joins data from multiple sources into population set for comparative analysis using a SQL or No-SQL tool approaches.Deliver actionable insights with data to propose operational or process changes.Identify key driver of desired outcomes both known and unknown at the start of the analysis. Explain the analysis to key stakeholdersDelivers presentations to upper leadership on findings through graphical displays, and ability to tell the story through data and examples.Here’s What You NeedEducationBachelor's Degree Statistics, Data Science, Finance, Engineering, Information Technology, or equivalent (required) ANDMaster's Degree Statistics, Data Science, Finance, Engineering, Information Technology, or equivalent. Will accept additional experience in lieu a Master's degree.Experience2 Years with a Bachelor's degree: 2 years in analytics - Financial or Healthcare Industry.With a Master's degree: Financial Modeling and Analysis.Experience working in healthcare or related field preferredSkills Strong Analytical Skills and ability to provide solutions through data analysis. Experience with Financial Modeling. Experience with any Visualization software - Power BI, Tableau, Cognos, Excel. Exceptional communication skills to develop and present dashboards.EXCELLENT BENEFITS, LONG-TERM GROWTH POTENTIAL, HEALTHCARE INDUSTRY, APPLY TODAY!For immediate consideration send your resume to: cmartinez@r2now.com\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"It ProfessionalsGrowing AI dvlpmt co seeks Data Scientists (NLP) [50] w/ base pay $130,450-$170K/yr. Deg'd/exp'd In-house FT great compens/benefitsSend resume to AppZen, San Jose, CA 50@AppZen.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title: Data ScientistLocation: 100% remoteDuration: 18 monthsJob DescriptionThe Microsoft Mixed Reality team works with big data. You will join the Hololens Product Integrity Group as we outline our next generation data analytics architecture, allowing us to monitor product quality, apply correlation and understanding to device measurements, and deploy new test coverage for the product.ExperienceAn Engineering B.S. with Data Science/Analytics experience, a grounding in statistics and analysis.Skills: JMP, PowerBI/ DAX Formulas, SQL manipulation, regression analysis. Also interesting: R, Python, Tableau or similar graphical reporting tools.Network infrastructure and experience architecting Azure based systems is also a plus.SkillsThis role involves H/W and Software background which allows the measurement of how the network performs.Candidate must be US Citizen or Green card holder.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Role : Data ScientistLocation : Remote (CST)(Contrect)Job DescriptionMandatory Skill : AI Cognitive AgencyManage GCP platform data loads in and out of the platform or within hybrid environmentTake offline models data scientists build and turn them into a real machine learning production systemDevelop and deploy scalable tools and services for our clients to handle machine learning training and inferenceDesign the data pipelines and engineering infrastructure to support internal clients- enterprise machine learning systems at scaleIdentify and evaluate new technologies to improve performance, maintainability, and reliability of our clients' machine learning systemsApply software engineering rigor and best practices to machine learning, including CI/CD, automation, etc.Support model development, with an emphasis on auditability, versioning, and data securityFacilitate the development and deployment of proof-of-concept machine learning systemsCommunication and requirements from various stake holders to build final requirements and track progressQualificationsExperience building end-to-end systems as a GCP Platform Engineer, ML DevOps Engineer, or Data Engineer (or equivalent)MLOps within the enterprise CI/CD process for ML modelsExperience deploying ML APIs in production environments in GCP using GKEExperience in using GCP Vertex AI for ML and BigQueryKnowledge in Terraform and Containers technologiesExperience writing data processing jobs using GCP Dataflow and DataprocExperience setting up ML model monitoring and autoscaling for ML prediction jobsStrong software engineering skills in complex, multi-language systemsFluency in Python and comfort with Linux administrationExperience working with cloud computing and database systems and cloud based various data formats NOSQL/HDFSExperience building custom integrations between cloud-based systems using APIsExperience developing and maintaining ML systems built with open source toolsExperience developing with containers and Kubernetes in cloud computing environmentsFamiliarity with one or more data-oriented workflow orchestration frameworks (KubeFlow, Airflow, Argo, etc.)Ability to translate business needs to technical requirementsStrong understanding of software testing, benchmarking, and continuous integrationExposure to machine learning methodology and best practicesExperience in deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Position: Data ScientistLocation: Elk Grove, CA (Day 1st Onsite)ContractThe data scientist role willUse SQL to access data and build tablesUse topic modeling (or a similar NLP methodology) to process survey commentsUse Tableau to share results of NLP modelingPSRTEK is a reputed technology recruitment and IT staffing brand with a global footprint and an admired client base. As an ideas and innovation powerhouse with a culture of excellence, we bring remarkable expertise and deliver powerfully transformative results.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Mission:VerAI is committed to accelerating the global zero-carbon transformation by discovering the minerals essential for our sustainable future. In the last two decades, the minerals exploration industry underperforms with a very low rate of discovery success, failing to supply the massive demand for these critical commodities. We are disrupting the Mineral Exploration Industry by deploying a revolutionary Artificial Intelligence Platform that detects concealed mineral deposits. The world awaits a revolutionary change, and the unique conditions we have created for success allow VerAI to lead a vital paradigm shift in the way mineral discoveries are made.We are well funded by strong financial and strategic investors, including funds and accounts advised by T. Rowe Price Associates, Inc., Orion Resources Partners, a global mineral asset management firm; Chrysalix Capital, which specializes in transformation industrial innovation, mining and its direct contribution to the global Clean Energy transition; and Blumberg Capital, which brings extensive experience in successfully applying AI solutions to different verticals and industries. www.ver-ai.comOur Culture: Why work with us?Our most valuable resource is our people--with a diversity of backgrounds, ideas, opinions, and life experiences. We have built a multidisciplinary and multicultural environment. We admire people who have original thinking and sound judgment. We hire outcome-oriented people who are comfortable with uncertainty. Our culture is filled with people who are positive, passionate, constructive, and success-oriented. Our employees are willing – and enjoy- expanding outside their comfort zones.Our leaders are transparent, accessible, authentic, and invest in their employees. There’s a dedication to one another that’s palpable. We are not your typical 100-hour-a-week grinding start-up. We believe in allowing our employees to have flexible hours and giving them the time needed to balance family/hobbies and work.We are a remote-only US-based company and are currently deploying our AI Minerals Targeting Platform in the Americas.What’s in it for you:Innovation: You will be provided with an amazing opportunity to work on state-of-the-art ML/AI technologies in a company that truly believes in innovation and continuous improvement. We take pride in our technology, and in leveraging this technology to disrupt the Mineral Exploration world. The challenge of finding minerals undercover is real and very hard – and you will have the opportunity to be part of the team that solves it!Influence: You will have a huge influence on how data science is done at VerAI, and you will help pave the way for future generations of our AI-based mineral discovery technology. Your experience and knowledge will impact everything from our developer environment, algorithms, cloud infrastructure, data visualization and so much more.Positive global impact: You will work on a product that has a direct positive impact on the world. Every pipeline improvement and mineral deposit we help find brings us one small step closer to a fossil fuel-free world.Salary range: $150,000-$170,000/yrLocation: Home-based, remote-only (At this time only seeking Colorado residents)Benefits: We offer excellent benefits: Unlimited PTO, Health and Dental Insurance, 401K Match, Stock Options, and more!A day in the life of this role:As our Data Scientist, you will play a crucial role in designing, developing, and implementing the VerAI AI/ML Mineral Targeting Platform. This Platform is at the core of our innovation, and a critical part of our ability to generate high-quality AI Targets that represent the location of concealed economic mineral deposits.You will assume full accountability for operating the Targeting Platform and will have a lot of freedom to continuously improve and enhance its capabilities. Your passion is being hands-on, but also designing and planning different aspects of our Machine Learning pipeline. You love collaborating with different teams and domains and are not afraid of getting your hands dirty with new data sets, technologies, or methodologies.You will help VerAI maintain a technological leadership in its domain and will represent us in the different data science communities and forums.What we need from you:Bachelor’s degree in computer science, applied mathematics, statistics, electrical engineering, or a related quantitative discipline.4+ years of relevant hands-on experience in Machine Learning/Statistical Analytics/Predictive Analytics in the image processing and analysis domain.Excellent understanding of machine learning techniques, algorithms, and methodologies.Extensive experience in Python programming language.Extensive experience with data science frameworks (NumPy, scikit-learn, Pandas, Keras, etc.)Experience with using and administrating cloud infrastructure and web services like AWSAttributes that will make you successful at VerAI:You are trustworthy, responsible, independent, take ownership, and delivers results.You have unquestionable integrity, credibility, and character. You have demonstrated high moral and ethical behavior.You are willing to embrace challenges, and you are comfortable with uncertainty and complex decision-making.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'About Us\\xa0\\xa0DeepLogica is a proprietary AI platform that empowers clients’ existing processes and systems to redefine eCommerce delivery. We utilize machine learning models to accurately predict supply chain events, provide actionable business insights and ultimately enhance the buying experience.\\xa0\\xa0About The Role\\xa0\\xa0We’re looking for a talented Data Scientist who is passionate about data, learning, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\\xa0A varied skill set, creativity, flexibility, and positive team attitude are high priorities. \\xa0Main Responsibilities\\xa0\\xa0In collaboration with the other members of your team and your supervisor you will be in charge or participate in the following activities:\\xa0Collecting, cleaning, and transforming large datasets for downstream processing.\\xa0Design accurate and scalable prediction algorithmsDevelop statistical and machine learning models to extract insights and predictions from data.\\xa0Visualize and present findings to stakeholders in a clear and concise manner.\\xa0Collaborate with cross-functional teams to identify business problems that can be solved using data.\\xa0Design experiments to test hypotheses and improve models.\\xa0Assist Data Engineering team members in building and deploying data pipelines and scalable infrastructure to support data analysis.\\xa0Ensure ethical use of data and compliance with privacy regulations.\\xa0Continuously monitor and evaluate the performance of models and adjusting as needed\\xa0Required Education, Qualifications and Experience\\xa0Bachelors or Masters degree in operations research, computer science, software engineering, or a related field\\xa0\\xa02-3 years of experience in quantitative analytics of data modeling.\\xa0Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)Passionate self-starter, able to prioritize tasks and manage time effectively.\\xa0Ability to take ownership of tasks to ensure high quality and successful on-time completion.\\xa0\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Are you seeking to grow and enhance your technical career to new heights, in a full-time, W-2 opportunity?What if an organization existed solely for the purpose of investing in YOU, being of service to YOU, showing you how, and supporting you every step of the way?Is a customized and personalized approach to your learning journey, career development, and overall ability to maximize your earning potential important to you?Let’s make it happen – together!What’s In It For YOU:Full Time, W-2 Employment, with Free, Paid 6-8 Week Training in Data Science (an Industry-Proof Technology) at Our HeadquartersComplete and Total Support to Secure and Maintain End-Client Projects, Post TrainingPaid Corporate-Sponsored Housing During Above-Mentioned TrainingRelocation Assistance for Training and All Projects, as NeededCompetitive, Industry-Leading Full Health Benefits (Medical, Dental, Vision)401K Eligibility Post 1 Year with CompanyWork Visa Sponsorship for Foreign NationalsA Chance for Nationwide TravelCompany-sponsored Technical Certifications, as Necessary, per TechnologyLearn to Become a Best-in-Class Engineer, Developer, and ConsultantDevelopment in Proven Soft Skills and Interviewing Skills MethodsAn Expert Technical Engineer Development ProgramProject Deliverable Support, Once on ProjectExposure to a Breadth and Depth of Best-Practice Production Environments, Code Bases, and Tech Stacks with 100s of Industry-Leading End ClientsHelp our end clients across multiple states design, architect, test, deploy, maintain, document, and scale upwardWho We Are:We\\'re a top-tier IT consulting firm, providing best-in-class Data Science solutions for companies across finance, energy, ecomm, logistics, travel, retail, entertainment, auto, and healthcare, specifically for our many end clients, including Microsoft, Google, Johnson and Johnson, Fannie Mae, Walmart, PayPal, T-Mobile, McDonalds, CVS, Verizon, Charter, Nike, Dell, Wells Fargo, Capital One, Charles Schwab, and many more.Yes! This means you, too, will have these types of well-known, industry-leading end-client experiences in your repertoire after coming on board with us!We\\'re a people development firm (that’s mean YOU!). When you join our family, you come to us with the required foundational technical skills, coding ability, educational degree, and general understanding that will serve as a foundation to learning Data Science. We’re then going to mentor, develop, and train you, as mentioned above, to learn Data Science, so you can then provide consultative services to our end clients!Some of Our HighlightsOur Expertise: IT consultative services and quality engineer development through recruiting, hiring, and coaching our consultants (that’s YOU!)Longevity: 25+ years\\' of combined domestic and international experienceDepth: Hundreds of Fortune 1000, 500, and innovative start-up end clients with 1000s of successfully completed and on-going projects across the US, EU, and UKGlobal: Employee work force is diverse, spanning across 4 continents of North America, Europe, South America, and AsiaGrowth and Innovation: Active monitoring and measurement of the market across all technological sectors to adapt to and implement what\\'s \"next”How We Will Help YouTeach and Develop: We will instruct and train you in Data Science to become a best-in-class consultant through our proven method and program, capable of delivering end-client deliverables, in our paid, 6-8-week training courseCustom Support: Several teams ready to collaborate with you in a custom-tailored way: Development Managers, Tech Subject Manager Experts, Project Deliverable Support, Teachers, Interview Coaches, Client Placement Specialists, Immigration Specialists (for our foreign national candidates)Project Placement: Personalized market-expertise team to enable your ability to secure and maintain a project with our myriad end clientsCareer Growth: We will help you gain the necessary industry experience to drive and propel your technical profession forwardWhat You Bring to the RoleMaster\\'s degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, PhD is preferred. Alternatively, Bachelor’s Degree with at least 2 years’ experience as a Data Analyst, Data Scientist, or Research Assistant6+ years of experience working in a corporate environment within ITStrong Proficiency in Python or Java programming language, or expertise with functional/object- oriented programmingAbility to translate objectives to a project plan with milestones, and resource/technology requirements, and teach, lead, and manage projects/people/clients to successful executionAbility to work across multiple engagements with clients to assess needs, provide assistance, and resolve problems, using structured problem solving and communication to both technical and non- technical audiencesAvailability to travel (80% after Training portion) and live in the U.SStrong English written and verbal communication skillsNice-to-Have:Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environmentExperience in machine learning, artificial intelligence and/or artificial neural networksProficiency in applying various mathematical and statistical models to include, but not limited to: discrete event simulation, factor analysis, genetic algorithms, Bayesian probability models, hidden Markov models, sensitivity analysis, sampling, probability, multivariate data analysis, regression, PCA, time-series analysisBroad understanding of databases (e.g. SQL, NoSQL, Lucene, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, and/or Hive)Experience with visualization software (Tableau, D3, MicroStrategy, PowerBI)Experience delivering solutions in an Agile environmentExperience with Tensorflow, Theano or KerasPortfolio of public & private data science projects you’re proud of (GitHub, Kaggle, DrivenData, etc.)Publications in peer-reviewed journalsOther programming languages such as Scala, Java, RGet to Know Us Our blog and testimonials speak for themselves, they are a great way to get to know us even more and underscore what we can offer you, as well!Instagram: https://www.instagram.com/enhanceitcommunity/ LinkedIn: https://www.linkedin.com/company/enhance-it-com/?viewAsMember=true Website: https://www.enhanceit.com YouTube: https://www.youtube.com/channel/UCYBe7WrZ8lM3MJInS1ZczvQ Facebook: https://www.facebook.com/enhanceitcommunity\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role is only available for W2 or 1099 individual.  100% Remote WorkLocation: Remote anywhere in the USContract to Hire our client is adamant about finding a long term fit. No difference between contract and FTE,  100% will convert.  Job Description: Our client is currently looking for a Data Scientist. We are working with a Director in the Machine Learning & Data Science in our client's cyber division.Our client hosts a true Big Data environment (Petabytes of data stored, and processing daily upwards of 235 billion market events). You will be tasked with researching and helping construct some of the most important machine learning models that protect our stock and bond markets.Our client is looking to incorporate anomaly detection/data science technology in their cyber environment to identify abnormal behavior.Our client is looking for someone with a great deal of intellectual curiosity, experience in a data science environment, who want to be very hands on and technical (coding and mathematical/research analysis is required).Minimum QualificationsPhD preferred, Master's required Computer Science, Math, Statistics, Physics and/or Electrical Engineering must have the mathematical background to apply mathematical analysis to data and determine relationships4+ years of experience in Data Science, Big Data, AI/Client and/or software/data engineeringExpertise in programming with PythonStrong SQL querying skillsExperience in Big Data environments and in a data science practiceKeen ability to research data and identify relationships (this is 85% of the job)Data science experienceHave worked on building and maintaining Machine Learning modelsExperience with PySpark and PyTorchMust have strong communication skillsPreferred:Coding experience with SparkBig Data engineering experienceAWS experienceExperience executing sophisticated SQL queries for backend, data testing.Powered by JazzHRb8OFsmkPmt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Allozymes is a deep tech company based in Singapore. We are revolutionising the way industry uses enzymes for manufacturing chemicals and natural compounds. Our rapid discovery and evolution of custom-designed enzymes enables breakthrough developments for sustainable production of ingredients for pharmaceuticals, cosmetics, chemical, food and beverages.We’re hiring a highly capable Machine Learning Engineer into our Data team. This team is responsible for developing and implementing state-of-the-art approaches for evolving enzymes and microbes to enhance the production of chemicals and natural compounds. The engineer will integrate the development of our cloud-based artificial intelligence platform for enhancing Allozymes’ enzyme optimization capabilities. Working in a highly collaborative and dynamic environment, this role has the opportunity to interact with other scientists, automation and process engineers to achieve these goals. Responsibilities:Contribute to the design and improvement of Allozymes cloud-based AI platform.Scope project requirements, assess data quality, process data and perform feature engineering.Build, train and deploy ML/DL models, using state-of-the-art technologies and proprietary data to accurately perform predictions and generate new, high performing, enzymes.Perform model evaluation and statistical analysis to improve model quality.Enhance the performance and deployment environment of implemented solutions.Qualifications:MS or PhD in mathematics, statistics, computer science, engineering or a related quantitative field with a focus on AI and Machine Learning.2+ years of relevant industry experience.Expertise in building, training and deploying Machine and Deep Learning models.Proficiency in Python.Expertise in using ML/DS specific python libraries (Pandas, Numpy, Scipy, Scikit-learn, PyTorch, Keras).Experience with ML life-cycle management and code/data version control tools.Familiarity working with Cloud computing.Ability to work in a fast-paced, collaborative and cross-functional environment and communicate results effectively to management.Experience with supervised and unsupervised learning algorithms, clustering, feature selection methods, evaluation, dimensionality reduction, Bayesian inference, hyper-parameter tuning and model optimization is a plusExperience with Language models, Encoders, Transformers, Attention, Generative models and GANs is a plusExperience in biology, bioinformatics or computational biology.Experience using AWS/SageMaker is a plusExperience with containers and container orchestration tools is a plusExperience writing production-ready code (version-controlled, scalable, well-documented, testable, deployment-ready) is a plusNumber of Vacancies: 1\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and that to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Ideal candidate traits🧠 Previously scaled ML systems to 1M + users📑 Willing to go deep in the weeds on research & development⚙️ Cares a Ton About How Backend Systems Work💨 Has worked on large systems but executes like a startup, fast, ships and iteratesPowered by JazzHRkSUPOAkuhD\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Entry Level Data Scientist with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'You’ll be the founding data scientist in a well-funded company looking to define Web 3 user identity and attribution.We plan on running a lean team: expect to totally own your area of responsibility and use your initiative and judgement to keep your part of Spindl running and growing.Be comfortable with being uncomfortable. You will be creating the metrics and methodologies that will define an entire industry within Web 3. There won’t be easy answers for most of what we do. We’re already making it up as we go along.Speed is a feature, in teams, products, and people: keep up with the Spindl pack. There isn’t a moment to lose.We’re looking for pirates now that Web 2 has become the navy.ResponsibilitiesBe a leader within a very flat and fast-moving teamUnderstand the often weird and hacked-together blockchain world, as well as the embryonic data stack being built on top of itNavigate the idea maze toward Truth (or something like it)Plot the critical curve or generate the essential dashboard that helps us understand Web 3. Creatively address business problems when there are no precedents and no clear answersWork with engineering to implement your findings and models into running product quickly. You are mapping the unknown terrain; we want to turn that into industry knowledge ASAP. Empathize with our customers, understand their worldview, and work with the UI team to translate your insights into customer insights. Convey your findings to colleagues; tell a story with data convincingly. Optionally, publish your work publicly will full credit. Must haves (this is an AND)N years doing data science or analysis (for reasonable N). Proficiency with data visualization and dashboarding tools like Looker or Tableau. Think those suck? Tell us why. Ideally, this would involve more than just descriptive dashboarding and extend into some predictive model-building around complicated ecosystems like markets or user behavior online. Experience with modeling in Python: Jupyter, Pandas, PyTorch, numpy, scipy, etc. Exception to the above: Outstanding familiarity with blockchains and protocols and their often quirky data, along with extensive experience in environments like Dune or Flipside, can compensate for a lack of more traditional data science experience. If you’re the #3 person on the Dune leaderboard, let’s talk. Be smart and get shit done. Be a doer and a risk-taker. Nice to haves (this is an OR)Experience with advertising technology or campaign management within Web 2 adsExperience with A/B testing and experimentationExperience in anti-fraud, either within ad tech or fin tech. There are lots of bad guys to block in Web 3. LocationYou can be located anywhere in the world, but we have a strong preference for SF or NYC. If you’re not in either city, expect some travel to work face-to-face with colleagues on a semi-regular basis. If you’re in one of those cities, you’ll find a balance between coming into the office and not. We think in-person work possesses a magic for early stage startups, something unobtainable in a fully remote environment where co-workers are simply images on a screen.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Our client, one of the top 5 Employers in DFW, is seeking to add a Data Scientist / Data Analyst to their growing team. BECOME A PART OF HEALTHCARE IMPROVEMENT, using your strong analytical skills!HYBRID - EXTREMELY FLEXIBLE REMOTE SCHEDULE!!! EXCELLENT OPPORTUNITY to use your FINANCIAL ANALYSIS BACKGROUND in SUPPORT OF IMPROVING PATIENT HEALTHCARE!What you will do:Conduct program or project analysis using statistical techniques to prove or disprove efficacy of the projects, tying in sources from the EMR, Supply Chain, Finance, Patient Experience, and third-party sources.Create Analytical and forecasting studies for C-Level Executives.With minimal guidance, manipulates and joins data from multiple sources into population set for comparative analysis using a SQL or No-SQL tool approaches.Deliver actionable insights with data to propose operational or process changes.Identify key driver of desired outcomes both known and unknown at the start of the analysis. Explain the analysis to key stakeholdersDelivers presentations to upper leadership on findings through graphical displays, and ability to tell the story through data and examples.Here’s What You NeedEducationBachelor's Degree Statistics, Data Science, Finance, Engineering, Information Technology, or equivalent (required) ANDMaster's Degree Statistics, Data Science, Finance, Engineering, Information Technology, or equivalent. Will accept additional experience in lieu a Master's degree.Experience2 Years with a Bachelor's degree: 2 years in analytics - Financial or Healthcare Industry.With a Master's degree: Financial Modeling and Analysis.Experience working in healthcare or related field preferredSkills Strong Analytical Skills and ability to provide solutions through data analysis. Experience with Financial Modeling. Experience with any Visualization software - Power BI, Tableau, Cognos, Excel. Exceptional communication skills to develop and present dashboards.EXCELLENT BENEFITS, LONG-TERM GROWTH POTENTIAL, HEALTHCARE INDUSTRY, APPLY TODAY!For immediate consideration send your resume to: cmartinez@r2now.com\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Role : Data ScientistLocation : Remote (CST)(Contrect)Job DescriptionMandatory Skill : AI Cognitive AgencyManage GCP platform data loads in and out of the platform or within hybrid environmentTake offline models data scientists build and turn them into a real machine learning production systemDevelop and deploy scalable tools and services for our clients to handle machine learning training and inferenceDesign the data pipelines and engineering infrastructure to support internal clients- enterprise machine learning systems at scaleIdentify and evaluate new technologies to improve performance, maintainability, and reliability of our clients' machine learning systemsApply software engineering rigor and best practices to machine learning, including CI/CD, automation, etc.Support model development, with an emphasis on auditability, versioning, and data securityFacilitate the development and deployment of proof-of-concept machine learning systemsCommunication and requirements from various stake holders to build final requirements and track progressQualificationsExperience building end-to-end systems as a GCP Platform Engineer, ML DevOps Engineer, or Data Engineer (or equivalent)MLOps within the enterprise CI/CD process for ML modelsExperience deploying ML APIs in production environments in GCP using GKEExperience in using GCP Vertex AI for ML and BigQueryKnowledge in Terraform and Containers technologiesExperience writing data processing jobs using GCP Dataflow and DataprocExperience setting up ML model monitoring and autoscaling for ML prediction jobsStrong software engineering skills in complex, multi-language systemsFluency in Python and comfort with Linux administrationExperience working with cloud computing and database systems and cloud based various data formats NOSQL/HDFSExperience building custom integrations between cloud-based systems using APIsExperience developing and maintaining ML systems built with open source toolsExperience developing with containers and Kubernetes in cloud computing environmentsFamiliarity with one or more data-oriented workflow orchestration frameworks (KubeFlow, Airflow, Argo, etc.)Ability to translate business needs to technical requirementsStrong understanding of software testing, benchmarking, and continuous integrationExposure to machine learning methodology and best practicesExperience in deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Position: Data ScientistLocation: Elk Grove, CA (Day 1st Onsite)ContractThe data scientist role willUse SQL to access data and build tablesUse topic modeling (or a similar NLP methodology) to process survey commentsUse Tableau to share results of NLP modelingPSRTEK is a reputed technology recruitment and IT staffing brand with a global footprint and an admired client base. As an ideas and innovation powerhouse with a culture of excellence, we bring remarkable expertise and deliver powerfully transformative results.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Mission:VerAI is committed to accelerating the global zero-carbon transformation by discovering the minerals essential for our sustainable future. In the last two decades, the minerals exploration industry underperforms with a very low rate of discovery success, failing to supply the massive demand for these critical commodities. We are disrupting the Mineral Exploration Industry by deploying a revolutionary Artificial Intelligence Platform that detects concealed mineral deposits. The world awaits a revolutionary change, and the unique conditions we have created for success allow VerAI to lead a vital paradigm shift in the way mineral discoveries are made.We are well funded by strong financial and strategic investors, including funds and accounts advised by T. Rowe Price Associates, Inc., Orion Resources Partners, a global mineral asset management firm; Chrysalix Capital, which specializes in transformation industrial innovation, mining and its direct contribution to the global Clean Energy transition; and Blumberg Capital, which brings extensive experience in successfully applying AI solutions to different verticals and industries. www.ver-ai.comOur Culture: Why work with us?Our most valuable resource is our people--with a diversity of backgrounds, ideas, opinions, and life experiences. We have built a multidisciplinary and multicultural environment. We admire people who have original thinking and sound judgment. We hire outcome-oriented people who are comfortable with uncertainty. Our culture is filled with people who are positive, passionate, constructive, and success-oriented. Our employees are willing – and enjoy- expanding outside their comfort zones.Our leaders are transparent, accessible, authentic, and invest in their employees. There’s a dedication to one another that’s palpable. We are not your typical 100-hour-a-week grinding start-up. We believe in allowing our employees to have flexible hours and giving them the time needed to balance family/hobbies and work.We are a remote-only US-based company and are currently deploying our AI Minerals Targeting Platform in the Americas.What’s in it for you:Innovation: You will be provided with an amazing opportunity to work on state-of-the-art ML/AI technologies in a company that truly believes in innovation and continuous improvement. We take pride in our technology, and in leveraging this technology to disrupt the Mineral Exploration world. The challenge of finding minerals undercover is real and very hard – and you will have the opportunity to be part of the team that solves it!Influence: You will have a huge influence on how data science is done at VerAI, and you will help pave the way for future generations of our AI-based mineral discovery technology. Your experience and knowledge will impact everything from our developer environment, algorithms, cloud infrastructure, data visualization and so much more.Positive global impact: You will work on a product that has a direct positive impact on the world. Every pipeline improvement and mineral deposit we help find brings us one small step closer to a fossil fuel-free world.Salary range: $150,000-$170,000/yrLocation: Home-based, remote-only (At this time only seeking Colorado residents)Benefits: We offer excellent benefits: Unlimited PTO, Health and Dental Insurance, 401K Match, Stock Options, and more!A day in the life of this role:As our Data Scientist, you will play a crucial role in designing, developing, and implementing the VerAI AI/ML Mineral Targeting Platform. This Platform is at the core of our innovation, and a critical part of our ability to generate high-quality AI Targets that represent the location of concealed economic mineral deposits.You will assume full accountability for operating the Targeting Platform and will have a lot of freedom to continuously improve and enhance its capabilities. Your passion is being hands-on, but also designing and planning different aspects of our Machine Learning pipeline. You love collaborating with different teams and domains and are not afraid of getting your hands dirty with new data sets, technologies, or methodologies.You will help VerAI maintain a technological leadership in its domain and will represent us in the different data science communities and forums.What we need from you:Bachelor’s degree in computer science, applied mathematics, statistics, electrical engineering, or a related quantitative discipline.4+ years of relevant hands-on experience in Machine Learning/Statistical Analytics/Predictive Analytics in the image processing and analysis domain.Excellent understanding of machine learning techniques, algorithms, and methodologies.Extensive experience in Python programming language.Extensive experience with data science frameworks (NumPy, scikit-learn, Pandas, Keras, etc.)Experience with using and administrating cloud infrastructure and web services like AWSAttributes that will make you successful at VerAI:You are trustworthy, responsible, independent, take ownership, and delivers results.You have unquestionable integrity, credibility, and character. You have demonstrated high moral and ethical behavior.You are willing to embrace challenges, and you are comfortable with uncertainty and complex decision-making.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role is only available for W2 or 1099 individual.  100% Remote WorkLocation: Remote anywhere in the USContract to Hire our client is adamant about finding a long term fit. No difference between contract and FTE,  100% will convert.  Job Description: Our client is currently looking for a Data Scientist. We are working with a Director in the Machine Learning & Data Science in our client's cyber division.Our client hosts a true Big Data environment (Petabytes of data stored, and processing daily upwards of 235 billion market events). You will be tasked with researching and helping construct some of the most important machine learning models that protect our stock and bond markets.Our client is looking to incorporate anomaly detection/data science technology in their cyber environment to identify abnormal behavior.Our client is looking for someone with a great deal of intellectual curiosity, experience in a data science environment, who want to be very hands on and technical (coding and mathematical/research analysis is required).Minimum QualificationsPhD preferred, Master's required Computer Science, Math, Statistics, Physics and/or Electrical Engineering must have the mathematical background to apply mathematical analysis to data and determine relationships4+ years of experience in Data Science, Big Data, AI/Client and/or software/data engineeringExpertise in programming with PythonStrong SQL querying skillsExperience in Big Data environments and in a data science practiceKeen ability to research data and identify relationships (this is 85% of the job)Data science experienceHave worked on building and maintaining Machine Learning modelsExperience with PySpark and PyTorchMust have strong communication skillsPreferred:Coding experience with SparkBig Data engineering experienceAWS experienceExperience executing sophisticated SQL queries for backend, data testing.Powered by JazzHRb8OFsmkPmt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"PacArctic,LLC, a Koniag Government Services company, is seeking an experienced Jr Data Scientist with a Secret Clearance to support PAC and our government customer in Washington, DC.We offer competitive compensation and an extraordinary benefits package including health, dental and vision insurance, 401K with company matching, flexible spending accounts, paid holidays, three weeks paid time off, and more.Essential Functions, Responsibilities & Duties may include, but are not limited to: Support research, analysis, and tracking OBO's HR function milestones and metrics. Using data collected in the study, assist the government to identify findings and recommendations of this assessment that will streamline the customer's functions/products, maximize efficiencies, and provide a concrete structural blueprint for the delivery of HR services in a cost-effective manner that optimizes the customer's long and short-term service goals. Recommendations as needed for project data visualizations. Support the government to analyze the data collected outputs throughout the different methodologies. Support data analysis and development of data sets for functional and performance analytics; turning data into value for IT solutions. Create data visualizations to communicate IT findings which enhance business functions. Support a wide variety of analytical techniques used to determine and communicate trends and patterns, fill gaps in information and project events, identify anomalies, ascribe meaning to events or information from disparate sources, and develop defensible judgments and conclusions based on accepted research and analytical methodologies.Work Experience, Knowledge, Skills & Abilities Able to obtain and maintain a Top-Secret clearance. Experience in statistical analysis and data mining Knowledgeable in Eclipse IDE, PyCharm, Java, Rstudio, Microsoft SQL, Python Knowledge of data management concepts, principles, and methods for database logical and physical design, development, and maintenance of information management systems. Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Highly developed oral and written communication skills required to present findings or translate the data into an understandable document. Must be skilled and able to prepare and present highly complex matters, material, and/or issues to others. Bachelor's degree in data science strongly preferred. Two years of professional experience required.Working Environment & ConditionsThis job operates in a professional office environment and has a noise level of mostly low to moderate. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines. This position is primarily indoors, consistent with a standard office position and has a noise level of mostly low to moderate. The incumbent is required to stand, walk; sit; use hands to finger, handle, or feel objects, tools, or controls; reach with hands and arms; talk and hear. The workload may require the incumbent to sit for extended periods of time. The incumbent must be able to read, do simple math calculations and withstand moderate amounts of stress. The incumbent must occasionally lift and/or move up to 25 lbs. Specific vision abilities required by the job include close vision, distance vision, color vision, depth perception, and the ability to adjust focus.Our Equal Employment Opportunity PolicyThe company is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, sex, sexual orientation, gender, or gender identity (except where gender is a bona fide occupational qualification), national origin, age, disability, military/veteran status, marital status, genetic information, or any other factor protected by law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits and all other privileges, terms, and conditions of employment.The company is dedicated to seeking all qualified applicants. If you require accommodation to navigate or to apply for a position on our website, please contact Heaven Wood via e-mail at accommodations@koniag-gs.com or by calling 703-488-9377 to request accommodation.Koniag Government Services (KGS) is an Alaska Native Owned corporation supporting the values and traditions of our native communities through an agile employee and corporate culture that delivers Enterprise Solutions, Professional Services and Operational Management to Federal Government Agencies. As a wholly owned subsidiary of Koniag, we apply our proven commercial solutions to a deep knowledge of Defense and Civilian missions to provide forward leaning technical, professional, and operational solutions. KGS enables successful mission outcomes for our customers through solution-oriented business partnerships and a commitment to exceptional service delivery. We ensure long-term success with a continuous improvement approach while balancing the collective interests of our customers, employees, and native communities. For more information, please visit www.koniag-gs.com.Equal Opportunity Employer/Veterans/Disabled. Shareholder Preference in accordance with Public Law 88-352\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Are you seeking to grow and enhance your technical career to new heights, in a full-time, W-2 opportunity?What if an organization existed solely for the purpose of investing in YOU, being of service to YOU, showing you how, and supporting you every step of the way?Is a customized and personalized approach to your learning journey, career development, and overall ability to maximize your earning potential important to you?Let’s make it happen – together!What’s In It For YOU:Full Time, W-2 Employment, with Free, Paid 6-8 Week Training in Data Science (an Industry-Proof Technology) at Our HeadquartersComplete and Total Support to Secure and Maintain End-Client Projects, Post TrainingPaid Corporate-Sponsored Housing During Above-Mentioned TrainingRelocation Assistance for Training and All Projects, as NeededCompetitive, Industry-Leading Full Health Benefits (Medical, Dental, Vision)401K Eligibility Post 1 Year with CompanyWork Visa Sponsorship for Foreign NationalsA Chance for Nationwide TravelCompany-sponsored Technical Certifications, as Necessary, per TechnologyLearn to Become a Best-in-Class Engineer, Developer, and ConsultantDevelopment in Proven Soft Skills and Interviewing Skills MethodsAn Expert Technical Engineer Development ProgramProject Deliverable Support, Once on ProjectExposure to a Breadth and Depth of Best-Practice Production Environments, Code Bases, and Tech Stacks with 100s of Industry-Leading End ClientsHelp our end clients across multiple states design, architect, test, deploy, maintain, document, and scale upwardWho We Are:We\\'re a top-tier IT consulting firm, providing best-in-class Data Science solutions for companies across finance, energy, ecomm, logistics, travel, retail, entertainment, auto, and healthcare, specifically for our many end clients, including Microsoft, Google, Johnson and Johnson, Fannie Mae, Walmart, PayPal, T-Mobile, McDonalds, CVS, Verizon, Charter, Nike, Dell, Wells Fargo, Capital One, Charles Schwab, and many more.Yes! This means you, too, will have these types of well-known, industry-leading end-client experiences in your repertoire after coming on board with us!We\\'re a people development firm (that’s mean YOU!). When you join our family, you come to us with the required foundational technical skills, coding ability, educational degree, and general understanding that will serve as a foundation to learning Data Science. We’re then going to mentor, develop, and train you, as mentioned above, to learn Data Science, so you can then provide consultative services to our end clients!Some of Our HighlightsOur Expertise: IT consultative services and quality engineer development through recruiting, hiring, and coaching our consultants (that’s YOU!)Longevity: 25+ years\\' of combined domestic and international experienceDepth: Hundreds of Fortune 1000, 500, and innovative start-up end clients with 1000s of successfully completed and on-going projects across the US, EU, and UKGlobal: Employee work force is diverse, spanning across 4 continents of North America, Europe, South America, and AsiaGrowth and Innovation: Active monitoring and measurement of the market across all technological sectors to adapt to and implement what\\'s \"next”How We Will Help YouTeach and Develop: We will instruct and train you in Data Science to become a best-in-class consultant through our proven method and program, capable of delivering end-client deliverables, in our paid, 6-8-week training courseCustom Support: Several teams ready to collaborate with you in a custom-tailored way: Development Managers, Tech Subject Manager Experts, Project Deliverable Support, Teachers, Interview Coaches, Client Placement Specialists, Immigration Specialists (for our foreign national candidates)Project Placement: Personalized market-expertise team to enable your ability to secure and maintain a project with our myriad end clientsCareer Growth: We will help you gain the necessary industry experience to drive and propel your technical profession forwardWhat You Bring to the RoleMaster\\'s degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, PhD is preferred. Alternatively, Bachelor’s Degree with at least 2 years’ experience as a Data Analyst, Data Scientist, or Research Assistant6+ years of experience working in a corporate environment within ITStrong Proficiency in Python or Java programming language, or expertise with functional/object- oriented programmingAbility to translate objectives to a project plan with milestones, and resource/technology requirements, and teach, lead, and manage projects/people/clients to successful executionAbility to work across multiple engagements with clients to assess needs, provide assistance, and resolve problems, using structured problem solving and communication to both technical and non- technical audiencesAvailability to travel (80% after Training portion) and live in the U.SStrong English written and verbal communication skillsNice-to-Have:Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environmentExperience in machine learning, artificial intelligence and/or artificial neural networksProficiency in applying various mathematical and statistical models to include, but not limited to: discrete event simulation, factor analysis, genetic algorithms, Bayesian probability models, hidden Markov models, sensitivity analysis, sampling, probability, multivariate data analysis, regression, PCA, time-series analysisBroad understanding of databases (e.g. SQL, NoSQL, Lucene, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, and/or Hive)Experience with visualization software (Tableau, D3, MicroStrategy, PowerBI)Experience delivering solutions in an Agile environmentExperience with Tensorflow, Theano or KerasPortfolio of public & private data science projects you’re proud of (GitHub, Kaggle, DrivenData, etc.)Publications in peer-reviewed journalsOther programming languages such as Scala, Java, RGet to Know Us Our blog and testimonials speak for themselves, they are a great way to get to know us even more and underscore what we can offer you, as well!Instagram: https://www.instagram.com/enhanceitcommunity/ LinkedIn: https://www.linkedin.com/company/enhance-it-com/?viewAsMember=true Website: https://www.enhanceit.com YouTube: https://www.youtube.com/channel/UCYBe7WrZ8lM3MJInS1ZczvQ Facebook: https://www.facebook.com/enhanceitcommunity\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Deep Learning Engineer - (CNN/RNN)AboutTrilogy Innovations is seeking a highly skilled Deep Learning Engineer / CNN Architect to join our team. The successful candidate will be responsible for designing, implementing, and optimizing deep learning models using Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Convolutional Recurrent Neural Networks (RCNN) for various applications such as image recognition, waveform analysis, and natural language processing.Telework: 100% remote supportFull-time (W2) Employment Benefits: Health, vision/dental, life/disability, 401(k) + matchPerks: 100% coverage of professional development, phone/internet reimbursements & bonus programsRequirementsMaster's or Ph.D. degree in Computer Science or related field.5+ years of experience in developing and implementing deep learning models.Strong understanding of Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Convolutional Recurrent Neural Networks (RCNN).Experience working with large datasets.Strong programming skills in Python, TensorFlow, and PyTorch.Experience with VGG16 and EfficientNet is highly desired.Experience working with embedded systems is a plus.ResponsibilitiesDesign, develop, and implement deep learning models using CNN, RNN, and RCNN for various applications.Work with large data sets to preprocess, clean, and prepare data for model training.Create datasets for training and testing.Train machine learning models and validate their accuracy, and deploy validated models into production.Optimize models for performance and accuracy, and fine-tune hyperparameters to achieve optimal results.Stay up to date with the latest developments in deep learning techniques and technology.Provide technical guidance and support to other team members.Why work for Trilogy Innovations?Professional Development Programs for all employeesUp to $150/month towards your phone and internet services per monthReferral Bonus Programs (Employees & Business Development)401(k) with company matchComprehensive medical, vision and dental insurance; life/disability insurance coverageHealth Spending Account (HSA)www.trilogyit.comTrilogy Innovations, Inc. is a minority-owned (8a) and HUBZone certified systems and software engineering company that delivers superior technical solutions across private and public sectors. Since 2010, our talented personnel have successfully provided Innovative IT solutions across government agencies such as the FBI, U.S. Air Force, NASA, Department of Education, Department of Energy, U.S. Coast Guard, SOCOM, and private industries in Oil & Gas, and Land Management Services.Trilogy Innovations, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About Us\\xa0\\xa0DeepLogica is a proprietary AI platform that empowers clients’ existing processes and systems to redefine eCommerce delivery. We utilize machine learning models to accurately predict supply chain events, provide actionable business insights and ultimately enhance the buying experience.\\xa0\\xa0About The Role\\xa0\\xa0We’re looking for a talented Data Scientist who is passionate about data, learning, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\\xa0A varied skill set, creativity, flexibility, and positive team attitude are high priorities. \\xa0Main Responsibilities\\xa0\\xa0In collaboration with the other members of your team and your supervisor you will be in charge or participate in the following activities:\\xa0Collecting, cleaning, and transforming large datasets for downstream processing.\\xa0Design accurate and scalable prediction algorithmsDevelop statistical and machine learning models to extract insights and predictions from data.\\xa0Visualize and present findings to stakeholders in a clear and concise manner.\\xa0Collaborate with cross-functional teams to identify business problems that can be solved using data.\\xa0Design experiments to test hypotheses and improve models.\\xa0Assist Data Engineering team members in building and deploying data pipelines and scalable infrastructure to support data analysis.\\xa0Ensure ethical use of data and compliance with privacy regulations.\\xa0Continuously monitor and evaluate the performance of models and adjusting as needed\\xa0Required Education, Qualifications and Experience\\xa0Bachelors or Masters degree in operations research, computer science, software engineering, or a related field\\xa0\\xa02-3 years of experience in quantitative analytics of data modeling.\\xa0Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)Passionate self-starter, able to prioritize tasks and manage time effectively.\\xa0Ability to take ownership of tasks to ensure high quality and successful on-time completion.\\xa0\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Iron EagleX is a veteran owned defense contracting company based in Tampa, FL.It is our mission to provide solutions to the most challenging technical problems facing the Department of Defense while simultaneously making a positive impact on our employees and community.Job DescriptionThe Data Scientist will support the United States Special Operations Command (USSOCOM) Chief Data Office (CDO) and be responsible for designing, implementing, and maintaining a data pipeline. Additionally, the Data Scientist shall interpret and analyze complex sets of data and plan, execute, and manage ML projects with cloud-native platforms and advanced ML solutions. They will leverage multiple methodologies such as data mining, natural language programming, and machine learning.Job Duties Include (but Not Limited To)Interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific methodCoordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the dataExperiment against data points, provide information based on experiment results, and provide previously undiscovered solutions to command data challengesCoordinate with Data Engineers to build data environments providing data identified by other data professionalsApply and develop scientific methodology, statistics, and algorithms to discover and frame relevant problems, hypotheses, and opportunitiesDevelop predictive and prescriptive modeling, natural language processing (NLP), Robotic Process Automation (RPA), text mining and processing, clustering, forecasting methods, and other advanced statistical techniquesDesign and automate processes to facilitate the manipulation and analysis of dataManage and integrate data across dissimilar data sets and analyze large-scale structured and unstructured dataUse frameworks to conduct large-scale data processingPerform statistical modeling and create data visualizations Research, design, and implement algorithms to solve complex problemsProgram using R, Python (NumPy, SciPy, Pandas) or similar analytical languagesPerform data engineering, data processing, and modeling techniques using cloud-based data management, data science, and ML platforms Communicate complex concepts and hypothesis to a non-technical audience through digital storytellingRequired Skills & ExperienceMinimum of 1-year of Data Science experience is required:Proficient with one or more programming languages (Java, C++, Python, R, etc.):Proficient in Agile Development and Git Operations: Demonstrated experience applying data science methods to real-world data problems:MUST BE US CITIZENDesired SkillsExperience working with the Department of DefenseEducation & CertificationsBachelors in Stem field or Master’s Degree in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fields:Security ClearanceActive TS/SCI Clearance is requiredBenefitsNational Health, vision and dental plans20 days of PTO and 11 paid holidaysLife InsuranceShort – and long-term disability plans401(K) retirement planIncentive and recognition programsRelocation opportunitiesIron EagleX is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, among other things, or status as a qualified individual with disability.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This job was posted by https://www.azjobconnection.gov : For more information, please see: https://www.azjobconnection.gov/jobs/5810394Special InformationThis position is subject to the availability of funding. The incumbent is not eligible for Service Professional non-renewal notice, or Classified Staff layoff or recall status.This position is eligible forhybrid workwhich allows the incumbent to complete their work at both an NAU site, campus, or facilityandat a non-centralized site with or without accommodation; ORThis position is eligible forremote workwhich allows the incumbent to complete their work at a location other than an NAU site, campus, or facility with or without accommodation. The incumbent may occasionally work in a shared site, but primarily will work elsewhere.FEWSION Lab is also hiring for a Postdoctoral Scholar (Job ID 607147),a Software Systems Engineer, Intermediate or Senior (Job ID 607151), and anOpen Rank Research Professor (Job ID 607158).Job DescriptionFlagstaff is not only home to Northern Arizona University but is known as Arizona\\\\'s outdoor playground due to its four-season outdoor recreation opportunities such as skiing, hiking, boating, and off-roading with nearby access to other world-class outdoor destinations such as Utah, the Colorado Rockies, Sonoran Desert, and the Grand Canyon. Employee benefit packages include a 75% discount on in-state tuition for dependents that can be applied at any of the three State universities, a generous defined-benefit pension, and exceptional health insurance plans. The public university system of Arizona provides excellent work-life balance and job security in an inclusive and diverse work environment.NAU currently seeks aData Scientist, Intermediate or Data Scientist, Seniorto join a team of dozens of engineers and scientists leading a large multi-year research project focused on supply chain and critical infrastructure resilience and data science (FEWSION, https://fewsion.us). The work focused on applied research and innovation with both public-serving and commercial use cases.This position is part of a cluster hire that includes software engineering, data science, postdoctoral, graduate research assistant, and research-track faculty positions; please consider applying for multiple positions as appropriate. This position allows negotiable flexibility in work location, with residence in Arizona and in-person work at the NAU campus in Flagstaff on multiple days per month preferred.Data Scientist work involves data science, modeling, data pipeline development, data discovery, supply chain analysis, network analysis, AI/ML modeling, statistical modeling, network modeling, timeseries forecasting, network modeling, and quantitative analysis of supply chains and critical infrastructures using both sensitive and open source data and related scientific workflow development, and documentation, in support of the FEWSION project and (as needed) other research projects in the School of Informatics Computing and Cyber Systems (SICCS) at NAU. At the senior rank this position will involve technical leadership of a small team of staff and students in the completion of data science tasks. Familiarity with spatio-temporal, remote sensing, and GIS sources open-source computing practices, cloud solutions, HPC, scientific modeling methods, operational AI/ML methods implementation, and security practices for proprietary or sensitive data sources is preferredMinimum QualificationsData Scientist, IntermediateBachelors Degree in computer science, Civil Engineering, Economics, Data Science, Statistics, or a related field, AND2-4 years of research experience; ORAny combination of relevant education and experience may be substituted for the educational requirement on a year-for-year basis Data Scientist, SeniorMaster\\\\'s Degree in Computer Science, Civil Engineering, Economics, Data Science, Statistics, or a related field, AND4-6 years of research experience; ORAny combination of relevant education and experience may be substituted for the educational requirement on a year-for-year basis.Preferred QualificationsData Scientist, IntermediateDemonstrated experience with data analysis, AI/ML, timeseries modeling, GIS, anomaly or change detection, network flow modeling, data visualization, handling sensitive or secure data sources, and scientific writing and communication in the context of supply chain and/or critical infrastructure data.Data Scientist, SeniorDemonstrated experience with data analysis, AI/ML, timeseries modeling, GIS, anomaly or change detection, network flow modeling, data visualization, handling sensitive or secure data sources, and scientific writing and communication in the context of supply chain and/or critical infrastructure data.Demonstrated experience with technical leadership of a small team of staff and students in the\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Junior Data Scientist (Remote) with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and that to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title: Data ScientistLocation: 100% remoteDuration: 18 monthsJob DescriptionThe Microsoft Mixed Reality team works with big data. You will join the Hololens Product Integrity Group as we outline our next generation data analytics architecture, allowing us to monitor product quality, apply correlation and understanding to device measurements, and deploy new test coverage for the product.ExperienceAn Engineering B.S. with Data Science/Analytics experience, a grounding in statistics and analysis.Skills: JMP, PowerBI/ DAX Formulas, SQL manipulation, regression analysis. Also interesting: R, Python, Tableau or similar graphical reporting tools.Network infrastructure and experience architecting Azure based systems is also a plus.SkillsThis role involves H/W and Software background which allows the measurement of how the network performs.Candidate must be US Citizen or Green card holder.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Role : Data ScientistLocation : Remote (CST)(Contrect)Job DescriptionMandatory Skill : AI Cognitive AgencyManage GCP platform data loads in and out of the platform or within hybrid environmentTake offline models data scientists build and turn them into a real machine learning production systemDevelop and deploy scalable tools and services for our clients to handle machine learning training and inferenceDesign the data pipelines and engineering infrastructure to support internal clients- enterprise machine learning systems at scaleIdentify and evaluate new technologies to improve performance, maintainability, and reliability of our clients' machine learning systemsApply software engineering rigor and best practices to machine learning, including CI/CD, automation, etc.Support model development, with an emphasis on auditability, versioning, and data securityFacilitate the development and deployment of proof-of-concept machine learning systemsCommunication and requirements from various stake holders to build final requirements and track progressQualificationsExperience building end-to-end systems as a GCP Platform Engineer, ML DevOps Engineer, or Data Engineer (or equivalent)MLOps within the enterprise CI/CD process for ML modelsExperience deploying ML APIs in production environments in GCP using GKEExperience in using GCP Vertex AI for ML and BigQueryKnowledge in Terraform and Containers technologiesExperience writing data processing jobs using GCP Dataflow and DataprocExperience setting up ML model monitoring and autoscaling for ML prediction jobsStrong software engineering skills in complex, multi-language systemsFluency in Python and comfort with Linux administrationExperience working with cloud computing and database systems and cloud based various data formats NOSQL/HDFSExperience building custom integrations between cloud-based systems using APIsExperience developing and maintaining ML systems built with open source toolsExperience developing with containers and Kubernetes in cloud computing environmentsFamiliarity with one or more data-oriented workflow orchestration frameworks (KubeFlow, Airflow, Argo, etc.)Ability to translate business needs to technical requirementsStrong understanding of software testing, benchmarking, and continuous integrationExposure to machine learning methodology and best practicesExperience in deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Our Mission:VerAI is committed to accelerating the global zero-carbon transformation by discovering the minerals essential for our sustainable future. In the last two decades, the minerals exploration industry underperforms with a very low rate of discovery success, failing to supply the massive demand for these critical commodities. We are disrupting the Mineral Exploration Industry by deploying a revolutionary Artificial Intelligence Platform that detects concealed mineral deposits. The world awaits a revolutionary change, and the unique conditions we have created for success allow VerAI to lead a vital paradigm shift in the way mineral discoveries are made.We are well funded by strong financial and strategic investors, including funds and accounts advised by T. Rowe Price Associates, Inc., Orion Resources Partners, a global mineral asset management firm; Chrysalix Capital, which specializes in transformation industrial innovation, mining and its direct contribution to the global Clean Energy transition; and Blumberg Capital, which brings extensive experience in successfully applying AI solutions to different verticals and industries. www.ver-ai.comOur Culture: Why work with us?Our most valuable resource is our people--with a diversity of backgrounds, ideas, opinions, and life experiences. We have built a multidisciplinary and multicultural environment. We admire people who have original thinking and sound judgment. We hire outcome-oriented people who are comfortable with uncertainty. Our culture is filled with people who are positive, passionate, constructive, and success-oriented. Our employees are willing – and enjoy- expanding outside their comfort zones.Our leaders are transparent, accessible, authentic, and invest in their employees. There’s a dedication to one another that’s palpable. We are not your typical 100-hour-a-week grinding start-up. We believe in allowing our employees to have flexible hours and giving them the time needed to balance family/hobbies and work.We are a remote-only US-based company and are currently deploying our AI Minerals Targeting Platform in the Americas.What’s in it for you:Innovation: You will be provided with an amazing opportunity to work on state-of-the-art ML/AI technologies in a company that truly believes in innovation and continuous improvement. We take pride in our technology, and in leveraging this technology to disrupt the Mineral Exploration world. The challenge of finding minerals undercover is real and very hard – and you will have the opportunity to be part of the team that solves it!Influence: You will have a huge influence on how data science is done at VerAI, and you will help pave the way for future generations of our AI-based mineral discovery technology. Your experience and knowledge will impact everything from our developer environment, algorithms, cloud infrastructure, data visualization and so much more.Positive global impact: You will work on a product that has a direct positive impact on the world. Every pipeline improvement and mineral deposit we help find brings us one small step closer to a fossil fuel-free world.Salary range: $150,000-$170,000/yrLocation: Home-based, remote-only (At this time only seeking Colorado residents)Benefits: We offer excellent benefits: Unlimited PTO, Health and Dental Insurance, 401K Match, Stock Options, and more!A day in the life of this role:As our Data Scientist, you will play a crucial role in designing, developing, and implementing the VerAI AI/ML Mineral Targeting Platform. This Platform is at the core of our innovation, and a critical part of our ability to generate high-quality AI Targets that represent the location of concealed economic mineral deposits.You will assume full accountability for operating the Targeting Platform and will have a lot of freedom to continuously improve and enhance its capabilities. Your passion is being hands-on, but also designing and planning different aspects of our Machine Learning pipeline. You love collaborating with different teams and domains and are not afraid of getting your hands dirty with new data sets, technologies, or methodologies.You will help VerAI maintain a technological leadership in its domain and will represent us in the different data science communities and forums.What we need from you:Bachelor’s degree in computer science, applied mathematics, statistics, electrical engineering, or a related quantitative discipline.4+ years of relevant hands-on experience in Machine Learning/Statistical Analytics/Predictive Analytics in the image processing and analysis domain.Excellent understanding of machine learning techniques, algorithms, and methodologies.Extensive experience in Python programming language.Extensive experience with data science frameworks (NumPy, scikit-learn, Pandas, Keras, etc.)Experience with using and administrating cloud infrastructure and web services like AWSAttributes that will make you successful at VerAI:You are trustworthy, responsible, independent, take ownership, and delivers results.You have unquestionable integrity, credibility, and character. You have demonstrated high moral and ethical behavior.You are willing to embrace challenges, and you are comfortable with uncertainty and complex decision-making.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Are you seeking to grow and enhance your technical career to new heights, in a full-time, W-2 opportunity?What if an organization existed solely for the purpose of investing in YOU, being of service to YOU, showing you how, and supporting you every step of the way?Is a customized and personalized approach to your learning journey, career development, and overall ability to maximize your earning potential important to you?Let’s make it happen – together!What’s In It For YOU:Full Time, W-2 Employment, with Free, Paid 6-8 Week Training in Data Science (an Industry-Proof Technology) at Our HeadquartersComplete and Total Support to Secure and Maintain End-Client Projects, Post TrainingPaid Corporate-Sponsored Housing During Above-Mentioned TrainingRelocation Assistance for Training and All Projects, as NeededCompetitive, Industry-Leading Full Health Benefits (Medical, Dental, Vision)401K Eligibility Post 1 Year with CompanyWork Visa Sponsorship for Foreign NationalsA Chance for Nationwide TravelCompany-sponsored Technical Certifications, as Necessary, per TechnologyLearn to Become a Best-in-Class Engineer, Developer, and ConsultantDevelopment in Proven Soft Skills and Interviewing Skills MethodsAn Expert Technical Engineer Development ProgramProject Deliverable Support, Once on ProjectExposure to a Breadth and Depth of Best-Practice Production Environments, Code Bases, and Tech Stacks with 100s of Industry-Leading End ClientsHelp our end clients across multiple states design, architect, test, deploy, maintain, document, and scale upwardWho We Are:We\\'re a top-tier IT consulting firm, providing best-in-class Data Science solutions for companies across finance, energy, ecomm, logistics, travel, retail, entertainment, auto, and healthcare, specifically for our many end clients, including Microsoft, Google, Johnson and Johnson, Fannie Mae, Walmart, PayPal, T-Mobile, McDonalds, CVS, Verizon, Charter, Nike, Dell, Wells Fargo, Capital One, Charles Schwab, and many more.Yes! This means you, too, will have these types of well-known, industry-leading end-client experiences in your repertoire after coming on board with us!We\\'re a people development firm (that’s mean YOU!). When you join our family, you come to us with the required foundational technical skills, coding ability, educational degree, and general understanding that will serve as a foundation to learning Data Science. We’re then going to mentor, develop, and train you, as mentioned above, to learn Data Science, so you can then provide consultative services to our end clients!Some of Our HighlightsOur Expertise: IT consultative services and quality engineer development through recruiting, hiring, and coaching our consultants (that’s YOU!)Longevity: 25+ years\\' of combined domestic and international experienceDepth: Hundreds of Fortune 1000, 500, and innovative start-up end clients with 1000s of successfully completed and on-going projects across the US, EU, and UKGlobal: Employee work force is diverse, spanning across 4 continents of North America, Europe, South America, and AsiaGrowth and Innovation: Active monitoring and measurement of the market across all technological sectors to adapt to and implement what\\'s \"next”How We Will Help YouTeach and Develop: We will instruct and train you in Data Science to become a best-in-class consultant through our proven method and program, capable of delivering end-client deliverables, in our paid, 6-8-week training courseCustom Support: Several teams ready to collaborate with you in a custom-tailored way: Development Managers, Tech Subject Manager Experts, Project Deliverable Support, Teachers, Interview Coaches, Client Placement Specialists, Immigration Specialists (for our foreign national candidates)Project Placement: Personalized market-expertise team to enable your ability to secure and maintain a project with our myriad end clientsCareer Growth: We will help you gain the necessary industry experience to drive and propel your technical profession forwardWhat You Bring to the RoleMaster\\'s degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, PhD is preferred. Alternatively, Bachelor’s Degree with at least 2 years’ experience as a Data Analyst, Data Scientist, or Research Assistant6+ years of experience working in a corporate environment within ITStrong Proficiency in Python or Java programming language, or expertise with functional/object- oriented programmingAbility to translate objectives to a project plan with milestones, and resource/technology requirements, and teach, lead, and manage projects/people/clients to successful executionAbility to work across multiple engagements with clients to assess needs, provide assistance, and resolve problems, using structured problem solving and communication to both technical and non- technical audiencesAvailability to travel (80% after Training portion) and live in the U.SStrong English written and verbal communication skillsNice-to-Have:Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environmentExperience in machine learning, artificial intelligence and/or artificial neural networksProficiency in applying various mathematical and statistical models to include, but not limited to: discrete event simulation, factor analysis, genetic algorithms, Bayesian probability models, hidden Markov models, sensitivity analysis, sampling, probability, multivariate data analysis, regression, PCA, time-series analysisBroad understanding of databases (e.g. SQL, NoSQL, Lucene, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, and/or Hive)Experience with visualization software (Tableau, D3, MicroStrategy, PowerBI)Experience delivering solutions in an Agile environmentExperience with Tensorflow, Theano or KerasPortfolio of public & private data science projects you’re proud of (GitHub, Kaggle, DrivenData, etc.)Publications in peer-reviewed journalsOther programming languages such as Scala, Java, RGet to Know Us Our blog and testimonials speak for themselves, they are a great way to get to know us even more and underscore what we can offer you, as well!Instagram: https://www.instagram.com/enhanceitcommunity/ LinkedIn: https://www.linkedin.com/company/enhance-it-com/?viewAsMember=true Website: https://www.enhanceit.com YouTube: https://www.youtube.com/channel/UCYBe7WrZ8lM3MJInS1ZczvQ Facebook: https://www.facebook.com/enhanceitcommunity\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role is only available for W2 or 1099 individual.  100% Remote WorkLocation: Remote anywhere in the USContract to Hire our client is adamant about finding a long term fit. No difference between contract and FTE,  100% will convert.  Job Description: Our client is currently looking for a Data Scientist. We are working with a Director in the Machine Learning & Data Science in our client's cyber division.Our client hosts a true Big Data environment (Petabytes of data stored, and processing daily upwards of 235 billion market events). You will be tasked with researching and helping construct some of the most important machine learning models that protect our stock and bond markets.Our client is looking to incorporate anomaly detection/data science technology in their cyber environment to identify abnormal behavior.Our client is looking for someone with a great deal of intellectual curiosity, experience in a data science environment, who want to be very hands on and technical (coding and mathematical/research analysis is required).Minimum QualificationsPhD preferred, Master's required Computer Science, Math, Statistics, Physics and/or Electrical Engineering must have the mathematical background to apply mathematical analysis to data and determine relationships4+ years of experience in Data Science, Big Data, AI/Client and/or software/data engineeringExpertise in programming with PythonStrong SQL querying skillsExperience in Big Data environments and in a data science practiceKeen ability to research data and identify relationships (this is 85% of the job)Data science experienceHave worked on building and maintaining Machine Learning modelsExperience with PySpark and PyTorchMust have strong communication skillsPreferred:Coding experience with SparkBig Data engineering experienceAWS experienceExperience executing sophisticated SQL queries for backend, data testing.Powered by JazzHRb8OFsmkPmt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Allozymes is a deep tech company based in Singapore. We are revolutionising the way industry uses enzymes for manufacturing chemicals and natural compounds. Our rapid discovery and evolution of custom-designed enzymes enables breakthrough developments for sustainable production of ingredients for pharmaceuticals, cosmetics, chemical, food and beverages.We’re hiring a highly capable Machine Learning Engineer into our Data team. This team is responsible for developing and implementing state-of-the-art approaches for evolving enzymes and microbes to enhance the production of chemicals and natural compounds. The engineer will integrate the development of our cloud-based artificial intelligence platform for enhancing Allozymes’ enzyme optimization capabilities. Working in a highly collaborative and dynamic environment, this role has the opportunity to interact with other scientists, automation and process engineers to achieve these goals. Responsibilities:Contribute to the design and improvement of Allozymes cloud-based AI platform.Scope project requirements, assess data quality, process data and perform feature engineering.Build, train and deploy ML/DL models, using state-of-the-art technologies and proprietary data to accurately perform predictions and generate new, high performing, enzymes.Perform model evaluation and statistical analysis to improve model quality.Enhance the performance and deployment environment of implemented solutions.Qualifications:MS or PhD in mathematics, statistics, computer science, engineering or a related quantitative field with a focus on AI and Machine Learning.2+ years of relevant industry experience.Expertise in building, training and deploying Machine and Deep Learning models.Proficiency in Python.Expertise in using ML/DS specific python libraries (Pandas, Numpy, Scipy, Scikit-learn, PyTorch, Keras).Experience with ML life-cycle management and code/data version control tools.Familiarity working with Cloud computing.Ability to work in a fast-paced, collaborative and cross-functional environment and communicate results effectively to management.Experience with supervised and unsupervised learning algorithms, clustering, feature selection methods, evaluation, dimensionality reduction, Bayesian inference, hyper-parameter tuning and model optimization is a plusExperience with Language models, Encoders, Transformers, Attention, Generative models and GANs is a plusExperience in biology, bioinformatics or computational biology.Experience using AWS/SageMaker is a plusExperience with containers and container orchestration tools is a plusExperience writing production-ready code (version-controlled, scalable, well-documented, testable, deployment-ready) is a plusNumber of Vacancies: 1\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and that to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Ideal candidate traits🧠 Previously scaled ML systems to 1M + users📑 Willing to go deep in the weeds on research & development⚙️ Cares a Ton About How Backend Systems Work💨 Has worked on large systems but executes like a startup, fast, ships and iteratesPowered by JazzHRkSUPOAkuhD\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"About the Role:We are looking for a highly analytical, data obsessed Data Scientist to join our growing company. The ideal candidate will work cross functionally to develop, maintain and implement predictive models that will provide actionable insights to inform key business decisions. This role will sit within our Product Team and report to our Senior Director, Product Analytics.What you'll be doing:Think critically and leverage data to test and iterate on new product features and business strategiesDeﬁne and implement client usage, churn, retention, and other key metricsBuild and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scaleQuery databases from multiple marketing and product sources and create usable KPI dashboardsSetup analytical framework for user journeys and lifecycle marketing funnelsStatistical modeling:Support business objectives through statistical modeling through the prediction of main KPIs such as churn, retention and LTVDesign, implement and maintain machine learning models to automate and optimize marketing, operations, and customer experienceA/B testing and causal modelingCommunication & Teamwork:Collaborate with stakeholders across the companyFull-stack data science analysis and present insights to both the data science team and internal company stakeholders. Minimum Qualifications:Bachelor's degree in computer science, mathematics, data science, engineering or a closely related field2+ years as a Data Scientist (Business Intelligence) involving data extraction, analysis, and statistical modelingExcellent problem solving skills with keen attention to detail Ability to communicate complex data insights to both technical and non-technical audience, including senior leadership Experience in product, wellness or healthcare company preferred Evidenced proﬁciency in skills listed by at 3 months experience in each:Python, SQL, git, and common data science and machine learning libraries (pandas, sklearn, etc.)Understanding of data visualization best practices, proﬁcient with BI Platforms (Looker, Tableau)This role offers a remote and/or hybrid work environment, but we would prefer candidates located in the NYC and NJ area.Salary Range: $115,000 to $120,000 + equity & benefits. The base pay is one component of Nanit's total compensation package, which may also include access to healthcare benefits, a 401(k) plan, short-term and long-term disability coverage, and basic life insurance. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Entry Level Data Scientist with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'You’ll be the founding data scientist in a well-funded company looking to define Web 3 user identity and attribution.We plan on running a lean team: expect to totally own your area of responsibility and use your initiative and judgement to keep your part of Spindl running and growing.Be comfortable with being uncomfortable. You will be creating the metrics and methodologies that will define an entire industry within Web 3. There won’t be easy answers for most of what we do. We’re already making it up as we go along.Speed is a feature, in teams, products, and people: keep up with the Spindl pack. There isn’t a moment to lose.We’re looking for pirates now that Web 2 has become the navy.ResponsibilitiesBe a leader within a very flat and fast-moving teamUnderstand the often weird and hacked-together blockchain world, as well as the embryonic data stack being built on top of itNavigate the idea maze toward Truth (or something like it)Plot the critical curve or generate the essential dashboard that helps us understand Web 3. Creatively address business problems when there are no precedents and no clear answersWork with engineering to implement your findings and models into running product quickly. You are mapping the unknown terrain; we want to turn that into industry knowledge ASAP. Empathize with our customers, understand their worldview, and work with the UI team to translate your insights into customer insights. Convey your findings to colleagues; tell a story with data convincingly. Optionally, publish your work publicly will full credit. Must haves (this is an AND)N years doing data science or analysis (for reasonable N). Proficiency with data visualization and dashboarding tools like Looker or Tableau. Think those suck? Tell us why. Ideally, this would involve more than just descriptive dashboarding and extend into some predictive model-building around complicated ecosystems like markets or user behavior online. Experience with modeling in Python: Jupyter, Pandas, PyTorch, numpy, scipy, etc. Exception to the above: Outstanding familiarity with blockchains and protocols and their often quirky data, along with extensive experience in environments like Dune or Flipside, can compensate for a lack of more traditional data science experience. If you’re the #3 person on the Dune leaderboard, let’s talk. Be smart and get shit done. Be a doer and a risk-taker. Nice to haves (this is an OR)Experience with advertising technology or campaign management within Web 2 adsExperience with A/B testing and experimentationExperience in anti-fraud, either within ad tech or fin tech. There are lots of bad guys to block in Web 3. LocationYou can be located anywhere in the world, but we have a strong preference for SF or NYC. If you’re not in either city, expect some travel to work face-to-face with colleagues on a semi-regular basis. If you’re in one of those cities, you’ll find a balance between coming into the office and not. We think in-person work possesses a magic for early stage startups, something unobtainable in a fully remote environment where co-workers are simply images on a screen.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Senior Data Scientist - Brightside Health - 100% Remote in U.S.Brightside Health delivers life-saving virtual mental healthcare to everyone who needs it. We are powered by proprietary AI, purpose-built technology, a world-class clinician network, and a care model that rivals the best of in-person treatment. When combined with precision psychiatry and leading-edge therapeutic techniques, we’re able to improve outcomes for those with mild-to-severe clinical depression, anxiety, and other mood disorders.We take an action-oriented, purposeful approach with everything we do and seek out team members who value collaboration and thoughtful prioritization. As a result, our organization is looking for the brightest and most innovative talent in the industry. We can promise you that, as a member of the Brightside team, you’ll have the opportunity to collaborate alongside smart and driven people while growing your professional skills.We are seeking a talented and experienced Senior Data Scientist to join our team. As a Senior Data Scientist, you will be responsible for developing and implementing advanced analytical and machine learning models that drive business value and support the experience of Brightside Health’s patients, clinicians, and internal teams.What you’ll be doing as a Senior Data Scientist:Design, develop, and deploy advanced analytic and machine learning models to explain or predict the behavior, experience and outcomes of patients, clinicians, and the businessCollaborate with cross functional teams to identify opportunities for data-driven decision making and translate business objectives into data science problems, and vice versaCommunicate complex data science concepts, ideas and results to technical and non-technical stakeholdersContribute to developing core data science and machine learning frameworks that shape the Data organizationRequirements:At least 4 years of relevant data science, analytics or machine learning professional experienceExperience in data engineering and feature preparationExperience in developing machine learning models using a variety of techniques (including regression, classification, clustering, time series, NLP)Track record of successfully developing and implementing ML modelsExperience working with large datasets (healthcare-relevant datasets are a plus)Interest in being an early DS/ML team member, with the technical ability to develop high value models independently while prioritizing collaboration with your teammates and stakeholders to ensure successful design and implementationMotivated to build relationships with teammates and stakeholders, and increase data literacy and expertise throughout the organizationPassionate about improving healthcareBonus: experience working with large healthcare or healthcare related data setsTools we use:Python, including common ML packages like NumPy, Scikit-Learn, Pandas, Tensorflow, etc.AWS and GoogleCloud environmentsSQLGitHubBenefits:A competitive salaryStock options so you have equityFully paid for comprehensive health care (medical, dental, vision)Pet Insurance Life Insurance & Short / Long Term Disability 401k Plan Unlimited PTO and sick leaveParental Leave Work remotely and whatever schedule works best for youAdditional memberships and perksFinal offer amounts are determined by multiple factors including geographic location as well as candidate experience and expertise. If you have questions on compensation bands, please ask your recruiter.Brightside Health is committed to equal employment opportunities for all team members. Every decision we make regarding employment is solely based on merit, competence, and performance. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We realize the full promise of diversity and want you to bring your whole self to work every single day.Research shows that underrepresented groups typically apply only if they meet 100% of the criteria listed. At Brightside, we are dedicated to fair play and encourage women, people of color, and LGBTQ+ job seekers to apply for positions even if they don’t check every box for the role.We know that diversity makes for the best problem-solving and creative thinking, and are committed to equity and inclusion. We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for. We’re an Equal Opportunity Employer and do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, age, religion, disability, national origin, protected veteran status, or any other status protected by applicable federal, state, or local law.Powered by JazzHRvPVWJtptOO\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Machine Learning EngineerLocation: San Francisco, CAType: Full TimeAbout This RoleYou will build the machine learning systems that power our general artificial intelligence for capital allocation. We are looking for researchers who want to discover elegant deep learning concepts and then put them into production as solutions to high-stakes, real-world problems.Ideal candidate traits3+ years of professional experience as a software engineer or machine learning researcherHistory of generating new ideas in AI, evidenced by published works or personal projectsExceptional engineering abilities, with a track record of putting complex systems into productionResearch leadership skills, with the capacity to own projects end-to-end, from idea generation through executionEnergized by fast-paced, intense work environmentsExceptional independence of thought and grittiness in the pursuit of success\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'SOCOM CDO – Tampa, FL – Top Secret Clearance RequiredSTEMBoard is seeking a data scientist with knowledge in programming for integrating complex models and using advanced software library frameworks to distribute large, clustered data sets. The data scientist work with a team of data scientists and engineers that collect and arrange data in a form that is useful for analytics. A knowledge of machine learning is also desired to build efficient and accurate data pipelines to meet the needs for downstream users such as data scientists to create the models and analytics that produce insight.Principal Duties and Responsibilities:Play a crucial role in building out the Data Steward program by developing data governance standards.Research, design, and implement algorithms to solve complex problems. Program using R, Python (NumPy, SciPy, Pandas) or similar analytical languages. Conduct large-scale data processing and perform statistical modeling and create data visualizations using products like Tableau, Microsoft Power BI and R Shiny. Perform data engineering, data processing and modeling techniques using cloud-based data management, data science, and ML platforms such as Databricks, IBM Cloud Pak, Cloudera, and Snowflake.Communicate complex concepts and hypothesis to a non-technical audience through digital storytelling.Developing, maintaining, and testing infrastructures for data generation to transform data from various structured and unstructured data sources.Create standards and process for developing data sciences projects to solve IC-related problems.Design and implement process for implementing an optimal data pipeline architecture.Interpret and analyze data using exploratory mathematic and statistical techniques.Coordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data.Work withing an Agile framework and utilize Git Repositories.Experiment against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges.Coordinate with Data Engineers to build Data environments providing data identified by other data professionalsApply and develop scientific methodology, statistics and algorithms to discover and frame relevant problems, hypotheses, and opportunities.Develop predictive and prescriptive modeling, natural language processing (NLP), Robotic Process Automation (RPA), text mining and processing, clustering, forecasting methods, and other advanced statistical techniques.Design and automate processes to facilitate the manipulation and analysis of data.Requirements Experience: 1+ years of experience with software engineering, data science or related experience.  Education: Bachelors or degree in STEM with a preference towards Data Science, Computer Science, or Software Engineering. Tools: Python, SQL, R, R Shiny, AWS, or related toolsDoD Security Clearance, minimum of TOP SECRET levelBenefitsHealthcare, Vision, and Dental Insurance20 Days of PTO401K MatchingTraining/Certification ReimbursementShort term/Long term disabilityParental/Maternity LeaveLife InsuranceSTEMBoard is committed to hiring and retaining a diverse workforce. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information. Selected applicant will be subject to a background investigation. STEMBoard is an Equal Opportunity/Affirmative Action employer.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Position: Data ScientistLocation: Elk Grove, CA (Day 1st Onsite)ContractThe data scientist role willUse SQL to access data and build tablesUse topic modeling (or a similar NLP methodology) to process survey commentsUse Tableau to share results of NLP modelingPSRTEK is a reputed technology recruitment and IT staffing brand with a global footprint and an admired client base. As an ideas and innovation powerhouse with a culture of excellence, we bring remarkable expertise and deliver powerfully transformative results.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'About Us\\xa0\\xa0DeepLogica is a proprietary AI platform that empowers clients’ existing processes and systems to redefine eCommerce delivery. We utilize machine learning models to accurately predict supply chain events, provide actionable business insights and ultimately enhance the buying experience.\\xa0\\xa0About The Role\\xa0\\xa0We’re looking for a talented Data Scientist who is passionate about data, learning, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\\xa0A varied skill set, creativity, flexibility, and positive team attitude are high priorities. \\xa0Main Responsibilities\\xa0\\xa0In collaboration with the other members of your team and your supervisor you will be in charge or participate in the following activities:\\xa0Collecting, cleaning, and transforming large datasets for downstream processing.\\xa0Design accurate and scalable prediction algorithmsDevelop statistical and machine learning models to extract insights and predictions from data.\\xa0Visualize and present findings to stakeholders in a clear and concise manner.\\xa0Collaborate with cross-functional teams to identify business problems that can be solved using data.\\xa0Design experiments to test hypotheses and improve models.\\xa0Assist Data Engineering team members in building and deploying data pipelines and scalable infrastructure to support data analysis.\\xa0Ensure ethical use of data and compliance with privacy regulations.\\xa0Continuously monitor and evaluate the performance of models and adjusting as needed\\xa0Required Education, Qualifications and Experience\\xa0Bachelors or Masters degree in operations research, computer science, software engineering, or a related field\\xa0\\xa02-3 years of experience in quantitative analytics of data modeling.\\xa0Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)Passionate self-starter, able to prioritize tasks and manage time effectively.\\xa0Ability to take ownership of tasks to ensure high quality and successful on-time completion.\\xa0\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role is only available for W2 or 1099 individual.  100% Remote WorkLocation: Remote anywhere in the USContract to Hire our client is adamant about finding a long term fit. No difference between contract and FTE,  100% will convert.  Job Description: Our client is currently looking for a Data Scientist. We are working with a Director in the Machine Learning & Data Science in our client's cyber division.Our client hosts a true Big Data environment (Petabytes of data stored, and processing daily upwards of 235 billion market events). You will be tasked with researching and helping construct some of the most important machine learning models that protect our stock and bond markets.Our client is looking to incorporate anomaly detection/data science technology in their cyber environment to identify abnormal behavior.Our client is looking for someone with a great deal of intellectual curiosity, experience in a data science environment, who want to be very hands on and technical (coding and mathematical/research analysis is required).Minimum QualificationsPhD preferred, Master's required Computer Science, Math, Statistics, Physics and/or Electrical Engineering must have the mathematical background to apply mathematical analysis to data and determine relationships4+ years of experience in Data Science, Big Data, AI/Client and/or software/data engineeringExpertise in programming with PythonStrong SQL querying skillsExperience in Big Data environments and in a data science practiceKeen ability to research data and identify relationships (this is 85% of the job)Data science experienceHave worked on building and maintaining Machine Learning modelsExperience with PySpark and PyTorchMust have strong communication skillsPreferred:Coding experience with SparkBig Data engineering experienceAWS experienceExperience executing sophisticated SQL queries for backend, data testing.Powered by JazzHRb8OFsmkPmt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Ideal candidate traits🧠 Previously scaled ML systems to 1M + users📑 Willing to go deep in the weeds on research & development⚙️ Cares a Ton About How Backend Systems Work💨 Has worked on large systems but executes like a startup, fast, ships and iteratesPowered by JazzHRkSUPOAkuhD\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'HiSatyam this side. We do have a new an excellent opportunity for you. This opportunity is a full time onsite position as Data Scientist.  Please have a look at the job description below and let me know if you or someone you know is interested in this role. You can mail me at satyam@extendinfosys.com.Job Title Data ScientistLocation Santa Clara, CAJob Type Full TimeJob DescriptionData Scientist -- Computer Vision Solid knowledge of various Image Filtering, Binary Morphology, Perspective / Affine transformation, Edge Detection, and Tracking. Machine Learning: Regression, Unsupervised Learning, PCA Nice but not necessary to have HDR, Panorama, and deep Learning object detectionThanksSatyam Prajapati | Technical Recruiter| Extend Information SystemsCell: (571) 547-2880Email: satyam@extendinfosys.comAddress: 44258 Mercure Circle, UNIT 102 A, Sterling VA, USA - 20166Web:www.extendinfosys.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"About the Role:We are looking for a highly analytical, data obsessed Data Scientist to join our growing company. The ideal candidate will work cross functionally to develop, maintain and implement predictive models that will provide actionable insights to inform key business decisions. This role will sit within our Product Team and report to our Senior Director, Product Analytics.What you'll be doing:Think critically and leverage data to test and iterate on new product features and business strategiesDeﬁne and implement client usage, churn, retention, and other key metricsBuild and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scaleQuery databases from multiple marketing and product sources and create usable KPI dashboardsSetup analytical framework for user journeys and lifecycle marketing funnelsStatistical modeling:Support business objectives through statistical modeling through the prediction of main KPIs such as churn, retention and LTVDesign, implement and maintain machine learning models to automate and optimize marketing, operations, and customer experienceA/B testing and causal modelingCommunication & Teamwork:Collaborate with stakeholders across the companyFull-stack data science analysis and present insights to both the data science team and internal company stakeholders. Minimum Qualifications:Bachelor's degree in computer science, mathematics, data science, engineering or a closely related field2+ years as a Data Scientist (Business Intelligence) involving data extraction, analysis, and statistical modelingExcellent problem solving skills with keen attention to detail Ability to communicate complex data insights to both technical and non-technical audience, including senior leadership Experience in product, wellness or healthcare company preferred Evidenced proﬁciency in skills listed by at 3 months experience in each:Python, SQL, git, and common data science and machine learning libraries (pandas, sklearn, etc.)Understanding of data visualization best practices, proﬁcient with BI Platforms (Looker, Tableau)This role offers a remote and/or hybrid work environment, but we would prefer candidates located in the NYC and NJ area.Salary Range: $115,000 to $120,000 + equity & benefits. The base pay is one component of Nanit's total compensation package, which may also include access to healthcare benefits, a 401(k) plan, short-term and long-term disability coverage, and basic life insurance. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Entry Level Data Scientist with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'You’ll be the founding data scientist in a well-funded company looking to define Web 3 user identity and attribution.We plan on running a lean team: expect to totally own your area of responsibility and use your initiative and judgement to keep your part of Spindl running and growing.Be comfortable with being uncomfortable. You will be creating the metrics and methodologies that will define an entire industry within Web 3. There won’t be easy answers for most of what we do. We’re already making it up as we go along.Speed is a feature, in teams, products, and people: keep up with the Spindl pack. There isn’t a moment to lose.We’re looking for pirates now that Web 2 has become the navy.ResponsibilitiesBe a leader within a very flat and fast-moving teamUnderstand the often weird and hacked-together blockchain world, as well as the embryonic data stack being built on top of itNavigate the idea maze toward Truth (or something like it)Plot the critical curve or generate the essential dashboard that helps us understand Web 3. Creatively address business problems when there are no precedents and no clear answersWork with engineering to implement your findings and models into running product quickly. You are mapping the unknown terrain; we want to turn that into industry knowledge ASAP. Empathize with our customers, understand their worldview, and work with the UI team to translate your insights into customer insights. Convey your findings to colleagues; tell a story with data convincingly. Optionally, publish your work publicly will full credit. Must haves (this is an AND)N years doing data science or analysis (for reasonable N). Proficiency with data visualization and dashboarding tools like Looker or Tableau. Think those suck? Tell us why. Ideally, this would involve more than just descriptive dashboarding and extend into some predictive model-building around complicated ecosystems like markets or user behavior online. Experience with modeling in Python: Jupyter, Pandas, PyTorch, numpy, scipy, etc. Exception to the above: Outstanding familiarity with blockchains and protocols and their often quirky data, along with extensive experience in environments like Dune or Flipside, can compensate for a lack of more traditional data science experience. If you’re the #3 person on the Dune leaderboard, let’s talk. Be smart and get shit done. Be a doer and a risk-taker. Nice to haves (this is an OR)Experience with advertising technology or campaign management within Web 2 adsExperience with A/B testing and experimentationExperience in anti-fraud, either within ad tech or fin tech. There are lots of bad guys to block in Web 3. LocationYou can be located anywhere in the world, but we have a strong preference for SF or NYC. If you’re not in either city, expect some travel to work face-to-face with colleagues on a semi-regular basis. If you’re in one of those cities, you’ll find a balance between coming into the office and not. We think in-person work possesses a magic for early stage startups, something unobtainable in a fully remote environment where co-workers are simply images on a screen.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Senior Data Scientist - Brightside Health - 100% Remote in U.S.Brightside Health delivers life-saving virtual mental healthcare to everyone who needs it. We are powered by proprietary AI, purpose-built technology, a world-class clinician network, and a care model that rivals the best of in-person treatment. When combined with precision psychiatry and leading-edge therapeutic techniques, we’re able to improve outcomes for those with mild-to-severe clinical depression, anxiety, and other mood disorders.We take an action-oriented, purposeful approach with everything we do and seek out team members who value collaboration and thoughtful prioritization. As a result, our organization is looking for the brightest and most innovative talent in the industry. We can promise you that, as a member of the Brightside team, you’ll have the opportunity to collaborate alongside smart and driven people while growing your professional skills.We are seeking a talented and experienced Senior Data Scientist to join our team. As a Senior Data Scientist, you will be responsible for developing and implementing advanced analytical and machine learning models that drive business value and support the experience of Brightside Health’s patients, clinicians, and internal teams.What you’ll be doing as a Senior Data Scientist:Design, develop, and deploy advanced analytic and machine learning models to explain or predict the behavior, experience and outcomes of patients, clinicians, and the businessCollaborate with cross functional teams to identify opportunities for data-driven decision making and translate business objectives into data science problems, and vice versaCommunicate complex data science concepts, ideas and results to technical and non-technical stakeholdersContribute to developing core data science and machine learning frameworks that shape the Data organizationRequirements:At least 4 years of relevant data science, analytics or machine learning professional experienceExperience in data engineering and feature preparationExperience in developing machine learning models using a variety of techniques (including regression, classification, clustering, time series, NLP)Track record of successfully developing and implementing ML modelsExperience working with large datasets (healthcare-relevant datasets are a plus)Interest in being an early DS/ML team member, with the technical ability to develop high value models independently while prioritizing collaboration with your teammates and stakeholders to ensure successful design and implementationMotivated to build relationships with teammates and stakeholders, and increase data literacy and expertise throughout the organizationPassionate about improving healthcareBonus: experience working with large healthcare or healthcare related data setsTools we use:Python, including common ML packages like NumPy, Scikit-Learn, Pandas, Tensorflow, etc.AWS and GoogleCloud environmentsSQLGitHubBenefits:A competitive salaryStock options so you have equityFully paid for comprehensive health care (medical, dental, vision)Pet Insurance Life Insurance & Short / Long Term Disability 401k Plan Unlimited PTO and sick leaveParental Leave Work remotely and whatever schedule works best for youAdditional memberships and perksFinal offer amounts are determined by multiple factors including geographic location as well as candidate experience and expertise. If you have questions on compensation bands, please ask your recruiter.Brightside Health is committed to equal employment opportunities for all team members. Every decision we make regarding employment is solely based on merit, competence, and performance. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We realize the full promise of diversity and want you to bring your whole self to work every single day.Research shows that underrepresented groups typically apply only if they meet 100% of the criteria listed. At Brightside, we are dedicated to fair play and encourage women, people of color, and LGBTQ+ job seekers to apply for positions even if they don’t check every box for the role.We know that diversity makes for the best problem-solving and creative thinking, and are committed to equity and inclusion. We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for. We’re an Equal Opportunity Employer and do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, age, religion, disability, national origin, protected veteran status, or any other status protected by applicable federal, state, or local law.Powered by JazzHRvPVWJtptOO\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job Description:- Must To Have Skills Python  Pandas  Data Analysis  Tableau  For more information please reachout Aslam aslam@dantatechnologies.net.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Machine Learning EngineerLocation: San Francisco, CAType: Full TimeAbout This RoleYou will build the machine learning systems that power our general artificial intelligence for capital allocation. We are looking for researchers who want to discover elegant deep learning concepts and then put them into production as solutions to high-stakes, real-world problems.Ideal candidate traits3+ years of professional experience as a software engineer or machine learning researcherHistory of generating new ideas in AI, evidenced by published works or personal projectsExceptional engineering abilities, with a track record of putting complex systems into productionResearch leadership skills, with the capacity to own projects end-to-end, from idea generation through executionEnergized by fast-paced, intense work environmentsExceptional independence of thought and grittiness in the pursuit of success\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Masters's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in the programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At QuantAQ, our mission is to mitigate global air pollution.As a company, we value the role that fundamental scientific and engineering research play in developing new technologies while doing so with the knowledge that what we build must scale if we want to meet our goals.At QuantAQ, we provide access to professional-grade air quality data to a variety of clients (including research, government, and the private sector) to empower informed decision-making and to create cleaner (air) outcomes. We provide our clients with everything they need to build and manage distributed air quality sensor networks at scale including our proprietary air quality sensors (developed through years of R+D at MIT and Aerodyne Research) and our integrated software platform. We care deeply about using innovative technologies and socio-technological approaches to help businesses, governments, and community stakeholders obtain actionable air quality information across a variety of contexts.If you're looking for an opportunity that allows you to highlight your own skills and solve one of society's most pressing environmental challenges, we would love to hear from you. To learn more about QuantAQ, check out our Climatetech Summit video.About The RoleWe are looking for a full-time Data Scientist to join our rapidly growing team at QuantAQ. We’re a small startup with a rapidly expanding product-market fit, so as an individual contributor, you will quickly gain end-to-end ownership over multiple areas of the business. If that excites you, let’s talk!The ideal candidate is an experienced data scientist who is excited about the opportunity to apply their data science and machine learning skills to improve our category-leading air quality sensors and help reduce the negative impacts of air pollution. At QuantAQ, we gather a lot of air quality data and need to improve our tooling and operations for synthesizing this incoming data to make it as useful as possible for decision-makers to act upon. Over the past decade, we have published some of the most highly-cited and widely-used machine-learning methods for air quality sensors and sensor networks on topics ranging from models for improving individual sensor measurements (supervised regression models) to classifying types and sources of pollution (unsupervised classification methods). You will help develop and improve novel approaches to measuring and locating sources of air pollution and help push those models from ideation to production for our global fleet of air quality sensors. If this sounds appealing, we would love to hear from you.This position is remote-friendly, with options to work hybrid or in-person in Somerville, MA, or San Francisco, CA.ResponsibilitiesIn this position, you will work directly with and report to the CEO, who is currently responsible for overseeing all data science efforts. Responsibilities of this position include:Develop internal and external tools and pipelines to help evaluate the continuous success of our fleet of sensorsApply statistical methods to determine failure rates and lifetimes of key sensor componentsDesign, develop, and grow data sets that enable a better understanding of our sensor performancePartner closely with product and engineering to identify and prioritize the most important data science projectsDevelop and maintain customer-facing data science tools to help customers and the broader scientific community use air quality data and air quality sensors Stay up to date with the machine learning literature, especially for its applications to air quality sensors and sensor networks, and quickly prototype ideas from the research fieldProvide data science customer support from time to time when neededDevelop and execute re-usable playbooks for common customer-facing data science needs (i.e. pilot project evaluation)QualificationsCandidates need not meet all requirements below, but the more that you meet, the better match you may be for existing work. Learning new tools on the fly is expected, and hopefully part of the fun.A Ph.D. or M.S. in a quantitative field such as statistics, applied math, environmental science, computer science, operations research, or relevant work experience combining domain expertise and rigorous quantitative methods2+ years of industry experience in a data science or analytics roleExpert knowledge in Python and the Python data science and machine learning ecosystem (i.e., pandas, scikit-learn, PyTorch, TensorFlow, etc) and proficiency in SQLProficiency in data visualizationExpertise in statistics and experimental designA demonstrated ability to manage and deliver on multiple projects with high attention to detailFamiliarity with cloud tooling for machine learning at scaleExcellent verbal and written communication skills and the ability to communicate clearly and effectivelyStrong organization skills and the ability to work effectively in a team environmentAbility to challenge assumptions and think independently while executing quicklyUS work authorizationCompensation And BenefitsCompensation for this position is competitive for Seed-stage companies in the Boston area. Benefits at QuantAQ include:Health insurance with 85% company contributionDental, vision, and life insurance401(k) with partial company matchFlexible vacation time3 weeks PTO + 10 observed Federal holidaysFlexible work hoursParticipation in QuantAQ’s profit-sharing planLocationQuantAQ is based out of Greentown Labs in Somerville, MA. Greentown Labs is the largest climate tech incubator in North America and includes an awesome community of mission-driven entrepreneurs. Greentown offers numerous networking opportunities and events that cover a variety of topics. We love working out of Greentown Labs!How to ApplyDoes this role seem like a good fit? Are you interested in learning more? Email us at join@quant-aq.com for more information. Otherwise, please apply using the provided form.QuantAQ values diversity of thought, access, and experiences and is an Equal Opportunity Employer → individuals seeking employment with us are considered without regard to race, color, religion, national origin, age, sex, marital status, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by law.Compensation Range: $109K - $147K\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in the programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About The CompanyBloomfield is a plant imaging platform shaping the future of precision agriculture. We scan farms and vineyards at scale (capturing high resolution imagery and other sensor data), analyze every plant, and derive actionable intelligence to help growers be more efficient and productive. We collaborate with a variety of movement platform companies, from ATV and tractor manufacturers to robotics startups.About The RoleThe Data Scientist will work closely with our Machine Learning and Product teams to transform phenotypic information into data products that can be used by our grower-partners to manage their operations.ResponsibilitiesWork closely with our AI, Product, and Engineering teams to deliver phenotypic analysis to our customersBuild frameworks to quantitatively and qualitatively describe plant behavior of specialty crops Interface with engineering team to integrate developed algorithms into product pipelineRequirementsStrong knowledge of plant physiology and/or plant development at the whole plant and molecular levels. Familiarity with plant responses to biotic and abiotic stress is a plusDemonstrated ability to independently design, conduct, and interpret experiments including the use of appropriate statistical methodsDegree in Plant Sciences, Agricultural Engineering, Plant Breeding and Crop Protection, Biology, or similar fieldProgramming languages: PythonNice to havesExperience with high-throughput phenotypingExperience using sensor data in an agricultural environmentAdvanced Degree in Plant Sciences, Agricultural Engineering, Plant Breeding and Crop Protection, Biology, or similar fieldWhat We OfferIn addition to the opportunity to apply and develop your skills toward key business objectives, we offer an excellent compensation package including:Competitive base salaryMedical, dental and vision insurance401(k) retirement plan with company matchUnlimited PTO Parental Leave Incentive stock optionsTraining & Development StipendBloomfield is an equal opportunity employer. We consider qualified applicants without regard to race, color, religion, sex, national origin, sexual orientation, disability, gender identity, protected veteran status, or other protected classes.Powered by JazzHRvdiZ24ZLKF\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Machine Learning Engineer , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job Requirements2 years of experience, or an advanced degree (MSc).Experience in applied Deep Learning (DL) and Computer Vision (CV) concepts including but are not limited to: CNNs, RNNs, Autoencoders, Transfer Learning.Hands-on experience (academic and/or industrial) in 3D Pose Estimation and Motion reconstruction from images and videosProficiency in general purpose programming languages: Python, and C++.Experience with ML frameworks such as: PyTorch, Tensorflow, etc.The ideal candidate would be very well acquainted with Computer Graphics techniques, Neural Rendering, and Numerical Optimization(Optional) Knowledge of 3D packages such as Blender, Maya, or any game engine technologyBSc in Computer Science, Mathematics, Electrical Engineering, or related technical field.Ability to speak and write in English fluently and idiomatically.Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatment.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role is only available for W2 or 1099 individual.  100% Remote WorkLocation: Remote anywhere in the USContract to Hire our client is adamant about finding a long term fit. No difference between contract and FTE,  100% will convert.  Job Description: Our client is currently looking for a Data Scientist. We are working with a Director in the Machine Learning & Data Science in our client's cyber division.Our client hosts a true Big Data environment (Petabytes of data stored, and processing daily upwards of 235 billion market events). You will be tasked with researching and helping construct some of the most important machine learning models that protect our stock and bond markets.Our client is looking to incorporate anomaly detection/data science technology in their cyber environment to identify abnormal behavior.Our client is looking for someone with a great deal of intellectual curiosity, experience in a data science environment, who want to be very hands on and technical (coding and mathematical/research analysis is required).Minimum QualificationsPhD preferred, Master's required Computer Science, Math, Statistics, Physics and/or Electrical Engineering must have the mathematical background to apply mathematical analysis to data and determine relationships4+ years of experience in Data Science, Big Data, AI/Client and/or software/data engineeringExpertise in programming with PythonStrong SQL querying skillsExperience in Big Data environments and in a data science practiceKeen ability to research data and identify relationships (this is 85% of the job)Data science experienceHave worked on building and maintaining Machine Learning modelsExperience with PySpark and PyTorchMust have strong communication skillsPreferred:Coding experience with SparkBig Data engineering experienceAWS experienceExperience executing sophisticated SQL queries for backend, data testing.Powered by JazzHRb8OFsmkPmt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and that to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Ideal candidate traits🧠 Previously scaled ML systems to 1M + users📑 Willing to go deep in the weeds on research & development⚙️ Cares a Ton About How Backend Systems Work💨 Has worked on large systems but executes like a startup, fast, ships and iteratesPowered by JazzHRkSUPOAkuhD\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'HiSatyam this side. We do have a new an excellent opportunity for you. This opportunity is a full time onsite position as Data Scientist.  Please have a look at the job description below and let me know if you or someone you know is interested in this role. You can mail me at satyam@extendinfosys.com.Job Title Data ScientistLocation Santa Clara, CAJob Type Full TimeJob DescriptionData Scientist -- Computer Vision Solid knowledge of various Image Filtering, Binary Morphology, Perspective / Affine transformation, Edge Detection, and Tracking. Machine Learning: Regression, Unsupervised Learning, PCA Nice but not necessary to have HDR, Panorama, and deep Learning object detectionThanksSatyam Prajapati | Technical Recruiter| Extend Information SystemsCell: (571) 547-2880Email: satyam@extendinfosys.comAddress: 44258 Mercure Circle, UNIT 102 A, Sterling VA, USA - 20166Web:www.extendinfosys.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"About the Role:We are looking for a highly analytical, data obsessed Data Scientist to join our growing company. The ideal candidate will work cross functionally to develop, maintain and implement predictive models that will provide actionable insights to inform key business decisions. This role will sit within our Product Team and report to our Senior Director, Product Analytics.What you'll be doing:Think critically and leverage data to test and iterate on new product features and business strategiesDeﬁne and implement client usage, churn, retention, and other key metricsBuild and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scaleQuery databases from multiple marketing and product sources and create usable KPI dashboardsSetup analytical framework for user journeys and lifecycle marketing funnelsStatistical modeling:Support business objectives through statistical modeling through the prediction of main KPIs such as churn, retention and LTVDesign, implement and maintain machine learning models to automate and optimize marketing, operations, and customer experienceA/B testing and causal modelingCommunication & Teamwork:Collaborate with stakeholders across the companyFull-stack data science analysis and present insights to both the data science team and internal company stakeholders. Minimum Qualifications:Bachelor's degree in computer science, mathematics, data science, engineering or a closely related field2+ years as a Data Scientist (Business Intelligence) involving data extraction, analysis, and statistical modelingExcellent problem solving skills with keen attention to detail Ability to communicate complex data insights to both technical and non-technical audience, including senior leadership Experience in product, wellness or healthcare company preferred Evidenced proﬁciency in skills listed by at 3 months experience in each:Python, SQL, git, and common data science and machine learning libraries (pandas, sklearn, etc.)Understanding of data visualization best practices, proﬁcient with BI Platforms (Looker, Tableau)This role offers a remote and/or hybrid work environment, but we would prefer candidates located in the NYC and NJ area.Salary Range: $115,000 to $120,000 + equity & benefits. The base pay is one component of Nanit's total compensation package, which may also include access to healthcare benefits, a 401(k) plan, short-term and long-term disability coverage, and basic life insurance. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'You’ll be the founding data scientist in a well-funded company looking to define Web 3 user identity and attribution.We plan on running a lean team: expect to totally own your area of responsibility and use your initiative and judgement to keep your part of Spindl running and growing.Be comfortable with being uncomfortable. You will be creating the metrics and methodologies that will define an entire industry within Web 3. There won’t be easy answers for most of what we do. We’re already making it up as we go along.Speed is a feature, in teams, products, and people: keep up with the Spindl pack. There isn’t a moment to lose.We’re looking for pirates now that Web 2 has become the navy.ResponsibilitiesBe a leader within a very flat and fast-moving teamUnderstand the often weird and hacked-together blockchain world, as well as the embryonic data stack being built on top of itNavigate the idea maze toward Truth (or something like it)Plot the critical curve or generate the essential dashboard that helps us understand Web 3. Creatively address business problems when there are no precedents and no clear answersWork with engineering to implement your findings and models into running product quickly. You are mapping the unknown terrain; we want to turn that into industry knowledge ASAP. Empathize with our customers, understand their worldview, and work with the UI team to translate your insights into customer insights. Convey your findings to colleagues; tell a story with data convincingly. Optionally, publish your work publicly will full credit. Must haves (this is an AND)N years doing data science or analysis (for reasonable N). Proficiency with data visualization and dashboarding tools like Looker or Tableau. Think those suck? Tell us why. Ideally, this would involve more than just descriptive dashboarding and extend into some predictive model-building around complicated ecosystems like markets or user behavior online. Experience with modeling in Python: Jupyter, Pandas, PyTorch, numpy, scipy, etc. Exception to the above: Outstanding familiarity with blockchains and protocols and their often quirky data, along with extensive experience in environments like Dune or Flipside, can compensate for a lack of more traditional data science experience. If you’re the #3 person on the Dune leaderboard, let’s talk. Be smart and get shit done. Be a doer and a risk-taker. Nice to haves (this is an OR)Experience with advertising technology or campaign management within Web 2 adsExperience with A/B testing and experimentationExperience in anti-fraud, either within ad tech or fin tech. There are lots of bad guys to block in Web 3. LocationYou can be located anywhere in the world, but we have a strong preference for SF or NYC. If you’re not in either city, expect some travel to work face-to-face with colleagues on a semi-regular basis. If you’re in one of those cities, you’ll find a balance between coming into the office and not. We think in-person work possesses a magic for early stage startups, something unobtainable in a fully remote environment where co-workers are simply images on a screen.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Senior Data Scientist - Brightside Health - 100% Remote in U.S.Brightside Health delivers life-saving virtual mental healthcare to everyone who needs it. We are powered by proprietary AI, purpose-built technology, a world-class clinician network, and a care model that rivals the best of in-person treatment. When combined with precision psychiatry and leading-edge therapeutic techniques, we’re able to improve outcomes for those with mild-to-severe clinical depression, anxiety, and other mood disorders.We take an action-oriented, purposeful approach with everything we do and seek out team members who value collaboration and thoughtful prioritization. As a result, our organization is looking for the brightest and most innovative talent in the industry. We can promise you that, as a member of the Brightside team, you’ll have the opportunity to collaborate alongside smart and driven people while growing your professional skills.We are seeking a talented and experienced Senior Data Scientist to join our team. As a Senior Data Scientist, you will be responsible for developing and implementing advanced analytical and machine learning models that drive business value and support the experience of Brightside Health’s patients, clinicians, and internal teams.What you’ll be doing as a Senior Data Scientist:Design, develop, and deploy advanced analytic and machine learning models to explain or predict the behavior, experience and outcomes of patients, clinicians, and the businessCollaborate with cross functional teams to identify opportunities for data-driven decision making and translate business objectives into data science problems, and vice versaCommunicate complex data science concepts, ideas and results to technical and non-technical stakeholdersContribute to developing core data science and machine learning frameworks that shape the Data organizationRequirements:At least 4 years of relevant data science, analytics or machine learning professional experienceExperience in data engineering and feature preparationExperience in developing machine learning models using a variety of techniques (including regression, classification, clustering, time series, NLP)Track record of successfully developing and implementing ML modelsExperience working with large datasets (healthcare-relevant datasets are a plus)Interest in being an early DS/ML team member, with the technical ability to develop high value models independently while prioritizing collaboration with your teammates and stakeholders to ensure successful design and implementationMotivated to build relationships with teammates and stakeholders, and increase data literacy and expertise throughout the organizationPassionate about improving healthcareBonus: experience working with large healthcare or healthcare related data setsTools we use:Python, including common ML packages like NumPy, Scikit-Learn, Pandas, Tensorflow, etc.AWS and GoogleCloud environmentsSQLGitHubBenefits:A competitive salaryStock options so you have equityFully paid for comprehensive health care (medical, dental, vision)Pet Insurance Life Insurance & Short / Long Term Disability 401k Plan Unlimited PTO and sick leaveParental Leave Work remotely and whatever schedule works best for youAdditional memberships and perksFinal offer amounts are determined by multiple factors including geographic location as well as candidate experience and expertise. If you have questions on compensation bands, please ask your recruiter.Brightside Health is committed to equal employment opportunities for all team members. Every decision we make regarding employment is solely based on merit, competence, and performance. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We realize the full promise of diversity and want you to bring your whole self to work every single day.Research shows that underrepresented groups typically apply only if they meet 100% of the criteria listed. At Brightside, we are dedicated to fair play and encourage women, people of color, and LGBTQ+ job seekers to apply for positions even if they don’t check every box for the role.We know that diversity makes for the best problem-solving and creative thinking, and are committed to equity and inclusion. We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for. We’re an Equal Opportunity Employer and do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, age, religion, disability, national origin, protected veteran status, or any other status protected by applicable federal, state, or local law.Powered by JazzHRvPVWJtptOO\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job Description:- Must To Have Skills Python  Pandas  Data Analysis  Tableau  For more information please reachout Aslam aslam@dantatechnologies.net.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Machine Learning EngineerLocation: San Francisco, CAType: Full TimeAbout This RoleYou will build the machine learning systems that power our general artificial intelligence for capital allocation. We are looking for researchers who want to discover elegant deep learning concepts and then put them into production as solutions to high-stakes, real-world problems.Ideal candidate traits3+ years of professional experience as a software engineer or machine learning researcherHistory of generating new ideas in AI, evidenced by published works or personal projectsExceptional engineering abilities, with a track record of putting complex systems into productionResearch leadership skills, with the capacity to own projects end-to-end, from idea generation through executionEnergized by fast-paced, intense work environmentsExceptional independence of thought and grittiness in the pursuit of success\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'SOCOM CDO – Tampa, FL – Top Secret Clearance RequiredSTEMBoard is seeking a data scientist with knowledge in programming for integrating complex models and using advanced software library frameworks to distribute large, clustered data sets. The data scientist work with a team of data scientists and engineers that collect and arrange data in a form that is useful for analytics. A knowledge of machine learning is also desired to build efficient and accurate data pipelines to meet the needs for downstream users such as data scientists to create the models and analytics that produce insight.Principal Duties and Responsibilities:Play a crucial role in building out the Data Steward program by developing data governance standards.Research, design, and implement algorithms to solve complex problems. Program using R, Python (NumPy, SciPy, Pandas) or similar analytical languages. Conduct large-scale data processing and perform statistical modeling and create data visualizations using products like Tableau, Microsoft Power BI and R Shiny. Perform data engineering, data processing and modeling techniques using cloud-based data management, data science, and ML platforms such as Databricks, IBM Cloud Pak, Cloudera, and Snowflake.Communicate complex concepts and hypothesis to a non-technical audience through digital storytelling.Developing, maintaining, and testing infrastructures for data generation to transform data from various structured and unstructured data sources.Create standards and process for developing data sciences projects to solve IC-related problems.Design and implement process for implementing an optimal data pipeline architecture.Interpret and analyze data using exploratory mathematic and statistical techniques.Coordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data.Work withing an Agile framework and utilize Git Repositories.Experiment against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges.Coordinate with Data Engineers to build Data environments providing data identified by other data professionalsApply and develop scientific methodology, statistics and algorithms to discover and frame relevant problems, hypotheses, and opportunities.Develop predictive and prescriptive modeling, natural language processing (NLP), Robotic Process Automation (RPA), text mining and processing, clustering, forecasting methods, and other advanced statistical techniques.Design and automate processes to facilitate the manipulation and analysis of data.Requirements Experience: 1+ years of experience with software engineering, data science or related experience.  Education: Bachelors or degree in STEM with a preference towards Data Science, Computer Science, or Software Engineering. Tools: Python, SQL, R, R Shiny, AWS, or related toolsDoD Security Clearance, minimum of TOP SECRET levelBenefitsHealthcare, Vision, and Dental Insurance20 Days of PTO401K MatchingTraining/Certification ReimbursementShort term/Long term disabilityParental/Maternity LeaveLife InsuranceSTEMBoard is committed to hiring and retaining a diverse workforce. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information. Selected applicant will be subject to a background investigation. STEMBoard is an Equal Opportunity/Affirmative Action employer.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Masters's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in the programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At QuantAQ, our mission is to mitigate global air pollution.As a company, we value the role that fundamental scientific and engineering research play in developing new technologies while doing so with the knowledge that what we build must scale if we want to meet our goals.At QuantAQ, we provide access to professional-grade air quality data to a variety of clients (including research, government, and the private sector) to empower informed decision-making and to create cleaner (air) outcomes. We provide our clients with everything they need to build and manage distributed air quality sensor networks at scale including our proprietary air quality sensors (developed through years of R+D at MIT and Aerodyne Research) and our integrated software platform. We care deeply about using innovative technologies and socio-technological approaches to help businesses, governments, and community stakeholders obtain actionable air quality information across a variety of contexts.If you're looking for an opportunity that allows you to highlight your own skills and solve one of society's most pressing environmental challenges, we would love to hear from you. To learn more about QuantAQ, check out our Climatetech Summit video.About The RoleWe are looking for a full-time Data Scientist to join our rapidly growing team at QuantAQ. We’re a small startup with a rapidly expanding product-market fit, so as an individual contributor, you will quickly gain end-to-end ownership over multiple areas of the business. If that excites you, let’s talk!The ideal candidate is an experienced data scientist who is excited about the opportunity to apply their data science and machine learning skills to improve our category-leading air quality sensors and help reduce the negative impacts of air pollution. At QuantAQ, we gather a lot of air quality data and need to improve our tooling and operations for synthesizing this incoming data to make it as useful as possible for decision-makers to act upon. Over the past decade, we have published some of the most highly-cited and widely-used machine-learning methods for air quality sensors and sensor networks on topics ranging from models for improving individual sensor measurements (supervised regression models) to classifying types and sources of pollution (unsupervised classification methods). You will help develop and improve novel approaches to measuring and locating sources of air pollution and help push those models from ideation to production for our global fleet of air quality sensors. If this sounds appealing, we would love to hear from you.This position is remote-friendly, with options to work hybrid or in-person in Somerville, MA, or San Francisco, CA.ResponsibilitiesIn this position, you will work directly with and report to the CEO, who is currently responsible for overseeing all data science efforts. Responsibilities of this position include:Develop internal and external tools and pipelines to help evaluate the continuous success of our fleet of sensorsApply statistical methods to determine failure rates and lifetimes of key sensor componentsDesign, develop, and grow data sets that enable a better understanding of our sensor performancePartner closely with product and engineering to identify and prioritize the most important data science projectsDevelop and maintain customer-facing data science tools to help customers and the broader scientific community use air quality data and air quality sensors Stay up to date with the machine learning literature, especially for its applications to air quality sensors and sensor networks, and quickly prototype ideas from the research fieldProvide data science customer support from time to time when neededDevelop and execute re-usable playbooks for common customer-facing data science needs (i.e. pilot project evaluation)QualificationsCandidates need not meet all requirements below, but the more that you meet, the better match you may be for existing work. Learning new tools on the fly is expected, and hopefully part of the fun.A Ph.D. or M.S. in a quantitative field such as statistics, applied math, environmental science, computer science, operations research, or relevant work experience combining domain expertise and rigorous quantitative methods2+ years of industry experience in a data science or analytics roleExpert knowledge in Python and the Python data science and machine learning ecosystem (i.e., pandas, scikit-learn, PyTorch, TensorFlow, etc) and proficiency in SQLProficiency in data visualizationExpertise in statistics and experimental designA demonstrated ability to manage and deliver on multiple projects with high attention to detailFamiliarity with cloud tooling for machine learning at scaleExcellent verbal and written communication skills and the ability to communicate clearly and effectivelyStrong organization skills and the ability to work effectively in a team environmentAbility to challenge assumptions and think independently while executing quicklyUS work authorizationCompensation And BenefitsCompensation for this position is competitive for Seed-stage companies in the Boston area. Benefits at QuantAQ include:Health insurance with 85% company contributionDental, vision, and life insurance401(k) with partial company matchFlexible vacation time3 weeks PTO + 10 observed Federal holidaysFlexible work hoursParticipation in QuantAQ’s profit-sharing planLocationQuantAQ is based out of Greentown Labs in Somerville, MA. Greentown Labs is the largest climate tech incubator in North America and includes an awesome community of mission-driven entrepreneurs. Greentown offers numerous networking opportunities and events that cover a variety of topics. We love working out of Greentown Labs!How to ApplyDoes this role seem like a good fit? Are you interested in learning more? Email us at join@quant-aq.com for more information. Otherwise, please apply using the provided form.QuantAQ values diversity of thought, access, and experiences and is an Equal Opportunity Employer → individuals seeking employment with us are considered without regard to race, color, religion, national origin, age, sex, marital status, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by law.Compensation Range: $109K - $147K\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in the programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About The CompanyBloomfield is a plant imaging platform shaping the future of precision agriculture. We scan farms and vineyards at scale (capturing high resolution imagery and other sensor data), analyze every plant, and derive actionable intelligence to help growers be more efficient and productive. We collaborate with a variety of movement platform companies, from ATV and tractor manufacturers to robotics startups.About The RoleThe Data Scientist will work closely with our Machine Learning and Product teams to transform phenotypic information into data products that can be used by our grower-partners to manage their operations.ResponsibilitiesWork closely with our AI, Product, and Engineering teams to deliver phenotypic analysis to our customersBuild frameworks to quantitatively and qualitatively describe plant behavior of specialty crops Interface with engineering team to integrate developed algorithms into product pipelineRequirementsStrong knowledge of plant physiology and/or plant development at the whole plant and molecular levels. Familiarity with plant responses to biotic and abiotic stress is a plusDemonstrated ability to independently design, conduct, and interpret experiments including the use of appropriate statistical methodsDegree in Plant Sciences, Agricultural Engineering, Plant Breeding and Crop Protection, Biology, or similar fieldProgramming languages: PythonNice to havesExperience with high-throughput phenotypingExperience using sensor data in an agricultural environmentAdvanced Degree in Plant Sciences, Agricultural Engineering, Plant Breeding and Crop Protection, Biology, or similar fieldWhat We OfferIn addition to the opportunity to apply and develop your skills toward key business objectives, we offer an excellent compensation package including:Competitive base salaryMedical, dental and vision insurance401(k) retirement plan with company matchUnlimited PTO Parental Leave Incentive stock optionsTraining & Development StipendBloomfield is an equal opportunity employer. We consider qualified applicants without regard to race, color, religion, sex, national origin, sexual orientation, disability, gender identity, protected veteran status, or other protected classes.Powered by JazzHRvdiZ24ZLKF\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionAetna Resources LLC, a CVS Health company, is hiring for the following role In New York, NY: Data Scientist to develop and implement analytics applications and models to transform data into meaningful information. Duties include: design and develop data solutions using industry leading tools, technologies and best practices to profile data and develop efficient ingestion by sourcing data from PBM, Specialty, Retail, and/or HealthCare business; develop advanced algorithms and statistical predictive models to evaluate scenarios, predict outcomes, and provide usable information on health metrics and potential future outcomes; utilize data mining, data modeling, natural language processing, and machine learning to extract and manipulate data from multiple large data sources and deliver predictive models that inform solutions for in-house teams (i.e. pharmacy pricing, medical costs, risk scores, onboarding) and customer engagement across critical journeys (i.e. calories, heart rate, breast cancer, maternity); utilize data-oriented programming languages and visualization software to explore, analyze, and interpret large volumes of data in various forms and solve complex business problems; visualize and interpret data and create reports, manipulate data using statistical software, and compare models using statistical performance metrics; and support deployment of insights across multiple channels using analysis methods, machine learning, and statistical analyses. Multiple openings.Pay RangeThe typical pay range for this role is:Minimum: $ 141,022.00Maximum: $ 141,022.00Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required QualificationsMaster’s degree (or foreign equivalent) in Computer Science, Data Science, Statistics, Mathematics, Analytics, Operations Research, or a related field and two (2) years of experience in the job offered or related occupation. Requires two (2) years of experience in each of the following: Analyzing large data sets from multiple data sources; Data analysis for health care industry, products, or systems; Machine learning, statistical analysis, and predictive modeling; Programming in R, Hadoop, Python, or SQL; Visualization tools, including PowerBI or Tableau; “Big data” platforms including Hadoop (Azure, GCP, or AWS); Designing data models and solutions for analytical and reporting use cases; and Machine Learning or NLP (Scikit-Learn, SpaCity, Pytorch, or Spark NLP).Preferred QualificationsSee Required Qualifications.EducationSee Required Qualifications.Business OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Machine Learning Engineer , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job Requirements2 years of experience, or an advanced degree (MSc).Experience in applied Deep Learning (DL) and Computer Vision (CV) concepts including but are not limited to: CNNs, RNNs, Autoencoders, Transfer Learning.Hands-on experience (academic and/or industrial) in 3D Pose Estimation and Motion reconstruction from images and videosProficiency in general purpose programming languages: Python, and C++.Experience with ML frameworks such as: PyTorch, Tensorflow, etc.The ideal candidate would be very well acquainted with Computer Graphics techniques, Neural Rendering, and Numerical Optimization(Optional) Knowledge of 3D packages such as Blender, Maya, or any game engine technologyBSc in Computer Science, Mathematics, Electrical Engineering, or related technical field.Ability to speak and write in English fluently and idiomatically.Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatment.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We’re on a missionAt Octaura, we continually evolve markets to unleash value for clients. It’s in our DNA to make a difference and do things differently.Existing workflows within our markets are painful for clients: they are outdated, overcomplicated, and time-consuming. We want to change that. Octaura fundamentally rebuilds and redefines the markets by streamlining workflows, digitizing platforms, and bringing transactions, data and analytics together for the first time.Join our inclusive cultureAt Octaura, everyone belongs.It’s so important to us that all Octaurians are confident in knowing they have the space to use their voice and talents. We love the diversity we see in the world and we actively want our team to reflect this. We’re a values-driven company and by engaging, solving and evolving together, we create a culture that is collaborative, switched-on, and fun to be part of.The role in a nutshellOur mission is to provide our customers with cutting-edge solutions that empower them to achieve their financial goals. We are seeking a highly motivated and talented individual to join our team as a Data Scientist.As a Data Scientist, you will work closely with our team to build the infrastructure for predictive modeling. You will be responsible for developing and implementing statistical models and algorithms to extract insights from large and complex data sets, and for building a cloud-based architecture. As part a startup, you will have the opportunity to take on a high level of responsibility and make a meaningful impact, as well as learn about different aspects of the business.Core responsibilitiesBuild predictive models using machine learning algorithms Develop and implement statistical models to extract insights from large data sets Design, build and maintain cloud-based infrastructure using AWS and/or Azure Work closely with cross-functional teams to design and implement data-driven solutions Analyze and interpret complex data sets to provide insights to stakeholders Develop and maintain data processing pipelines Perform ad-hoc analysis and present findings to key stakeholdersDesired qualificationsPhD/MSc in technical majors such as computer science, statistics, mathematics, physics or related fields Strong programming skills in Python and AI packages. Experience in building predictive models using machine learning algorithms Strong analytical skills with the ability to analyze and interpret complex data sets Excellent written and verbal communication skills Ability to work collaboratively in a team environmentExperience in cloud-based architecture using AWS and Azure (preferred)If you are passionate about data science in finance, have a strong background in technical majors, and are excited about building predictive models and cloud-based infrastructure using AWS and Azure, we want to hear from you. As a startup, we offer a dynamic and entrepreneurial work environment, where you will have the opportunity to take ownership of your work and make a real impact on our business.The base pay range for this position in New York is $150,000 - $175,000 annually. Pay may vary depending on job-related knowledge, skills, and experience. Equity and year-end bonus may be provided as part of the compensation package, in addition to a full range of medical, financial, and other benefits, dependent on the position offered. Applicants should apply via Octaura's internal or external careers site.We’re committed to equal opportunity employmentOctaura is committed to a diverse and inclusive workplace. We are an equal opportunity employer and do not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Position: Data ScientistLocation: Elk Grove, CA (Day 1st Onsite)ContractThe data scientist role willUse SQL to access data and build tablesUse topic modeling (or a similar NLP methodology) to process survey commentsUse Tableau to share results of NLP modelingPSRTEK is a reputed technology recruitment and IT staffing brand with a global footprint and an admired client base. As an ideas and innovation powerhouse with a culture of excellence, we bring remarkable expertise and deliver powerfully transformative results.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Mission:VerAI is committed to accelerating the global zero-carbon transformation by discovering the minerals essential for our sustainable future. In the last two decades, the minerals exploration industry underperforms with a very low rate of discovery success, failing to supply the massive demand for these critical commodities. We are disrupting the Mineral Exploration Industry by deploying a revolutionary Artificial Intelligence Platform that detects concealed mineral deposits. The world awaits a revolutionary change, and the unique conditions we have created for success allow VerAI to lead a vital paradigm shift in the way mineral discoveries are made.We are well funded by strong financial and strategic investors, including funds and accounts advised by T. Rowe Price Associates, Inc., Orion Resources Partners, a global mineral asset management firm; Chrysalix Capital, which specializes in transformation industrial innovation, mining and its direct contribution to the global Clean Energy transition; and Blumberg Capital, which brings extensive experience in successfully applying AI solutions to different verticals and industries. www.ver-ai.comOur Culture: Why work with us?Our most valuable resource is our people--with a diversity of backgrounds, ideas, opinions, and life experiences. We have built a multidisciplinary and multicultural environment. We admire people who have original thinking and sound judgment. We hire outcome-oriented people who are comfortable with uncertainty. Our culture is filled with people who are positive, passionate, constructive, and success-oriented. Our employees are willing – and enjoy- expanding outside their comfort zones.Our leaders are transparent, accessible, authentic, and invest in their employees. There’s a dedication to one another that’s palpable. We are not your typical 100-hour-a-week grinding start-up. We believe in allowing our employees to have flexible hours and giving them the time needed to balance family/hobbies and work.We are a remote-only US-based company and are currently deploying our AI Minerals Targeting Platform in the Americas.What’s in it for you:Innovation: You will be provided with an amazing opportunity to work on state-of-the-art ML/AI technologies in a company that truly believes in innovation and continuous improvement. We take pride in our technology, and in leveraging this technology to disrupt the Mineral Exploration world. The challenge of finding minerals undercover is real and very hard – and you will have the opportunity to be part of the team that solves it!Influence: You will have a huge influence on how data science is done at VerAI, and you will help pave the way for future generations of our AI-based mineral discovery technology. Your experience and knowledge will impact everything from our developer environment, algorithms, cloud infrastructure, data visualization and so much more.Positive global impact: You will work on a product that has a direct positive impact on the world. Every pipeline improvement and mineral deposit we help find brings us one small step closer to a fossil fuel-free world.Salary range: $150,000-$170,000/yrLocation: Home-based, remote-only (At this time only seeking Colorado residents)Benefits: We offer excellent benefits: Unlimited PTO, Health and Dental Insurance, 401K Match, Stock Options, and more!A day in the life of this role:As our Data Scientist, you will play a crucial role in designing, developing, and implementing the VerAI AI/ML Mineral Targeting Platform. This Platform is at the core of our innovation, and a critical part of our ability to generate high-quality AI Targets that represent the location of concealed economic mineral deposits.You will assume full accountability for operating the Targeting Platform and will have a lot of freedom to continuously improve and enhance its capabilities. Your passion is being hands-on, but also designing and planning different aspects of our Machine Learning pipeline. You love collaborating with different teams and domains and are not afraid of getting your hands dirty with new data sets, technologies, or methodologies.You will help VerAI maintain a technological leadership in its domain and will represent us in the different data science communities and forums.What we need from you:Bachelor’s degree in computer science, applied mathematics, statistics, electrical engineering, or a related quantitative discipline.4+ years of relevant hands-on experience in Machine Learning/Statistical Analytics/Predictive Analytics in the image processing and analysis domain.Excellent understanding of machine learning techniques, algorithms, and methodologies.Extensive experience in Python programming language.Extensive experience with data science frameworks (NumPy, scikit-learn, Pandas, Keras, etc.)Experience with using and administrating cloud infrastructure and web services like AWSAttributes that will make you successful at VerAI:You are trustworthy, responsible, independent, take ownership, and delivers results.You have unquestionable integrity, credibility, and character. You have demonstrated high moral and ethical behavior.You are willing to embrace challenges, and you are comfortable with uncertainty and complex decision-making.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'About Us\\xa0\\xa0DeepLogica is a proprietary AI platform that empowers clients’ existing processes and systems to redefine eCommerce delivery. We utilize machine learning models to accurately predict supply chain events, provide actionable business insights and ultimately enhance the buying experience.\\xa0\\xa0About The Role\\xa0\\xa0We’re looking for a talented Data Scientist who is passionate about data, learning, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\\xa0A varied skill set, creativity, flexibility, and positive team attitude are high priorities. \\xa0Main Responsibilities\\xa0\\xa0In collaboration with the other members of your team and your supervisor you will be in charge or participate in the following activities:\\xa0Collecting, cleaning, and transforming large datasets for downstream processing.\\xa0Design accurate and scalable prediction algorithmsDevelop statistical and machine learning models to extract insights and predictions from data.\\xa0Visualize and present findings to stakeholders in a clear and concise manner.\\xa0Collaborate with cross-functional teams to identify business problems that can be solved using data.\\xa0Design experiments to test hypotheses and improve models.\\xa0Assist Data Engineering team members in building and deploying data pipelines and scalable infrastructure to support data analysis.\\xa0Ensure ethical use of data and compliance with privacy regulations.\\xa0Continuously monitor and evaluate the performance of models and adjusting as needed\\xa0Required Education, Qualifications and Experience\\xa0Bachelors or Masters degree in operations research, computer science, software engineering, or a related field\\xa0\\xa02-3 years of experience in quantitative analytics of data modeling.\\xa0Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)Passionate self-starter, able to prioritize tasks and manage time effectively.\\xa0Ability to take ownership of tasks to ensure high quality and successful on-time completion.\\xa0\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Allozymes is a deep tech company based in Singapore. We are revolutionising the way industry uses enzymes for manufacturing chemicals and natural compounds. Our rapid discovery and evolution of custom-designed enzymes enables breakthrough developments for sustainable production of ingredients for pharmaceuticals, cosmetics, chemical, food and beverages.We’re hiring a highly capable Machine Learning Engineer into our Data team. This team is responsible for developing and implementing state-of-the-art approaches for evolving enzymes and microbes to enhance the production of chemicals and natural compounds. The engineer will integrate the development of our cloud-based artificial intelligence platform for enhancing Allozymes’ enzyme optimization capabilities. Working in a highly collaborative and dynamic environment, this role has the opportunity to interact with other scientists, automation and process engineers to achieve these goals. Responsibilities:Contribute to the design and improvement of Allozymes cloud-based AI platform.Scope project requirements, assess data quality, process data and perform feature engineering.Build, train and deploy ML/DL models, using state-of-the-art technologies and proprietary data to accurately perform predictions and generate new, high performing, enzymes.Perform model evaluation and statistical analysis to improve model quality.Enhance the performance and deployment environment of implemented solutions.Qualifications:MS or PhD in mathematics, statistics, computer science, engineering or a related quantitative field with a focus on AI and Machine Learning.2+ years of relevant industry experience.Expertise in building, training and deploying Machine and Deep Learning models.Proficiency in Python.Expertise in using ML/DS specific python libraries (Pandas, Numpy, Scipy, Scikit-learn, PyTorch, Keras).Experience with ML life-cycle management and code/data version control tools.Familiarity working with Cloud computing.Ability to work in a fast-paced, collaborative and cross-functional environment and communicate results effectively to management.Experience with supervised and unsupervised learning algorithms, clustering, feature selection methods, evaluation, dimensionality reduction, Bayesian inference, hyper-parameter tuning and model optimization is a plusExperience with Language models, Encoders, Transformers, Attention, Generative models and GANs is a plusExperience in biology, bioinformatics or computational biology.Experience using AWS/SageMaker is a plusExperience with containers and container orchestration tools is a plusExperience writing production-ready code (version-controlled, scalable, well-documented, testable, deployment-ready) is a plusNumber of Vacancies: 1\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and that to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Ideal candidate traits🧠 Previously scaled ML systems to 1M + users📑 Willing to go deep in the weeds on research & development⚙️ Cares a Ton About How Backend Systems Work💨 Has worked on large systems but executes like a startup, fast, ships and iteratesPowered by JazzHRkSUPOAkuhD\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'You’ll be the founding data scientist in a well-funded company looking to define Web 3 user identity and attribution.We plan on running a lean team: expect to totally own your area of responsibility and use your initiative and judgement to keep your part of Spindl running and growing.Be comfortable with being uncomfortable. You will be creating the metrics and methodologies that will define an entire industry within Web 3. There won’t be easy answers for most of what we do. We’re already making it up as we go along.Speed is a feature, in teams, products, and people: keep up with the Spindl pack. There isn’t a moment to lose.We’re looking for pirates now that Web 2 has become the navy.ResponsibilitiesBe a leader within a very flat and fast-moving teamUnderstand the often weird and hacked-together blockchain world, as well as the embryonic data stack being built on top of itNavigate the idea maze toward Truth (or something like it)Plot the critical curve or generate the essential dashboard that helps us understand Web 3. Creatively address business problems when there are no precedents and no clear answersWork with engineering to implement your findings and models into running product quickly. You are mapping the unknown terrain; we want to turn that into industry knowledge ASAP. Empathize with our customers, understand their worldview, and work with the UI team to translate your insights into customer insights. Convey your findings to colleagues; tell a story with data convincingly. Optionally, publish your work publicly will full credit. Must haves (this is an AND)N years doing data science or analysis (for reasonable N). Proficiency with data visualization and dashboarding tools like Looker or Tableau. Think those suck? Tell us why. Ideally, this would involve more than just descriptive dashboarding and extend into some predictive model-building around complicated ecosystems like markets or user behavior online. Experience with modeling in Python: Jupyter, Pandas, PyTorch, numpy, scipy, etc. Exception to the above: Outstanding familiarity with blockchains and protocols and their often quirky data, along with extensive experience in environments like Dune or Flipside, can compensate for a lack of more traditional data science experience. If you’re the #3 person on the Dune leaderboard, let’s talk. Be smart and get shit done. Be a doer and a risk-taker. Nice to haves (this is an OR)Experience with advertising technology or campaign management within Web 2 adsExperience with A/B testing and experimentationExperience in anti-fraud, either within ad tech or fin tech. There are lots of bad guys to block in Web 3. LocationYou can be located anywhere in the world, but we have a strong preference for SF or NYC. If you’re not in either city, expect some travel to work face-to-face with colleagues on a semi-regular basis. If you’re in one of those cities, you’ll find a balance between coming into the office and not. We think in-person work possesses a magic for early stage startups, something unobtainable in a fully remote environment where co-workers are simply images on a screen.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Senior Data Scientist - Brightside Health - 100% Remote in U.S.Brightside Health delivers life-saving virtual mental healthcare to everyone who needs it. We are powered by proprietary AI, purpose-built technology, a world-class clinician network, and a care model that rivals the best of in-person treatment. When combined with precision psychiatry and leading-edge therapeutic techniques, we’re able to improve outcomes for those with mild-to-severe clinical depression, anxiety, and other mood disorders.We take an action-oriented, purposeful approach with everything we do and seek out team members who value collaboration and thoughtful prioritization. As a result, our organization is looking for the brightest and most innovative talent in the industry. We can promise you that, as a member of the Brightside team, you’ll have the opportunity to collaborate alongside smart and driven people while growing your professional skills.We are seeking a talented and experienced Senior Data Scientist to join our team. As a Senior Data Scientist, you will be responsible for developing and implementing advanced analytical and machine learning models that drive business value and support the experience of Brightside Health’s patients, clinicians, and internal teams.What you’ll be doing as a Senior Data Scientist:Design, develop, and deploy advanced analytic and machine learning models to explain or predict the behavior, experience and outcomes of patients, clinicians, and the businessCollaborate with cross functional teams to identify opportunities for data-driven decision making and translate business objectives into data science problems, and vice versaCommunicate complex data science concepts, ideas and results to technical and non-technical stakeholdersContribute to developing core data science and machine learning frameworks that shape the Data organizationRequirements:At least 4 years of relevant data science, analytics or machine learning professional experienceExperience in data engineering and feature preparationExperience in developing machine learning models using a variety of techniques (including regression, classification, clustering, time series, NLP)Track record of successfully developing and implementing ML modelsExperience working with large datasets (healthcare-relevant datasets are a plus)Interest in being an early DS/ML team member, with the technical ability to develop high value models independently while prioritizing collaboration with your teammates and stakeholders to ensure successful design and implementationMotivated to build relationships with teammates and stakeholders, and increase data literacy and expertise throughout the organizationPassionate about improving healthcareBonus: experience working with large healthcare or healthcare related data setsTools we use:Python, including common ML packages like NumPy, Scikit-Learn, Pandas, Tensorflow, etc.AWS and GoogleCloud environmentsSQLGitHubBenefits:A competitive salaryStock options so you have equityFully paid for comprehensive health care (medical, dental, vision)Pet Insurance Life Insurance & Short / Long Term Disability 401k Plan Unlimited PTO and sick leaveParental Leave Work remotely and whatever schedule works best for youAdditional memberships and perksFinal offer amounts are determined by multiple factors including geographic location as well as candidate experience and expertise. If you have questions on compensation bands, please ask your recruiter.Brightside Health is committed to equal employment opportunities for all team members. Every decision we make regarding employment is solely based on merit, competence, and performance. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We realize the full promise of diversity and want you to bring your whole self to work every single day.Research shows that underrepresented groups typically apply only if they meet 100% of the criteria listed. At Brightside, we are dedicated to fair play and encourage women, people of color, and LGBTQ+ job seekers to apply for positions even if they don’t check every box for the role.We know that diversity makes for the best problem-solving and creative thinking, and are committed to equity and inclusion. We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for. We’re an Equal Opportunity Employer and do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, age, religion, disability, national origin, protected veteran status, or any other status protected by applicable federal, state, or local law.Powered by JazzHRvPVWJtptOO\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Machine Learning EngineerLocation: San Francisco, CAType: Full TimeAbout This RoleYou will build the machine learning systems that power our general artificial intelligence for capital allocation. We are looking for researchers who want to discover elegant deep learning concepts and then put them into production as solutions to high-stakes, real-world problems.Ideal candidate traits3+ years of professional experience as a software engineer or machine learning researcherHistory of generating new ideas in AI, evidenced by published works or personal projectsExceptional engineering abilities, with a track record of putting complex systems into productionResearch leadership skills, with the capacity to own projects end-to-end, from idea generation through executionEnergized by fast-paced, intense work environmentsExceptional independence of thought and grittiness in the pursuit of success\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'SOCOM CDO – Tampa, FL – Top Secret Clearance RequiredSTEMBoard is seeking a data scientist with knowledge in programming for integrating complex models and using advanced software library frameworks to distribute large, clustered data sets. The data scientist work with a team of data scientists and engineers that collect and arrange data in a form that is useful for analytics. A knowledge of machine learning is also desired to build efficient and accurate data pipelines to meet the needs for downstream users such as data scientists to create the models and analytics that produce insight.Principal Duties and Responsibilities:Play a crucial role in building out the Data Steward program by developing data governance standards.Research, design, and implement algorithms to solve complex problems. Program using R, Python (NumPy, SciPy, Pandas) or similar analytical languages. Conduct large-scale data processing and perform statistical modeling and create data visualizations using products like Tableau, Microsoft Power BI and R Shiny. Perform data engineering, data processing and modeling techniques using cloud-based data management, data science, and ML platforms such as Databricks, IBM Cloud Pak, Cloudera, and Snowflake.Communicate complex concepts and hypothesis to a non-technical audience through digital storytelling.Developing, maintaining, and testing infrastructures for data generation to transform data from various structured and unstructured data sources.Create standards and process for developing data sciences projects to solve IC-related problems.Design and implement process for implementing an optimal data pipeline architecture.Interpret and analyze data using exploratory mathematic and statistical techniques.Coordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data.Work withing an Agile framework and utilize Git Repositories.Experiment against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges.Coordinate with Data Engineers to build Data environments providing data identified by other data professionalsApply and develop scientific methodology, statistics and algorithms to discover and frame relevant problems, hypotheses, and opportunities.Develop predictive and prescriptive modeling, natural language processing (NLP), Robotic Process Automation (RPA), text mining and processing, clustering, forecasting methods, and other advanced statistical techniques.Design and automate processes to facilitate the manipulation and analysis of data.Requirements Experience: 1+ years of experience with software engineering, data science or related experience.  Education: Bachelors or degree in STEM with a preference towards Data Science, Computer Science, or Software Engineering. Tools: Python, SQL, R, R Shiny, AWS, or related toolsDoD Security Clearance, minimum of TOP SECRET levelBenefitsHealthcare, Vision, and Dental Insurance20 Days of PTO401K MatchingTraining/Certification ReimbursementShort term/Long term disabilityParental/Maternity LeaveLife InsuranceSTEMBoard is committed to hiring and retaining a diverse workforce. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information. Selected applicant will be subject to a background investigation. STEMBoard is an Equal Opportunity/Affirmative Action employer.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'To get considered for this position, you have to answer the following questions and send them to adam.mohammed@clinovo.com along with your resume.1) Which RWE data lake and platforms you have used and for how many years? 2) How many years of experience working on healthcare claim data and EMR data and conducting a variety of analyses to generate RWE related to Client medical products? 3) Experience in advanced analytics and statistical models in analyses of real- world data (RWD)? 4) Do you have experience in transforming RWD into actionable RWE? 5) Experience in RWD data, including medical claims data, electronic medical records, chargemaster data, de-identified patient-level data, and prescription data? 6) Visualize data to effectively present data insight and business intelligence? 7) Experience with administrative claims or EMR Data? 8) Familiarity with US and Global health care delivery systems (e.g. payers and reimbursement models)? 9) Experience in the healthcare industry across multiple therapeutic areas, medical reimbursement, and technical expertise in clinical outcomes and economic evaluations? 10) Do you have Experience with developing econometric and statistical models such as regression models, mixed models, interrupted time series analysis, survival analysis, propensity score matching, and non-parametric models? How many years? 11) Proficiency in Programming skills with R or Python on a Scale of 10? 12) Do you have experience in Data lake analytical platforms? 13) Experience in data visualization tools and techniques (matplotlib, seaborn, SAS graph, etc.)14) Experience in machine learning or/and deep learning?\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Masters's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in the programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At QuantAQ, our mission is to mitigate global air pollution.As a company, we value the role that fundamental scientific and engineering research play in developing new technologies while doing so with the knowledge that what we build must scale if we want to meet our goals.At QuantAQ, we provide access to professional-grade air quality data to a variety of clients (including research, government, and the private sector) to empower informed decision-making and to create cleaner (air) outcomes. We provide our clients with everything they need to build and manage distributed air quality sensor networks at scale including our proprietary air quality sensors (developed through years of R+D at MIT and Aerodyne Research) and our integrated software platform. We care deeply about using innovative technologies and socio-technological approaches to help businesses, governments, and community stakeholders obtain actionable air quality information across a variety of contexts.If you're looking for an opportunity that allows you to highlight your own skills and solve one of society's most pressing environmental challenges, we would love to hear from you. To learn more about QuantAQ, check out our Climatetech Summit video.About The RoleWe are looking for a full-time Data Scientist to join our rapidly growing team at QuantAQ. We’re a small startup with a rapidly expanding product-market fit, so as an individual contributor, you will quickly gain end-to-end ownership over multiple areas of the business. If that excites you, let’s talk!The ideal candidate is an experienced data scientist who is excited about the opportunity to apply their data science and machine learning skills to improve our category-leading air quality sensors and help reduce the negative impacts of air pollution. At QuantAQ, we gather a lot of air quality data and need to improve our tooling and operations for synthesizing this incoming data to make it as useful as possible for decision-makers to act upon. Over the past decade, we have published some of the most highly-cited and widely-used machine-learning methods for air quality sensors and sensor networks on topics ranging from models for improving individual sensor measurements (supervised regression models) to classifying types and sources of pollution (unsupervised classification methods). You will help develop and improve novel approaches to measuring and locating sources of air pollution and help push those models from ideation to production for our global fleet of air quality sensors. If this sounds appealing, we would love to hear from you.This position is remote-friendly, with options to work hybrid or in-person in Somerville, MA, or San Francisco, CA.ResponsibilitiesIn this position, you will work directly with and report to the CEO, who is currently responsible for overseeing all data science efforts. Responsibilities of this position include:Develop internal and external tools and pipelines to help evaluate the continuous success of our fleet of sensorsApply statistical methods to determine failure rates and lifetimes of key sensor componentsDesign, develop, and grow data sets that enable a better understanding of our sensor performancePartner closely with product and engineering to identify and prioritize the most important data science projectsDevelop and maintain customer-facing data science tools to help customers and the broader scientific community use air quality data and air quality sensors Stay up to date with the machine learning literature, especially for its applications to air quality sensors and sensor networks, and quickly prototype ideas from the research fieldProvide data science customer support from time to time when neededDevelop and execute re-usable playbooks for common customer-facing data science needs (i.e. pilot project evaluation)QualificationsCandidates need not meet all requirements below, but the more that you meet, the better match you may be for existing work. Learning new tools on the fly is expected, and hopefully part of the fun.A Ph.D. or M.S. in a quantitative field such as statistics, applied math, environmental science, computer science, operations research, or relevant work experience combining domain expertise and rigorous quantitative methods2+ years of industry experience in a data science or analytics roleExpert knowledge in Python and the Python data science and machine learning ecosystem (i.e., pandas, scikit-learn, PyTorch, TensorFlow, etc) and proficiency in SQLProficiency in data visualizationExpertise in statistics and experimental designA demonstrated ability to manage and deliver on multiple projects with high attention to detailFamiliarity with cloud tooling for machine learning at scaleExcellent verbal and written communication skills and the ability to communicate clearly and effectivelyStrong organization skills and the ability to work effectively in a team environmentAbility to challenge assumptions and think independently while executing quicklyUS work authorizationCompensation And BenefitsCompensation for this position is competitive for Seed-stage companies in the Boston area. Benefits at QuantAQ include:Health insurance with 85% company contributionDental, vision, and life insurance401(k) with partial company matchFlexible vacation time3 weeks PTO + 10 observed Federal holidaysFlexible work hoursParticipation in QuantAQ’s profit-sharing planLocationQuantAQ is based out of Greentown Labs in Somerville, MA. Greentown Labs is the largest climate tech incubator in North America and includes an awesome community of mission-driven entrepreneurs. Greentown offers numerous networking opportunities and events that cover a variety of topics. We love working out of Greentown Labs!How to ApplyDoes this role seem like a good fit? Are you interested in learning more? Email us at join@quant-aq.com for more information. Otherwise, please apply using the provided form.QuantAQ values diversity of thought, access, and experiences and is an Equal Opportunity Employer → individuals seeking employment with us are considered without regard to race, color, religion, national origin, age, sex, marital status, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by law.Compensation Range: $109K - $147K\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and that to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Ideal candidate traits🧠 Previously scaled ML systems to 1M + users📑 Willing to go deep in the weeds on research & development⚙️ Cares a Ton About How Backend Systems Work💨 Has worked on large systems but executes like a startup, fast, ships and iteratesPowered by JazzHRkSUPOAkuhD\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'HiSatyam this side. We do have a new an excellent opportunity for you. This opportunity is a full time onsite position as Data Scientist.  Please have a look at the job description below and let me know if you or someone you know is interested in this role. You can mail me at satyam@extendinfosys.com.Job Title Data ScientistLocation Santa Clara, CAJob Type Full TimeJob DescriptionData Scientist -- Computer Vision Solid knowledge of various Image Filtering, Binary Morphology, Perspective / Affine transformation, Edge Detection, and Tracking. Machine Learning: Regression, Unsupervised Learning, PCA Nice but not necessary to have HDR, Panorama, and deep Learning object detectionThanksSatyam Prajapati | Technical Recruiter| Extend Information SystemsCell: (571) 547-2880Email: satyam@extendinfosys.comAddress: 44258 Mercure Circle, UNIT 102 A, Sterling VA, USA - 20166Web:www.extendinfosys.com\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"About the Role:We are looking for a highly analytical, data obsessed Data Scientist to join our growing company. The ideal candidate will work cross functionally to develop, maintain and implement predictive models that will provide actionable insights to inform key business decisions. This role will sit within our Product Team and report to our Senior Director, Product Analytics.What you'll be doing:Think critically and leverage data to test and iterate on new product features and business strategiesDeﬁne and implement client usage, churn, retention, and other key metricsBuild and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scaleQuery databases from multiple marketing and product sources and create usable KPI dashboardsSetup analytical framework for user journeys and lifecycle marketing funnelsStatistical modeling:Support business objectives through statistical modeling through the prediction of main KPIs such as churn, retention and LTVDesign, implement and maintain machine learning models to automate and optimize marketing, operations, and customer experienceA/B testing and causal modelingCommunication & Teamwork:Collaborate with stakeholders across the companyFull-stack data science analysis and present insights to both the data science team and internal company stakeholders. Minimum Qualifications:Bachelor's degree in computer science, mathematics, data science, engineering or a closely related field2+ years as a Data Scientist (Business Intelligence) involving data extraction, analysis, and statistical modelingExcellent problem solving skills with keen attention to detail Ability to communicate complex data insights to both technical and non-technical audience, including senior leadership Experience in product, wellness or healthcare company preferred Evidenced proﬁciency in skills listed by at 3 months experience in each:Python, SQL, git, and common data science and machine learning libraries (pandas, sklearn, etc.)Understanding of data visualization best practices, proﬁcient with BI Platforms (Looker, Tableau)This role offers a remote and/or hybrid work environment, but we would prefer candidates located in the NYC and NJ area.Salary Range: $115,000 to $120,000 + equity & benefits. The base pay is one component of Nanit's total compensation package, which may also include access to healthcare benefits, a 401(k) plan, short-term and long-term disability coverage, and basic life insurance. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Entry Level Data Scientist with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ResponsibilityModelDesign, develop, deploy and improve production-grade near realtime scalable machine learning and statistical predictive models and NLP from near realtime call transcripts and utterancesDevelop novel algorithms and models using state-of-the-art techniques like deep learning neural networks (auto-encoders, feedforward networks, RNNs/CNNs, etc.) and NLP model architectures and algorithms such as BERT (and derivatives like BioBERT, RoBERTa, ALBERT etc.), BiLSTM, XLNet, T5, ELECTRA, PaLM and morePartner with cross-functional teams, understand problems, and identify opportunities where advanced analytics and machine learning techniques can be used to make a significant impact and then design, develop, deploy and monitor those ML solutionsDeploymentCapture and inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).Design, implement, deploy, and maintain deep learning and ML models using cloud technologies (e.g., Azure Databricks, MLFlows and Azure ML)Write production-ready modeling code that can be scaled out to 100 millions of calls and millions of usersCollaborationPromote deep scientific expertise, constant learning, attention to detail, and best practices while always being friendly, humble, and open to challenging any assumptionsCollaborate with data engineers, machine learning engineers, product managers and capability teams to coordinate timely deployments from conception to releasePromotes and integrates best practices in data science and adheres to established work standardsOtherResearch new machine learning solutions to complex business problemsCommunicate process, requirements, assumptions and caveats of advanced ML and NLP concepts and deliverables in laymen languages to non-technical business leadersExperienceBS, MS, or PhD in Computer Science, Statistics, Applied Mathematics, Data Science, Economics or related quantitative fields5+ years experience in designing, developing and deploying production-grade machine learning solutions (supervised, unsupervised, reinforcement learning), deep learning framework (e.g. TensorFlow, PyTorch, Keras, etc) and NLP (NLTK, Spark NLP, spaCy, HuggingFace, Flair, NLTK, etc) for real-world business problemsExpertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systemsDevelopment and ML experience in cloud platforms such as Microsoft AzureCombination of deep technical skills and business sense, to interface with all levels and disciplines within an organization.Excellent written and verbal communication skills to explain complex research to both technical and non-technical audiencesSelf-motivated individual that thrives in a dynamic environment\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'You’ll be the founding data scientist in a well-funded company looking to define Web 3 user identity and attribution.We plan on running a lean team: expect to totally own your area of responsibility and use your initiative and judgement to keep your part of Spindl running and growing.Be comfortable with being uncomfortable. You will be creating the metrics and methodologies that will define an entire industry within Web 3. There won’t be easy answers for most of what we do. We’re already making it up as we go along.Speed is a feature, in teams, products, and people: keep up with the Spindl pack. There isn’t a moment to lose.We’re looking for pirates now that Web 2 has become the navy.ResponsibilitiesBe a leader within a very flat and fast-moving teamUnderstand the often weird and hacked-together blockchain world, as well as the embryonic data stack being built on top of itNavigate the idea maze toward Truth (or something like it)Plot the critical curve or generate the essential dashboard that helps us understand Web 3. Creatively address business problems when there are no precedents and no clear answersWork with engineering to implement your findings and models into running product quickly. You are mapping the unknown terrain; we want to turn that into industry knowledge ASAP. Empathize with our customers, understand their worldview, and work with the UI team to translate your insights into customer insights. Convey your findings to colleagues; tell a story with data convincingly. Optionally, publish your work publicly will full credit. Must haves (this is an AND)N years doing data science or analysis (for reasonable N). Proficiency with data visualization and dashboarding tools like Looker or Tableau. Think those suck? Tell us why. Ideally, this would involve more than just descriptive dashboarding and extend into some predictive model-building around complicated ecosystems like markets or user behavior online. Experience with modeling in Python: Jupyter, Pandas, PyTorch, numpy, scipy, etc. Exception to the above: Outstanding familiarity with blockchains and protocols and their often quirky data, along with extensive experience in environments like Dune or Flipside, can compensate for a lack of more traditional data science experience. If you’re the #3 person on the Dune leaderboard, let’s talk. Be smart and get shit done. Be a doer and a risk-taker. Nice to haves (this is an OR)Experience with advertising technology or campaign management within Web 2 adsExperience with A/B testing and experimentationExperience in anti-fraud, either within ad tech or fin tech. There are lots of bad guys to block in Web 3. LocationYou can be located anywhere in the world, but we have a strong preference for SF or NYC. If you’re not in either city, expect some travel to work face-to-face with colleagues on a semi-regular basis. If you’re in one of those cities, you’ll find a balance between coming into the office and not. We think in-person work possesses a magic for early stage startups, something unobtainable in a fully remote environment where co-workers are simply images on a screen.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Senior Data Scientist - Brightside Health - 100% Remote in U.S.Brightside Health delivers life-saving virtual mental healthcare to everyone who needs it. We are powered by proprietary AI, purpose-built technology, a world-class clinician network, and a care model that rivals the best of in-person treatment. When combined with precision psychiatry and leading-edge therapeutic techniques, we’re able to improve outcomes for those with mild-to-severe clinical depression, anxiety, and other mood disorders.We take an action-oriented, purposeful approach with everything we do and seek out team members who value collaboration and thoughtful prioritization. As a result, our organization is looking for the brightest and most innovative talent in the industry. We can promise you that, as a member of the Brightside team, you’ll have the opportunity to collaborate alongside smart and driven people while growing your professional skills.We are seeking a talented and experienced Senior Data Scientist to join our team. As a Senior Data Scientist, you will be responsible for developing and implementing advanced analytical and machine learning models that drive business value and support the experience of Brightside Health’s patients, clinicians, and internal teams.What you’ll be doing as a Senior Data Scientist:Design, develop, and deploy advanced analytic and machine learning models to explain or predict the behavior, experience and outcomes of patients, clinicians, and the businessCollaborate with cross functional teams to identify opportunities for data-driven decision making and translate business objectives into data science problems, and vice versaCommunicate complex data science concepts, ideas and results to technical and non-technical stakeholdersContribute to developing core data science and machine learning frameworks that shape the Data organizationRequirements:At least 4 years of relevant data science, analytics or machine learning professional experienceExperience in data engineering and feature preparationExperience in developing machine learning models using a variety of techniques (including regression, classification, clustering, time series, NLP)Track record of successfully developing and implementing ML modelsExperience working with large datasets (healthcare-relevant datasets are a plus)Interest in being an early DS/ML team member, with the technical ability to develop high value models independently while prioritizing collaboration with your teammates and stakeholders to ensure successful design and implementationMotivated to build relationships with teammates and stakeholders, and increase data literacy and expertise throughout the organizationPassionate about improving healthcareBonus: experience working with large healthcare or healthcare related data setsTools we use:Python, including common ML packages like NumPy, Scikit-Learn, Pandas, Tensorflow, etc.AWS and GoogleCloud environmentsSQLGitHubBenefits:A competitive salaryStock options so you have equityFully paid for comprehensive health care (medical, dental, vision)Pet Insurance Life Insurance & Short / Long Term Disability 401k Plan Unlimited PTO and sick leaveParental Leave Work remotely and whatever schedule works best for youAdditional memberships and perksFinal offer amounts are determined by multiple factors including geographic location as well as candidate experience and expertise. If you have questions on compensation bands, please ask your recruiter.Brightside Health is committed to equal employment opportunities for all team members. Every decision we make regarding employment is solely based on merit, competence, and performance. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We realize the full promise of diversity and want you to bring your whole self to work every single day.Research shows that underrepresented groups typically apply only if they meet 100% of the criteria listed. At Brightside, we are dedicated to fair play and encourage women, people of color, and LGBTQ+ job seekers to apply for positions even if they don’t check every box for the role.We know that diversity makes for the best problem-solving and creative thinking, and are committed to equity and inclusion. We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for. We’re an Equal Opportunity Employer and do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, age, religion, disability, national origin, protected veteran status, or any other status protected by applicable federal, state, or local law.Powered by JazzHRvPVWJtptOO\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs, etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Masters's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in the programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please . Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At QuantAQ, our mission is to mitigate global air pollution.As a company, we value the role that fundamental scientific and engineering research play in developing new technologies while doing so with the knowledge that what we build must scale if we want to meet our goals.At QuantAQ, we provide access to professional-grade air quality data to a variety of clients (including research, government, and the private sector) to empower informed decision-making and to create cleaner (air) outcomes. We provide our clients with everything they need to build and manage distributed air quality sensor networks at scale including our proprietary air quality sensors (developed through years of R+D at MIT and Aerodyne Research) and our integrated software platform. We care deeply about using innovative technologies and socio-technological approaches to help businesses, governments, and community stakeholders obtain actionable air quality information across a variety of contexts.If you're looking for an opportunity that allows you to highlight your own skills and solve one of society's most pressing environmental challenges, we would love to hear from you. To learn more about QuantAQ, check out our Climatetech Summit video.About The RoleWe are looking for a full-time Data Scientist to join our rapidly growing team at QuantAQ. We’re a small startup with a rapidly expanding product-market fit, so as an individual contributor, you will quickly gain end-to-end ownership over multiple areas of the business. If that excites you, let’s talk!The ideal candidate is an experienced data scientist who is excited about the opportunity to apply their data science and machine learning skills to improve our category-leading air quality sensors and help reduce the negative impacts of air pollution. At QuantAQ, we gather a lot of air quality data and need to improve our tooling and operations for synthesizing this incoming data to make it as useful as possible for decision-makers to act upon. Over the past decade, we have published some of the most highly-cited and widely-used machine-learning methods for air quality sensors and sensor networks on topics ranging from models for improving individual sensor measurements (supervised regression models) to classifying types and sources of pollution (unsupervised classification methods). You will help develop and improve novel approaches to measuring and locating sources of air pollution and help push those models from ideation to production for our global fleet of air quality sensors. If this sounds appealing, we would love to hear from you.This position is remote-friendly, with options to work hybrid or in-person in Somerville, MA, or San Francisco, CA.ResponsibilitiesIn this position, you will work directly with and report to the CEO, who is currently responsible for overseeing all data science efforts. Responsibilities of this position include:Develop internal and external tools and pipelines to help evaluate the continuous success of our fleet of sensorsApply statistical methods to determine failure rates and lifetimes of key sensor componentsDesign, develop, and grow data sets that enable a better understanding of our sensor performancePartner closely with product and engineering to identify and prioritize the most important data science projectsDevelop and maintain customer-facing data science tools to help customers and the broader scientific community use air quality data and air quality sensors Stay up to date with the machine learning literature, especially for its applications to air quality sensors and sensor networks, and quickly prototype ideas from the research fieldProvide data science customer support from time to time when neededDevelop and execute re-usable playbooks for common customer-facing data science needs (i.e. pilot project evaluation)QualificationsCandidates need not meet all requirements below, but the more that you meet, the better match you may be for existing work. Learning new tools on the fly is expected, and hopefully part of the fun.A Ph.D. or M.S. in a quantitative field such as statistics, applied math, environmental science, computer science, operations research, or relevant work experience combining domain expertise and rigorous quantitative methods2+ years of industry experience in a data science or analytics roleExpert knowledge in Python and the Python data science and machine learning ecosystem (i.e., pandas, scikit-learn, PyTorch, TensorFlow, etc) and proficiency in SQLProficiency in data visualizationExpertise in statistics and experimental designA demonstrated ability to manage and deliver on multiple projects with high attention to detailFamiliarity with cloud tooling for machine learning at scaleExcellent verbal and written communication skills and the ability to communicate clearly and effectivelyStrong organization skills and the ability to work effectively in a team environmentAbility to challenge assumptions and think independently while executing quicklyUS work authorizationCompensation And BenefitsCompensation for this position is competitive for Seed-stage companies in the Boston area. Benefits at QuantAQ include:Health insurance with 85% company contributionDental, vision, and life insurance401(k) with partial company matchFlexible vacation time3 weeks PTO + 10 observed Federal holidaysFlexible work hoursParticipation in QuantAQ’s profit-sharing planLocationQuantAQ is based out of Greentown Labs in Somerville, MA. Greentown Labs is the largest climate tech incubator in North America and includes an awesome community of mission-driven entrepreneurs. Greentown offers numerous networking opportunities and events that cover a variety of topics. We love working out of Greentown Labs!How to ApplyDoes this role seem like a good fit? Are you interested in learning more? Email us at join@quant-aq.com for more information. Otherwise, please apply using the provided form.QuantAQ values diversity of thought, access, and experiences and is an Equal Opportunity Employer → individuals seeking employment with us are considered without regard to race, color, religion, national origin, age, sex, marital status, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by law.Compensation Range: $109K - $147K\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in the programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About The CompanyBloomfield is a plant imaging platform shaping the future of precision agriculture. We scan farms and vineyards at scale (capturing high resolution imagery and other sensor data), analyze every plant, and derive actionable intelligence to help growers be more efficient and productive. We collaborate with a variety of movement platform companies, from ATV and tractor manufacturers to robotics startups.About The RoleThe Data Scientist will work closely with our Machine Learning and Product teams to transform phenotypic information into data products that can be used by our grower-partners to manage their operations.ResponsibilitiesWork closely with our AI, Product, and Engineering teams to deliver phenotypic analysis to our customersBuild frameworks to quantitatively and qualitatively describe plant behavior of specialty crops Interface with engineering team to integrate developed algorithms into product pipelineRequirementsStrong knowledge of plant physiology and/or plant development at the whole plant and molecular levels. Familiarity with plant responses to biotic and abiotic stress is a plusDemonstrated ability to independently design, conduct, and interpret experiments including the use of appropriate statistical methodsDegree in Plant Sciences, Agricultural Engineering, Plant Breeding and Crop Protection, Biology, or similar fieldProgramming languages: PythonNice to havesExperience with high-throughput phenotypingExperience using sensor data in an agricultural environmentAdvanced Degree in Plant Sciences, Agricultural Engineering, Plant Breeding and Crop Protection, Biology, or similar fieldWhat We OfferIn addition to the opportunity to apply and develop your skills toward key business objectives, we offer an excellent compensation package including:Competitive base salaryMedical, dental and vision insurance401(k) retirement plan with company matchUnlimited PTO Parental Leave Incentive stock optionsTraining & Development StipendBloomfield is an equal opportunity employer. We consider qualified applicants without regard to race, color, religion, sex, national origin, sexual orientation, disability, gender identity, protected veteran status, or other protected classes.Powered by JazzHRvdiZ24ZLKF\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionAetna Resources LLC, a CVS Health company, is hiring for the following role In New York, NY: Data Scientist to develop and implement analytics applications and models to transform data into meaningful information. Duties include: design and develop data solutions using industry leading tools, technologies and best practices to profile data and develop efficient ingestion by sourcing data from PBM, Specialty, Retail, and/or HealthCare business; develop advanced algorithms and statistical predictive models to evaluate scenarios, predict outcomes, and provide usable information on health metrics and potential future outcomes; utilize data mining, data modeling, natural language processing, and machine learning to extract and manipulate data from multiple large data sources and deliver predictive models that inform solutions for in-house teams (i.e. pharmacy pricing, medical costs, risk scores, onboarding) and customer engagement across critical journeys (i.e. calories, heart rate, breast cancer, maternity); utilize data-oriented programming languages and visualization software to explore, analyze, and interpret large volumes of data in various forms and solve complex business problems; visualize and interpret data and create reports, manipulate data using statistical software, and compare models using statistical performance metrics; and support deployment of insights across multiple channels using analysis methods, machine learning, and statistical analyses. Multiple openings.Pay RangeThe typical pay range for this role is:Minimum: $ 141,022.00Maximum: $ 141,022.00Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required QualificationsMaster’s degree (or foreign equivalent) in Computer Science, Data Science, Statistics, Mathematics, Analytics, Operations Research, or a related field and two (2) years of experience in the job offered or related occupation. Requires two (2) years of experience in each of the following: Analyzing large data sets from multiple data sources; Data analysis for health care industry, products, or systems; Machine learning, statistical analysis, and predictive modeling; Programming in R, Hadoop, Python, or SQL; Visualization tools, including PowerBI or Tableau; “Big data” platforms including Hadoop (Azure, GCP, or AWS); Designing data models and solutions for analytical and reporting use cases; and Machine Learning or NLP (Scikit-Learn, SpaCity, Pytorch, or Spark NLP).Preferred QualificationsSee Required Qualifications.EducationSee Required Qualifications.Business OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We’re on a missionAt Octaura, we continually evolve markets to unleash value for clients. It’s in our DNA to make a difference and do things differently.Existing workflows within our markets are painful for clients: they are outdated, overcomplicated, and time-consuming. We want to change that. Octaura fundamentally rebuilds and redefines the markets by streamlining workflows, digitizing platforms, and bringing transactions, data and analytics together for the first time.Join our inclusive cultureAt Octaura, everyone belongs.It’s so important to us that all Octaurians are confident in knowing they have the space to use their voice and talents. We love the diversity we see in the world and we actively want our team to reflect this. We’re a values-driven company and by engaging, solving and evolving together, we create a culture that is collaborative, switched-on, and fun to be part of.The role in a nutshellOur mission is to provide our customers with cutting-edge solutions that empower them to achieve their financial goals. We are seeking a highly motivated and talented individual to join our team as a Data Scientist.As a Data Scientist, you will work closely with our team to build the infrastructure for predictive modeling. You will be responsible for developing and implementing statistical models and algorithms to extract insights from large and complex data sets, and for building a cloud-based architecture. As part a startup, you will have the opportunity to take on a high level of responsibility and make a meaningful impact, as well as learn about different aspects of the business.Core responsibilitiesBuild predictive models using machine learning algorithms Develop and implement statistical models to extract insights from large data sets Design, build and maintain cloud-based infrastructure using AWS and/or Azure Work closely with cross-functional teams to design and implement data-driven solutions Analyze and interpret complex data sets to provide insights to stakeholders Develop and maintain data processing pipelines Perform ad-hoc analysis and present findings to key stakeholdersDesired qualificationsPhD/MSc in technical majors such as computer science, statistics, mathematics, physics or related fields Strong programming skills in Python and AI packages. Experience in building predictive models using machine learning algorithms Strong analytical skills with the ability to analyze and interpret complex data sets Excellent written and verbal communication skills Ability to work collaboratively in a team environmentExperience in cloud-based architecture using AWS and Azure (preferred)If you are passionate about data science in finance, have a strong background in technical majors, and are excited about building predictive models and cloud-based infrastructure using AWS and Azure, we want to hear from you. As a startup, we offer a dynamic and entrepreneurial work environment, where you will have the opportunity to take ownership of your work and make a real impact on our business.The base pay range for this position in New York is $150,000 - $175,000 annually. Pay may vary depending on job-related knowledge, skills, and experience. Equity and year-end bonus may be provided as part of the compensation package, in addition to a full range of medical, financial, and other benefits, dependent on the position offered. Applicants should apply via Octaura's internal or external careers site.We’re committed to equal opportunity employmentOctaura is committed to a diverse and inclusive workplace. We are an equal opportunity employer and do not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At QuantAQ, our mission is to mitigate global air pollution.As a company, we value the role that fundamental scientific and engineering research play in developing new technologies while doing so with the knowledge that what we build must scale if we want to meet our goals.At QuantAQ, we provide access to professional-grade air quality data to a variety of clients (including research, government, and the private sector) to empower informed decision-making and to create cleaner (air) outcomes. We provide our clients with everything they need to build and manage distributed air quality sensor networks at scale including our proprietary air quality sensors (developed through years of R+D at MIT and Aerodyne Research) and our integrated software platform. We care deeply about using innovative technologies and socio-technological approaches to help businesses, governments, and community stakeholders obtain actionable air quality information across a variety of contexts.If you're looking for an opportunity that allows you to highlight your own skills and solve one of society's most pressing environmental challenges, we would love to hear from you. To learn more about QuantAQ, check out our Climatetech Summit video.About The RoleWe are looking for a full-time Data Scientist to join our rapidly growing team at QuantAQ. We’re a small startup with a rapidly expanding product-market fit, so as an individual contributor, you will quickly gain end-to-end ownership over multiple areas of the business. If that excites you, let’s talk!The ideal candidate is an experienced data scientist who is excited about the opportunity to apply their data science and machine learning skills to improve our category-leading air quality sensors and help reduce the negative impacts of air pollution. At QuantAQ, we gather a lot of air quality data and need to improve our tooling and operations for synthesizing this incoming data to make it as useful as possible for decision-makers to act upon. Over the past decade, we have published some of the most highly-cited and widely-used machine-learning methods for air quality sensors and sensor networks on topics ranging from models for improving individual sensor measurements (supervised regression models) to classifying types and sources of pollution (unsupervised classification methods). You will help develop and improve novel approaches to measuring and locating sources of air pollution and help push those models from ideation to production for our global fleet of air quality sensors. If this sounds appealing, we would love to hear from you.This position is remote-friendly, with options to work hybrid or in-person in Somerville, MA, or San Francisco, CA.ResponsibilitiesIn this position, you will work directly with and report to the CEO, who is currently responsible for overseeing all data science efforts. Responsibilities of this position include:Develop internal and external tools and pipelines to help evaluate the continuous success of our fleet of sensorsApply statistical methods to determine failure rates and lifetimes of key sensor componentsDesign, develop, and grow data sets that enable a better understanding of our sensor performancePartner closely with product and engineering to identify and prioritize the most important data science projectsDevelop and maintain customer-facing data science tools to help customers and the broader scientific community use air quality data and air quality sensors Stay up to date with the machine learning literature, especially for its applications to air quality sensors and sensor networks, and quickly prototype ideas from the research fieldProvide data science customer support from time to time when neededDevelop and execute re-usable playbooks for common customer-facing data science needs (i.e. pilot project evaluation)QualificationsCandidates need not meet all requirements below, but the more that you meet, the better match you may be for existing work. Learning new tools on the fly is expected, and hopefully part of the fun.A Ph.D. or M.S. in a quantitative field such as statistics, applied math, environmental science, computer science, operations research, or relevant work experience combining domain expertise and rigorous quantitative methods2+ years of industry experience in a data science or analytics roleExpert knowledge in Python and the Python data science and machine learning ecosystem (i.e., pandas, scikit-learn, PyTorch, TensorFlow, etc) and proficiency in SQLProficiency in data visualizationExpertise in statistics and experimental designA demonstrated ability to manage and deliver on multiple projects with high attention to detailFamiliarity with cloud tooling for machine learning at scaleExcellent verbal and written communication skills and the ability to communicate clearly and effectivelyStrong organization skills and the ability to work effectively in a team environmentAbility to challenge assumptions and think independently while executing quicklyUS work authorizationCompensation And BenefitsCompensation for this position is competitive for Seed-stage companies in the Boston area. Benefits at QuantAQ include:Health insurance with 85% company contributionDental, vision, and life insurance401(k) with partial company matchFlexible vacation time3 weeks PTO + 10 observed Federal holidaysFlexible work hoursParticipation in QuantAQ’s profit-sharing planLocationQuantAQ is based out of Greentown Labs in Somerville, MA. Greentown Labs is the largest climate tech incubator in North America and includes an awesome community of mission-driven entrepreneurs. Greentown offers numerous networking opportunities and events that cover a variety of topics. We love working out of Greentown Labs!How to ApplyDoes this role seem like a good fit? Are you interested in learning more? Email us at join@quant-aq.com for more information. Otherwise, please apply using the provided form.QuantAQ values diversity of thought, access, and experiences and is an Equal Opportunity Employer → individuals seeking employment with us are considered without regard to race, color, religion, national origin, age, sex, marital status, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by law.Compensation Range: $109K - $147K\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Our Mission:VerAI is committed to accelerating the global zero-carbon transformation by discovering the minerals essential for our sustainable future. In the last two decades, the minerals exploration industry underperforms with a very low rate of discovery success, failing to supply the massive demand for these critical commodities. We are disrupting the Mineral Exploration Industry by deploying a revolutionary Artificial Intelligence Platform that detects concealed mineral deposits. The world awaits a revolutionary change, and the unique conditions we have created for success allow VerAI to lead a vital paradigm shift in the way mineral discoveries are made.We are well funded by strong financial and strategic investors, including funds and accounts advised by T. Rowe Price Associates, Inc., Orion Resources Partners, a global mineral asset management firm; Chrysalix Capital, which specializes in transformation industrial innovation, mining and its direct contribution to the global Clean Energy transition; and Blumberg Capital, which brings extensive experience in successfully applying AI solutions to different verticals and industries. www.ver-ai.comOur Culture: Why work with us?Our most valuable resource is our people--with a diversity of backgrounds, ideas, opinions, and life experiences. We have built a multidisciplinary and multicultural environment. We admire people who have original thinking and sound judgment. We hire outcome-oriented people who are comfortable with uncertainty. Our culture is filled with people who are positive, passionate, constructive, and success-oriented. Our employees are willing – and enjoy- expanding outside their comfort zones.Our leaders are transparent, accessible, authentic, and invest in their employees. There’s a dedication to one another that’s palpable. We are not your typical 100-hour-a-week grinding start-up. We believe in allowing our employees to have flexible hours and giving them the time needed to balance family/hobbies and work.We are a remote-only US-based company and are currently deploying our AI Minerals Targeting Platform in the Americas.What’s in it for you:Innovation: You will be provided with an amazing opportunity to work on state-of-the-art ML/AI technologies in a company that truly believes in innovation and continuous improvement. We take pride in our technology, and in leveraging this technology to disrupt the Mineral Exploration world. The challenge of finding minerals undercover is real and very hard – and you will have the opportunity to be part of the team that solves it!Influence: You will have a huge influence on how data science is done at VerAI, and you will help pave the way for future generations of our AI-based mineral discovery technology. Your experience and knowledge will impact everything from our developer environment, algorithms, cloud infrastructure, data visualization and so much more.Positive global impact: You will work on a product that has a direct positive impact on the world. Every pipeline improvement and mineral deposit we help find brings us one small step closer to a fossil fuel-free world.Salary range: $150,000-$170,000/yrLocation: Home-based, remote-only (At this time only seeking Colorado residents)Benefits: We offer excellent benefits: Unlimited PTO, Health and Dental Insurance, 401K Match, Stock Options, and more!A day in the life of this role:As our Data Scientist, you will play a crucial role in designing, developing, and implementing the VerAI AI/ML Mineral Targeting Platform. This Platform is at the core of our innovation, and a critical part of our ability to generate high-quality AI Targets that represent the location of concealed economic mineral deposits.You will assume full accountability for operating the Targeting Platform and will have a lot of freedom to continuously improve and enhance its capabilities. Your passion is being hands-on, but also designing and planning different aspects of our Machine Learning pipeline. You love collaborating with different teams and domains and are not afraid of getting your hands dirty with new data sets, technologies, or methodologies.You will help VerAI maintain a technological leadership in its domain and will represent us in the different data science communities and forums.What we need from you:Bachelor’s degree in computer science, applied mathematics, statistics, electrical engineering, or a related quantitative discipline.4+ years of relevant hands-on experience in Machine Learning/Statistical Analytics/Predictive Analytics in the image processing and analysis domain.Excellent understanding of machine learning techniques, algorithms, and methodologies.Extensive experience in Python programming language.Extensive experience with data science frameworks (NumPy, scikit-learn, Pandas, Keras, etc.)Experience with using and administrating cloud infrastructure and web services like AWSAttributes that will make you successful at VerAI:You are trustworthy, responsible, independent, take ownership, and delivers results.You have unquestionable integrity, credibility, and character. You have demonstrated high moral and ethical behavior.You are willing to embrace challenges, and you are comfortable with uncertainty and complex decision-making.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionTitle: ML Data ScientistLocation: Oceanside, CA, 100% OnsiteDuration: Long termExperience required: 10+ yearsRoles & Responsibilities: Lead analytics projects end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.  Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.  Apply technical expertise with machine learning, quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products.  Inform direction and strategic decisions for the future of ML and large scale distributed systems at Meta.  Identify opportunities and develop solutions in existing large scale distributed systems and ML stack.  Define, understand, and test opportunities and levers to improve the product through ML models and applications, and drive ML-modeling roadmaps through your insights and recommendations.  Contribute towards advancing the Data Science discipline at Meta, including but not limited to driving data best practices (e.g. analysis, goaling, experimentation, machine learning), improving analytical processes, scaling knowledge and tools, and mentoring other data scientists. Minimum Qualifications:Bachelor's degree in Mathematics, Statistics, related technical field, or equivalent practical experience.A minimum of 8 years of experience in ML Modeling,Experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, and sampling methods.Experience with applying machine learning techniques to big data systems (e.g., Spark and Hadoop) with TB to PB scale datasets.Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R).Additional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTechnical Skillset (Mandatory)Hands On Experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExperience in Business Intelligence, Database Migration, Data Visualization, Data warehousingTechnical Skillset (Optional)Tableau, Big Data EcosystemRole And ResponsibilitiesProficient in Auto- After Sales Domain.Data Science and Machine Learning, Supervised /unsupervised LearningPrepare Data - Loading Data - Data Visualization - Data Cleaning Data Mining-feature SelectionData Transforms - Evaluate Algorithms - Resampling Methods - Evaluation MetricsModel Selection - Algorithm Tuning - Ensemble Methods - Present Results - Finalize ModelLinear Algorithms Linear Regression, Logistic Regression, and Linear Discriminant Analysis Non-Linear Algorithms CART Model, Decision Tree, Na ve Bayes and Support Vector MachineEvaluate the performance Split into Train and Test and K-Fold cross-validation algorithmsGood hands on experience in Python EcoSystesms Pandas, Numpy, Scikit LearnExpertise in NLP Text Classification, Word Cloud, Term Document Matrix and Corpus,Expertise in NLTK Tokenizer, Tfidfvectorizer, Countervectorizer, Stemming3 + years of experience in Business Intelligence, Database Migration, Data Visualization, Data warehousing, Reporting Tool Tableau and BigFrame ETL Tool.Project Specific Requirement (if Any)MS Degree in Computer Science or related Study\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"PacArctic,LLC, a Koniag Government Services company, is seeking an experienced Jr Data Scientist with a Secret Clearance to support PAC and our government customer in Washington, DC.We offer competitive compensation and an extraordinary benefits package including health, dental and vision insurance, 401K with company matching, flexible spending accounts, paid holidays, three weeks paid time off, and more.Essential Functions, Responsibilities & Duties may include, but are not limited to: Support research, analysis, and tracking OBO's HR function milestones and metrics. Using data collected in the study, assist the government to identify findings and recommendations of this assessment that will streamline the customer's functions/products, maximize efficiencies, and provide a concrete structural blueprint for the delivery of HR services in a cost-effective manner that optimizes the customer's long and short-term service goals. Recommendations as needed for project data visualizations. Support the government to analyze the data collected outputs throughout the different methodologies. Support data analysis and development of data sets for functional and performance analytics; turning data into value for IT solutions. Create data visualizations to communicate IT findings which enhance business functions. Support a wide variety of analytical techniques used to determine and communicate trends and patterns, fill gaps in information and project events, identify anomalies, ascribe meaning to events or information from disparate sources, and develop defensible judgments and conclusions based on accepted research and analytical methodologies.Work Experience, Knowledge, Skills & Abilities Able to obtain and maintain a Top-Secret clearance. Experience in statistical analysis and data mining Knowledgeable in Eclipse IDE, PyCharm, Java, Rstudio, Microsoft SQL, Python Knowledge of data management concepts, principles, and methods for database logical and physical design, development, and maintenance of information management systems. Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Highly developed oral and written communication skills required to present findings or translate the data into an understandable document. Must be skilled and able to prepare and present highly complex matters, material, and/or issues to others. Bachelor's degree in data science strongly preferred. Two years of professional experience required.Working Environment & ConditionsThis job operates in a professional office environment and has a noise level of mostly low to moderate. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines. This position is primarily indoors, consistent with a standard office position and has a noise level of mostly low to moderate. The incumbent is required to stand, walk; sit; use hands to finger, handle, or feel objects, tools, or controls; reach with hands and arms; talk and hear. The workload may require the incumbent to sit for extended periods of time. The incumbent must be able to read, do simple math calculations and withstand moderate amounts of stress. The incumbent must occasionally lift and/or move up to 25 lbs. Specific vision abilities required by the job include close vision, distance vision, color vision, depth perception, and the ability to adjust focus.Our Equal Employment Opportunity PolicyThe company is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, sex, sexual orientation, gender, or gender identity (except where gender is a bona fide occupational qualification), national origin, age, disability, military/veteran status, marital status, genetic information, or any other factor protected by law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits and all other privileges, terms, and conditions of employment.The company is dedicated to seeking all qualified applicants. If you require accommodation to navigate or to apply for a position on our website, please contact Heaven Wood via e-mail at accommodations@koniag-gs.com or by calling 703-488-9377 to request accommodation.Koniag Government Services (KGS) is an Alaska Native Owned corporation supporting the values and traditions of our native communities through an agile employee and corporate culture that delivers Enterprise Solutions, Professional Services and Operational Management to Federal Government Agencies. As a wholly owned subsidiary of Koniag, we apply our proven commercial solutions to a deep knowledge of Defense and Civilian missions to provide forward leaning technical, professional, and operational solutions. KGS enables successful mission outcomes for our customers through solution-oriented business partnerships and a commitment to exceptional service delivery. We ensure long-term success with a continuous improvement approach while balancing the collective interests of our customers, employees, and native communities. For more information, please visit www.koniag-gs.com.Equal Opportunity Employer/Veterans/Disabled. Shareholder Preference in accordance with Public Law 88-352\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Are you seeking to grow and enhance your technical career to new heights, in a full-time, W-2 opportunity?What if an organization existed solely for the purpose of investing in YOU, being of service to YOU, showing you how, and supporting you every step of the way?Is a customized and personalized approach to your learning journey, career development, and overall ability to maximize your earning potential important to you?Let’s make it happen – together!What’s In It For YOU:Full Time, W-2 Employment, with Free, Paid 6-8 Week Training in Data Science (an Industry-Proof Technology) at Our HeadquartersComplete and Total Support to Secure and Maintain End-Client Projects, Post TrainingPaid Corporate-Sponsored Housing During Above-Mentioned TrainingRelocation Assistance for Training and All Projects, as NeededCompetitive, Industry-Leading Full Health Benefits (Medical, Dental, Vision)401K Eligibility Post 1 Year with CompanyWork Visa Sponsorship for Foreign NationalsA Chance for Nationwide TravelCompany-sponsored Technical Certifications, as Necessary, per TechnologyLearn to Become a Best-in-Class Engineer, Developer, and ConsultantDevelopment in Proven Soft Skills and Interviewing Skills MethodsAn Expert Technical Engineer Development ProgramProject Deliverable Support, Once on ProjectExposure to a Breadth and Depth of Best-Practice Production Environments, Code Bases, and Tech Stacks with 100s of Industry-Leading End ClientsHelp our end clients across multiple states design, architect, test, deploy, maintain, document, and scale upwardWho We Are:We\\'re a top-tier IT consulting firm, providing best-in-class Data Science solutions for companies across finance, energy, ecomm, logistics, travel, retail, entertainment, auto, and healthcare, specifically for our many end clients, including Microsoft, Google, Johnson and Johnson, Fannie Mae, Walmart, PayPal, T-Mobile, McDonalds, CVS, Verizon, Charter, Nike, Dell, Wells Fargo, Capital One, Charles Schwab, and many more.Yes! This means you, too, will have these types of well-known, industry-leading end-client experiences in your repertoire after coming on board with us!We\\'re a people development firm (that’s mean YOU!). When you join our family, you come to us with the required foundational technical skills, coding ability, educational degree, and general understanding that will serve as a foundation to learning Data Science. We’re then going to mentor, develop, and train you, as mentioned above, to learn Data Science, so you can then provide consultative services to our end clients!Some of Our HighlightsOur Expertise: IT consultative services and quality engineer development through recruiting, hiring, and coaching our consultants (that’s YOU!)Longevity: 25+ years\\' of combined domestic and international experienceDepth: Hundreds of Fortune 1000, 500, and innovative start-up end clients with 1000s of successfully completed and on-going projects across the US, EU, and UKGlobal: Employee work force is diverse, spanning across 4 continents of North America, Europe, South America, and AsiaGrowth and Innovation: Active monitoring and measurement of the market across all technological sectors to adapt to and implement what\\'s \"next”How We Will Help YouTeach and Develop: We will instruct and train you in Data Science to become a best-in-class consultant through our proven method and program, capable of delivering end-client deliverables, in our paid, 6-8-week training courseCustom Support: Several teams ready to collaborate with you in a custom-tailored way: Development Managers, Tech Subject Manager Experts, Project Deliverable Support, Teachers, Interview Coaches, Client Placement Specialists, Immigration Specialists (for our foreign national candidates)Project Placement: Personalized market-expertise team to enable your ability to secure and maintain a project with our myriad end clientsCareer Growth: We will help you gain the necessary industry experience to drive and propel your technical profession forwardWhat You Bring to the RoleMaster\\'s degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, PhD is preferred. Alternatively, Bachelor’s Degree with at least 2 years’ experience as a Data Analyst, Data Scientist, or Research Assistant6+ years of experience working in a corporate environment within ITStrong Proficiency in Python or Java programming language, or expertise with functional/object- oriented programmingAbility to translate objectives to a project plan with milestones, and resource/technology requirements, and teach, lead, and manage projects/people/clients to successful executionAbility to work across multiple engagements with clients to assess needs, provide assistance, and resolve problems, using structured problem solving and communication to both technical and non- technical audiencesAvailability to travel (80% after Training portion) and live in the U.SStrong English written and verbal communication skillsNice-to-Have:Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environmentExperience in machine learning, artificial intelligence and/or artificial neural networksProficiency in applying various mathematical and statistical models to include, but not limited to: discrete event simulation, factor analysis, genetic algorithms, Bayesian probability models, hidden Markov models, sensitivity analysis, sampling, probability, multivariate data analysis, regression, PCA, time-series analysisBroad understanding of databases (e.g. SQL, NoSQL, Lucene, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, and/or Hive)Experience with visualization software (Tableau, D3, MicroStrategy, PowerBI)Experience delivering solutions in an Agile environmentExperience with Tensorflow, Theano or KerasPortfolio of public & private data science projects you’re proud of (GitHub, Kaggle, DrivenData, etc.)Publications in peer-reviewed journalsOther programming languages such as Scala, Java, RGet to Know Us Our blog and testimonials speak for themselves, they are a great way to get to know us even more and underscore what we can offer you, as well!Instagram: https://www.instagram.com/enhanceitcommunity/ LinkedIn: https://www.linkedin.com/company/enhance-it-com/?viewAsMember=true Website: https://www.enhanceit.com YouTube: https://www.youtube.com/channel/UCYBe7WrZ8lM3MJInS1ZczvQ Facebook: https://www.facebook.com/enhanceitcommunity\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Deep Learning Engineer - (CNN/RNN)AboutTrilogy Innovations is seeking a highly skilled Deep Learning Engineer / CNN Architect to join our team. The successful candidate will be responsible for designing, implementing, and optimizing deep learning models using Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Convolutional Recurrent Neural Networks (RCNN) for various applications such as image recognition, waveform analysis, and natural language processing.Telework: 100% remote supportFull-time (W2) Employment Benefits: Health, vision/dental, life/disability, 401(k) + matchPerks: 100% coverage of professional development, phone/internet reimbursements & bonus programsRequirementsMaster's or Ph.D. degree in Computer Science or related field.5+ years of experience in developing and implementing deep learning models.Strong understanding of Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Convolutional Recurrent Neural Networks (RCNN).Experience working with large datasets.Strong programming skills in Python, TensorFlow, and PyTorch.Experience with VGG16 and EfficientNet is highly desired.Experience working with embedded systems is a plus.ResponsibilitiesDesign, develop, and implement deep learning models using CNN, RNN, and RCNN for various applications.Work with large data sets to preprocess, clean, and prepare data for model training.Create datasets for training and testing.Train machine learning models and validate their accuracy, and deploy validated models into production.Optimize models for performance and accuracy, and fine-tune hyperparameters to achieve optimal results.Stay up to date with the latest developments in deep learning techniques and technology.Provide technical guidance and support to other team members.Why work for Trilogy Innovations?Professional Development Programs for all employeesUp to $150/month towards your phone and internet services per monthReferral Bonus Programs (Employees & Business Development)401(k) with company matchComprehensive medical, vision and dental insurance; life/disability insurance coverageHealth Spending Account (HSA)www.trilogyit.comTrilogy Innovations, Inc. is a minority-owned (8a) and HUBZone certified systems and software engineering company that delivers superior technical solutions across private and public sectors. Since 2010, our talented personnel have successfully provided Innovative IT solutions across government agencies such as the FBI, U.S. Air Force, NASA, Department of Education, Department of Energy, U.S. Coast Guard, SOCOM, and private industries in Oil & Gas, and Land Management Services.Trilogy Innovations, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"This role is only available for W2 or 1099 individual.  100% Remote WorkLocation: Remote anywhere in the USContract to Hire our client is adamant about finding a long term fit. No difference between contract and FTE,  100% will convert.  Job Description: Our client is currently looking for a Data Scientist. We are working with a Director in the Machine Learning & Data Science in our client's cyber division.Our client hosts a true Big Data environment (Petabytes of data stored, and processing daily upwards of 235 billion market events). You will be tasked with researching and helping construct some of the most important machine learning models that protect our stock and bond markets.Our client is looking to incorporate anomaly detection/data science technology in their cyber environment to identify abnormal behavior.Our client is looking for someone with a great deal of intellectual curiosity, experience in a data science environment, who want to be very hands on and technical (coding and mathematical/research analysis is required).Minimum QualificationsPhD preferred, Master's required Computer Science, Math, Statistics, Physics and/or Electrical Engineering must have the mathematical background to apply mathematical analysis to data and determine relationships4+ years of experience in Data Science, Big Data, AI/Client and/or software/data engineeringExpertise in programming with PythonStrong SQL querying skillsExperience in Big Data environments and in a data science practiceKeen ability to research data and identify relationships (this is 85% of the job)Data science experienceHave worked on building and maintaining Machine Learning modelsExperience with PySpark and PyTorchMust have strong communication skillsPreferred:Coding experience with SparkBig Data engineering experienceAWS experienceExperience executing sophisticated SQL queries for backend, data testing.Powered by JazzHRb8OFsmkPmt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Iron EagleX is a veteran owned defense contracting company based in Tampa, FL.It is our mission to provide solutions to the most challenging technical problems facing the Department of Defense while simultaneously making a positive impact on our employees and community.Job DescriptionThe Data Scientist will support the United States Special Operations Command (USSOCOM) Chief Data Office (CDO) and be responsible for designing, implementing, and maintaining a data pipeline. Additionally, the Data Scientist shall interpret and analyze complex sets of data and plan, execute, and manage ML projects with cloud-native platforms and advanced ML solutions. They will leverage multiple methodologies such as data mining, natural language programming, and machine learning.Job Duties Include (but Not Limited To)Interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific methodCoordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the dataExperiment against data points, provide information based on experiment results, and provide previously undiscovered solutions to command data challengesCoordinate with Data Engineers to build data environments providing data identified by other data professionalsApply and develop scientific methodology, statistics, and algorithms to discover and frame relevant problems, hypotheses, and opportunitiesDevelop predictive and prescriptive modeling, natural language processing (NLP), Robotic Process Automation (RPA), text mining and processing, clustering, forecasting methods, and other advanced statistical techniquesDesign and automate processes to facilitate the manipulation and analysis of dataManage and integrate data across dissimilar data sets and analyze large-scale structured and unstructured dataUse frameworks to conduct large-scale data processingPerform statistical modeling and create data visualizations Research, design, and implement algorithms to solve complex problemsProgram using R, Python (NumPy, SciPy, Pandas) or similar analytical languagesPerform data engineering, data processing, and modeling techniques using cloud-based data management, data science, and ML platforms Communicate complex concepts and hypothesis to a non-technical audience through digital storytellingRequired Skills & ExperienceMinimum of 1-year of Data Science experience is required:Proficient with one or more programming languages (Java, C++, Python, R, etc.):Proficient in Agile Development and Git Operations: Demonstrated experience applying data science methods to real-world data problems:MUST BE US CITIZENDesired SkillsExperience working with the Department of DefenseEducation & CertificationsBachelors in Stem field or Master’s Degree in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fields:Security ClearanceActive TS/SCI Clearance is requiredBenefitsNational Health, vision and dental plans20 days of PTO and 11 paid holidaysLife InsuranceShort – and long-term disability plans401(K) retirement planIncentive and recognition programsRelocation opportunitiesIron EagleX is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, among other things, or status as a qualified individual with disability.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'About Us\\xa0\\xa0DeepLogica is a proprietary AI platform that empowers clients’ existing processes and systems to redefine eCommerce delivery. We utilize machine learning models to accurately predict supply chain events, provide actionable business insights and ultimately enhance the buying experience.\\xa0\\xa0About The Role\\xa0\\xa0We’re looking for a talented Data Scientist who is passionate about data, learning, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\\xa0A varied skill set, creativity, flexibility, and positive team attitude are high priorities. \\xa0Main Responsibilities\\xa0\\xa0In collaboration with the other members of your team and your supervisor you will be in charge or participate in the following activities:\\xa0Collecting, cleaning, and transforming large datasets for downstream processing.\\xa0Design accurate and scalable prediction algorithmsDevelop statistical and machine learning models to extract insights and predictions from data.\\xa0Visualize and present findings to stakeholders in a clear and concise manner.\\xa0Collaborate with cross-functional teams to identify business problems that can be solved using data.\\xa0Design experiments to test hypotheses and improve models.\\xa0Assist Data Engineering team members in building and deploying data pipelines and scalable infrastructure to support data analysis.\\xa0Ensure ethical use of data and compliance with privacy regulations.\\xa0Continuously monitor and evaluate the performance of models and adjusting as needed\\xa0Required Education, Qualifications and Experience\\xa0Bachelors or Masters degree in operations research, computer science, software engineering, or a related field\\xa0\\xa02-3 years of experience in quantitative analytics of data modeling.\\xa0Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)Passionate self-starter, able to prioritize tasks and manage time effectively.\\xa0Ability to take ownership of tasks to ensure high quality and successful on-time completion.\\xa0\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our Client is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, they offer you many development opportunities.This is an onsite position. There are three different locations to work from:Fort Mill, SCWooster, OHTroy, MIYour Key Responsibilities• Lead discovery processes with business stakeholders to identify opportunities and business problems and framing them into an IT data science/ advanced data analytics project initiative.• Identification and extraction of available and relevant data from internal and external data sources to perform data science solution development.• Perform data cleansing using data processing and statistical software packages.• Perform data quality assessments and statistical testing to verify data quality and data integrity• Exploratory data analysis for extracting business insights from large volume of data using data science toolkits and statistical packages.• Translate and visualize data into information and insights to discover trends and patterns for solving the business problem and improving the Key Performance Indicators (KPIs)• Develop custom data models, standard statistical models, machine learning or deep learning algorithms for building diagnostic, predictive and prescriptive data science solution.• Coordinate with different functional agile teams such as data engineering and software development to deploy the data science solutions to production and integrate it with existing IT digital solutions and productsYour QualificationsRequired:Master’s degree in Applied Mathematics, Statistics, Machine Learning, Electrical Engineering, Computer Science/Information Systems or related fields or MBA with quantitative focus.Minimum 2 years of full time experienceIndustrial research and development and advanced data analytics experience.Experience in data mining for large volumes of data, extracting insights and building prediction and system optimization models.Comprehensive statistical knowledge (regression/classification models, design of experiments, statistical testing etc.) and experience applying it to real-world projects.Strong knowledge in the application of Machine LearningExperience with common data science toolkits, such as SQL, R and/or Python with high proficiency in the use of opensource statistical and machine learning packages (numpy, pandas, scikit-learn, stats tool etc.)Experience delivering data science projects from model development to production deploymentPreferred:Deep Learning algorithms (TensorFlow or Equivalent framework), ideally demonstrated by relevant industrial experienceExperience in deploying predictive or prescriptive data science solutions from any embedded electronic sensor data streams (such as IoT sensors, PLC systems, condition monitoring systems, wearables etc.)We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Allozymes is a deep tech company based in Singapore. We are revolutionising the way industry uses enzymes for manufacturing chemicals and natural compounds. Our rapid discovery and evolution of custom-designed enzymes enables breakthrough developments for sustainable production of ingredients for pharmaceuticals, cosmetics, chemical, food and beverages.We’re hiring a highly capable Machine Learning Engineer into our Data team. This team is responsible for developing and implementing state-of-the-art approaches for evolving enzymes and microbes to enhance the production of chemicals and natural compounds. The engineer will integrate the development of our cloud-based artificial intelligence platform for enhancing Allozymes’ enzyme optimization capabilities. Working in a highly collaborative and dynamic environment, this role has the opportunity to interact with other scientists, automation and process engineers to achieve these goals. Responsibilities:Contribute to the design and improvement of Allozymes cloud-based AI platform.Scope project requirements, assess data quality, process data and perform feature engineering.Build, train and deploy ML/DL models, using state-of-the-art technologies and proprietary data to accurately perform predictions and generate new, high performing, enzymes.Perform model evaluation and statistical analysis to improve model quality.Enhance the performance and deployment environment of implemented solutions.Qualifications:MS or PhD in mathematics, statistics, computer science, engineering or a related quantitative field with a focus on AI and Machine Learning.2+ years of relevant industry experience.Expertise in building, training and deploying Machine and Deep Learning models.Proficiency in Python.Expertise in using ML/DS specific python libraries (Pandas, Numpy, Scipy, Scikit-learn, PyTorch, Keras).Experience with ML life-cycle management and code/data version control tools.Familiarity working with Cloud computing.Ability to work in a fast-paced, collaborative and cross-functional environment and communicate results effectively to management.Experience with supervised and unsupervised learning algorithms, clustering, feature selection methods, evaluation, dimensionality reduction, Bayesian inference, hyper-parameter tuning and model optimization is a plusExperience with Language models, Encoders, Transformers, Attention, Generative models and GANs is a plusExperience in biology, bioinformatics or computational biology.Experience using AWS/SageMaker is a plusExperience with containers and container orchestration tools is a plusExperience writing production-ready code (version-controlled, scalable, well-documented, testable, deployment-ready) is a plusNumber of Vacancies: 1\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Location Lawrenceville, New Jersey 08648Role is 100% onsite.Junior (0-3 Yrs.)DescriptionLeads discovery and optimization (LDO) is a diverse group of scientists and engineers, providing critical assay information to therapeutic research centers (TRCs) throughout research and early development (R&ED). We are seeking a highly motivated and innovative data scientist to join the data science and advanced analytics team within LDO until the end of 2023. The individual will develop a machine learning and Bayesian statistics-based approach to model assay variability using medium to high throughput screening datasets. The individual will work in a highly dynamic environment at the center of the R&ED drug discovery engine to develop cutting edge tools applied to complex drug discovery problems.Roles and ResponsibilitiesWrite python scripts to enable rapid cleaning and analysis of medium and high throughput datasetsUtilize machine learning (ML) approaches to generate small molecules featuresUtilize Bayesian statistics approaches to estimate uncertainties in assay datasets, based on results on above ML outputsWrite and document programming code (python preferred) to facilitate data preparation / cleaning, model development, and evaluationProduce high quality scripts, documentation, and processing pipeline by the end of 2023Create deployable version of processing pipeline for near term use as a stand-alone application and ultimately future integration with enterprise suiteQualificationsPh.D. in quantitative sciences/engineering (computer science, mathematics, statistics, or engineering)5+ years of relevant professional experience with a proven track record in machine learning and data science experience in drug discovery machine learning is desirable but not requiredStrong knowledge of one or more scripting programming languages, with a focus on machine learning (e.g., Python (preferred), R, Matlab, C/C++)Experience utilizing molecular features of small molecules in machine learning modelsExperience with the use and application of Bayesian statistics and simulation methods in generating probabilistic outcomesAble to extract information from databases using a variety of software packages (e.g., Oracle SQL developer)Ability to build and maintain databases aligned with enterprise solutions is desirable but not requiredStrong analytical and problem solving skills to understand technical business problems and implement solutionsAbility to work effectively on matrixed teams to collaboratively solve challenging problems, while also able to work independently with minimal resourcesHas good interpersonal, communication, writing and organizational skillsStrong preference for on-site presence to enable colocation with data science team\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for Junior Data Scientist (Remote) with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech IndustryPlease Also Check The Below LinksIf the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Associate, Data ScienceNew York, United States of AmericaWhat You Will Be DoingUSA Job Function Description:Designs and monitors control systems which ensure the integrity and security of data and for advising on the optimal use of the organization's computing resources.Assesses the completeness, accuracy, validity and efficiency of information processing, business and application systems, reviews the operations, systems software, systems development and security of the organization's computing environment, and recommends appropriate software and hardware acquisitions.Essential Functions/Responsibility StatementsTranslates business queries into actionable and commercial insights leveraging unstructured data and statistically robust techniques.Drives cross functional analytics projects from beginning to end: builds relationships with partner teams, frames and structures questions, collects and analyzes data, and summarizes key insights in support of decision making.Works with engineers to evangelize data best practices and implement analytics solutions.Evaluation and discovery of alternative data vendors including ability to quantifiably validate external algorithms and apply insights to commercially driven use cases.Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.Education: Bachelor's Degree or equivalent work experienceWork Experience: 5-9 years ; Data mining/advanced analytics applied to large-scale data-intensive projects.Skills And AbilitiesKnowledge of the principles of machine earning, classification models, time series regression and stochastic statistics to deliver improved business performanceDemonstrated experience with SQL, R or a comparable programming language (such as Python, SAS, SPSS, or MATLAB)Demonstrated ability to communicate complex concepts.Strong quantitative and problem solving skills with focus hypothesis formulation and testing.Strong evidence of leveraging analytics to drive business results.Strong project management skills.Individually motivated and possess sound judgment, integrity, and a solid work ethic.Diversity & EEO Statements: At Santander, we value and respect differences in our workforce and strive to increase the diversity of our teams. We actively encourage everyone to apply.Santander is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, genetics, disability, age, veteran status or any other characteristic protected by law.Working Conditions: Frequent Minimal physical effort such as sitting, standing and walking. Occasional moving and lifting equipment and furniture is required to support onsite and offsite meeting setup and teardown. Physically capable of lifting up to fifty pounds, able to bend, kneel, climb ladders.Employer Rights: Employer Rights: This job description does not list all of the job duties of the job. You may be asked by your supervisors or managers to perform other duties. You may be evaluated in part based upon your performance of the tasks listed in this job description. The employer has the right to revise this job description at any time. This job description is not a contract for employment and either you or the employer may terminate at any time for any reason.For NYC Job Applicants: The base annual salary range for this position is $41,600-$172,500.The exact compensation may vary based on skills, experience, training, licensure and certifications and location.Masters of Science (MS) EnglishPrimary Location: New York, NY, Madison Ave CorpOther Locations: New York-New YorkOrganization: Banco Santander S.A.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Summary This position is located in the Office of Nuclear Reactor Regulation (NRR), Embark Venture Studio (EVS) and Office of Nuclear Material Safety and Safeguards (NMSS), Program Management, Policy Development, and Analysis Staff (PMDA). This position is Bargaining Unit with the National Treasury Employees Union, Chapter 20This position is not subject to Confidential Financial Disclosure reporting requirements. This position is subject to security ownership restriction reporting requirements. Responsibilities The incumbent serves as a Data Scientist with specific technical expertise. Duties include but are not limited to: data mining/data analysis methods (e.g., data cleansing, data management, analytics, visualization, and engineering), modeling (e.g., model selection, training, evaluation, and tuning), mathematics, statistics, and artificial intelligence to collect, analyze, and interpret large datasets. collection and maintenance of data, data analytics, development of methodological approaches, study design, development of data strategies and data policies, and advanced written, verbal, and visual communications of study/analysis output. provides direction and scientific expertise to a wide range of highly complex, highly visible initiatives and projects. leads and/or consults with cross-functional teams to develop data-driven solutions that address NRC's program and business challenges. leverages data visualization tools (e.g., Tableau, Power BI) to visualize and analyze data in support of metrics, trend analysis, and other reports and projects. utilizes scripting languages (such as JavaScript, Java, Python) to create predictive models to drive data-driven decision-making and automate existing processes. analyzes management information requirements to develop program or administrative reporting systems including the systems specifications, data gathering and analytical techniques, and systems evaluation methodology. leads the development and implementation of mathematical, and/or statistical (e.g., regression, classification, resampling, statistical tests, and proper usage) techniques and concepts that are applicable to data management, analysis, regulatory issues, and program oversight, including understanding the issues and limitations of these techniques. Requirements Conditions of Employment U.S. Citizenship Required This is a Drug Testing position. Background investigation leading to a clearance is required for new hires. To ensure compliance with an applicable preliminary nationwide injunction, which may be supplemented, modified, or vacated, depending on the course of ongoing litigation, the NRC will take no action to implement or enforce the COVID-19 vaccination requirement pursuant to Executive Order 14043 on Requiring Coronavirus Disease 2019 Vaccination for Federal Employees. Therefore, to the extent that an NRC job announcement includes the requirement that applicants must be fully vaccinated against COVID-19 pursuant to Executive Order 14043, that requirement does not currently apply. You must meet the qualifications for this position by no later than 30 calendar days after the closing date of this announcement and before placement in the position. Qualifications The ideal candidate will be able to demonstrate the following:Demonstrated knowledge of and experience in developing data analytics/science related products (e.g. machine learning, natural language processing, robotics process automation, and artificial intelligence) and applied programming or data manipulation with a programing language (e.g., Python; R; SQL; or equivalent) to analyze large volumes of data to build and enhance products, processes, and systems. Demonstrated knowledge and experience in identifying problematic issues and reporting discrepancies and providing appropriate recommendations to leadership.Demonstrated ability to establish and maintain effective work relationships with peers, management, and personnel of other U.S. government agencies, equivalent industry organizations, or international organizations.Demonstrated ability to effectively communicate technical information both orally and in writing.Knowledge of regulatory programs, policies, guidance, and support activities. In order to qualify for this position, you must have at least one year of specialized experience at the next lower grade level in the Federal service or equivalent experience in the private or public sector. SPECIALIZED EXPERIENCE is defined as experience performing data acquisition, data cleansing, and data visualization with tools such as Tableau and Power BI; having familiarity with data discovery to take an unknown data set and extract meaning; possessing effective software development skills and understanding scripting languages; and exhibiting excellent skills related to written and oral communications, organization, problem solving, and the ability to work independently and collaboratively in a team environment. A description of how you possess the specialized experience as well as how you meet the qualifications desired in an ideal candidate must be addressed in your resume. Education Basic Requirements: Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. or Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience. Additional Information The duty location of this position is Rockville, MD. In general, employees are expected to be in the office at a minimum of 4 days per pay period**. Telework schedules, including full-time telework, are approved, on a case-by-case basis. If selected, telework will be determined in accordance with Agency policy and the Collective Bargaining Agreement, if applicable.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you needWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, and Data analysts/ Data Scientists.We welcome candidates with all visas and citizens to apply.We assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill/enhance their IT skills.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementWe are looking for Jobseekers wanting to file H1b visaPosition open to all visas and US citizensCandidates Who Lack ExperienceHave had a break in careersLack Technical CompetencyDifferent visa candidates who want to get employed and settle down in the USAplease also check the below links(url removed)Required SkillsBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in the programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, and data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, Time series analysisPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.No third-party candidates or c2c candidatesTo apply for this position, please apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Senior Data Scientist - Brightside Health - 100% Remote in U.S.Brightside Health delivers life-saving virtual mental healthcare to everyone who needs it. We are powered by proprietary AI, purpose-built technology, a world-class clinician network, and a care model that rivals the best of in-person treatment. When combined with precision psychiatry and leading-edge therapeutic techniques, we’re able to improve outcomes for those with mild-to-severe clinical depression, anxiety, and other mood disorders.We take an action-oriented, purposeful approach with everything we do and seek out team members who value collaboration and thoughtful prioritization. As a result, our organization is looking for the brightest and most innovative talent in the industry. We can promise you that, as a member of the Brightside team, you’ll have the opportunity to collaborate alongside smart and driven people while growing your professional skills.We are seeking a talented and experienced Senior Data Scientist to join our team. As a Senior Data Scientist, you will be responsible for developing and implementing advanced analytical and machine learning models that drive business value and support the experience of Brightside Health’s patients, clinicians, and internal teams.What you’ll be doing as a Senior Data Scientist:Design, develop, and deploy advanced analytic and machine learning models to explain or predict the behavior, experience and outcomes of patients, clinicians, and the businessCollaborate with cross functional teams to identify opportunities for data-driven decision making and translate business objectives into data science problems, and vice versaCommunicate complex data science concepts, ideas and results to technical and non-technical stakeholdersContribute to developing core data science and machine learning frameworks that shape the Data organizationRequirements:At least 4 years of relevant data science, analytics or machine learning professional experienceExperience in data engineering and feature preparationExperience in developing machine learning models using a variety of techniques (including regression, classification, clustering, time series, NLP)Track record of successfully developing and implementing ML modelsExperience working with large datasets (healthcare-relevant datasets are a plus)Interest in being an early DS/ML team member, with the technical ability to develop high value models independently while prioritizing collaboration with your teammates and stakeholders to ensure successful design and implementationMotivated to build relationships with teammates and stakeholders, and increase data literacy and expertise throughout the organizationPassionate about improving healthcareBonus: experience working with large healthcare or healthcare related data setsTools we use:Python, including common ML packages like NumPy, Scikit-Learn, Pandas, Tensorflow, etc.AWS and GoogleCloud environmentsSQLGitHubBenefits:A competitive salaryStock options so you have equityFully paid for comprehensive health care (medical, dental, vision)Pet Insurance Life Insurance & Short / Long Term Disability 401k Plan Unlimited PTO and sick leaveParental Leave Work remotely and whatever schedule works best for youAdditional memberships and perksFinal offer amounts are determined by multiple factors including geographic location as well as candidate experience and expertise. If you have questions on compensation bands, please ask your recruiter.Brightside Health is committed to equal employment opportunities for all team members. Every decision we make regarding employment is solely based on merit, competence, and performance. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We realize the full promise of diversity and want you to bring your whole self to work every single day.Research shows that underrepresented groups typically apply only if they meet 100% of the criteria listed. At Brightside, we are dedicated to fair play and encourage women, people of color, and LGBTQ+ job seekers to apply for positions even if they don’t check every box for the role.We know that diversity makes for the best problem-solving and creative thinking, and are committed to equity and inclusion. We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for. We’re an Equal Opportunity Employer and do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, age, religion, disability, national origin, protected veteran status, or any other status protected by applicable federal, state, or local law.Powered by JazzHRvPVWJtptOO\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.What PepsiCo Data Management and Operations does: Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders Increase awareness about available data and democratize access to it across the companyJob DescriptionAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company.As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, onpremise data sources as well as cloud and remote systems.ResponsibilitiesActive contributor to code development in projects and services.Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.Build and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.Responsible for implementing best practices around systems integration, security, performance and data management.Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape.Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.Develop and optimize procedures to “productionalize” data science models.Define and manage SLA’s for data products and processes running in production.Support large-scale experimentation done by data scientists.Prototype new approaches and build solutions at scale.Research in state-of-the-art methodologies.Create documentation for learnings and knowledge transfer.Create and audit reusable packages or libraries.Qualifications4+ years of overall technology experience that includes at least 3+ years of hands-on software development, data engineering, and systems architecture.3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.3+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).2+ years in cloud data engineering experience in Azure.Fluent with Azure cloud services. Azure Certification is a plus.Experience with integration of multi cloud services with on-premises technologies.Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines.Experience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.Experience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.Experience with version control systems like Github and deployment & CI tools.Experience with Azure Data Factory, Azure Databricks and Azure Machine learning tools is a plus.Experience with Statistical/ML techniques is a plus.Experience with building solutions in the retail or in the supply chain space is a plusUnderstanding of metadata management, data lineage, and data glossaries is a plus.Working knowledge of agile development, including DevOps and DataOps concepts. Familiarity with business intelligence tools (such as PowerBI).EducationBA/BS in Computer Science, Math, Physics, or other technical fields.Skills, Abilities, KnowledgeExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.Proven track record of leading, mentoring data teams.Strong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.Ability to understand and translate business requirements into data and technical requirements. High degree of organization and ability to manage multiple, competing projects and priorities simultaneously.Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment.Strong leadership, organizational and interpersonal skills; comfortable managing trade-offs.Foster a team culture of accountability, communication, and self-management.Proactively drives impact and engagement while bringing others along.Consistently attain/exceed individual and team goals.Ability to lead others without direct authority in a matrixed environment.CompetenciesHighly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.Understands both the engineering and business side of the Data Products released.Places the user in the center of decision making.Teams up and collaborates for speed, agility, and innovation.Experience with and embraces agile methodologies.Strong negotiation and decision-making skill.Experience managing and working with globally distributed teamsCOVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable lawEEO StatementAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender IdentityIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.Please view our Pay Transparency Statement\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'To support internal and external clients via processing and handling of data. To generate data solutions for ongoing immediate day to day business needs.Essential FunctionsDay to day functions include the following:Design data models and develop database structures in Microsoft SQL server.Write various database objects like stored procedures, functions, views, triggers for various front end applications.Write SQL scripts, create SQL agent jobs to automate tasks like data importing, exporting, cleansing tasks.Create database deployment packages for deploying changes.Identify & repair inconsistencies in data, database tuning, query optimization.Able to generate ad hoc data on demand.Able to identify best practices, documentation, communicate all aspects of projects in a clear, concise mannerDevelop simple SSIS packages to perform various ETL functions including data cleansing, manipulating, importing, exporting.Develop & maintain client facing reports by using various data manipulation techniques in SSRS and Visual Studio.DocumentationOptimization recommendationsDay to day troubleshooting.NET Programming as neededEducation/ExperienceBA, BS, or Masters in computer science/related field preferred or an equivalent combination of education and experience derived from at least 2 years of professional work experienceSolid experience with various versions of MS SQL Server and TSQL programmingMicrosoft Certified DBA a plusSkills/KnowledgeStrong experience in writing efficient SQL codeWorking knowledge of SQL Server Management Studio (SSMS)Knowledge of SQL Server Reporting Services (SSRS)Knowledge of SQL Server Integration Services (SSIS)Knowledge of Red Gate DBA Tool Belt (SQL Compare, SQL Data Compare, SQL Source Control) a plusKnowledge of data science technologies is a plusClear, concise communication skills, excellent organizational skillsHighly self-motivated and directedKeen attention to detailHigh level of work intensity in a team environmentHigh integrity and values-drivenEager for professional developmentExperience and understanding of source control management a plusWhat We OfferAt Bloom, we offer an engaging, supportive work environment, great benefits, and the opportunity to build the career you always wanted. Benefits of working for Bloom include:Competitive compensation Comprehensive health benefits Long-term career growth and mentoring About BloomAs an insurance services company licensed in 48 contiguous U.S. states, Bloom focuses on enabling health plans to increase membership and improve the enrollee experience while reducing costs. We concentrate on two areas of service: technology services and call center services and are committed to ensuring our state-of-the-art software products and services provide greater efficiency and cost savings to clients.Ascend Technology ™Bloom provides advanced sales and enrollment automation technology to the insurance industry through our Ascend ™. Our Ascend™ technology platform focuses on sales automation efficiencies and optimizing the member experience from the first moment a prospect considers a health plan membership.Bloom is proud to be an Equal Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAt Johnson & Johnson, we use technology and the power of teamwork to discover new ways to prevent and overcome the world’s the most significant healthcare challenges. Our Corporate, Consumer Health, Medical Devices, and Pharmaceutical teams leverage data, real-world insights, and creative minds to make life-changing healthcare products and medicines. We're disrupting outdated healthcare ecosystems and infusing them with transformative ideas to help people thrive throughout every stage of their lives. With a reach of more than a billion people every day, there’s no limit to the impact you can make here. Are you ready to reimagine healthcare?Here, your career breakthroughs will change the future of health, in all the best ways. And you’ll change, too. You’ll be inspired, and you’ll inspire people across the world to change how they care for themselves and those they love. Amplify your impact. Join us! Tasked with transforming data into a format that can be easily consumes by ML algorithms. Adept Database basics SQL, capable of basic data engineering techniques – data wrangling, data cleansing, data curation. Fluent in one of the programming languages R or Python.  Data Engineering skills, e.g., cleaning/organizing data, data preparation, data collection, data integration across different data sources, data storage, relational/non-relational database management.  Proficient in structured query language (SQL), NoSQL, MATLAB, and programming in Python or R.  Proficient in Applied Machine Learning – Experience with a variety of algorithms, Building Predictive Models, Cross-validating, Hypertuning and Deployment.  Experience with devising and implementing ML methods for protein or antibody modeling or design, or with deep learning methods that relate protein sequence, structure, property or function.  MD simulation software (e.g., Commercial tools like Schrodinger, or open-source software AMBER, GROMACS, etc.). Additionally, prior experience in homology modeling and structural refinement  Knowledgeable of AWS services including Redshift, RDS, EMR and EC2  Working knowledge using software and tools including big data tools like Kafka, Spark and Hadoop. At Johnson & Johnson, we’re on a mission to change the trajectory of health for humanity. That starts by creating the world’s healthiest workforce. Through cutting-edge programs and policies, we empower the physical, mental, emotional and financial health of our employees and the ones they love. As such, candidates offered employment must show proof of COVID-19 vaccination or secure an approved accommodation prior to the commencement of employment to support the well-being of our employees, their families and the communities in which we live and work.Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Primary LocationNA-US-Pennsylvania-Spring HouseOrganizationJanssen Research & Development, LLC (6084)Job FunctionAdministration\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatmentSchedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewMailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaigns, CRM, and analytics tools.The Data Platform team at Mailchimp is responsible for creating and managing our BI platform that enables peeps from across the company to make better decisions with data. What that actually looks like is working with folks from across the company to understand their needs and then surface data in a meaningful way, across tools and teams, to help them drive the business forward. Day to day you could be building an ETL pipeline, designing a data access tool, modeling out new data in Looker, or working with teams to develop better data governance practices. We have a lot of tools in our toolbelt, but all with the main goal helping Mailchimp to continue to use data more effectively.Intuit Mailchimp is a hybrid workplace , giving employees the opportunity to collaborate in person with team members in our Atlanta and Brooklyn offices two or more days per week.What You'll BringExperience with Python, Java, Go, or another OOP languageExperience with SQL and data analysis skillsExperience with data transformation tools like dbt or DataformExperience in visualization technologies like Looker, Tableau, or Qlik SenseExperience with Airflow or other ETL orchestration toolsSolid business intuition and ability to understand and work with cross-functional partnersExperience with GCP/AWS or other cloud providers is preferredBachelors degree is Computer Science or equivalent experience Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Mailchimp we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.How You Will LeadPartner with analysts, data scientists, business users, and other engineers to understand their needs and come up with data solutionsHelp build robust transformation pipelines to help clean up, normalize, and govern our data for broad consumptionHelp build scalable transformation pipelines that enables teams to easily clean up, normalize, and govern data for broad consumptionBuild tools and processes to help make the right data accessible to the right peopleModel data in Looker, to provide a collaborative data analytics platform for the companyWork with Data Stewards to better document our data\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Well known NY based Non-Profit seeks a Data Engineer.An ideal candidate will have strong data engineering skills with both SQL and Python.This position can be based out of NYC or be 100% remote.Compensation includes salary, excellent medical, dental, vision benefits, pto, 401k, a quality of life oriented work life balance, and lots of other benefits.ResponsibilitiesThis position will work within the enterprise data engineering team to continuously build, maintain, and improve the design, performance, reliability, scalability, security, and architecture of enterprise data products.Responsibilities include:Develop robust database solutions, data integration (ETL, ELT) packages, automation, performance monitoring, SQL coding, database tuning and optimizations, security management, capacity planning, database HA, and database DR solutions across required data platforms.Conduct in-depth data analysis to support data product design.Identify and resolve production database and data integration issues.Collaborates closely with data quality, application, and visualization teams to deliver high-quality data products.Participate in code review, QA, release, and continuous deployment processes.Qualifications:Bachelors Degree in Computer Science or other quantitative disciplines such as Science, Statistics, Economics or Mathematics.5+ years of progressive database development experience with the Microsoft SQL Server family suite.Experience with data modeling and data architecture principles for both analytics and transactional systems.Hands-on experience with SQL Server, Oracle, or other RDBMS required.Python ScriptingExperience with Cloud Data PlatformsPreferred Experience:Scripting experience in Powershell, C#, Java, and/or R.Experience in the Microsoft Azure technology stack is a plus.Experience with data analytics and visualization is a plus.Preferred Knowledge:Intermediate knowledge of OLTP and OLAP database designIntermediate knowledge of data modeling (normalized and dimensional)Intermediate knowledge of ETL, ELT architecture especially for real and near-real-time scenariosIntermediate knowledge of Data Architecture implementation patternsAnticipated salary for candidates living in the NY Metro market in the 140,000 to 160,000 range.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Laguna Games is the developer of Crypto Unicorns, the #1 NFT project on Polygon, and now one of the fastest-growing games. We are looking to hire an experienced Data Engineer to join our team. You are self-motivated, goal-orientated, and a strong team player. As a Data Engineer, you will be responsible for designing, building, and maintaining the data infrastructure that supports our gaming platform. You will work closely with our product, engineering, and data science teams to collect, process, and analyze large amounts of data generated by our gaming platform to inform our business decisions and improve user experience. You will work and innovate at the forefront of web3 gaming, bringing together unique technologies to deliver a new gaming experience.As a Data Engineer at our Web3 Gaming Startup, Key Responsibilities:Develop and maintain the data pipeline that ingests, processes and stores large amounts of data generated by our gaming platformDesign and build scalable data solutions that support the real-time analytics and reporting needs of the businessCollaborate with the product, engineering and data science teams to identify and implement data-driven solutions to improve user engagement, retention and monetizationBuild and maintain data models, data warehouses and data marts to support business intelligence and reporting needsEnsure data quality, integrity and security across all data sources and systemsMonitor and optimize data performance and scalability, and identify and resolve any data-related issues and bottlenecksKeep up-to-date with the latest trends, tools and technologies in data engineering and apply them to improve our data infrastructureQualificationsBachelor's degree in Computer Science, Computer Engineering, or related field3+ years of experience in data engineering or related fieldExperience with big data technologies such as Hadoop, Spark, Kafka, and ElasticsearchStrong proficiency in SQL, Python and/or Java programming languagesExperience with cloud-based data solutions such as AWS, Azure or Google CloudFamiliarity with data modeling, ETL/ELT processes, data warehousing, and business intelligence toolsUnderstanding of blockchain technology and its use in gaming platforms is a plusExcellent communication skills, both written and verbal, and ability to collaborate with cross-functional teamsIf you are passionate about data engineering and excited about the opportunity to work in a fast-paced and dynamic startup environment, we would love to hear from you!Laguna Games is the developer of Crypto Unicorns, a new blockchain-based game centered around awesomely unique Unicorn NFTs that players use in a fun farming simulation and in a variety of exciting battle loops. As game developers, we are excited to move away from the extractive nature of Free-2-Play to foster and nurture community-run game economies. Crypto Unicorns is our first digital nation and we are extremely excited to build it in tandem with our player community!We are headquartered in San Francisco, CA but operate as a remote company with locations around the world. We offer competitive compensation along with health benefits (medical, dental, and vision), 401k retirement savings, open paid time off, and a remote work support stipend.Learn more here!https://laguna.gameshttps://www.cryptounicorns.fun\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Become a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Nike USA, Inc., located in Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into engineering designs and logical units of work. Profile and analyze data for the purpose of designing scalable solutions. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Implement complex automated routines using workflow orchestration tools. Anticipate, identify and tackle issues concerning data management to improve data quality. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks.Applicant must have a Bachelor’s degree in Data Science, Computer Engineering, Computer Science, or Computer Information Systems and five (5) years of progressive post-baccalaureate experience in the job offered or engineering-related occupation. Experience must include the following- Programming ability (Python, SQL);  Database related concept;  Big Data exposure;  Spark;  Airflow (Orchestration tools);  Cloud Solutions;  Software/Data design ability;  CI/CD understanding and implementation;  Code review;  Data Architecture; and  AWS, Azure. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.]]>\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Applicants must be authorized to work for any employer in the United States. We are unable to sponsor, or take over sponsorship, of an employment visa at this time.About the roleReporting to the SVP, Data & Technology and Lead Data Engineer, the Data Engineer will play a critical role in supporting and advancing Geopath’s new audience measurement platform.Responsibilities:Build scalable functions, fault tolerant batch & real time data pipelines to validate/extract/transform/integrate large scale datasets inclusive of location and time series data, across multiple platformsReview current data processes to identify improvement areas: design and implement solutions to improve scalability, performance, cost efficiencies and data qualityExtend and optimize Geopath’s data platform, which spans across multiple cloud services, data warehouses, and applications in order to meet the industry’s evolving data needsResearch, evaluate, analyze and integrate new data sources and develop quick prototypes for new data productsWork closely with product owners, data architects, data scientists and application development teams to quickly define prototypes, and build new data productsDevelop a solid understanding of the nuances within Geopath’s foundational data sourcesSupport internal stakeholders including data, design, product and executive teams by assisting them with data-related technical issuesRequirements:Bachelor’s or master's degree in computer science, computer engineering, informatics, or equivalent fields3+ years of experience as a Data Engineer with demonstrated experience in data modeling, ETL, data warehouse/data lakes, and consolidating data from multiple data sources3+ years of experience with SQL, solid experience in writing stored procedures and UDFs, familiarity with Snowflake’s data warehouse a plus2+ years of experience in building and optimizing scalable and robust big data pipelines in Apache Airflow or other workflow engines and fluent in Python or Java programmingGood working knowledge in data partition and query optimizationExperience or desire to work in a start-up environment, good team player, and can work independently with minimal supervisionGreat analytical and problem-solving skills, eager to learn new technologies and willing to wear different hats in a small team settingGreat communication and organizational skillsExpected salary for this role is between $75,000-$140,000 per year, depending on experience.About Geopath Inc.Established in 1933, Geopath, (previously the Traffic Audit Bureau for Media Measurement Inc.,) has been the gold standard in providing media auditing and audience measurement services for the Out of Home industry in the US for 90 years. Geopath has now expanded its historical mission and is looking to the future by modernizing its mission critical, industry-standard media audience rating platform while embracing the digital era. In addition to being the industry’s media auditing solution, Geopath also analyzes people’s movement data, develops deep consumer insights, innovations and advanced media research methodologies to uncover critical insights about how consumers engage with Out of Home advertising across a multi-channel ecosystem and in the physical world.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We are currently hiring a Senior Data Platform Engineer to help grow our company and ensure our mission is achieved!This role is a work from home position and can be performed remotely anywhere in the continental US or in one of our corporate locations in Utah or Arizona.WE ARE: Our Data Platforms embodies the modernity and transformational vision that is core to our business evolution. As passionate and hungry technical experts, we progress through technology. We take pride in our engineering, daily progress, and bringing others along as we improve. We experiment, fail fast, and drive to delivery.YOU ARE: A self-starter mindset to proactively take ownership and execute work without daily oversight and excited to develop your data administration & data DevOps skills. We have a great team of engineers building next-generation data platforms. You are motivated by challenges and thrive with continuous innovation.YOUR DAY-TO-DAY:Coach and develop fellow team membersWorking in an agile-scrum development environmentWork with engineers and leaders to promote a shared vision of our data platform & architectureTrack operating metrics for our data platforms, driving improvements and making trade-offs among competing constraints. We use MS SQL Server, AWS RDS (Postgres, MariaDB) MongoDB, DynamoDB, Redis, Rabbit MQ, AWS managed messaging/eventing systems (Kafka, Kinesis, SQS, SNS) to name a few of our platformsBe a strategic player in designing enterprise-wide data infrastructureBuilds robust systems with an eye on the long-term maintenance and support of the applicationDiscover automation opportunities to replace manual processes using PowerShell, Terraform, Python etcBuild out frameworks for data administration /data deployment /monitoring where neededLeverage reusable code modules to solve problems across the team and organizationCreate and maintain automated pipelines to deploy changes via Octopus, CircleCI, Azure DevOps and JenkinsProactive and reactive performance analysis, monitoring, troubleshooting and resolution of escalated issuesParticipate in the team on-call rotationsYOU’LL BRING:Used multiple data platforms and can define which is optimal for a given scenario (such as document databases, RDBMS, caching, eventing, etc. On-prem or cloud)An engineering mindset when developing a solution using PowerShell / Python or SQL. In depth knowledge and use of tools such as dbatools and other modules is a plusUnderstand how to fully automate systems using infrastructure/configuration as code technologies (we use Terraform, CloudFormation, Ansible, SaltStack)Experience working with CI/CD pipeline and tools preferably Octopus, CircleCI, AzureDevOps and JenkinsProven ability to mentor and coach engineersThrive on a high level of autonomy and responsibility, while having the ability to dig into technical details to inform decisionsAdvanced Sql Server Knowledge and experience in performance analysis and tuning skills such as tracing and profiling and Dynamic Management Views and Functions (DMVs) and other third-party tools like SentryOne to ensure high levels of performance, availability, and securityKnowledge of database deployment using DACPAC via pipelinesExperience with enterprise features of SQL Server: AlwaysOn Availability Groups, clustering, Disaster RecoveryContribute to the management and reliability of database HA/DR processesYOU MIGHT ALSO HAVE:Ability to clearly articulate complex subjects to leadership and others not familiar with this spaceExperience with code-based data developmentA self-starter mindset to proactively take ownership and execute work without daily oversightExperience in AWS cloud-based solutionsWE OFFER: Competitive Compensation; Eligible for STI + LTIFull Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental LeaveCompany Matched 401kPaid Time Off + Paid Holidays + Paid Volunteer HoursEmployee Resource Groups (Black Inclusion Group, Women in Leadership, PRIDE, Adelante)Employee Stock Purchase ProgramTuition ReimbursementCharitable Gift MatchingJob required equipment and services\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our team relies on clean datasets accessible via the latest tools to answer questions that are often not simple or clear. You will be creating solutions that will help derive value from our rich datasets that will solve tough problems impacting consumers across geographies & industries (healthcare, retail/ consumer, telecom, industrial) driving technology transformation. At the core of our team, we believe data is best used to create transparency & generate communal value.  What You’ll Do: · Design, Build & ImplementDesign & build batch, event driven and real-time data pipelines using some of the latest technologies available on Microsoft Azure, Google Cloud Platform and AWSImplement large-scale data platforms to meet the analytical & operational needs across various organizationsBuild products & frameworks that can be re-used across different use-cases in increase efficiency in coding and agility in implementation of solutionsBuild streaming ingestion processes to efficiently read, process, analyze & publish data for real-time need of applications and data science modelsPerform analyses of large structured and unstructured data to solve multiple & complex business problemsInvestigate and prototype different task dependency frameworks to understand the most appropriate design for a given use case to assess & advise Understand business use cases to design engineering routines to affect the outcomesReview & assess data frameworks & technology platforms with the goal of suggesting & implementing improvements on the existing frameworks & platforms.Understand quality of data used in existing use cases to suggest process improvements & implement data quality routines   Who You Are : An Engineer interested in working in batch, event driven and streaming processing environments A tech-enthusiast excited to work with Cloud Based Technologies like GCP, Azure & AWSA data parser expert who gets excited about structuring and re-structuring datasets programmatically A doer who loves to produce meaningful analytic insights for an innovative, data-intensive productsAlways curious about analytics frameworks and you are well-versed in the advantages and limitations of various big data architectures and technologiesTechnologist who loves studying software platforms with an eye towards modernizing the architectureBeliever in transparency, communication, and teamworkLove to learn and not afraid to take ownershipNexus Staffing is committed to diversity, inclusion, and equal opportunity. We take affirmative steps to ensure that all programs and services are open to all Americans, free of discrimination based on protected class status, including race, religion/creed, color, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, national origin (including limited English proficiency), age, political affiliation or belief, military or veteran status, disability, predisposing genetic characteristics, marital or family status, domestic violence victim status, arrest record or criminal conviction history, or any other impermissible basis.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Company OverviewPrivately owned and operated, Digible was founded in 2017 with a mission to bring sophisticated digital marketing solutions to the multifamily industry. We offer a comprehensive suite of digital services as well as a predictive analytics platform, Fiona, that is the first of its kind.At Digible, Inc. we love to celebrate our diverse group of hardworking employees – and it shows. We pride ourselves on our collaborative, transparent, and authentic culture. These values are pervasive throughout every step of a Digible employee\\'s journey. Starting with our interviews and continuing through our weekly All Hands Transparency Round-up, values are at the heart of working at Digible.We value diversity and believe forming teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds and different industries to apply. Come join us and find out what the best work of your career could look like here at Digible.The RoleDigible, Inc. is looking for an Junior Software Engineer to join our team!We are seeking a highly motivated and detail-oriented Junior Data Engineer to join our growing team. As a Junior Data Engineer, you will be responsible for assisting with the development, implementation, and maintenance of our data infrastructure. You will work closely with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources.Responsibilities:Assist with the design, development, and maintenance of our data infrastructure using Python, Prefect, Snowflake, Google Cloud, and AWS. Collaborate with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources. Develop and maintain ETL pipelines to extract, transform, and load data from various sources into our data warehouse. Assist with the implementation of data security and governance policies. Monitor and troubleshoot data issues as they arise. Continuously seek ways to improve our data infrastructure and processes. Requirements:Bachelor\\'s degree in Computer Science, Data Science, or a related field. Experience with Python, SQL, and data modeling. Familiarity with data warehousing concepts and ETL processes. Experience working with cloud-based platforms such as Google Cloud and AWS. Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Expectations:Ability to learn and adapt quickly to new technologies and processes. Work collaboratively with our Data Engineering team to meet project goals and deadlines. Demonstrate a high level of professionalism and dedication to quality work. Communicate effectively with cross-functional teams to ensure project success. Success Metrics:Deliver high-quality data infrastructure projects on time and within scope. Ensure data accuracy and completeness across all data sources. Maintain a high level of data security and governance. Continuously seek ways to improve our data infrastructure and processes. Collaborate effectively with cross-functional teams to meet project goals and objectives. Core ValuesAuthenticity - The commitment to be steadfast and genuine with our actions and communication toward everyone we touch.Curiosity - The belief that a deep and fundamental curiosity (the \"why\") in our work is vital to company innovation and evolution.Focus - The collective will to remain completely devoted and ultimately accountable to our deliverables.Humility - The recognition and daily practice that \"we\" is always greater than \"I\".Happiness - The decision to prioritize passion and love for what we do above everything else.Perks and such:4-Day Work Week (32 Hour Work Week)WFA (Work From Anywhere)Profit Sharing BonusWe offer 3 weeks of PTO as well as Sick leave, and Bereavement. We offer 10 paid holidays (New Years Eve, New Years Day, MLK day, Memorial Day, Independence Day, Labor Day, Thanksgiving + day after, Christmas Eve, and Christmas)401(k) + Match50% employer paid health benefits, including Medical, Dental, and Vision. We provide $75/ month reimbursement for Physical WellnessWe provide $75/ month reimbursement for Mental Wellness$1000/year travel fund for employees who have been with Digible 3+ yearsMonthly subscription for financial wellnessDog-Friendly OfficePaid Parental LeaveCompany Sponsored Social EventsCompany Provided Lunches, SnacksEmployee Development Program\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'R-27413Who Are We?Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.Compensation OverviewThe annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.Salary Range$102,600.00 - $169,200.00Target Openings1What Is the Opportunity?Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Personal Insurance Analytics and business intelligence/insights.What Will You Do?Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.Design data solutions.Analyze sources to determine value and recommend data to include in analytical processes.Incorporate core data management competencies including data governance, data security and data quality.Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.Test data movement, transformation code, and data components.Perform other duties as assigned.What Will Our Ideal Candidate Have?Bachelor’s Degree in STEM related field or equivalentSix years of related experienceProficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. Experience with Salesforce and Tealium Product Suite a plus.The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.Strong verbal and written communication skills with the ability to interact with team members and business partners.Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.What is a Must Have?Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.What Is in It for You?Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.Employment PracticesTravelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.Travelers reserves the right to fill this position at a level above or below the level included in this posting.To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role has a preference for a local Austin, TX candidate and will be a hybrid work environment meeting in-person a few times/month. Our client is a fast-growing, Private Equity backed GovTech company that provides SaaS Software solutions to the Public Sector (City / State Local Government) and is looking for a Data Engineer to join their team. Reporting to the Director of Analytics as their first hire, you will be responsible for the ongoing development and management of the data infrastructure of the business and will be providing essential support to internal customers. This pivotal role will be in the Analytics team reporting to Finance and is aimed to drive greater efficiency in data, processes, and tools, ultimately enhancing data-driven decision-making capabilities. For someone with an interest in more of the analytics side of things, this role could also serve as a hybrid Analytics / Dashboarding role as well. This role is great for someone who perhaps hasn't yet chosen a specific specialization or path in the data realm and wants to gain exposure or opportunity in different areas - Whether BI Front End, Business Strategy, Analytics / Dashboarding, or Data Engineering there are a plethora of opportunities to learn and jump in to help the business. One of the major projects you'll be working on is how to collect data on the usage of their underlying SaaS Software products and how to marry that with their CRM data. They have different products that were built at different times so getting to and extracting that data is going to be an especially interesting challenge for this team. ResponsibilitiesDesign, develop, and maintain scalable data pipelines and ETL processes to ingest and process data from various sourcesBuild and optimize the data warehouse in SnowflakeCollaborate with data users to understand requirements and create efficient data models and structures for seamless reporting and analysis using BI tools. Monitor and optimize data pipeline performanceImplement data governance and security best practices, manage user access, and ensure compliance is adhered toContinuously explore and evaluate new data engineering techniques and tools, including AI applications, to improve data processing and exploration capabilities. QualificationsExperience building or using data marts (sql heavy data modeling) and interacting with users that use the data. The ability to find the shortest path to making data available and widely usable. Experience building or extending a Data WarehouseStrong exposure to Data Warehouse patterns and the application of those patternsPrevious experience working with business stakeholdersStrong initiative to start new projects or take existing projects and make them better. Proficiency with Snowflake, Tableau, and Stitch, or similar data warehousing, BI, and ETL tools. Strong knowledge of SQL is required with database design and data modeling experience. Experience with Python or another programming language for data processing. Familiarity with data engineering best practices, including data quality, data governance, and data security. Interest in AI applications for data engineering and data exploration. Excellent problem-solving, communication, and collaboration skills. Extra informationCareer development opportunitiesCompetitive insurance (medical, dental, vision, and voluntary life & disability)Mental health benefits401(k) plan (company matching)Paid holidaysFlexible PTO - no accrualsPaid generous parental leaveBusiness casual environment #ZR\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"As a Data Engineer for our Data Platform Engineering team you will join skilled Scala/ Spark engineers and core database developers responsible for developing hosted cloud analytics infrastructure (Apache Spark-based), distributed SQL processingframeworks, proprietary data science platforms, and core database optimization. This team is responsible for building the automated, intelligent, and highly performant query planner and execution engines, RPC calls between datawarehouse clusters, shared secondary cold storage, etc. This includes building new SQL features and customer-facing functionality, developing novel query optimization techniques for industry-leading performance, and building a databasesystem that's highly parallel, efficient and fault-tolerant. This is a vital role reporting to exec leadership and senior engineering leadershipRequirementsResponsibilities:Writing Scala code with tools like Apache Spark + Apache Arrow + Apache Kafka to build a hosted, multi-cluster data warehouse for Web3Developing database optimizers, query planners, query and data routing mechanisms, cluster-to-cluster communication, and workload management techniques.Scaling up from proof of concept to “cluster scale” (and eventually hundreds of clusters with hundreds of terabytes each), in terms of both infrastructure/architecture and problem structureCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate meta data capturing and managementManaging a team of software engineers writing new code to build a bigger, better, faster, more optimized HTAP database (using Apache Spark, Apache Arrow, Kafka, and a wealth of other open source data tools)Interacting with exec team and senior engineering leadership to define, prioritize, and ensure smooth deployments with other operational componentsHighly engaged with industry trends within analytics domain from a data acquisition processing, engineering, management perspectiveUnderstand data and analytics use cases across Web3 / blockchainsSkills & QualificationsBachelor’s degree in computer science or related technical field. Masters or PhD a plus.6+ years experience engineering software and data platforms / enterprise-scale data warehouses, preferably with knowledge of open source Apache stack (especially Apache Spark, Apache Arrow, Kafka, and others)3+ years experience with Scala and Apache Spark (or Kafka)A track record of recruiting and leading technical teams in a demanding talent marketRock solid engineering fundamentals; query planning, optimizing and distributed data warehouse systems experience is preferred but not requiredNice to have: Knowledge of blockchain indexing, web3 compute paradigms, Proofs and consensus mechanisms... is a strong plus but not requiredExperience with rapid development cycles in a web-based environmentStrong scripting and test automation knowledgeNice to have: Passionate about Web3, blockchain, decentralization, and a base understanding of how data/analytics plays into this\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Data Engineer Qualifications7+ years of experience as a Database Developer3+ years of experience as a hands on Team LeadExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectureStrong data modeling skills (relational, dimensional and flattened)5-7 years of experience with SQL Server On-Prem and/or Azure cloud, required5-7 years of SSIS experience utilizing SQL Agent jobs and Integration Services Catalog, required3-4 years of experience running ETL/ELT SSIS projects independently from end to end, requiredExperience with DevOps Repository and Git, preferredAzure Data Lake storage experience, a plusAzure Data Factory and/or Databricks experience, a plusLocation: Denver, COEmployment Type: Direct HireDuration: Full TimeWork Location: Denver / HybridPay: Based on experienceOther: PTO, Medical, Dental, Vision, Disability, Life, 401k benefits available Thank you in advance for your interest in this opportunity!If you are able to work on a W2 basis without sponsorship for ANY US employer and fit the description above, please apply. Third-Party Applications Not Accepted.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Hi,Hope you are doing well,We at Software Technology Inc. hiring for a Data Engineer/Data Analyst, role, if you are interested and a good fit, feel free to reach me directly at ksuresh@stiorg.com or (609) 998-3431.Role : Data Engineer/Data AnalystLocation : RemoteSkillGCP Big Query, Python, SQL and knowledge of Healthcare domain\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'To support internal and external clients via processing and handling of data. To generate data solutions for ongoing immediate day to day business needs.Essential FunctionsDay to day functions include the following:Design data models and develop database structures in Microsoft SQL server.Write various database objects like stored procedures, functions, views, triggers for various front end applications.Write SQL scripts, create SQL agent jobs to automate tasks like data importing, exporting, cleansing tasks.Create database deployment packages for deploying changes.Identify & repair inconsistencies in data, database tuning, query optimization.Able to generate ad hoc data on demand.Able to identify best practices, documentation, communicate all aspects of projects in a clear, concise mannerDevelop simple SSIS packages to perform various ETL functions including data cleansing, manipulating, importing, exporting.Develop & maintain client facing reports by using various data manipulation techniques in SSRS and Visual Studio.DocumentationOptimization recommendationsDay to day troubleshooting.NET Programming as neededEducation/ExperienceBA, BS, or Masters in computer science/related field preferred or an equivalent combination of education and experience derived from at least 2 years of professional work experienceSolid experience with various versions of MS SQL Server and TSQL programmingMicrosoft Certified DBA a plusSkills/KnowledgeStrong experience in writing efficient SQL codeWorking knowledge of SQL Server Management Studio (SSMS)Knowledge of SQL Server Reporting Services (SSRS)Knowledge of SQL Server Integration Services (SSIS)Knowledge of Red Gate DBA Tool Belt (SQL Compare, SQL Data Compare, SQL Source Control) a plusKnowledge of data science technologies is a plusClear, concise communication skills, excellent organizational skillsHighly self-motivated and directedKeen attention to detailHigh level of work intensity in a team environmentHigh integrity and values-drivenEager for professional developmentExperience and understanding of source control management a plusWhat We OfferAt Bloom, we offer an engaging, supportive work environment, great benefits, and the opportunity to build the career you always wanted. Benefits of working for Bloom include:Competitive compensation Comprehensive health benefits Long-term career growth and mentoring About BloomAs an insurance services company licensed in 48 contiguous U.S. states, Bloom focuses on enabling health plans to increase membership and improve the enrollee experience while reducing costs. We concentrate on two areas of service: technology services and call center services and are committed to ensuring our state-of-the-art software products and services provide greater efficiency and cost savings to clients.Ascend Technology ™Bloom provides advanced sales and enrollment automation technology to the insurance industry through our Ascend ™. Our Ascend™ technology platform focuses on sales automation efficiencies and optimizing the member experience from the first moment a prospect considers a health plan membership.Bloom is proud to be an Equal Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.What PepsiCo Data Management and Operations does: Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders Increase awareness about available data and democratize access to it across the companyJob DescriptionAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company.As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, onpremise data sources as well as cloud and remote systems.ResponsibilitiesActive contributor to code development in projects and services.Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.Build and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.Responsible for implementing best practices around systems integration, security, performance and data management.Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape.Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.Develop and optimize procedures to “productionalize” data science models.Define and manage SLA’s for data products and processes running in production.Support large-scale experimentation done by data scientists.Prototype new approaches and build solutions at scale.Research in state-of-the-art methodologies.Create documentation for learnings and knowledge transfer.Create and audit reusable packages or libraries.Qualifications4+ years of overall technology experience that includes at least 3+ years of hands-on software development, data engineering, and systems architecture.3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.3+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).2+ years in cloud data engineering experience in Azure.Fluent with Azure cloud services. Azure Certification is a plus.Experience with integration of multi cloud services with on-premises technologies.Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines.Experience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.Experience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.Experience with version control systems like Github and deployment & CI tools.Experience with Azure Data Factory, Azure Databricks and Azure Machine learning tools is a plus.Experience with Statistical/ML techniques is a plus.Experience with building solutions in the retail or in the supply chain space is a plusUnderstanding of metadata management, data lineage, and data glossaries is a plus.Working knowledge of agile development, including DevOps and DataOps concepts. Familiarity with business intelligence tools (such as PowerBI).EducationBA/BS in Computer Science, Math, Physics, or other technical fields.Skills, Abilities, KnowledgeExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.Proven track record of leading, mentoring data teams.Strong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.Ability to understand and translate business requirements into data and technical requirements. High degree of organization and ability to manage multiple, competing projects and priorities simultaneously.Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment.Strong leadership, organizational and interpersonal skills; comfortable managing trade-offs.Foster a team culture of accountability, communication, and self-management.Proactively drives impact and engagement while bringing others along.Consistently attain/exceed individual and team goals.Ability to lead others without direct authority in a matrixed environment.CompetenciesHighly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.Understands both the engineering and business side of the Data Products released.Places the user in the center of decision making.Teams up and collaborates for speed, agility, and innovation.Experience with and embraces agile methodologies.Strong negotiation and decision-making skill.Experience managing and working with globally distributed teamsCOVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable lawEEO StatementAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender IdentityIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.Please view our Pay Transparency Statement\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionAt Johnson & Johnson, we use technology and the power of teamwork to discover new ways to prevent and overcome the world’s the most significant healthcare challenges. Our Corporate, Consumer Health, Medical Devices, and Pharmaceutical teams leverage data, real-world insights, and creative minds to make life-changing healthcare products and medicines. We're disrupting outdated healthcare ecosystems and infusing them with transformative ideas to help people thrive throughout every stage of their lives. With a reach of more than a billion people every day, there’s no limit to the impact you can make here. Are you ready to reimagine healthcare?Here, your career breakthroughs will change the future of health, in all the best ways. And you’ll change, too. You’ll be inspired, and you’ll inspire people across the world to change how they care for themselves and those they love. Amplify your impact. Join us! Tasked with transforming data into a format that can be easily consumes by ML algorithms. Adept Database basics SQL, capable of basic data engineering techniques – data wrangling, data cleansing, data curation. Fluent in one of the programming languages R or Python.  Data Engineering skills, e.g., cleaning/organizing data, data preparation, data collection, data integration across different data sources, data storage, relational/non-relational database management.  Proficient in structured query language (SQL), NoSQL, MATLAB, and programming in Python or R.  Proficient in Applied Machine Learning – Experience with a variety of algorithms, Building Predictive Models, Cross-validating, Hypertuning and Deployment.  Experience with devising and implementing ML methods for protein or antibody modeling or design, or with deep learning methods that relate protein sequence, structure, property or function.  MD simulation software (e.g., Commercial tools like Schrodinger, or open-source software AMBER, GROMACS, etc.). Additionally, prior experience in homology modeling and structural refinement  Knowledgeable of AWS services including Redshift, RDS, EMR and EC2  Working knowledge using software and tools including big data tools like Kafka, Spark and Hadoop. At Johnson & Johnson, we’re on a mission to change the trajectory of health for humanity. That starts by creating the world’s healthiest workforce. Through cutting-edge programs and policies, we empower the physical, mental, emotional and financial health of our employees and the ones they love. As such, candidates offered employment must show proof of COVID-19 vaccination or secure an approved accommodation prior to the commencement of employment to support the well-being of our employees, their families and the communities in which we live and work.Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Primary LocationNA-US-Pennsylvania-Spring HouseOrganizationJanssen Research & Development, LLC (6084)Job FunctionAdministration\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatmentSchedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewMailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaigns, CRM, and analytics tools.The Data Platform team at Mailchimp is responsible for creating and managing our BI platform that enables peeps from across the company to make better decisions with data. What that actually looks like is working with folks from across the company to understand their needs and then surface data in a meaningful way, across tools and teams, to help them drive the business forward. Day to day you could be building an ETL pipeline, designing a data access tool, modeling out new data in Looker, or working with teams to develop better data governance practices. We have a lot of tools in our toolbelt, but all with the main goal helping Mailchimp to continue to use data more effectively.Intuit Mailchimp is a hybrid workplace , giving employees the opportunity to collaborate in person with team members in our Atlanta and Brooklyn offices two or more days per week.What You'll BringExperience with Python, Java, Go, or another OOP languageExperience with SQL and data analysis skillsExperience with data transformation tools like dbt or DataformExperience in visualization technologies like Looker, Tableau, or Qlik SenseExperience with Airflow or other ETL orchestration toolsSolid business intuition and ability to understand and work with cross-functional partnersExperience with GCP/AWS or other cloud providers is preferredBachelors degree is Computer Science or equivalent experience Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Mailchimp we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.How You Will LeadPartner with analysts, data scientists, business users, and other engineers to understand their needs and come up with data solutionsHelp build robust transformation pipelines to help clean up, normalize, and govern our data for broad consumptionHelp build scalable transformation pipelines that enables teams to easily clean up, normalize, and govern data for broad consumptionBuild tools and processes to help make the right data accessible to the right peopleModel data in Looker, to provide a collaborative data analytics platform for the companyWork with Data Stewards to better document our data\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Well known NY based Non-Profit seeks a Data Engineer.An ideal candidate will have strong data engineering skills with both SQL and Python.This position can be based out of NYC or be 100% remote.Compensation includes salary, excellent medical, dental, vision benefits, pto, 401k, a quality of life oriented work life balance, and lots of other benefits.ResponsibilitiesThis position will work within the enterprise data engineering team to continuously build, maintain, and improve the design, performance, reliability, scalability, security, and architecture of enterprise data products.Responsibilities include:Develop robust database solutions, data integration (ETL, ELT) packages, automation, performance monitoring, SQL coding, database tuning and optimizations, security management, capacity planning, database HA, and database DR solutions across required data platforms.Conduct in-depth data analysis to support data product design.Identify and resolve production database and data integration issues.Collaborates closely with data quality, application, and visualization teams to deliver high-quality data products.Participate in code review, QA, release, and continuous deployment processes.Qualifications:Bachelors Degree in Computer Science or other quantitative disciplines such as Science, Statistics, Economics or Mathematics.5+ years of progressive database development experience with the Microsoft SQL Server family suite.Experience with data modeling and data architecture principles for both analytics and transactional systems.Hands-on experience with SQL Server, Oracle, or other RDBMS required.Python ScriptingExperience with Cloud Data PlatformsPreferred Experience:Scripting experience in Powershell, C#, Java, and/or R.Experience in the Microsoft Azure technology stack is a plus.Experience with data analytics and visualization is a plus.Preferred Knowledge:Intermediate knowledge of OLTP and OLAP database designIntermediate knowledge of data modeling (normalized and dimensional)Intermediate knowledge of ETL, ELT architecture especially for real and near-real-time scenariosIntermediate knowledge of Data Architecture implementation patternsAnticipated salary for candidates living in the NY Metro market in the 140,000 to 160,000 range.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Laguna Games is the developer of Crypto Unicorns, the #1 NFT project on Polygon, and now one of the fastest-growing games. We are looking to hire an experienced Data Engineer to join our team. You are self-motivated, goal-orientated, and a strong team player. As a Data Engineer, you will be responsible for designing, building, and maintaining the data infrastructure that supports our gaming platform. You will work closely with our product, engineering, and data science teams to collect, process, and analyze large amounts of data generated by our gaming platform to inform our business decisions and improve user experience. You will work and innovate at the forefront of web3 gaming, bringing together unique technologies to deliver a new gaming experience.As a Data Engineer at our Web3 Gaming Startup, Key Responsibilities:Develop and maintain the data pipeline that ingests, processes and stores large amounts of data generated by our gaming platformDesign and build scalable data solutions that support the real-time analytics and reporting needs of the businessCollaborate with the product, engineering and data science teams to identify and implement data-driven solutions to improve user engagement, retention and monetizationBuild and maintain data models, data warehouses and data marts to support business intelligence and reporting needsEnsure data quality, integrity and security across all data sources and systemsMonitor and optimize data performance and scalability, and identify and resolve any data-related issues and bottlenecksKeep up-to-date with the latest trends, tools and technologies in data engineering and apply them to improve our data infrastructureQualificationsBachelor's degree in Computer Science, Computer Engineering, or related field3+ years of experience in data engineering or related fieldExperience with big data technologies such as Hadoop, Spark, Kafka, and ElasticsearchStrong proficiency in SQL, Python and/or Java programming languagesExperience with cloud-based data solutions such as AWS, Azure or Google CloudFamiliarity with data modeling, ETL/ELT processes, data warehousing, and business intelligence toolsUnderstanding of blockchain technology and its use in gaming platforms is a plusExcellent communication skills, both written and verbal, and ability to collaborate with cross-functional teamsIf you are passionate about data engineering and excited about the opportunity to work in a fast-paced and dynamic startup environment, we would love to hear from you!Laguna Games is the developer of Crypto Unicorns, a new blockchain-based game centered around awesomely unique Unicorn NFTs that players use in a fun farming simulation and in a variety of exciting battle loops. As game developers, we are excited to move away from the extractive nature of Free-2-Play to foster and nurture community-run game economies. Crypto Unicorns is our first digital nation and we are extremely excited to build it in tandem with our player community!We are headquartered in San Francisco, CA but operate as a remote company with locations around the world. We offer competitive compensation along with health benefits (medical, dental, and vision), 401k retirement savings, open paid time off, and a remote work support stipend.Learn more here!https://laguna.gameshttps://www.cryptounicorns.fun\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Become a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Nike USA, Inc., located in Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into engineering designs and logical units of work. Profile and analyze data for the purpose of designing scalable solutions. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Implement complex automated routines using workflow orchestration tools. Anticipate, identify and tackle issues concerning data management to improve data quality. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks.Applicant must have a Bachelor’s degree in Data Science, Computer Engineering, Computer Science, or Computer Information Systems and five (5) years of progressive post-baccalaureate experience in the job offered or engineering-related occupation. Experience must include the following- Programming ability (Python, SQL);  Database related concept;  Big Data exposure;  Spark;  Airflow (Orchestration tools);  Cloud Solutions;  Software/Data design ability;  CI/CD understanding and implementation;  Code review;  Data Architecture; and  AWS, Azure. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.]]>\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We are currently hiring a Senior Data Platform Engineer to help grow our company and ensure our mission is achieved!This role is a work from home position and can be performed remotely anywhere in the continental US or in one of our corporate locations in Utah or Arizona.WE ARE: Our Data Platforms embodies the modernity and transformational vision that is core to our business evolution. As passionate and hungry technical experts, we progress through technology. We take pride in our engineering, daily progress, and bringing others along as we improve. We experiment, fail fast, and drive to delivery.YOU ARE: A self-starter mindset to proactively take ownership and execute work without daily oversight and excited to develop your data administration & data DevOps skills. We have a great team of engineers building next-generation data platforms. You are motivated by challenges and thrive with continuous innovation.YOUR DAY-TO-DAY:Coach and develop fellow team membersWorking in an agile-scrum development environmentWork with engineers and leaders to promote a shared vision of our data platform & architectureTrack operating metrics for our data platforms, driving improvements and making trade-offs among competing constraints. We use MS SQL Server, AWS RDS (Postgres, MariaDB) MongoDB, DynamoDB, Redis, Rabbit MQ, AWS managed messaging/eventing systems (Kafka, Kinesis, SQS, SNS) to name a few of our platformsBe a strategic player in designing enterprise-wide data infrastructureBuilds robust systems with an eye on the long-term maintenance and support of the applicationDiscover automation opportunities to replace manual processes using PowerShell, Terraform, Python etcBuild out frameworks for data administration /data deployment /monitoring where neededLeverage reusable code modules to solve problems across the team and organizationCreate and maintain automated pipelines to deploy changes via Octopus, CircleCI, Azure DevOps and JenkinsProactive and reactive performance analysis, monitoring, troubleshooting and resolution of escalated issuesParticipate in the team on-call rotationsYOU’LL BRING:Used multiple data platforms and can define which is optimal for a given scenario (such as document databases, RDBMS, caching, eventing, etc. On-prem or cloud)An engineering mindset when developing a solution using PowerShell / Python or SQL. In depth knowledge and use of tools such as dbatools and other modules is a plusUnderstand how to fully automate systems using infrastructure/configuration as code technologies (we use Terraform, CloudFormation, Ansible, SaltStack)Experience working with CI/CD pipeline and tools preferably Octopus, CircleCI, AzureDevOps and JenkinsProven ability to mentor and coach engineersThrive on a high level of autonomy and responsibility, while having the ability to dig into technical details to inform decisionsAdvanced Sql Server Knowledge and experience in performance analysis and tuning skills such as tracing and profiling and Dynamic Management Views and Functions (DMVs) and other third-party tools like SentryOne to ensure high levels of performance, availability, and securityKnowledge of database deployment using DACPAC via pipelinesExperience with enterprise features of SQL Server: AlwaysOn Availability Groups, clustering, Disaster RecoveryContribute to the management and reliability of database HA/DR processesYOU MIGHT ALSO HAVE:Ability to clearly articulate complex subjects to leadership and others not familiar with this spaceExperience with code-based data developmentA self-starter mindset to proactively take ownership and execute work without daily oversightExperience in AWS cloud-based solutionsWE OFFER: Competitive Compensation; Eligible for STI + LTIFull Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental LeaveCompany Matched 401kPaid Time Off + Paid Holidays + Paid Volunteer HoursEmployee Resource Groups (Black Inclusion Group, Women in Leadership, PRIDE, Adelante)Employee Stock Purchase ProgramTuition ReimbursementCharitable Gift MatchingJob required equipment and services\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our team relies on clean datasets accessible via the latest tools to answer questions that are often not simple or clear. You will be creating solutions that will help derive value from our rich datasets that will solve tough problems impacting consumers across geographies & industries (healthcare, retail/ consumer, telecom, industrial) driving technology transformation. At the core of our team, we believe data is best used to create transparency & generate communal value.  What You’ll Do: · Design, Build & ImplementDesign & build batch, event driven and real-time data pipelines using some of the latest technologies available on Microsoft Azure, Google Cloud Platform and AWSImplement large-scale data platforms to meet the analytical & operational needs across various organizationsBuild products & frameworks that can be re-used across different use-cases in increase efficiency in coding and agility in implementation of solutionsBuild streaming ingestion processes to efficiently read, process, analyze & publish data for real-time need of applications and data science modelsPerform analyses of large structured and unstructured data to solve multiple & complex business problemsInvestigate and prototype different task dependency frameworks to understand the most appropriate design for a given use case to assess & advise Understand business use cases to design engineering routines to affect the outcomesReview & assess data frameworks & technology platforms with the goal of suggesting & implementing improvements on the existing frameworks & platforms.Understand quality of data used in existing use cases to suggest process improvements & implement data quality routines   Who You Are : An Engineer interested in working in batch, event driven and streaming processing environments A tech-enthusiast excited to work with Cloud Based Technologies like GCP, Azure & AWSA data parser expert who gets excited about structuring and re-structuring datasets programmatically A doer who loves to produce meaningful analytic insights for an innovative, data-intensive productsAlways curious about analytics frameworks and you are well-versed in the advantages and limitations of various big data architectures and technologiesTechnologist who loves studying software platforms with an eye towards modernizing the architectureBeliever in transparency, communication, and teamworkLove to learn and not afraid to take ownershipNexus Staffing is committed to diversity, inclusion, and equal opportunity. We take affirmative steps to ensure that all programs and services are open to all Americans, free of discrimination based on protected class status, including race, religion/creed, color, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, national origin (including limited English proficiency), age, political affiliation or belief, military or veteran status, disability, predisposing genetic characteristics, marital or family status, domestic violence victim status, arrest record or criminal conviction history, or any other impermissible basis.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Company OverviewPrivately owned and operated, Digible was founded in 2017 with a mission to bring sophisticated digital marketing solutions to the multifamily industry. We offer a comprehensive suite of digital services as well as a predictive analytics platform, Fiona, that is the first of its kind.At Digible, Inc. we love to celebrate our diverse group of hardworking employees – and it shows. We pride ourselves on our collaborative, transparent, and authentic culture. These values are pervasive throughout every step of a Digible employee\\'s journey. Starting with our interviews and continuing through our weekly All Hands Transparency Round-up, values are at the heart of working at Digible.We value diversity and believe forming teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds and different industries to apply. Come join us and find out what the best work of your career could look like here at Digible.The RoleDigible, Inc. is looking for an Junior Software Engineer to join our team!We are seeking a highly motivated and detail-oriented Junior Data Engineer to join our growing team. As a Junior Data Engineer, you will be responsible for assisting with the development, implementation, and maintenance of our data infrastructure. You will work closely with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources.Responsibilities:Assist with the design, development, and maintenance of our data infrastructure using Python, Prefect, Snowflake, Google Cloud, and AWS. Collaborate with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources. Develop and maintain ETL pipelines to extract, transform, and load data from various sources into our data warehouse. Assist with the implementation of data security and governance policies. Monitor and troubleshoot data issues as they arise. Continuously seek ways to improve our data infrastructure and processes. Requirements:Bachelor\\'s degree in Computer Science, Data Science, or a related field. Experience with Python, SQL, and data modeling. Familiarity with data warehousing concepts and ETL processes. Experience working with cloud-based platforms such as Google Cloud and AWS. Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Expectations:Ability to learn and adapt quickly to new technologies and processes. Work collaboratively with our Data Engineering team to meet project goals and deadlines. Demonstrate a high level of professionalism and dedication to quality work. Communicate effectively with cross-functional teams to ensure project success. Success Metrics:Deliver high-quality data infrastructure projects on time and within scope. Ensure data accuracy and completeness across all data sources. Maintain a high level of data security and governance. Continuously seek ways to improve our data infrastructure and processes. Collaborate effectively with cross-functional teams to meet project goals and objectives. Core ValuesAuthenticity - The commitment to be steadfast and genuine with our actions and communication toward everyone we touch.Curiosity - The belief that a deep and fundamental curiosity (the \"why\") in our work is vital to company innovation and evolution.Focus - The collective will to remain completely devoted and ultimately accountable to our deliverables.Humility - The recognition and daily practice that \"we\" is always greater than \"I\".Happiness - The decision to prioritize passion and love for what we do above everything else.Perks and such:4-Day Work Week (32 Hour Work Week)WFA (Work From Anywhere)Profit Sharing BonusWe offer 3 weeks of PTO as well as Sick leave, and Bereavement. We offer 10 paid holidays (New Years Eve, New Years Day, MLK day, Memorial Day, Independence Day, Labor Day, Thanksgiving + day after, Christmas Eve, and Christmas)401(k) + Match50% employer paid health benefits, including Medical, Dental, and Vision. We provide $75/ month reimbursement for Physical WellnessWe provide $75/ month reimbursement for Mental Wellness$1000/year travel fund for employees who have been with Digible 3+ yearsMonthly subscription for financial wellnessDog-Friendly OfficePaid Parental LeaveCompany Sponsored Social EventsCompany Provided Lunches, SnacksEmployee Development Program\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'R-27413Who Are We?Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.Compensation OverviewThe annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.Salary Range$102,600.00 - $169,200.00Target Openings1What Is the Opportunity?Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Personal Insurance Analytics and business intelligence/insights.What Will You Do?Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.Design data solutions.Analyze sources to determine value and recommend data to include in analytical processes.Incorporate core data management competencies including data governance, data security and data quality.Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.Test data movement, transformation code, and data components.Perform other duties as assigned.What Will Our Ideal Candidate Have?Bachelor’s Degree in STEM related field or equivalentSix years of related experienceProficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. Experience with Salesforce and Tealium Product Suite a plus.The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.Strong verbal and written communication skills with the ability to interact with team members and business partners.Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.What is a Must Have?Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.What Is in It for You?Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.Employment PracticesTravelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.Travelers reserves the right to fill this position at a level above or below the level included in this posting.To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role has a preference for a local Austin, TX candidate and will be a hybrid work environment meeting in-person a few times/month. Our client is a fast-growing, Private Equity backed GovTech company that provides SaaS Software solutions to the Public Sector (City / State Local Government) and is looking for a Data Engineer to join their team. Reporting to the Director of Analytics as their first hire, you will be responsible for the ongoing development and management of the data infrastructure of the business and will be providing essential support to internal customers. This pivotal role will be in the Analytics team reporting to Finance and is aimed to drive greater efficiency in data, processes, and tools, ultimately enhancing data-driven decision-making capabilities. For someone with an interest in more of the analytics side of things, this role could also serve as a hybrid Analytics / Dashboarding role as well. This role is great for someone who perhaps hasn't yet chosen a specific specialization or path in the data realm and wants to gain exposure or opportunity in different areas - Whether BI Front End, Business Strategy, Analytics / Dashboarding, or Data Engineering there are a plethora of opportunities to learn and jump in to help the business. One of the major projects you'll be working on is how to collect data on the usage of their underlying SaaS Software products and how to marry that with their CRM data. They have different products that were built at different times so getting to and extracting that data is going to be an especially interesting challenge for this team. ResponsibilitiesDesign, develop, and maintain scalable data pipelines and ETL processes to ingest and process data from various sourcesBuild and optimize the data warehouse in SnowflakeCollaborate with data users to understand requirements and create efficient data models and structures for seamless reporting and analysis using BI tools. Monitor and optimize data pipeline performanceImplement data governance and security best practices, manage user access, and ensure compliance is adhered toContinuously explore and evaluate new data engineering techniques and tools, including AI applications, to improve data processing and exploration capabilities. QualificationsExperience building or using data marts (sql heavy data modeling) and interacting with users that use the data. The ability to find the shortest path to making data available and widely usable. Experience building or extending a Data WarehouseStrong exposure to Data Warehouse patterns and the application of those patternsPrevious experience working with business stakeholdersStrong initiative to start new projects or take existing projects and make them better. Proficiency with Snowflake, Tableau, and Stitch, or similar data warehousing, BI, and ETL tools. Strong knowledge of SQL is required with database design and data modeling experience. Experience with Python or another programming language for data processing. Familiarity with data engineering best practices, including data quality, data governance, and data security. Interest in AI applications for data engineering and data exploration. Excellent problem-solving, communication, and collaboration skills. Extra informationCareer development opportunitiesCompetitive insurance (medical, dental, vision, and voluntary life & disability)Mental health benefits401(k) plan (company matching)Paid holidaysFlexible PTO - no accrualsPaid generous parental leaveBusiness casual environment #ZR\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"As a Data Engineer for our Data Platform Engineering team you will join skilled Scala/ Spark engineers and core database developers responsible for developing hosted cloud analytics infrastructure (Apache Spark-based), distributed SQL processingframeworks, proprietary data science platforms, and core database optimization. This team is responsible for building the automated, intelligent, and highly performant query planner and execution engines, RPC calls between datawarehouse clusters, shared secondary cold storage, etc. This includes building new SQL features and customer-facing functionality, developing novel query optimization techniques for industry-leading performance, and building a databasesystem that's highly parallel, efficient and fault-tolerant. This is a vital role reporting to exec leadership and senior engineering leadershipRequirementsResponsibilities:Writing Scala code with tools like Apache Spark + Apache Arrow + Apache Kafka to build a hosted, multi-cluster data warehouse for Web3Developing database optimizers, query planners, query and data routing mechanisms, cluster-to-cluster communication, and workload management techniques.Scaling up from proof of concept to “cluster scale” (and eventually hundreds of clusters with hundreds of terabytes each), in terms of both infrastructure/architecture and problem structureCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate meta data capturing and managementManaging a team of software engineers writing new code to build a bigger, better, faster, more optimized HTAP database (using Apache Spark, Apache Arrow, Kafka, and a wealth of other open source data tools)Interacting with exec team and senior engineering leadership to define, prioritize, and ensure smooth deployments with other operational componentsHighly engaged with industry trends within analytics domain from a data acquisition processing, engineering, management perspectiveUnderstand data and analytics use cases across Web3 / blockchainsSkills & QualificationsBachelor’s degree in computer science or related technical field. Masters or PhD a plus.6+ years experience engineering software and data platforms / enterprise-scale data warehouses, preferably with knowledge of open source Apache stack (especially Apache Spark, Apache Arrow, Kafka, and others)3+ years experience with Scala and Apache Spark (or Kafka)A track record of recruiting and leading technical teams in a demanding talent marketRock solid engineering fundamentals; query planning, optimizing and distributed data warehouse systems experience is preferred but not requiredNice to have: Knowledge of blockchain indexing, web3 compute paradigms, Proofs and consensus mechanisms... is a strong plus but not requiredExperience with rapid development cycles in a web-based environmentStrong scripting and test automation knowledgeNice to have: Passionate about Web3, blockchain, decentralization, and a base understanding of how data/analytics plays into this\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Data Engineer Qualifications7+ years of experience as a Database Developer3+ years of experience as a hands on Team LeadExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectureStrong data modeling skills (relational, dimensional and flattened)5-7 years of experience with SQL Server On-Prem and/or Azure cloud, required5-7 years of SSIS experience utilizing SQL Agent jobs and Integration Services Catalog, required3-4 years of experience running ETL/ELT SSIS projects independently from end to end, requiredExperience with DevOps Repository and Git, preferredAzure Data Lake storage experience, a plusAzure Data Factory and/or Databricks experience, a plusLocation: Denver, COEmployment Type: Direct HireDuration: Full TimeWork Location: Denver / HybridPay: Based on experienceOther: PTO, Medical, Dental, Vision, Disability, Life, 401k benefits available Thank you in advance for your interest in this opportunity!If you are able to work on a W2 basis without sponsorship for ANY US employer and fit the description above, please apply. Third-Party Applications Not Accepted.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'To support internal and external clients via processing and handling of data. To generate data solutions for ongoing immediate day to day business needs.Essential FunctionsDay to day functions include the following:Design data models and develop database structures in Microsoft SQL server.Write various database objects like stored procedures, functions, views, triggers for various front end applications.Write SQL scripts, create SQL agent jobs to automate tasks like data importing, exporting, cleansing tasks.Create database deployment packages for deploying changes.Identify & repair inconsistencies in data, database tuning, query optimization.Able to generate ad hoc data on demand.Able to identify best practices, documentation, communicate all aspects of projects in a clear, concise mannerDevelop simple SSIS packages to perform various ETL functions including data cleansing, manipulating, importing, exporting.Develop & maintain client facing reports by using various data manipulation techniques in SSRS and Visual Studio.DocumentationOptimization recommendationsDay to day troubleshooting.NET Programming as neededEducation/ExperienceBA, BS, or Masters in computer science/related field preferred or an equivalent combination of education and experience derived from at least 2 years of professional work experienceSolid experience with various versions of MS SQL Server and TSQL programmingMicrosoft Certified DBA a plusSkills/KnowledgeStrong experience in writing efficient SQL codeWorking knowledge of SQL Server Management Studio (SSMS)Knowledge of SQL Server Reporting Services (SSRS)Knowledge of SQL Server Integration Services (SSIS)Knowledge of Red Gate DBA Tool Belt (SQL Compare, SQL Data Compare, SQL Source Control) a plusKnowledge of data science technologies is a plusClear, concise communication skills, excellent organizational skillsHighly self-motivated and directedKeen attention to detailHigh level of work intensity in a team environmentHigh integrity and values-drivenEager for professional developmentExperience and understanding of source control management a plusWhat We OfferAt Bloom, we offer an engaging, supportive work environment, great benefits, and the opportunity to build the career you always wanted. Benefits of working for Bloom include:Competitive compensation Comprehensive health benefits Long-term career growth and mentoring About BloomAs an insurance services company licensed in 48 contiguous U.S. states, Bloom focuses on enabling health plans to increase membership and improve the enrollee experience while reducing costs. We concentrate on two areas of service: technology services and call center services and are committed to ensuring our state-of-the-art software products and services provide greater efficiency and cost savings to clients.Ascend Technology ™Bloom provides advanced sales and enrollment automation technology to the insurance industry through our Ascend ™. Our Ascend™ technology platform focuses on sales automation efficiencies and optimizing the member experience from the first moment a prospect considers a health plan membership.Bloom is proud to be an Equal Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAt Johnson & Johnson, we use technology and the power of teamwork to discover new ways to prevent and overcome the world’s the most significant healthcare challenges. Our Corporate, Consumer Health, Medical Devices, and Pharmaceutical teams leverage data, real-world insights, and creative minds to make life-changing healthcare products and medicines. We're disrupting outdated healthcare ecosystems and infusing them with transformative ideas to help people thrive throughout every stage of their lives. With a reach of more than a billion people every day, there’s no limit to the impact you can make here. Are you ready to reimagine healthcare?Here, your career breakthroughs will change the future of health, in all the best ways. And you’ll change, too. You’ll be inspired, and you’ll inspire people across the world to change how they care for themselves and those they love. Amplify your impact. Join us! Tasked with transforming data into a format that can be easily consumes by ML algorithms. Adept Database basics SQL, capable of basic data engineering techniques – data wrangling, data cleansing, data curation. Fluent in one of the programming languages R or Python.  Data Engineering skills, e.g., cleaning/organizing data, data preparation, data collection, data integration across different data sources, data storage, relational/non-relational database management.  Proficient in structured query language (SQL), NoSQL, MATLAB, and programming in Python or R.  Proficient in Applied Machine Learning – Experience with a variety of algorithms, Building Predictive Models, Cross-validating, Hypertuning and Deployment.  Experience with devising and implementing ML methods for protein or antibody modeling or design, or with deep learning methods that relate protein sequence, structure, property or function.  MD simulation software (e.g., Commercial tools like Schrodinger, or open-source software AMBER, GROMACS, etc.). Additionally, prior experience in homology modeling and structural refinement  Knowledgeable of AWS services including Redshift, RDS, EMR and EC2  Working knowledge using software and tools including big data tools like Kafka, Spark and Hadoop. At Johnson & Johnson, we’re on a mission to change the trajectory of health for humanity. That starts by creating the world’s healthiest workforce. Through cutting-edge programs and policies, we empower the physical, mental, emotional and financial health of our employees and the ones they love. As such, candidates offered employment must show proof of COVID-19 vaccination or secure an approved accommodation prior to the commencement of employment to support the well-being of our employees, their families and the communities in which we live and work.Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Primary LocationNA-US-Pennsylvania-Spring HouseOrganizationJanssen Research & Development, LLC (6084)Job FunctionAdministration\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatmentSchedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewMailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaigns, CRM, and analytics tools.The Data Platform team at Mailchimp is responsible for creating and managing our BI platform that enables peeps from across the company to make better decisions with data. What that actually looks like is working with folks from across the company to understand their needs and then surface data in a meaningful way, across tools and teams, to help them drive the business forward. Day to day you could be building an ETL pipeline, designing a data access tool, modeling out new data in Looker, or working with teams to develop better data governance practices. We have a lot of tools in our toolbelt, but all with the main goal helping Mailchimp to continue to use data more effectively.Intuit Mailchimp is a hybrid workplace , giving employees the opportunity to collaborate in person with team members in our Atlanta and Brooklyn offices two or more days per week.What You'll BringExperience with Python, Java, Go, or another OOP languageExperience with SQL and data analysis skillsExperience with data transformation tools like dbt or DataformExperience in visualization technologies like Looker, Tableau, or Qlik SenseExperience with Airflow or other ETL orchestration toolsSolid business intuition and ability to understand and work with cross-functional partnersExperience with GCP/AWS or other cloud providers is preferredBachelors degree is Computer Science or equivalent experience Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Mailchimp we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.How You Will LeadPartner with analysts, data scientists, business users, and other engineers to understand their needs and come up with data solutionsHelp build robust transformation pipelines to help clean up, normalize, and govern our data for broad consumptionHelp build scalable transformation pipelines that enables teams to easily clean up, normalize, and govern data for broad consumptionBuild tools and processes to help make the right data accessible to the right peopleModel data in Looker, to provide a collaborative data analytics platform for the companyWork with Data Stewards to better document our data\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Well known NY based Non-Profit seeks a Data Engineer.An ideal candidate will have strong data engineering skills with both SQL and Python.This position can be based out of NYC or be 100% remote.Compensation includes salary, excellent medical, dental, vision benefits, pto, 401k, a quality of life oriented work life balance, and lots of other benefits.ResponsibilitiesThis position will work within the enterprise data engineering team to continuously build, maintain, and improve the design, performance, reliability, scalability, security, and architecture of enterprise data products.Responsibilities include:Develop robust database solutions, data integration (ETL, ELT) packages, automation, performance monitoring, SQL coding, database tuning and optimizations, security management, capacity planning, database HA, and database DR solutions across required data platforms.Conduct in-depth data analysis to support data product design.Identify and resolve production database and data integration issues.Collaborates closely with data quality, application, and visualization teams to deliver high-quality data products.Participate in code review, QA, release, and continuous deployment processes.Qualifications:Bachelors Degree in Computer Science or other quantitative disciplines such as Science, Statistics, Economics or Mathematics.5+ years of progressive database development experience with the Microsoft SQL Server family suite.Experience with data modeling and data architecture principles for both analytics and transactional systems.Hands-on experience with SQL Server, Oracle, or other RDBMS required.Python ScriptingExperience with Cloud Data PlatformsPreferred Experience:Scripting experience in Powershell, C#, Java, and/or R.Experience in the Microsoft Azure technology stack is a plus.Experience with data analytics and visualization is a plus.Preferred Knowledge:Intermediate knowledge of OLTP and OLAP database designIntermediate knowledge of data modeling (normalized and dimensional)Intermediate knowledge of ETL, ELT architecture especially for real and near-real-time scenariosIntermediate knowledge of Data Architecture implementation patternsAnticipated salary for candidates living in the NY Metro market in the 140,000 to 160,000 range.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Laguna Games is the developer of Crypto Unicorns, the #1 NFT project on Polygon, and now one of the fastest-growing games. We are looking to hire an experienced Data Engineer to join our team. You are self-motivated, goal-orientated, and a strong team player. As a Data Engineer, you will be responsible for designing, building, and maintaining the data infrastructure that supports our gaming platform. You will work closely with our product, engineering, and data science teams to collect, process, and analyze large amounts of data generated by our gaming platform to inform our business decisions and improve user experience. You will work and innovate at the forefront of web3 gaming, bringing together unique technologies to deliver a new gaming experience.As a Data Engineer at our Web3 Gaming Startup, Key Responsibilities:Develop and maintain the data pipeline that ingests, processes and stores large amounts of data generated by our gaming platformDesign and build scalable data solutions that support the real-time analytics and reporting needs of the businessCollaborate with the product, engineering and data science teams to identify and implement data-driven solutions to improve user engagement, retention and monetizationBuild and maintain data models, data warehouses and data marts to support business intelligence and reporting needsEnsure data quality, integrity and security across all data sources and systemsMonitor and optimize data performance and scalability, and identify and resolve any data-related issues and bottlenecksKeep up-to-date with the latest trends, tools and technologies in data engineering and apply them to improve our data infrastructureQualificationsBachelor's degree in Computer Science, Computer Engineering, or related field3+ years of experience in data engineering or related fieldExperience with big data technologies such as Hadoop, Spark, Kafka, and ElasticsearchStrong proficiency in SQL, Python and/or Java programming languagesExperience with cloud-based data solutions such as AWS, Azure or Google CloudFamiliarity with data modeling, ETL/ELT processes, data warehousing, and business intelligence toolsUnderstanding of blockchain technology and its use in gaming platforms is a plusExcellent communication skills, both written and verbal, and ability to collaborate with cross-functional teamsIf you are passionate about data engineering and excited about the opportunity to work in a fast-paced and dynamic startup environment, we would love to hear from you!Laguna Games is the developer of Crypto Unicorns, a new blockchain-based game centered around awesomely unique Unicorn NFTs that players use in a fun farming simulation and in a variety of exciting battle loops. As game developers, we are excited to move away from the extractive nature of Free-2-Play to foster and nurture community-run game economies. Crypto Unicorns is our first digital nation and we are extremely excited to build it in tandem with our player community!We are headquartered in San Francisco, CA but operate as a remote company with locations around the world. We offer competitive compensation along with health benefits (medical, dental, and vision), 401k retirement savings, open paid time off, and a remote work support stipend.Learn more here!https://laguna.gameshttps://www.cryptounicorns.fun\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Become a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Nike USA, Inc., located in Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into engineering designs and logical units of work. Profile and analyze data for the purpose of designing scalable solutions. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Implement complex automated routines using workflow orchestration tools. Anticipate, identify and tackle issues concerning data management to improve data quality. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks.Applicant must have a Bachelor’s degree in Data Science, Computer Engineering, Computer Science, or Computer Information Systems and five (5) years of progressive post-baccalaureate experience in the job offered or engineering-related occupation. Experience must include the following- Programming ability (Python, SQL);  Database related concept;  Big Data exposure;  Spark;  Airflow (Orchestration tools);  Cloud Solutions;  Software/Data design ability;  CI/CD understanding and implementation;  Code review;  Data Architecture; and  AWS, Azure. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.]]>\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We are currently hiring a Senior Data Platform Engineer to help grow our company and ensure our mission is achieved!This role is a work from home position and can be performed remotely anywhere in the continental US or in one of our corporate locations in Utah or Arizona.WE ARE: Our Data Platforms embodies the modernity and transformational vision that is core to our business evolution. As passionate and hungry technical experts, we progress through technology. We take pride in our engineering, daily progress, and bringing others along as we improve. We experiment, fail fast, and drive to delivery.YOU ARE: A self-starter mindset to proactively take ownership and execute work without daily oversight and excited to develop your data administration & data DevOps skills. We have a great team of engineers building next-generation data platforms. You are motivated by challenges and thrive with continuous innovation.YOUR DAY-TO-DAY:Coach and develop fellow team membersWorking in an agile-scrum development environmentWork with engineers and leaders to promote a shared vision of our data platform & architectureTrack operating metrics for our data platforms, driving improvements and making trade-offs among competing constraints. We use MS SQL Server, AWS RDS (Postgres, MariaDB) MongoDB, DynamoDB, Redis, Rabbit MQ, AWS managed messaging/eventing systems (Kafka, Kinesis, SQS, SNS) to name a few of our platformsBe a strategic player in designing enterprise-wide data infrastructureBuilds robust systems with an eye on the long-term maintenance and support of the applicationDiscover automation opportunities to replace manual processes using PowerShell, Terraform, Python etcBuild out frameworks for data administration /data deployment /monitoring where neededLeverage reusable code modules to solve problems across the team and organizationCreate and maintain automated pipelines to deploy changes via Octopus, CircleCI, Azure DevOps and JenkinsProactive and reactive performance analysis, monitoring, troubleshooting and resolution of escalated issuesParticipate in the team on-call rotationsYOU’LL BRING:Used multiple data platforms and can define which is optimal for a given scenario (such as document databases, RDBMS, caching, eventing, etc. On-prem or cloud)An engineering mindset when developing a solution using PowerShell / Python or SQL. In depth knowledge and use of tools such as dbatools and other modules is a plusUnderstand how to fully automate systems using infrastructure/configuration as code technologies (we use Terraform, CloudFormation, Ansible, SaltStack)Experience working with CI/CD pipeline and tools preferably Octopus, CircleCI, AzureDevOps and JenkinsProven ability to mentor and coach engineersThrive on a high level of autonomy and responsibility, while having the ability to dig into technical details to inform decisionsAdvanced Sql Server Knowledge and experience in performance analysis and tuning skills such as tracing and profiling and Dynamic Management Views and Functions (DMVs) and other third-party tools like SentryOne to ensure high levels of performance, availability, and securityKnowledge of database deployment using DACPAC via pipelinesExperience with enterprise features of SQL Server: AlwaysOn Availability Groups, clustering, Disaster RecoveryContribute to the management and reliability of database HA/DR processesYOU MIGHT ALSO HAVE:Ability to clearly articulate complex subjects to leadership and others not familiar with this spaceExperience with code-based data developmentA self-starter mindset to proactively take ownership and execute work without daily oversightExperience in AWS cloud-based solutionsWE OFFER: Competitive Compensation; Eligible for STI + LTIFull Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental LeaveCompany Matched 401kPaid Time Off + Paid Holidays + Paid Volunteer HoursEmployee Resource Groups (Black Inclusion Group, Women in Leadership, PRIDE, Adelante)Employee Stock Purchase ProgramTuition ReimbursementCharitable Gift MatchingJob required equipment and services\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our team relies on clean datasets accessible via the latest tools to answer questions that are often not simple or clear. You will be creating solutions that will help derive value from our rich datasets that will solve tough problems impacting consumers across geographies & industries (healthcare, retail/ consumer, telecom, industrial) driving technology transformation. At the core of our team, we believe data is best used to create transparency & generate communal value.  What You’ll Do: · Design, Build & ImplementDesign & build batch, event driven and real-time data pipelines using some of the latest technologies available on Microsoft Azure, Google Cloud Platform and AWSImplement large-scale data platforms to meet the analytical & operational needs across various organizationsBuild products & frameworks that can be re-used across different use-cases in increase efficiency in coding and agility in implementation of solutionsBuild streaming ingestion processes to efficiently read, process, analyze & publish data for real-time need of applications and data science modelsPerform analyses of large structured and unstructured data to solve multiple & complex business problemsInvestigate and prototype different task dependency frameworks to understand the most appropriate design for a given use case to assess & advise Understand business use cases to design engineering routines to affect the outcomesReview & assess data frameworks & technology platforms with the goal of suggesting & implementing improvements on the existing frameworks & platforms.Understand quality of data used in existing use cases to suggest process improvements & implement data quality routines   Who You Are : An Engineer interested in working in batch, event driven and streaming processing environments A tech-enthusiast excited to work with Cloud Based Technologies like GCP, Azure & AWSA data parser expert who gets excited about structuring and re-structuring datasets programmatically A doer who loves to produce meaningful analytic insights for an innovative, data-intensive productsAlways curious about analytics frameworks and you are well-versed in the advantages and limitations of various big data architectures and technologiesTechnologist who loves studying software platforms with an eye towards modernizing the architectureBeliever in transparency, communication, and teamworkLove to learn and not afraid to take ownershipNexus Staffing is committed to diversity, inclusion, and equal opportunity. We take affirmative steps to ensure that all programs and services are open to all Americans, free of discrimination based on protected class status, including race, religion/creed, color, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, national origin (including limited English proficiency), age, political affiliation or belief, military or veteran status, disability, predisposing genetic characteristics, marital or family status, domestic violence victim status, arrest record or criminal conviction history, or any other impermissible basis.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'R-27413Who Are We?Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.Compensation OverviewThe annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.Salary Range$102,600.00 - $169,200.00Target Openings1What Is the Opportunity?Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Personal Insurance Analytics and business intelligence/insights.What Will You Do?Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.Design data solutions.Analyze sources to determine value and recommend data to include in analytical processes.Incorporate core data management competencies including data governance, data security and data quality.Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.Test data movement, transformation code, and data components.Perform other duties as assigned.What Will Our Ideal Candidate Have?Bachelor’s Degree in STEM related field or equivalentSix years of related experienceProficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. Experience with Salesforce and Tealium Product Suite a plus.The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.Strong verbal and written communication skills with the ability to interact with team members and business partners.Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.What is a Must Have?Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.What Is in It for You?Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.Employment PracticesTravelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.Travelers reserves the right to fill this position at a level above or below the level included in this posting.To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role has a preference for a local Austin, TX candidate and will be a hybrid work environment meeting in-person a few times/month. Our client is a fast-growing, Private Equity backed GovTech company that provides SaaS Software solutions to the Public Sector (City / State Local Government) and is looking for a Data Engineer to join their team. Reporting to the Director of Analytics as their first hire, you will be responsible for the ongoing development and management of the data infrastructure of the business and will be providing essential support to internal customers. This pivotal role will be in the Analytics team reporting to Finance and is aimed to drive greater efficiency in data, processes, and tools, ultimately enhancing data-driven decision-making capabilities. For someone with an interest in more of the analytics side of things, this role could also serve as a hybrid Analytics / Dashboarding role as well. This role is great for someone who perhaps hasn't yet chosen a specific specialization or path in the data realm and wants to gain exposure or opportunity in different areas - Whether BI Front End, Business Strategy, Analytics / Dashboarding, or Data Engineering there are a plethora of opportunities to learn and jump in to help the business. One of the major projects you'll be working on is how to collect data on the usage of their underlying SaaS Software products and how to marry that with their CRM data. They have different products that were built at different times so getting to and extracting that data is going to be an especially interesting challenge for this team. ResponsibilitiesDesign, develop, and maintain scalable data pipelines and ETL processes to ingest and process data from various sourcesBuild and optimize the data warehouse in SnowflakeCollaborate with data users to understand requirements and create efficient data models and structures for seamless reporting and analysis using BI tools. Monitor and optimize data pipeline performanceImplement data governance and security best practices, manage user access, and ensure compliance is adhered toContinuously explore and evaluate new data engineering techniques and tools, including AI applications, to improve data processing and exploration capabilities. QualificationsExperience building or using data marts (sql heavy data modeling) and interacting with users that use the data. The ability to find the shortest path to making data available and widely usable. Experience building or extending a Data WarehouseStrong exposure to Data Warehouse patterns and the application of those patternsPrevious experience working with business stakeholdersStrong initiative to start new projects or take existing projects and make them better. Proficiency with Snowflake, Tableau, and Stitch, or similar data warehousing, BI, and ETL tools. Strong knowledge of SQL is required with database design and data modeling experience. Experience with Python or another programming language for data processing. Familiarity with data engineering best practices, including data quality, data governance, and data security. Interest in AI applications for data engineering and data exploration. Excellent problem-solving, communication, and collaboration skills. Extra informationCareer development opportunitiesCompetitive insurance (medical, dental, vision, and voluntary life & disability)Mental health benefits401(k) plan (company matching)Paid holidaysFlexible PTO - no accrualsPaid generous parental leaveBusiness casual environment #ZR\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"As a Data Engineer for our Data Platform Engineering team you will join skilled Scala/ Spark engineers and core database developers responsible for developing hosted cloud analytics infrastructure (Apache Spark-based), distributed SQL processingframeworks, proprietary data science platforms, and core database optimization. This team is responsible for building the automated, intelligent, and highly performant query planner and execution engines, RPC calls between datawarehouse clusters, shared secondary cold storage, etc. This includes building new SQL features and customer-facing functionality, developing novel query optimization techniques for industry-leading performance, and building a databasesystem that's highly parallel, efficient and fault-tolerant. This is a vital role reporting to exec leadership and senior engineering leadershipRequirementsResponsibilities:Writing Scala code with tools like Apache Spark + Apache Arrow + Apache Kafka to build a hosted, multi-cluster data warehouse for Web3Developing database optimizers, query planners, query and data routing mechanisms, cluster-to-cluster communication, and workload management techniques.Scaling up from proof of concept to “cluster scale” (and eventually hundreds of clusters with hundreds of terabytes each), in terms of both infrastructure/architecture and problem structureCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate meta data capturing and managementManaging a team of software engineers writing new code to build a bigger, better, faster, more optimized HTAP database (using Apache Spark, Apache Arrow, Kafka, and a wealth of other open source data tools)Interacting with exec team and senior engineering leadership to define, prioritize, and ensure smooth deployments with other operational componentsHighly engaged with industry trends within analytics domain from a data acquisition processing, engineering, management perspectiveUnderstand data and analytics use cases across Web3 / blockchainsSkills & QualificationsBachelor’s degree in computer science or related technical field. Masters or PhD a plus.6+ years experience engineering software and data platforms / enterprise-scale data warehouses, preferably with knowledge of open source Apache stack (especially Apache Spark, Apache Arrow, Kafka, and others)3+ years experience with Scala and Apache Spark (or Kafka)A track record of recruiting and leading technical teams in a demanding talent marketRock solid engineering fundamentals; query planning, optimizing and distributed data warehouse systems experience is preferred but not requiredNice to have: Knowledge of blockchain indexing, web3 compute paradigms, Proofs and consensus mechanisms... is a strong plus but not requiredExperience with rapid development cycles in a web-based environmentStrong scripting and test automation knowledgeNice to have: Passionate about Web3, blockchain, decentralization, and a base understanding of how data/analytics plays into this\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Data Engineer Qualifications7+ years of experience as a Database Developer3+ years of experience as a hands on Team LeadExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectureStrong data modeling skills (relational, dimensional and flattened)5-7 years of experience with SQL Server On-Prem and/or Azure cloud, required5-7 years of SSIS experience utilizing SQL Agent jobs and Integration Services Catalog, required3-4 years of experience running ETL/ELT SSIS projects independently from end to end, requiredExperience with DevOps Repository and Git, preferredAzure Data Lake storage experience, a plusAzure Data Factory and/or Databricks experience, a plusLocation: Denver, COEmployment Type: Direct HireDuration: Full TimeWork Location: Denver / HybridPay: Based on experienceOther: PTO, Medical, Dental, Vision, Disability, Life, 401k benefits available Thank you in advance for your interest in this opportunity!If you are able to work on a W2 basis without sponsorship for ANY US employer and fit the description above, please apply. Third-Party Applications Not Accepted.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Hi,Hope you are doing well,We at Software Technology Inc. hiring for a Data Engineer/Data Analyst, role, if you are interested and a good fit, feel free to reach me directly at ksuresh@stiorg.com or (609) 998-3431.Role : Data Engineer/Data AnalystLocation : RemoteSkillGCP Big Query, Python, SQL and knowledge of Healthcare domain\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'adQuadrant helps DTC (direct-to-consumer) brands dream bigger. We are a trusted advisor that provides holistic, strategic omni-channel digital marketing solutions by partnering with our clients to solve the biggest challenges in terms of customer acquisition and growth. Our efforts produce tangible results backed by measurable data. We have the strategic capabilities, quantitative chops, deep creative understanding, and world-class talent with the best tools to drive revenue and profits. We are not simply a vendor checking boxes — our seasoned team serves as an extension of the companies we work with, leading strategy and execution. Our goal is to be the go-to marketing consultants for solving the biggest challenges.adQuadrant is looking for a Data Engineer to support a growing team. This role is responsible for developing, testing, and maintaining data pipelines and data architectures. You will be building and optimizing our data pipeline architecture, as well as optimizing data flows and collections for cross functional teams. The ideal candidate will enjoy optimizing data systems and building them from the ground up, you must be ready for a challenge. This role will ensure optimal data delivery architecture is consistent throughout current and ongoing projects. You must be a self-starter and enjoy supporting multiple cross-functional teams.The Ideal Candidate must have: Experience in Snowflake, architecting and building a data warehouse from scratchData pipeline (ETL tools) development and deployment experienceExtensive experience deploying and maintaining a Tableau ServerRequirementsYour Responsibilities: Consulting with the data team to get a strong understanding of the organization’s data storage needsDesigning and constructing the data warehousing system to the organization’s specificationsDefining and implementing scalable data pipelines that ingest data from various external sources, storing it in the database system, and making it useful to our data analystsImplementing processes to monitor data quality, ensuring production data is always accurate and available for data analysts and business processes that rely on itRecognize, troubleshoot, and resolve unexpected performance and process fail issues, on an ongoing basisQualifications:Bachelor’s degree in computer science, information technology, or a related field5+ years experience in data warehousing, data modeling and building data pipelinesExtensive knowledge of SQL, and coding languages, such as PythonProficiency in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDWProven work experience as an ETL developerExperience working with online marketing dataStrong project management skills and experience with Agile engineering practicesAbility to analyze a company’s big-picture data needsClear communication skillsStrategic thought and extreme attention to detailAbility to troubleshoot and solve complex technical problemsComfortable supporting distributed remote individualsBenefitsOur people come first. No jerks. No egos. Just people who like to work hard and enjoy winning as a team.Annual Compensation: $95,000 - $120,000 per yearExcellent Health Benefits (health, dental, vision, and life insurance)401K + company matchUnlimited Vacation PolicyPaid Sick Leave2 Mindfulness Days Annually2PM Fridays each week$300/ year to equip your work space with new equipment$30/ month for home internetAn extremely supportive and fun company cultureWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Attune is making it easier, faster, and more reliable for small businesses to access insurance (think, pizza place down the street or main street store). They all need insurance to protect their businesses, but when it comes time to get a policy, they're bogged down by hundreds of questions, lots of paperwork, and a seemingly never-ending timeline stretching for weeks or months.We are changing all that. By using data and technology expertise to understand risk, automating legacy processes, and creating a better user experience for brokers, we're able to provide policies that are more applicable and more transparent in just minutes.Simply put, we're pushing insurance into the future, focusing on accuracy, speed, and ease.Our mission and our team are growing. In staying true to our values, we've earned our spot on many workplace award lists. Attune is dedicated to creating a diverse team of curious, focused, and motivated people who are excited about changing the future of an entire industry.Job DescriptionAs a Data Engineer joining our growing Data team, you will help maintain our existing data pipelines and internal web applications. You will also work with team members across the organization to develop and test new pipelines as we launch new products and integrate with third-party data sources. We work with various tools including Python/Pandas, Postgresql, Bash, AWS EC2, and S3. We are always open to using whatever tool is best for the job.Responsibilities:Maintain and improve batch ETL jobs - including SQL query optimization, bug fixes and code improvementsWork with our data engineers, BI, and other teams across the business to develop/refine ETL processesUnderstand and answer questions on the data our team maintainsQualifications:3+ years experience in analytics, data science, or data engineering roleStrong Python and Postgresql skillsSolid understanding of relational database design and basic query optimization techniquesExperience working with git, and Gitlab or GithubNice to have:Experience with Linux CLI, shell programmingUnderstanding of CI/CDExperience with AWS EC2 and S3What we offer you:140-170k per yearUnlimited PTOGenerous parental and caregiver leave401K matchExcellent medical, dental, and vision plansRemote-first cultureAnd more!\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatmentSchedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Company DescriptionAt Lakeshore, we create innovative learning materials and world-class guest experiences for teachers, parents and children. Since 1954, we’ve grown into a global community—with a thriving e-commerce business, multiple catalogs, 60+ retail stores, a peerless national sales force, plus international offices that support our preeminent supply chain division. But today we’re working better, smarter and faster than ever—and setting our sights even higher. We’re building an infrastructure designed for scalability, embracing data-driven decision-making and using technology to improve efficiency and ensure the best tools for the best work. Most importantly, we continue to invest in a diverse team of inquisitive top talent who fuel each other’s passions and curiosity, take risks, try new things, and believe that every new day brings opportunities for growth.Job DescriptionIn a time of unprecedented expansion, are seeking a Junior Data Engineer who will be responsible for enabling and enhancing data insights for internal stakeholders, with significant overlap and collaboration with different teams. In this role, you will design, build, enhance and maintain an enterprise business intelligence (BI) platform that supports advanced analytics. The position also requires data cleanup, requirements gathering, data modeling and transformation, reports/dashboard creation, data mining and analytics on complex data sets. The ideal candidate has proven experience working with complex data and has a passion for improving technology. And we’re here to help you succeed—in 2022 Lakeshore earned its Great Place to Work® Certification™ and is proud to put its associates first.A day in the office looks like this: Serving as the primary point of contact with business teams to provide actionable insights into current delivery performance, as well as ad hoc investigations into future improvements or innovations Using BI and visualization software (SQL Server, Redshift, AWS Data Lake, Qlik, etc.) to empower nontechnical, internal customers to drive their own analytics and reporting Providing complex analysis, conceptualization, design, implementation and development of solutions for critical BI components Performing dataflow, system and data analysis; developing meaningful presentation of data in BI applications Contributing to data analysis, design and development of new and ongoing BI projects Collaborating closely with internal and external teams to understand modifications impacting data lake, visualization, etc. Participating in the entire lifecycle of BI solution delivery Helping plan, design, implement and manage the deployment of a self-service data visualization platform in Qlik Building and maintaining data visualizations that inform and engage business stakeholders Analyzing key performance indicators to discover root causes for various parameters QualificationsGot the skills and experience? Here’s what we’re looking for:At least 1 year of experience in relevant business domains, including data warehousing and BI tools, techniques and technology Knowledge of data warehouse platforms such as SQL Server, AWS Redshift and SSIS required Knowledge of Qlik and Tableau as visualization tools required Knowledge of ETL, presentation layer and design strategy reporting required Knowledge of data mining and experience using large-scale, complex data sets in a business environment Proficiency in SQL and performance optimization Technical capability to query large data sets and apply statistical models Knowledge of advanced statistics and experience with statistical data analysis systems (scikit-learn, Pandas) a plus Additional InformationAnd here’s our end of the bargain! Hourly: $27-$31 with an annual bonus of up to 10%Excellent medical/dental and vision coverage—EPO, PPO and HSA401(k) retirement plan with company contribution (because you will retire someday)Flexible benefits—choose what you like, ignore the restOn-site preschool for our employees’ childrenOn-site employee gym for all levels/fitness needsGenerous employee discount on products that make you smarterCasual dress…and we really mean itAt Lakeshore, we know our diversity makes us stronger, and when everyone feels included and valued, we all win. We strive to embrace our differences and create an intentionally diverse and inclusive community that is representative of the teachers, families and children we serve.We know we couldn’t do the extraordinary things we’re doing without the people on our team. Thanks to the passion and enthusiasm of this spectacular group, Lakeshore is more than a great place to work—it’s a great experience to be part of. Day in and day out, we give everything we’ve got to create products that instill a sense of wonder and foster a true love of learning. To help maintain this high bar for success, we’re constantly on the lookout for people to join us. So if you’re a down-to-earth professional who shares our desire for making a difference, we’d love to hear from you.To learn more about Lakeshore, visit www.lakeshorelearning.com/careersEqual Employment Opportunity PolicyPeople are selected to become members of the Lakeshore family based on skill, merit and mind-boggling talent—not based on race, color, creed, sexual orientation, gender or gender identity, marital status, domestic partnership status, military status, religion, age, national origin, ancestry, alienage, AIDS or AIDS-related complex status, genetic information, predisposition or carrier status, status as a victim of domestic violence, physical or mental disability, or any other characteristic protected by applicable law. If things aren’t equal, we all lose.To learn about how we collect and use Applicant information, please visit our Employee/Applicant Privacy Policy. INDRLL10\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'To support internal and external clients via processing and handling of data. To generate data solutions for ongoing immediate day to day business needs.Essential FunctionsDay to day functions include the following:Design data models and develop database structures in Microsoft SQL server.Write various database objects like stored procedures, functions, views, triggers for various front end applications.Write SQL scripts, create SQL agent jobs to automate tasks like data importing, exporting, cleansing tasks.Create database deployment packages for deploying changes.Identify & repair inconsistencies in data, database tuning, query optimization.Able to generate ad hoc data on demand.Able to identify best practices, documentation, communicate all aspects of projects in a clear, concise mannerDevelop simple SSIS packages to perform various ETL functions including data cleansing, manipulating, importing, exporting.Develop & maintain client facing reports by using various data manipulation techniques in SSRS and Visual Studio.DocumentationOptimization recommendationsDay to day troubleshooting.NET Programming as neededEducation/ExperienceBA, BS, or Masters in computer science/related field preferred or an equivalent combination of education and experience derived from at least 2 years of professional work experienceSolid experience with various versions of MS SQL Server and TSQL programmingMicrosoft Certified DBA a plusSkills/KnowledgeStrong experience in writing efficient SQL codeWorking knowledge of SQL Server Management Studio (SSMS)Knowledge of SQL Server Reporting Services (SSRS)Knowledge of SQL Server Integration Services (SSIS)Knowledge of Red Gate DBA Tool Belt (SQL Compare, SQL Data Compare, SQL Source Control) a plusKnowledge of data science technologies is a plusClear, concise communication skills, excellent organizational skillsHighly self-motivated and directedKeen attention to detailHigh level of work intensity in a team environmentHigh integrity and values-drivenEager for professional developmentExperience and understanding of source control management a plusWhat We OfferAt Bloom, we offer an engaging, supportive work environment, great benefits, and the opportunity to build the career you always wanted. Benefits of working for Bloom include:Competitive compensation Comprehensive health benefits Long-term career growth and mentoring About BloomAs an insurance services company licensed in 48 contiguous U.S. states, Bloom focuses on enabling health plans to increase membership and improve the enrollee experience while reducing costs. We concentrate on two areas of service: technology services and call center services and are committed to ensuring our state-of-the-art software products and services provide greater efficiency and cost savings to clients.Ascend Technology ™Bloom provides advanced sales and enrollment automation technology to the insurance industry through our Ascend ™. Our Ascend™ technology platform focuses on sales automation efficiencies and optimizing the member experience from the first moment a prospect considers a health plan membership.Bloom is proud to be an Equal Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.What PepsiCo Data Management and Operations does: Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders Increase awareness about available data and democratize access to it across the companyJob DescriptionAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company.As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, onpremise data sources as well as cloud and remote systems.ResponsibilitiesActive contributor to code development in projects and services.Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.Build and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.Responsible for implementing best practices around systems integration, security, performance and data management.Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape.Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.Develop and optimize procedures to “productionalize” data science models.Define and manage SLA’s for data products and processes running in production.Support large-scale experimentation done by data scientists.Prototype new approaches and build solutions at scale.Research in state-of-the-art methodologies.Create documentation for learnings and knowledge transfer.Create and audit reusable packages or libraries.Qualifications4+ years of overall technology experience that includes at least 3+ years of hands-on software development, data engineering, and systems architecture.3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.3+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).2+ years in cloud data engineering experience in Azure.Fluent with Azure cloud services. Azure Certification is a plus.Experience with integration of multi cloud services with on-premises technologies.Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines.Experience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.Experience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.Experience with version control systems like Github and deployment & CI tools.Experience with Azure Data Factory, Azure Databricks and Azure Machine learning tools is a plus.Experience with Statistical/ML techniques is a plus.Experience with building solutions in the retail or in the supply chain space is a plusUnderstanding of metadata management, data lineage, and data glossaries is a plus.Working knowledge of agile development, including DevOps and DataOps concepts. Familiarity with business intelligence tools (such as PowerBI).EducationBA/BS in Computer Science, Math, Physics, or other technical fields.Skills, Abilities, KnowledgeExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.Proven track record of leading, mentoring data teams.Strong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.Ability to understand and translate business requirements into data and technical requirements. High degree of organization and ability to manage multiple, competing projects and priorities simultaneously.Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment.Strong leadership, organizational and interpersonal skills; comfortable managing trade-offs.Foster a team culture of accountability, communication, and self-management.Proactively drives impact and engagement while bringing others along.Consistently attain/exceed individual and team goals.Ability to lead others without direct authority in a matrixed environment.CompetenciesHighly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.Understands both the engineering and business side of the Data Products released.Places the user in the center of decision making.Teams up and collaborates for speed, agility, and innovation.Experience with and embraces agile methodologies.Strong negotiation and decision-making skill.Experience managing and working with globally distributed teamsCOVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable lawEEO StatementAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender IdentityIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.Please view our Pay Transparency Statement\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Location:Bedford, MA; HybridThis Role:As a Data Engineer at LogixHealth, you will work with a globally distributed team of engineers to design, build and maintain cutting edge solutions that will directly improve the healthcare industry. You’ll contribute to our fast-paced, collaborative environment and will bring your expertise to continue delivering innovative technology solutions. The ideal candidate will be able to develop large scale, distributed data pipelines with an eye towards data security, availability and quality. The candidate should be experienced with modern data storage & transmission techniques, big data tools and distributed processes. The candidate should have excellent interpersonal communication and an aptitude to continue learning.Key Responsibilities:Design highly scalable, available and fault tolerant data processing systemsBuild out data quality proceduresCollaborate with other engineers on existing software and data integration solutionsKeep up with the latest technology industry trends and innovations Help other team members learn and adopt new technologies and practicesQuickly learn new and existing technologiesQualifications:To perform this job successfully, an individual must be able to perform each Key Responsibility satisfactorily. The following requirements are representative of the knowledge, skills, and/or ability required to perform this job successfully. Reasonable accommodation may be made to enable individuals with disabilities to perform the duties. Required:BS/MS in Computer Science, related technical field or equivalent experienceStrong programming and scripting skillsData modeling and data warehousing/lakesREST API servicesExpertise in data storage systems, including SQL & NoSQL database systems & file object storageAdvanced SQL and query performance tuning skillsUnderstanding of cloud computing technologies & platformsExperience with gitExcellent interpersonal communication skillsPreferred:Big data analysis techniquesBig data visualization solutionsDistributed systems design Healthcare industry knowledgeBenefits at LogixHealth:We offer a comprehensive benefits package including health, dental and vision, 401(k), PTO, paid holidays, life and disability insurance, on-site fitness center and company-wide social events.About LogixHealth:At LogixHealth we provide expert coding and billing services that allow physicians to focus on providing great clinical care. LogixHealth was founded in the 1990s by physicians to service their own practices and has grown to become the nation’s leading provider of unsurpassed software-enabled revenue cycle management services, offering a complete range of solutions, including coding and claims management and the latest business intelligence reporting dashboards for clients in 40 states.Since our first day, we have had a clear vision of a better healthcare system and have continually evolved to get there. In addition to providing expert revenue cycle services, we utilize proprietary software to provide valuable financial, clinical, and other data insights that directly improve the quality and efficiency of patient care.At LogixHealth, we’re committed to Making intelligence matter through our pillars of Physician-Inspired Knowledge, Unrivaled Technology and Impeccable Service.To learn more about us, visit our website https://www.logixhealth.com/.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAt Johnson & Johnson, we use technology and the power of teamwork to discover new ways to prevent and overcome the world’s the most significant healthcare challenges. Our Corporate, Consumer Health, Medical Devices, and Pharmaceutical teams leverage data, real-world insights, and creative minds to make life-changing healthcare products and medicines. We're disrupting outdated healthcare ecosystems and infusing them with transformative ideas to help people thrive throughout every stage of their lives. With a reach of more than a billion people every day, there’s no limit to the impact you can make here. Are you ready to reimagine healthcare?Here, your career breakthroughs will change the future of health, in all the best ways. And you’ll change, too. You’ll be inspired, and you’ll inspire people across the world to change how they care for themselves and those they love. Amplify your impact. Join us! Tasked with transforming data into a format that can be easily consumes by ML algorithms. Adept Database basics SQL, capable of basic data engineering techniques – data wrangling, data cleansing, data curation. Fluent in one of the programming languages R or Python.  Data Engineering skills, e.g., cleaning/organizing data, data preparation, data collection, data integration across different data sources, data storage, relational/non-relational database management.  Proficient in structured query language (SQL), NoSQL, MATLAB, and programming in Python or R.  Proficient in Applied Machine Learning – Experience with a variety of algorithms, Building Predictive Models, Cross-validating, Hypertuning and Deployment.  Experience with devising and implementing ML methods for protein or antibody modeling or design, or with deep learning methods that relate protein sequence, structure, property or function.  MD simulation software (e.g., Commercial tools like Schrodinger, or open-source software AMBER, GROMACS, etc.). Additionally, prior experience in homology modeling and structural refinement  Knowledgeable of AWS services including Redshift, RDS, EMR and EC2  Working knowledge using software and tools including big data tools like Kafka, Spark and Hadoop. At Johnson & Johnson, we’re on a mission to change the trajectory of health for humanity. That starts by creating the world’s healthiest workforce. Through cutting-edge programs and policies, we empower the physical, mental, emotional and financial health of our employees and the ones they love. As such, candidates offered employment must show proof of COVID-19 vaccination or secure an approved accommodation prior to the commencement of employment to support the well-being of our employees, their families and the communities in which we live and work.Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Primary LocationNA-US-Pennsylvania-Spring HouseOrganizationJanssen Research & Development, LLC (6084)Job FunctionAdministration\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Data Engineer (Mid/Jr Level)Pura has been revolutionizing the smart home experience for the past several years. We obsess over providing world-class experiences for our customers, partners, and vendors. We pride ourselves on maintaining a high standard of quality and innovation with our products, and continuous growth and development for our people.We are looking for a Data Engineer to help business users and analysts throughout the organization access the data they need to operate and grow the business.What you’ll own:In this high-impact role, you will:Work closely with the Data Science team to design and develop scalable data pipelines for processing and analyzing large volumes of dataBuild and maintain ETL processes using Python, SQL, Apache Airflow, and other technologiesDevelop and deploy data processing jobs on AWS or GCP using Docker and KubernetesWrite API wrappers to integrate with various external data sources and third-party toolsImplement and maintain best practices for data security, data quality, and data governanceCollaborate with other cross-functional teams to ensure data is available, reliable, and accessible to support business decisionsWrite clean, readable, and maintainable code and ensure code is thoroughly tested and documentedQualifications:Bachelor's degree in Computer Science, Software Engineering, or related field1-3 years of experience in data engineering or a related fieldProficiency in Python, SQL, Apache Airflow, and DockerExperience with AWS or GCP and some Kubernetes experienceStrong analytical and problem-solving skillsExcellent communication and collaboration skillsAbility to work independently and as part of a teamPassion for writing clean, readable code and ensuring code qualityIf you are passionate about data engineering and want to join a fast-paced, dynamic team that is making a real impact, we encourage you to apply today!.Pura’s StoryAt Pura, we’re pairing smart tech with premium fragrance to create a perfectly personalized and customized scenting experience for the individual. We partner with brands like Disney, Capri Blue, and Anthropologie to bring original and well-loved fragrances to homes in a modern, convenient, and safe way. We know we’ve only just begun to unlock the possibility of scent, and we’re excited for the opportunities that lie ahead.We’re quickly turning heads and getting noticed. We raised a seed round of 4.4M in February of 2020, was recognized by Inc. Magazine as a 2021 Best Workplace, won the Silicon Slopes Hall of Fame & Awards Advertising category in 2022, and we’re currently the 6th-fastest growing company in Utah. Check out our Instagram @pura and TikTok @trypura channels for a look into the excited, engaged community we’re building. We pride ourselves on being a human brand and in creating a culture worth talking about, and we have big goals for the future.Join the Pura Team!All candidates are subject to a background check.Pura provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.Powered by JazzHRPSRu221guI\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Attune is making it easier, faster, and more reliable for small businesses to access insurance (think, pizza place down the street or main street store). They all need insurance to protect their businesses, but when it comes time to get a policy, they're bogged down by hundreds of questions, lots of paperwork, and a seemingly never-ending timeline stretching for weeks or months.We are changing all that. By using data and technology expertise to understand risk, automating legacy processes, and creating a better user experience for brokers, we're able to provide policies that are more applicable and more transparent in just minutes.Simply put, we're pushing insurance into the future, focusing on accuracy, speed, and ease.Our mission and our team are growing. In staying true to our values, we've earned our spot on many workplace award lists. Attune is dedicated to creating a diverse team of curious, focused, and motivated people who are excited about changing the future of an entire industry.Job DescriptionAs a Data Engineer joining our growing Data team, you will help maintain our existing data pipelines and internal web applications. You will also work with team members across the organization to develop and test new pipelines as we launch new products and integrate with third-party data sources. We work with various tools including Python/Pandas, Postgresql, Bash, AWS EC2, and S3. We are always open to using whatever tool is best for the job.Responsibilities:Maintain and improve batch ETL jobs - including SQL query optimization, bug fixes and code improvementsWork with our data engineers, BI, and other teams across the business to develop/refine ETL processesUnderstand and answer questions on the data our team maintainsQualifications:3+ years experience in analytics, data science, or data engineering roleStrong Python and Postgresql skillsSolid understanding of relational database design and basic query optimization techniquesExperience working with git, and Gitlab or GithubNice to have:Experience with Linux CLI, shell programmingUnderstanding of CI/CDExperience with AWS EC2 and S3What we offer you:140-170k per yearUnlimited PTOGenerous parental and caregiver leave401K matchExcellent medical, dental, and vision plansRemote-first cultureAnd more!\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"OverviewMailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaigns, CRM, and analytics tools.The Data Platform team at Mailchimp is responsible for creating and managing our BI platform that enables peeps from across the company to make better decisions with data. What that actually looks like is working with folks from across the company to understand their needs and then surface data in a meaningful way, across tools and teams, to help them drive the business forward. Day to day you could be building an ETL pipeline, designing a data access tool, modeling out new data in Looker, or working with teams to develop better data governance practices. We have a lot of tools in our toolbelt, but all with the main goal helping Mailchimp to continue to use data more effectively.Intuit Mailchimp is a hybrid workplace , giving employees the opportunity to collaborate in person with team members in our Atlanta and Brooklyn offices two or more days per week.What You'll BringExperience with Python, Java, Go, or another OOP languageExperience with SQL and data analysis skillsExperience with data transformation tools like dbt or DataformExperience in visualization technologies like Looker, Tableau, or Qlik SenseExperience with Airflow or other ETL orchestration toolsSolid business intuition and ability to understand and work with cross-functional partnersExperience with GCP/AWS or other cloud providers is preferredBachelors degree is Computer Science or equivalent experience Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Mailchimp we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.How You Will LeadPartner with analysts, data scientists, business users, and other engineers to understand their needs and come up with data solutionsHelp build robust transformation pipelines to help clean up, normalize, and govern our data for broad consumptionHelp build scalable transformation pipelines that enables teams to easily clean up, normalize, and govern data for broad consumptionBuild tools and processes to help make the right data accessible to the right peopleModel data in Looker, to provide a collaborative data analytics platform for the companyWork with Data Stewards to better document our data\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Laguna Games is the developer of Crypto Unicorns, the #1 NFT project on Polygon, and now one of the fastest-growing games. We are looking to hire an experienced Data Engineer to join our team. You are self-motivated, goal-orientated, and a strong team player. As a Data Engineer, you will be responsible for designing, building, and maintaining the data infrastructure that supports our gaming platform. You will work closely with our product, engineering, and data science teams to collect, process, and analyze large amounts of data generated by our gaming platform to inform our business decisions and improve user experience. You will work and innovate at the forefront of web3 gaming, bringing together unique technologies to deliver a new gaming experience.As a Data Engineer at our Web3 Gaming Startup, Key Responsibilities:Develop and maintain the data pipeline that ingests, processes and stores large amounts of data generated by our gaming platformDesign and build scalable data solutions that support the real-time analytics and reporting needs of the businessCollaborate with the product, engineering and data science teams to identify and implement data-driven solutions to improve user engagement, retention and monetizationBuild and maintain data models, data warehouses and data marts to support business intelligence and reporting needsEnsure data quality, integrity and security across all data sources and systemsMonitor and optimize data performance and scalability, and identify and resolve any data-related issues and bottlenecksKeep up-to-date with the latest trends, tools and technologies in data engineering and apply them to improve our data infrastructureQualificationsBachelor's degree in Computer Science, Computer Engineering, or related field3+ years of experience in data engineering or related fieldExperience with big data technologies such as Hadoop, Spark, Kafka, and ElasticsearchStrong proficiency in SQL, Python and/or Java programming languagesExperience with cloud-based data solutions such as AWS, Azure or Google CloudFamiliarity with data modeling, ETL/ELT processes, data warehousing, and business intelligence toolsUnderstanding of blockchain technology and its use in gaming platforms is a plusExcellent communication skills, both written and verbal, and ability to collaborate with cross-functional teamsIf you are passionate about data engineering and excited about the opportunity to work in a fast-paced and dynamic startup environment, we would love to hear from you!Laguna Games is the developer of Crypto Unicorns, a new blockchain-based game centered around awesomely unique Unicorn NFTs that players use in a fun farming simulation and in a variety of exciting battle loops. As game developers, we are excited to move away from the extractive nature of Free-2-Play to foster and nurture community-run game economies. Crypto Unicorns is our first digital nation and we are extremely excited to build it in tandem with our player community!We are headquartered in San Francisco, CA but operate as a remote company with locations around the world. We offer competitive compensation along with health benefits (medical, dental, and vision), 401k retirement savings, open paid time off, and a remote work support stipend.Learn more here!https://laguna.gameshttps://www.cryptounicorns.fun\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Follow us on Linkedin: https://www.linkedin.com/company/pulivarthigroup/Pulivarthi Group LLC is a Global Staffing & IT Technology Solutions company, with our prime focus of providing world class solutions to our customers with the right talent. We combine the expertise of our team and the culture of your company to help you with the solution that is affordable and innovative using high quality standards and technologies.We’ve served some of the largest healthcare, financial services, and government entities in the U.S.Follow us on Linkedin: https://www.linkedin.com/company/pulivarthigroup/Data Engineer - Experience in data engineering and building applications; Experience in Python/PySpark; Experience in Typescript (Preferred) or JavascriptExperience in building applications or dashboards using no- and low-code tools.Coding Skills: Python complete language proficiency; SQL proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints);PySpark basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas);Typescript experience in TypeScript or Javascript;Application building working with no- and low-code tools to query databases, define variables, filters, cross-filters, responsive front-end and user based applications.Databases familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.; Git knowledge of version control / collaboration workflows and best practices; Agile familiarity with agile and iterative working methodology and rapid user feedback gathering concepts; UX design knowledge of best practices and applications; Data literacy data analysis and statistical basics to ensure correctness in data aggregation and visualization.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Become a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Nike USA, Inc., located in Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into engineering designs and logical units of work. Profile and analyze data for the purpose of designing scalable solutions. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Implement complex automated routines using workflow orchestration tools. Anticipate, identify and tackle issues concerning data management to improve data quality. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks.Applicant must have a Bachelor’s degree in Data Science, Computer Engineering, Computer Science, or Computer Information Systems and five (5) years of progressive post-baccalaureate experience in the job offered or engineering-related occupation. Experience must include the following- Programming ability (Python, SQL);  Database related concept;  Big Data exposure;  Spark;  Airflow (Orchestration tools);  Cloud Solutions;  Software/Data design ability;  CI/CD understanding and implementation;  Code review;  Data Architecture; and  AWS, Azure. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.]]>\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"New Opportunity Systems Engineer Greeneville, TN On-site $110-120k plus excellent benefits We are looking for an enthusiastic Systems Engineer to design, develop and install software solutions. The successful candidate will be able to review software applications standards and technical design. Implement new software platforms work with third party vendors. Support and/or install software applications/operating systems. Participate in the testing process through test review and analysis, test witnessing and certification of software. Requires a bachelor's degree in a related area and 2-5years of experience in the field or in a related area. Has knowledge of commonly used concepts, practices, and procedures within a particular field. Rely on instructions and pre-established guidelines to perform the functions of the job. Work as subject manner expert with minimum supervision. Primary job functions will exercise independent judgment when required. Typically reports to a department manager. Responsibilities: * Performance tuning, improvement, balancing, usability, automation * Support, maintain and document software functionality * Integrate new systems with existing systems * Evaluate and identify innovative technologies for implementation * Project planning and Project management * Maintain standards compliance * Implement new software platforms work with third party vendors * Document and demonstrates solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code * Improve operations by conducting systems analysis, recommending changes in policies and procedures * Protect operations by keeping information confidential * Provide information by collecting, analyzing, and summarizing development and service issues * Accomplish engineering and organization mission by completing related results as needed * Develop software/system solutions by studying information needs; conferring with users; studying systems flow, data usage and work processes; investigating problem areas; following the software/system development lifecycle. * Produce specifications and determine operational feasibility * Document and maintain software functionality * Serve as a subject matter expert * Comply with project plans and industry standards * * Requirements: Software Engineer top skills & proficiency: * Proven work experience in software engineering and/or Database Management * Firsthand experience in implementing and maintaining software/system applications * Firsthand experience in Relational Databases, SQL and etc. * Knowledge of ERP Systems * Experience with test-driven development * Ability to document requirements and specifications * Familiarity with software/system development methodology and release processes * Installing and configuring operating systems and application software * BS degree in Computer Science or relevant degree in Information Systems * Proficient in SQL Queries, stored procedures and working with in relational databases like SQL Server, MySQL, and ERP Systems * Analytical & Problem-Solving Skills * Ability to Learn Quickly * Team Player * Project Management * Written and Verbal Communication * Customer-Oriented * Analysis * General Programming Skills * SharePoint, MS Dynamics, HTML, and other related software a PLUS Company Description Each and every day RemX puts over 90,000 people to work, helping more than 15,000 companies find the talent they need in order to succeed. And, as a part of the 10th largest staffing company in the world, we understand that at the heart of every successful business are people. That's why we work hard to find you the right job at the right company. Explore all the exciting opportunities that RemX offers and find the right fit for you!Each and every day RemX puts over 90,000 people to work, helping more than 15,000 companies find the talent they need in order to succeed. And, as a part of the 10th largest staffing company in the world, we understand that at the heart of every successful business are people. That’s why we work hard to find you the right job at the right company. Explore all the exciting opportunities that RemX offers and find the right fit for you!\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatmentSchedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewMailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaigns, CRM, and analytics tools.The Data Platform team at Mailchimp is responsible for creating and managing our BI platform that enables peeps from across the company to make better decisions with data. What that actually looks like is working with folks from across the company to understand their needs and then surface data in a meaningful way, across tools and teams, to help them drive the business forward. Day to day you could be building an ETL pipeline, designing a data access tool, modeling out new data in Looker, or working with teams to develop better data governance practices. We have a lot of tools in our toolbelt, but all with the main goal helping Mailchimp to continue to use data more effectively.Intuit Mailchimp is a hybrid workplace , giving employees the opportunity to collaborate in person with team members in our Atlanta and Brooklyn offices two or more days per week.What You'll BringExperience with Python, Java, Go, or another OOP languageExperience with SQL and data analysis skillsExperience with data transformation tools like dbt or DataformExperience in visualization technologies like Looker, Tableau, or Qlik SenseExperience with Airflow or other ETL orchestration toolsSolid business intuition and ability to understand and work with cross-functional partnersExperience with GCP/AWS or other cloud providers is preferredBachelors degree is Computer Science or equivalent experience Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Mailchimp we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.How You Will LeadPartner with analysts, data scientists, business users, and other engineers to understand their needs and come up with data solutionsHelp build robust transformation pipelines to help clean up, normalize, and govern our data for broad consumptionHelp build scalable transformation pipelines that enables teams to easily clean up, normalize, and govern data for broad consumptionBuild tools and processes to help make the right data accessible to the right peopleModel data in Looker, to provide a collaborative data analytics platform for the companyWork with Data Stewards to better document our data\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Well known NY based Non-Profit seeks a Data Engineer.An ideal candidate will have strong data engineering skills with both SQL and Python.This position can be based out of NYC or be 100% remote.Compensation includes salary, excellent medical, dental, vision benefits, pto, 401k, a quality of life oriented work life balance, and lots of other benefits.ResponsibilitiesThis position will work within the enterprise data engineering team to continuously build, maintain, and improve the design, performance, reliability, scalability, security, and architecture of enterprise data products.Responsibilities include:Develop robust database solutions, data integration (ETL, ELT) packages, automation, performance monitoring, SQL coding, database tuning and optimizations, security management, capacity planning, database HA, and database DR solutions across required data platforms.Conduct in-depth data analysis to support data product design.Identify and resolve production database and data integration issues.Collaborates closely with data quality, application, and visualization teams to deliver high-quality data products.Participate in code review, QA, release, and continuous deployment processes.Qualifications:Bachelors Degree in Computer Science or other quantitative disciplines such as Science, Statistics, Economics or Mathematics.5+ years of progressive database development experience with the Microsoft SQL Server family suite.Experience with data modeling and data architecture principles for both analytics and transactional systems.Hands-on experience with SQL Server, Oracle, or other RDBMS required.Python ScriptingExperience with Cloud Data PlatformsPreferred Experience:Scripting experience in Powershell, C#, Java, and/or R.Experience in the Microsoft Azure technology stack is a plus.Experience with data analytics and visualization is a plus.Preferred Knowledge:Intermediate knowledge of OLTP and OLAP database designIntermediate knowledge of data modeling (normalized and dimensional)Intermediate knowledge of ETL, ELT architecture especially for real and near-real-time scenariosIntermediate knowledge of Data Architecture implementation patternsAnticipated salary for candidates living in the NY Metro market in the 140,000 to 160,000 range.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Laguna Games is the developer of Crypto Unicorns, the #1 NFT project on Polygon, and now one of the fastest-growing games. We are looking to hire an experienced Data Engineer to join our team. You are self-motivated, goal-orientated, and a strong team player. As a Data Engineer, you will be responsible for designing, building, and maintaining the data infrastructure that supports our gaming platform. You will work closely with our product, engineering, and data science teams to collect, process, and analyze large amounts of data generated by our gaming platform to inform our business decisions and improve user experience. You will work and innovate at the forefront of web3 gaming, bringing together unique technologies to deliver a new gaming experience.As a Data Engineer at our Web3 Gaming Startup, Key Responsibilities:Develop and maintain the data pipeline that ingests, processes and stores large amounts of data generated by our gaming platformDesign and build scalable data solutions that support the real-time analytics and reporting needs of the businessCollaborate with the product, engineering and data science teams to identify and implement data-driven solutions to improve user engagement, retention and monetizationBuild and maintain data models, data warehouses and data marts to support business intelligence and reporting needsEnsure data quality, integrity and security across all data sources and systemsMonitor and optimize data performance and scalability, and identify and resolve any data-related issues and bottlenecksKeep up-to-date with the latest trends, tools and technologies in data engineering and apply them to improve our data infrastructureQualificationsBachelor's degree in Computer Science, Computer Engineering, or related field3+ years of experience in data engineering or related fieldExperience with big data technologies such as Hadoop, Spark, Kafka, and ElasticsearchStrong proficiency in SQL, Python and/or Java programming languagesExperience with cloud-based data solutions such as AWS, Azure or Google CloudFamiliarity with data modeling, ETL/ELT processes, data warehousing, and business intelligence toolsUnderstanding of blockchain technology and its use in gaming platforms is a plusExcellent communication skills, both written and verbal, and ability to collaborate with cross-functional teamsIf you are passionate about data engineering and excited about the opportunity to work in a fast-paced and dynamic startup environment, we would love to hear from you!Laguna Games is the developer of Crypto Unicorns, a new blockchain-based game centered around awesomely unique Unicorn NFTs that players use in a fun farming simulation and in a variety of exciting battle loops. As game developers, we are excited to move away from the extractive nature of Free-2-Play to foster and nurture community-run game economies. Crypto Unicorns is our first digital nation and we are extremely excited to build it in tandem with our player community!We are headquartered in San Francisco, CA but operate as a remote company with locations around the world. We offer competitive compensation along with health benefits (medical, dental, and vision), 401k retirement savings, open paid time off, and a remote work support stipend.Learn more here!https://laguna.gameshttps://www.cryptounicorns.fun\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Become a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Nike USA, Inc., located in Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into engineering designs and logical units of work. Profile and analyze data for the purpose of designing scalable solutions. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Implement complex automated routines using workflow orchestration tools. Anticipate, identify and tackle issues concerning data management to improve data quality. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks.Applicant must have a Bachelor’s degree in Data Science, Computer Engineering, Computer Science, or Computer Information Systems and five (5) years of progressive post-baccalaureate experience in the job offered or engineering-related occupation. Experience must include the following- Programming ability (Python, SQL);  Database related concept;  Big Data exposure;  Spark;  Airflow (Orchestration tools);  Cloud Solutions;  Software/Data design ability;  CI/CD understanding and implementation;  Code review;  Data Architecture; and  AWS, Azure. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.]]>\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Applicants must be authorized to work for any employer in the United States. We are unable to sponsor, or take over sponsorship, of an employment visa at this time.About the roleReporting to the SVP, Data & Technology and Lead Data Engineer, the Data Engineer will play a critical role in supporting and advancing Geopath’s new audience measurement platform.Responsibilities:Build scalable functions, fault tolerant batch & real time data pipelines to validate/extract/transform/integrate large scale datasets inclusive of location and time series data, across multiple platformsReview current data processes to identify improvement areas: design and implement solutions to improve scalability, performance, cost efficiencies and data qualityExtend and optimize Geopath’s data platform, which spans across multiple cloud services, data warehouses, and applications in order to meet the industry’s evolving data needsResearch, evaluate, analyze and integrate new data sources and develop quick prototypes for new data productsWork closely with product owners, data architects, data scientists and application development teams to quickly define prototypes, and build new data productsDevelop a solid understanding of the nuances within Geopath’s foundational data sourcesSupport internal stakeholders including data, design, product and executive teams by assisting them with data-related technical issuesRequirements:Bachelor’s or master's degree in computer science, computer engineering, informatics, or equivalent fields3+ years of experience as a Data Engineer with demonstrated experience in data modeling, ETL, data warehouse/data lakes, and consolidating data from multiple data sources3+ years of experience with SQL, solid experience in writing stored procedures and UDFs, familiarity with Snowflake’s data warehouse a plus2+ years of experience in building and optimizing scalable and robust big data pipelines in Apache Airflow or other workflow engines and fluent in Python or Java programmingGood working knowledge in data partition and query optimizationExperience or desire to work in a start-up environment, good team player, and can work independently with minimal supervisionGreat analytical and problem-solving skills, eager to learn new technologies and willing to wear different hats in a small team settingGreat communication and organizational skillsExpected salary for this role is between $75,000-$140,000 per year, depending on experience.About Geopath Inc.Established in 1933, Geopath, (previously the Traffic Audit Bureau for Media Measurement Inc.,) has been the gold standard in providing media auditing and audience measurement services for the Out of Home industry in the US for 90 years. Geopath has now expanded its historical mission and is looking to the future by modernizing its mission critical, industry-standard media audience rating platform while embracing the digital era. In addition to being the industry’s media auditing solution, Geopath also analyzes people’s movement data, develops deep consumer insights, innovations and advanced media research methodologies to uncover critical insights about how consumers engage with Out of Home advertising across a multi-channel ecosystem and in the physical world.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We are currently hiring a Senior Data Platform Engineer to help grow our company and ensure our mission is achieved!This role is a work from home position and can be performed remotely anywhere in the continental US or in one of our corporate locations in Utah or Arizona.WE ARE: Our Data Platforms embodies the modernity and transformational vision that is core to our business evolution. As passionate and hungry technical experts, we progress through technology. We take pride in our engineering, daily progress, and bringing others along as we improve. We experiment, fail fast, and drive to delivery.YOU ARE: A self-starter mindset to proactively take ownership and execute work without daily oversight and excited to develop your data administration & data DevOps skills. We have a great team of engineers building next-generation data platforms. You are motivated by challenges and thrive with continuous innovation.YOUR DAY-TO-DAY:Coach and develop fellow team membersWorking in an agile-scrum development environmentWork with engineers and leaders to promote a shared vision of our data platform & architectureTrack operating metrics for our data platforms, driving improvements and making trade-offs among competing constraints. We use MS SQL Server, AWS RDS (Postgres, MariaDB) MongoDB, DynamoDB, Redis, Rabbit MQ, AWS managed messaging/eventing systems (Kafka, Kinesis, SQS, SNS) to name a few of our platformsBe a strategic player in designing enterprise-wide data infrastructureBuilds robust systems with an eye on the long-term maintenance and support of the applicationDiscover automation opportunities to replace manual processes using PowerShell, Terraform, Python etcBuild out frameworks for data administration /data deployment /monitoring where neededLeverage reusable code modules to solve problems across the team and organizationCreate and maintain automated pipelines to deploy changes via Octopus, CircleCI, Azure DevOps and JenkinsProactive and reactive performance analysis, monitoring, troubleshooting and resolution of escalated issuesParticipate in the team on-call rotationsYOU’LL BRING:Used multiple data platforms and can define which is optimal for a given scenario (such as document databases, RDBMS, caching, eventing, etc. On-prem or cloud)An engineering mindset when developing a solution using PowerShell / Python or SQL. In depth knowledge and use of tools such as dbatools and other modules is a plusUnderstand how to fully automate systems using infrastructure/configuration as code technologies (we use Terraform, CloudFormation, Ansible, SaltStack)Experience working with CI/CD pipeline and tools preferably Octopus, CircleCI, AzureDevOps and JenkinsProven ability to mentor and coach engineersThrive on a high level of autonomy and responsibility, while having the ability to dig into technical details to inform decisionsAdvanced Sql Server Knowledge and experience in performance analysis and tuning skills such as tracing and profiling and Dynamic Management Views and Functions (DMVs) and other third-party tools like SentryOne to ensure high levels of performance, availability, and securityKnowledge of database deployment using DACPAC via pipelinesExperience with enterprise features of SQL Server: AlwaysOn Availability Groups, clustering, Disaster RecoveryContribute to the management and reliability of database HA/DR processesYOU MIGHT ALSO HAVE:Ability to clearly articulate complex subjects to leadership and others not familiar with this spaceExperience with code-based data developmentA self-starter mindset to proactively take ownership and execute work without daily oversightExperience in AWS cloud-based solutionsWE OFFER: Competitive Compensation; Eligible for STI + LTIFull Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental LeaveCompany Matched 401kPaid Time Off + Paid Holidays + Paid Volunteer HoursEmployee Resource Groups (Black Inclusion Group, Women in Leadership, PRIDE, Adelante)Employee Stock Purchase ProgramTuition ReimbursementCharitable Gift MatchingJob required equipment and services\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our team relies on clean datasets accessible via the latest tools to answer questions that are often not simple or clear. You will be creating solutions that will help derive value from our rich datasets that will solve tough problems impacting consumers across geographies & industries (healthcare, retail/ consumer, telecom, industrial) driving technology transformation. At the core of our team, we believe data is best used to create transparency & generate communal value.  What You’ll Do: · Design, Build & ImplementDesign & build batch, event driven and real-time data pipelines using some of the latest technologies available on Microsoft Azure, Google Cloud Platform and AWSImplement large-scale data platforms to meet the analytical & operational needs across various organizationsBuild products & frameworks that can be re-used across different use-cases in increase efficiency in coding and agility in implementation of solutionsBuild streaming ingestion processes to efficiently read, process, analyze & publish data for real-time need of applications and data science modelsPerform analyses of large structured and unstructured data to solve multiple & complex business problemsInvestigate and prototype different task dependency frameworks to understand the most appropriate design for a given use case to assess & advise Understand business use cases to design engineering routines to affect the outcomesReview & assess data frameworks & technology platforms with the goal of suggesting & implementing improvements on the existing frameworks & platforms.Understand quality of data used in existing use cases to suggest process improvements & implement data quality routines   Who You Are : An Engineer interested in working in batch, event driven and streaming processing environments A tech-enthusiast excited to work with Cloud Based Technologies like GCP, Azure & AWSA data parser expert who gets excited about structuring and re-structuring datasets programmatically A doer who loves to produce meaningful analytic insights for an innovative, data-intensive productsAlways curious about analytics frameworks and you are well-versed in the advantages and limitations of various big data architectures and technologiesTechnologist who loves studying software platforms with an eye towards modernizing the architectureBeliever in transparency, communication, and teamworkLove to learn and not afraid to take ownershipNexus Staffing is committed to diversity, inclusion, and equal opportunity. We take affirmative steps to ensure that all programs and services are open to all Americans, free of discrimination based on protected class status, including race, religion/creed, color, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, national origin (including limited English proficiency), age, political affiliation or belief, military or veteran status, disability, predisposing genetic characteristics, marital or family status, domestic violence victim status, arrest record or criminal conviction history, or any other impermissible basis.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Company OverviewPrivately owned and operated, Digible was founded in 2017 with a mission to bring sophisticated digital marketing solutions to the multifamily industry. We offer a comprehensive suite of digital services as well as a predictive analytics platform, Fiona, that is the first of its kind.At Digible, Inc. we love to celebrate our diverse group of hardworking employees – and it shows. We pride ourselves on our collaborative, transparent, and authentic culture. These values are pervasive throughout every step of a Digible employee\\'s journey. Starting with our interviews and continuing through our weekly All Hands Transparency Round-up, values are at the heart of working at Digible.We value diversity and believe forming teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds and different industries to apply. Come join us and find out what the best work of your career could look like here at Digible.The RoleDigible, Inc. is looking for an Junior Software Engineer to join our team!We are seeking a highly motivated and detail-oriented Junior Data Engineer to join our growing team. As a Junior Data Engineer, you will be responsible for assisting with the development, implementation, and maintenance of our data infrastructure. You will work closely with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources.Responsibilities:Assist with the design, development, and maintenance of our data infrastructure using Python, Prefect, Snowflake, Google Cloud, and AWS. Collaborate with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources. Develop and maintain ETL pipelines to extract, transform, and load data from various sources into our data warehouse. Assist with the implementation of data security and governance policies. Monitor and troubleshoot data issues as they arise. Continuously seek ways to improve our data infrastructure and processes. Requirements:Bachelor\\'s degree in Computer Science, Data Science, or a related field. Experience with Python, SQL, and data modeling. Familiarity with data warehousing concepts and ETL processes. Experience working with cloud-based platforms such as Google Cloud and AWS. Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Expectations:Ability to learn and adapt quickly to new technologies and processes. Work collaboratively with our Data Engineering team to meet project goals and deadlines. Demonstrate a high level of professionalism and dedication to quality work. Communicate effectively with cross-functional teams to ensure project success. Success Metrics:Deliver high-quality data infrastructure projects on time and within scope. Ensure data accuracy and completeness across all data sources. Maintain a high level of data security and governance. Continuously seek ways to improve our data infrastructure and processes. Collaborate effectively with cross-functional teams to meet project goals and objectives. Core ValuesAuthenticity - The commitment to be steadfast and genuine with our actions and communication toward everyone we touch.Curiosity - The belief that a deep and fundamental curiosity (the \"why\") in our work is vital to company innovation and evolution.Focus - The collective will to remain completely devoted and ultimately accountable to our deliverables.Humility - The recognition and daily practice that \"we\" is always greater than \"I\".Happiness - The decision to prioritize passion and love for what we do above everything else.Perks and such:4-Day Work Week (32 Hour Work Week)WFA (Work From Anywhere)Profit Sharing BonusWe offer 3 weeks of PTO as well as Sick leave, and Bereavement. We offer 10 paid holidays (New Years Eve, New Years Day, MLK day, Memorial Day, Independence Day, Labor Day, Thanksgiving + day after, Christmas Eve, and Christmas)401(k) + Match50% employer paid health benefits, including Medical, Dental, and Vision. We provide $75/ month reimbursement for Physical WellnessWe provide $75/ month reimbursement for Mental Wellness$1000/year travel fund for employees who have been with Digible 3+ yearsMonthly subscription for financial wellnessDog-Friendly OfficePaid Parental LeaveCompany Sponsored Social EventsCompany Provided Lunches, SnacksEmployee Development Program\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'R-27413Who Are We?Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.Compensation OverviewThe annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.Salary Range$102,600.00 - $169,200.00Target Openings1What Is the Opportunity?Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Personal Insurance Analytics and business intelligence/insights.What Will You Do?Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.Design data solutions.Analyze sources to determine value and recommend data to include in analytical processes.Incorporate core data management competencies including data governance, data security and data quality.Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.Test data movement, transformation code, and data components.Perform other duties as assigned.What Will Our Ideal Candidate Have?Bachelor’s Degree in STEM related field or equivalentSix years of related experienceProficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. Experience with Salesforce and Tealium Product Suite a plus.The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.Strong verbal and written communication skills with the ability to interact with team members and business partners.Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.What is a Must Have?Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.What Is in It for You?Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.Employment PracticesTravelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.Travelers reserves the right to fill this position at a level above or below the level included in this posting.To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role has a preference for a local Austin, TX candidate and will be a hybrid work environment meeting in-person a few times/month. Our client is a fast-growing, Private Equity backed GovTech company that provides SaaS Software solutions to the Public Sector (City / State Local Government) and is looking for a Data Engineer to join their team. Reporting to the Director of Analytics as their first hire, you will be responsible for the ongoing development and management of the data infrastructure of the business and will be providing essential support to internal customers. This pivotal role will be in the Analytics team reporting to Finance and is aimed to drive greater efficiency in data, processes, and tools, ultimately enhancing data-driven decision-making capabilities. For someone with an interest in more of the analytics side of things, this role could also serve as a hybrid Analytics / Dashboarding role as well. This role is great for someone who perhaps hasn't yet chosen a specific specialization or path in the data realm and wants to gain exposure or opportunity in different areas - Whether BI Front End, Business Strategy, Analytics / Dashboarding, or Data Engineering there are a plethora of opportunities to learn and jump in to help the business. One of the major projects you'll be working on is how to collect data on the usage of their underlying SaaS Software products and how to marry that with their CRM data. They have different products that were built at different times so getting to and extracting that data is going to be an especially interesting challenge for this team. ResponsibilitiesDesign, develop, and maintain scalable data pipelines and ETL processes to ingest and process data from various sourcesBuild and optimize the data warehouse in SnowflakeCollaborate with data users to understand requirements and create efficient data models and structures for seamless reporting and analysis using BI tools. Monitor and optimize data pipeline performanceImplement data governance and security best practices, manage user access, and ensure compliance is adhered toContinuously explore and evaluate new data engineering techniques and tools, including AI applications, to improve data processing and exploration capabilities. QualificationsExperience building or using data marts (sql heavy data modeling) and interacting with users that use the data. The ability to find the shortest path to making data available and widely usable. Experience building or extending a Data WarehouseStrong exposure to Data Warehouse patterns and the application of those patternsPrevious experience working with business stakeholdersStrong initiative to start new projects or take existing projects and make them better. Proficiency with Snowflake, Tableau, and Stitch, or similar data warehousing, BI, and ETL tools. Strong knowledge of SQL is required with database design and data modeling experience. Experience with Python or another programming language for data processing. Familiarity with data engineering best practices, including data quality, data governance, and data security. Interest in AI applications for data engineering and data exploration. Excellent problem-solving, communication, and collaboration skills. Extra informationCareer development opportunitiesCompetitive insurance (medical, dental, vision, and voluntary life & disability)Mental health benefits401(k) plan (company matching)Paid holidaysFlexible PTO - no accrualsPaid generous parental leaveBusiness casual environment #ZR\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"As a Data Engineer for our Data Platform Engineering team you will join skilled Scala/ Spark engineers and core database developers responsible for developing hosted cloud analytics infrastructure (Apache Spark-based), distributed SQL processingframeworks, proprietary data science platforms, and core database optimization. This team is responsible for building the automated, intelligent, and highly performant query planner and execution engines, RPC calls between datawarehouse clusters, shared secondary cold storage, etc. This includes building new SQL features and customer-facing functionality, developing novel query optimization techniques for industry-leading performance, and building a databasesystem that's highly parallel, efficient and fault-tolerant. This is a vital role reporting to exec leadership and senior engineering leadershipRequirementsResponsibilities:Writing Scala code with tools like Apache Spark + Apache Arrow + Apache Kafka to build a hosted, multi-cluster data warehouse for Web3Developing database optimizers, query planners, query and data routing mechanisms, cluster-to-cluster communication, and workload management techniques.Scaling up from proof of concept to “cluster scale” (and eventually hundreds of clusters with hundreds of terabytes each), in terms of both infrastructure/architecture and problem structureCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate meta data capturing and managementManaging a team of software engineers writing new code to build a bigger, better, faster, more optimized HTAP database (using Apache Spark, Apache Arrow, Kafka, and a wealth of other open source data tools)Interacting with exec team and senior engineering leadership to define, prioritize, and ensure smooth deployments with other operational componentsHighly engaged with industry trends within analytics domain from a data acquisition processing, engineering, management perspectiveUnderstand data and analytics use cases across Web3 / blockchainsSkills & QualificationsBachelor’s degree in computer science or related technical field. Masters or PhD a plus.6+ years experience engineering software and data platforms / enterprise-scale data warehouses, preferably with knowledge of open source Apache stack (especially Apache Spark, Apache Arrow, Kafka, and others)3+ years experience with Scala and Apache Spark (or Kafka)A track record of recruiting and leading technical teams in a demanding talent marketRock solid engineering fundamentals; query planning, optimizing and distributed data warehouse systems experience is preferred but not requiredNice to have: Knowledge of blockchain indexing, web3 compute paradigms, Proofs and consensus mechanisms... is a strong plus but not requiredExperience with rapid development cycles in a web-based environmentStrong scripting and test automation knowledgeNice to have: Passionate about Web3, blockchain, decentralization, and a base understanding of how data/analytics plays into this\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Data Engineer Qualifications7+ years of experience as a Database Developer3+ years of experience as a hands on Team LeadExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectureStrong data modeling skills (relational, dimensional and flattened)5-7 years of experience with SQL Server On-Prem and/or Azure cloud, required5-7 years of SSIS experience utilizing SQL Agent jobs and Integration Services Catalog, required3-4 years of experience running ETL/ELT SSIS projects independently from end to end, requiredExperience with DevOps Repository and Git, preferredAzure Data Lake storage experience, a plusAzure Data Factory and/or Databricks experience, a plusLocation: Denver, COEmployment Type: Direct HireDuration: Full TimeWork Location: Denver / HybridPay: Based on experienceOther: PTO, Medical, Dental, Vision, Disability, Life, 401k benefits available Thank you in advance for your interest in this opportunity!If you are able to work on a W2 basis without sponsorship for ANY US employer and fit the description above, please apply. Third-Party Applications Not Accepted.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Hi,Hope you are doing well,We at Software Technology Inc. hiring for a Data Engineer/Data Analyst, role, if you are interested and a good fit, feel free to reach me directly at ksuresh@stiorg.com or (609) 998-3431.Role : Data Engineer/Data AnalystLocation : RemoteSkillGCP Big Query, Python, SQL and knowledge of Healthcare domain\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'adQuadrant helps DTC (direct-to-consumer) brands dream bigger. We are a trusted advisor that provides holistic, strategic omni-channel digital marketing solutions by partnering with our clients to solve the biggest challenges in terms of customer acquisition and growth. Our efforts produce tangible results backed by measurable data. We have the strategic capabilities, quantitative chops, deep creative understanding, and world-class talent with the best tools to drive revenue and profits. We are not simply a vendor checking boxes — our seasoned team serves as an extension of the companies we work with, leading strategy and execution. Our goal is to be the go-to marketing consultants for solving the biggest challenges.adQuadrant is looking for a Data Engineer to support a growing team. This role is responsible for developing, testing, and maintaining data pipelines and data architectures. You will be building and optimizing our data pipeline architecture, as well as optimizing data flows and collections for cross functional teams. The ideal candidate will enjoy optimizing data systems and building them from the ground up, you must be ready for a challenge. This role will ensure optimal data delivery architecture is consistent throughout current and ongoing projects. You must be a self-starter and enjoy supporting multiple cross-functional teams.The Ideal Candidate must have: Experience in Snowflake, architecting and building a data warehouse from scratchData pipeline (ETL tools) development and deployment experienceExtensive experience deploying and maintaining a Tableau ServerRequirementsYour Responsibilities: Consulting with the data team to get a strong understanding of the organization’s data storage needsDesigning and constructing the data warehousing system to the organization’s specificationsDefining and implementing scalable data pipelines that ingest data from various external sources, storing it in the database system, and making it useful to our data analystsImplementing processes to monitor data quality, ensuring production data is always accurate and available for data analysts and business processes that rely on itRecognize, troubleshoot, and resolve unexpected performance and process fail issues, on an ongoing basisQualifications:Bachelor’s degree in computer science, information technology, or a related field5+ years experience in data warehousing, data modeling and building data pipelinesExtensive knowledge of SQL, and coding languages, such as PythonProficiency in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDWProven work experience as an ETL developerExperience working with online marketing dataStrong project management skills and experience with Agile engineering practicesAbility to analyze a company’s big-picture data needsClear communication skillsStrategic thought and extreme attention to detailAbility to troubleshoot and solve complex technical problemsComfortable supporting distributed remote individualsBenefitsOur people come first. No jerks. No egos. Just people who like to work hard and enjoy winning as a team.Annual Compensation: $95,000 - $120,000 per yearExcellent Health Benefits (health, dental, vision, and life insurance)401K + company matchUnlimited Vacation PolicyPaid Sick Leave2 Mindfulness Days Annually2PM Fridays each week$300/ year to equip your work space with new equipment$30/ month for home internetAn extremely supportive and fun company cultureWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Attune is making it easier, faster, and more reliable for small businesses to access insurance (think, pizza place down the street or main street store). They all need insurance to protect their businesses, but when it comes time to get a policy, they're bogged down by hundreds of questions, lots of paperwork, and a seemingly never-ending timeline stretching for weeks or months.We are changing all that. By using data and technology expertise to understand risk, automating legacy processes, and creating a better user experience for brokers, we're able to provide policies that are more applicable and more transparent in just minutes.Simply put, we're pushing insurance into the future, focusing on accuracy, speed, and ease.Our mission and our team are growing. In staying true to our values, we've earned our spot on many workplace award lists. Attune is dedicated to creating a diverse team of curious, focused, and motivated people who are excited about changing the future of an entire industry.Job DescriptionAs a Data Engineer joining our growing Data team, you will help maintain our existing data pipelines and internal web applications. You will also work with team members across the organization to develop and test new pipelines as we launch new products and integrate with third-party data sources. We work with various tools including Python/Pandas, Postgresql, Bash, AWS EC2, and S3. We are always open to using whatever tool is best for the job.Responsibilities:Maintain and improve batch ETL jobs - including SQL query optimization, bug fixes and code improvementsWork with our data engineers, BI, and other teams across the business to develop/refine ETL processesUnderstand and answer questions on the data our team maintainsQualifications:3+ years experience in analytics, data science, or data engineering roleStrong Python and Postgresql skillsSolid understanding of relational database design and basic query optimization techniquesExperience working with git, and Gitlab or GithubNice to have:Experience with Linux CLI, shell programmingUnderstanding of CI/CDExperience with AWS EC2 and S3What we offer you:140-170k per yearUnlimited PTOGenerous parental and caregiver leave401K matchExcellent medical, dental, and vision plansRemote-first cultureAnd more!\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionSkills (Must Have):Python – Ingestion/manipulation of large datasets to S3 using pandasPython – Consumption of data from REST APIs using requestsAny language (Most preferably Python) – Small automation tasks within AWS S3, Glue, AthenaExperience developing in AWS. Key services: S3, Lambda, Athena, Step Functions, GlueGeneral familiarity with a variety of other systems such as Oracle/Postgres, REST APIs, SplunkDeployment of resources to AWS using ServerlessGeneral understand of Infrastructure as CodeSkills (Nice To Have)AI/Client experience in SagemakerGeneral knowledge of cyber security practices and frameworksExperience writing complex queries in Presto/HadoopDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewMailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaigns, CRM, and analytics tools.The Data Platform team at Mailchimp is responsible for creating and managing our BI platform that enables peeps from across the company to make better decisions with data. What that actually looks like is working with folks from across the company to understand their needs and then surface data in a meaningful way, across tools and teams, to help them drive the business forward. Day to day you could be building an ETL pipeline, designing a data access tool, modeling out new data in Looker, or working with teams to develop better data governance practices. We have a lot of tools in our toolbelt, but all with the main goal helping Mailchimp to continue to use data more effectively.Intuit Mailchimp is a hybrid workplace , giving employees the opportunity to collaborate in person with team members in our Atlanta and Brooklyn offices two or more days per week.What You'll BringExperience with Python, Java, Go, or another OOP languageExperience with SQL and data analysis skillsExperience with data transformation tools like dbt or DataformExperience in visualization technologies like Looker, Tableau, or Qlik SenseExperience with Airflow or other ETL orchestration toolsSolid business intuition and ability to understand and work with cross-functional partnersExperience with GCP/AWS or other cloud providers is preferredBachelors degree is Computer Science or equivalent experience Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Mailchimp we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.How You Will LeadPartner with analysts, data scientists, business users, and other engineers to understand their needs and come up with data solutionsHelp build robust transformation pipelines to help clean up, normalize, and govern our data for broad consumptionHelp build scalable transformation pipelines that enables teams to easily clean up, normalize, and govern data for broad consumptionBuild tools and processes to help make the right data accessible to the right peopleModel data in Looker, to provide a collaborative data analytics platform for the companyWork with Data Stewards to better document our data\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Laguna Games is the developer of Crypto Unicorns, the #1 NFT project on Polygon, and now one of the fastest-growing games. We are looking to hire an experienced Data Engineer to join our team. You are self-motivated, goal-orientated, and a strong team player. As a Data Engineer, you will be responsible for designing, building, and maintaining the data infrastructure that supports our gaming platform. You will work closely with our product, engineering, and data science teams to collect, process, and analyze large amounts of data generated by our gaming platform to inform our business decisions and improve user experience. You will work and innovate at the forefront of web3 gaming, bringing together unique technologies to deliver a new gaming experience.As a Data Engineer at our Web3 Gaming Startup, Key Responsibilities:Develop and maintain the data pipeline that ingests, processes and stores large amounts of data generated by our gaming platformDesign and build scalable data solutions that support the real-time analytics and reporting needs of the businessCollaborate with the product, engineering and data science teams to identify and implement data-driven solutions to improve user engagement, retention and monetizationBuild and maintain data models, data warehouses and data marts to support business intelligence and reporting needsEnsure data quality, integrity and security across all data sources and systemsMonitor and optimize data performance and scalability, and identify and resolve any data-related issues and bottlenecksKeep up-to-date with the latest trends, tools and technologies in data engineering and apply them to improve our data infrastructureQualificationsBachelor's degree in Computer Science, Computer Engineering, or related field3+ years of experience in data engineering or related fieldExperience with big data technologies such as Hadoop, Spark, Kafka, and ElasticsearchStrong proficiency in SQL, Python and/or Java programming languagesExperience with cloud-based data solutions such as AWS, Azure or Google CloudFamiliarity with data modeling, ETL/ELT processes, data warehousing, and business intelligence toolsUnderstanding of blockchain technology and its use in gaming platforms is a plusExcellent communication skills, both written and verbal, and ability to collaborate with cross-functional teamsIf you are passionate about data engineering and excited about the opportunity to work in a fast-paced and dynamic startup environment, we would love to hear from you!Laguna Games is the developer of Crypto Unicorns, a new blockchain-based game centered around awesomely unique Unicorn NFTs that players use in a fun farming simulation and in a variety of exciting battle loops. As game developers, we are excited to move away from the extractive nature of Free-2-Play to foster and nurture community-run game economies. Crypto Unicorns is our first digital nation and we are extremely excited to build it in tandem with our player community!We are headquartered in San Francisco, CA but operate as a remote company with locations around the world. We offer competitive compensation along with health benefits (medical, dental, and vision), 401k retirement savings, open paid time off, and a remote work support stipend.Learn more here!https://laguna.gameshttps://www.cryptounicorns.fun\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Become a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Nike USA, Inc., located in Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into engineering designs and logical units of work. Profile and analyze data for the purpose of designing scalable solutions. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Implement complex automated routines using workflow orchestration tools. Anticipate, identify and tackle issues concerning data management to improve data quality. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks.Applicant must have a Bachelor’s degree in Data Science, Computer Engineering, Computer Science, or Computer Information Systems and five (5) years of progressive post-baccalaureate experience in the job offered or engineering-related occupation. Experience must include the following- Programming ability (Python, SQL);  Database related concept;  Big Data exposure;  Spark;  Airflow (Orchestration tools);  Cloud Solutions;  Software/Data design ability;  CI/CD understanding and implementation;  Code review;  Data Architecture; and  AWS, Azure. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.]]>\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"This role has a preference for a local Austin, TX candidate and will be a hybrid work environment meeting in-person a few times/month. Our client is a fast-growing, Private Equity backed GovTech company that provides SaaS Software solutions to the Public Sector (City / State Local Government) and is looking for a Data Engineer to join their team. Reporting to the Director of Analytics as their first hire, you will be responsible for the ongoing development and management of the data infrastructure of the business and will be providing essential support to internal customers. This pivotal role will be in the Analytics team reporting to Finance and is aimed to drive greater efficiency in data, processes, and tools, ultimately enhancing data-driven decision-making capabilities. For someone with an interest in more of the analytics side of things, this role could also serve as a hybrid Analytics / Dashboarding role as well. This role is great for someone who perhaps hasn't yet chosen a specific specialization or path in the data realm and wants to gain exposure or opportunity in different areas - Whether BI Front End, Business Strategy, Analytics / Dashboarding, or Data Engineering there are a plethora of opportunities to learn and jump in to help the business. One of the major projects you'll be working on is how to collect data on the usage of their underlying SaaS Software products and how to marry that with their CRM data. They have different products that were built at different times so getting to and extracting that data is going to be an especially interesting challenge for this team. ResponsibilitiesDesign, develop, and maintain scalable data pipelines and ETL processes to ingest and process data from various sourcesBuild and optimize the data warehouse in SnowflakeCollaborate with data users to understand requirements and create efficient data models and structures for seamless reporting and analysis using BI tools. Monitor and optimize data pipeline performanceImplement data governance and security best practices, manage user access, and ensure compliance is adhered toContinuously explore and evaluate new data engineering techniques and tools, including AI applications, to improve data processing and exploration capabilities. QualificationsExperience building or using data marts (sql heavy data modeling) and interacting with users that use the data. The ability to find the shortest path to making data available and widely usable. Experience building or extending a Data WarehouseStrong exposure to Data Warehouse patterns and the application of those patternsPrevious experience working with business stakeholdersStrong initiative to start new projects or take existing projects and make them better. Proficiency with Snowflake, Tableau, and Stitch, or similar data warehousing, BI, and ETL tools. Strong knowledge of SQL is required with database design and data modeling experience. Experience with Python or another programming language for data processing. Familiarity with data engineering best practices, including data quality, data governance, and data security. Interest in AI applications for data engineering and data exploration. Excellent problem-solving, communication, and collaboration skills. Extra informationCareer development opportunitiesCompetitive insurance (medical, dental, vision, and voluntary life & disability)Mental health benefits401(k) plan (company matching)Paid holidaysFlexible PTO - no accrualsPaid generous parental leaveBusiness casual environment #ZR\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Hi,Hope you are doing well,We at Software Technology Inc. hiring for a Data Engineer/Data Analyst, role, if you are interested and a good fit, feel free to reach me directly at ksuresh@stiorg.com or (609) 998-3431.Role : Data Engineer/Data AnalystLocation : RemoteSkillGCP Big Query, Python, SQL and knowledge of Healthcare domain\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'adQuadrant helps DTC (direct-to-consumer) brands dream bigger. We are a trusted advisor that provides holistic, strategic omni-channel digital marketing solutions by partnering with our clients to solve the biggest challenges in terms of customer acquisition and growth. Our efforts produce tangible results backed by measurable data. We have the strategic capabilities, quantitative chops, deep creative understanding, and world-class talent with the best tools to drive revenue and profits. We are not simply a vendor checking boxes — our seasoned team serves as an extension of the companies we work with, leading strategy and execution. Our goal is to be the go-to marketing consultants for solving the biggest challenges.adQuadrant is looking for a Data Engineer to support a growing team. This role is responsible for developing, testing, and maintaining data pipelines and data architectures. You will be building and optimizing our data pipeline architecture, as well as optimizing data flows and collections for cross functional teams. The ideal candidate will enjoy optimizing data systems and building them from the ground up, you must be ready for a challenge. This role will ensure optimal data delivery architecture is consistent throughout current and ongoing projects. You must be a self-starter and enjoy supporting multiple cross-functional teams.The Ideal Candidate must have: Experience in Snowflake, architecting and building a data warehouse from scratchData pipeline (ETL tools) development and deployment experienceExtensive experience deploying and maintaining a Tableau ServerRequirementsYour Responsibilities: Consulting with the data team to get a strong understanding of the organization’s data storage needsDesigning and constructing the data warehousing system to the organization’s specificationsDefining and implementing scalable data pipelines that ingest data from various external sources, storing it in the database system, and making it useful to our data analystsImplementing processes to monitor data quality, ensuring production data is always accurate and available for data analysts and business processes that rely on itRecognize, troubleshoot, and resolve unexpected performance and process fail issues, on an ongoing basisQualifications:Bachelor’s degree in computer science, information technology, or a related field5+ years experience in data warehousing, data modeling and building data pipelinesExtensive knowledge of SQL, and coding languages, such as PythonProficiency in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDWProven work experience as an ETL developerExperience working with online marketing dataStrong project management skills and experience with Agile engineering practicesAbility to analyze a company’s big-picture data needsClear communication skillsStrategic thought and extreme attention to detailAbility to troubleshoot and solve complex technical problemsComfortable supporting distributed remote individualsBenefitsOur people come first. No jerks. No egos. Just people who like to work hard and enjoy winning as a team.Annual Compensation: $95,000 - $120,000 per yearExcellent Health Benefits (health, dental, vision, and life insurance)401K + company matchUnlimited Vacation PolicyPaid Sick Leave2 Mindfulness Days Annually2PM Fridays each week$300/ year to equip your work space with new equipment$30/ month for home internetAn extremely supportive and fun company cultureWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Attune is making it easier, faster, and more reliable for small businesses to access insurance (think, pizza place down the street or main street store). They all need insurance to protect their businesses, but when it comes time to get a policy, they're bogged down by hundreds of questions, lots of paperwork, and a seemingly never-ending timeline stretching for weeks or months.We are changing all that. By using data and technology expertise to understand risk, automating legacy processes, and creating a better user experience for brokers, we're able to provide policies that are more applicable and more transparent in just minutes.Simply put, we're pushing insurance into the future, focusing on accuracy, speed, and ease.Our mission and our team are growing. In staying true to our values, we've earned our spot on many workplace award lists. Attune is dedicated to creating a diverse team of curious, focused, and motivated people who are excited about changing the future of an entire industry.Job DescriptionAs a Data Engineer joining our growing Data team, you will help maintain our existing data pipelines and internal web applications. You will also work with team members across the organization to develop and test new pipelines as we launch new products and integrate with third-party data sources. We work with various tools including Python/Pandas, Postgresql, Bash, AWS EC2, and S3. We are always open to using whatever tool is best for the job.Responsibilities:Maintain and improve batch ETL jobs - including SQL query optimization, bug fixes and code improvementsWork with our data engineers, BI, and other teams across the business to develop/refine ETL processesUnderstand and answer questions on the data our team maintainsQualifications:3+ years experience in analytics, data science, or data engineering roleStrong Python and Postgresql skillsSolid understanding of relational database design and basic query optimization techniquesExperience working with git, and Gitlab or GithubNice to have:Experience with Linux CLI, shell programmingUnderstanding of CI/CDExperience with AWS EC2 and S3What we offer you:140-170k per yearUnlimited PTOGenerous parental and caregiver leave401K matchExcellent medical, dental, and vision plansRemote-first cultureAnd more!\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionSkills (Must Have):Python – Ingestion/manipulation of large datasets to S3 using pandasPython – Consumption of data from REST APIs using requestsAny language (Most preferably Python) – Small automation tasks within AWS S3, Glue, AthenaExperience developing in AWS. Key services: S3, Lambda, Athena, Step Functions, GlueGeneral familiarity with a variety of other systems such as Oracle/Postgres, REST APIs, SplunkDeployment of resources to AWS using ServerlessGeneral understand of Infrastructure as CodeSkills (Nice To Have)AI/Client experience in SagemakerGeneral knowledge of cyber security practices and frameworksExperience writing complex queries in Presto/HadoopDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Sayari is looking for Data Engineers to join our growing team! We are hiring at all levels and encourage junior through senior level candidates to apply. As a member of Sayari's data team you will work with our Product and Software Engineering teams to collect data from around the globe, maintain existing ETL pipelines, and develop new pipelines that power Sayari Graph.About Sayari:Sayari is a venture-backed and founder-led global corporate data provider and commercial intelligence platform, serving financial institutions, legal & advisory service providers, multinationals, journalists, and governments. We are building world-class SaaS products that help our clients glean insights from vast datasets that we collect, extract, enrich, match and analyze using a highly scalable data pipeline. From financial intelligence to anti-counterfeiting, and from free trade zones to war zones, Sayari powers cross-border and cross-lingual insight into customers, counterparties, and competitors. Thousands of analysts and investigators in over 30 countries rely on our products to safely conduct cross-border trade, research front-page news stories, confidently enter new markets, and prevent financial crimes such as corruption and money laundering.Our company culture is defined by a dedication to our mission of using open data to prevent illicit commercial and financial activity, a passion for finding novel approaches to complex problems, and an understanding that diverse perspectives create optimal outcomes. We embrace cross-team collaboration, encourage training and learning opportunities, and reward initiative and innovation. If you enjoy working with supportive, high-performing, and curious teams, Sayari is the place for you.Position DescriptionSayari’s flagship product, Sayari Graph, provides instant access to structured business information from hundreds of millions of corporate, legal, and trade records. As a member of Sayari's data team you will work with our Product and Software Engineering teams to collect data from around the globe, maintain existing ETL pipelines, and develop new pipelines that power Sayari Graph.RequirementsWhat You Will Need:Professional experience with Python and a JVM language (e.g., Scala)2+ years of experience designing and maintaining ETL pipelinesExperience using Apache Spark and Apache AirflowExperience with SQL and NoSQL databases (e.g., columns stores, graph, etc.)Experience working on a cloud platform like GCP, AWS, or AzureExperience working collaboratively with gitWhat We Would Like:Understanding of Docker/KubernetesUnderstanding of or interest in knowledge graphsWho You Are:Experienced in supporting and working with cross-functional teams in a dynamic environmentInterested in learning from and mentoring team members Passionate about open source development and innovative technologyBenefitsA collaborative and positive culture - your team will be as smart and driven as youLimitless growth and learning opportunities A strong commitment to diversity, equity, and inclusion Performance and incentive bonuses Outstanding competitive compensation and comprehensive family-friendly benefits, including full healthcare coverage plans, commuter benefits, 401K matching, generous vacation, and parental leave.Conference & Continuing Education Coverage Team building events & opportunitiesSayari is an equal opportunity employer and strongly encourages diverse candidates to apply. We believe diversity and inclusion mean our team members should reflect the diversity of the United States. No employee or applicant will face discrimination or harassment based on race, color, ethnicity, religion, age, gender, gender identity or expression, sexual orientation, disability status, veteran status, genetics, or political affiliation. We strongly encourage applicants of all backgrounds to apply.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The Data Engineer (DE) position requires a creative problem solver who is passionate about client service. This role will work with the Project Manager and Senior Data Engineers to produce timely, best-in-class deliverables. This role specializes in obtaining, reconciling, analyzing, and preparing data for use in performing sales tax consulting engagements with emphasis on preparing audit ready data populations for the Service Delivery teams quickly and efficiently.PeopleDuties and Responsibilities:Creates a positive team member experience.Demonstrates strong written and verbal communication skills, displays a positive demeanor and team spirit.Plays a key role in driving collaboration across team members, other practices and outside entities.ClientAssists senior team members in retrieving data from client systems.Assists clients and Ryan consultants in data analysis and manipulation.Travels to client sites to assist client in gathering additional data and other necessary documentation.Collaborates with remote and local teammates to ensure efficient design and timely completion of deliverables.Assist senior team members in preparing client and project correspondence.ValueAssists in the acquisition, extraction, and transfer of client data.Analyzes data from client accounting systems to verify accuracy and completeness.Develops and deploys data extraction technologies to perform data extractions from client systems.Manipulates data using Microsoft® Access, SQL, and proprietary software.Assists with the installation of data extraction tools such as Ryan eExtract®, for various ERP systems.Analyzes large data at terabyte scale using modern database technologies.Develops code in Java or Python to support ETL process and contribute to existing code bases. Performs other duties as assigned.Education And ExperienceBS or MBA preferred in information systems or computer science. Other STEM degrees with relevant work experience or coursework are considered.1-3 years of full-time work experience is a plus. Client facing or consulting experience is considered a differentiator.Experience with an enterprise or NoSQL database is a plus.Implementation experience with a major ERP system is a plus.Computer SkillsThe candidate must have a strong command of SQL and uses ETL software such as Visual Studio to build and execute SSIS packages for data manipulation, loading, and processing as well as either Java or Python to perform successfully. Ability to work in the Microsoft Office suite is required.Certificates And LicensesValid driver’s license required.Supervisory ResponsibilitiesThe position requires no direct supervisory responsibilities.Work EnvironmentStandard indoor working environment.Occasional long periods of sitting while working at computer.Position requires regular interaction with employees and clients both in person and via e-mail and telephone.Independent travel requirement: 30 to 40%. Compensation For certain California based roles, the base salary hiring range for this position is $72,069 - $88,044For other California based locations, the base salary hiring range for this position is $66,033 - $80,707For Colorado based roles, the base salary hiring range for this position is $63,032 - $77,039For New York based roles, the base salary hiring range for this position is $72,036 - $88,044For Washington based roles, the base salary hiring range for this position is $66,033 - $80,707The Company makes offers based on many factors, including qualifications and experience.Equal Opportunity Employer: disability/veteran\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"RumbleOn, the nation's largest retailer of powersports vehicles, is adding a Data Engineer to our Software Architecture team to work ON-SITE at our office in Irving, TX. We are seeking a driven, analytical, hands-on Data Engineer who will be responsible for helping to develop the vision for our database architecture and to assist with the creation of a comprehensive data strategy and roadmap, including recommendations for data storage, data integration, data quality, and data models.You will be responsible for organizing and managing cloud data storage, defining appropriate data stores for structured and unstructured data, designing databases for transactional and analytical workloads, and developing pipelines for data transformation.This is a unique opportunity to join a promising company fueled by excitement, innovative ideas, a fun product, and an impressive roadmap for future opportunity. There has never been a better time to join RumbleOn!Responsibilities:Oversee transactional database design in support of applications developmentCollaborate with DBA staff on management of data warehouse in support of analytical workloads Design and build data collection and transformation pipelines Build optimal ETL infrastructure for a variety of data sources Perform validation procedures to ensure data qualityRecommend and implement ways to improve data reliability, efficiency, and qualityDefine security and backup proceduresDevelop and maintains schema designs, data models, data dictionaries, API, and troubleshooting documentationRequirements5+ years software development experience3+ years experience in Data EngineeringDegree in Math, Statistics, Computer Science or a related degree or equivalent experience Certified Data Engineer or equivalent experienceProficiency with SQL, Python, and JavaProficiency with AWS cloud storage offerings for all data types and workloads (Dynamo, Redshift, Snowflake)Experience with big data tools and pipelines, including stream processing (Airflow, Kinesis, DBT)Experience with data pipelines and workflow management tools (Pipeline, Glue)Experience managing cloud services for OLAP, document, and NoSQL databasesStrong written and verbal communication skillsExposure to analytical tools (Athena, Power BI) Strongly DesiredBenefitsWhat RumbleOn Offers You:A fun, relaxed, and casual work environment with awesome people by your side working as a team to ensure the entire group's success! Plus...Healthcare, Dental, & Vision Insurance (RumbleOn pays a generous portion of employee's medical premium!)Generous Vacation/PTO PlanClose knit, open, inviting startup environment where you can make your mark and where your ideas are heard!Employee discounts on purchasesExtremely competitive compensation packages commensurate with experience and skillsetFully stocked kitchen with drinks and snacks all dayFun company eventsThe opportunity for growth and a solid long term career...we promote from within!!Casual Dress codeTraining and full support while you learnAnd more…All applicants must pass pre-employment testing to include: background checks, MVR, and drug testing in order to qualify for employment*\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Do you love to work with data, finding ways to make it reportable, and building models that will add clinical and commercial value for the future?Do you want to bring your skills and experience to a growth stage engineering team, and help set us up for smart expansion?Are you excited by the prospect of having a high-visibility high-impact role in a fast-moving startup?Are you passionate about healthcare, and looking to create a revolutionary new approach to digestive healthcare with a radically better patient experience?If so, you could be a perfect fit for our team of like-minded professionals who share a common mission and passion for helping others and a desire to build a great company.Oshi Health is revolutionizing GI care with a virtual clinic that provides easy, convenient access to a multidisciplinary care team including a GI Physician, Registered Dietician, Mental Health Professional, and Health Coach that takes a whole-person approach to diagnosing, managing and treating digestive health conditions. Our care is built on the latest evidence-based protocols and is delivered virtually through an app, secure messaging and telehealth visits with the care team. NOTE: Oshi is a fully remote company, with team members all over the US.What You’ll Do:This role will be a perfect fit if you enjoy learning the entire stack and taking on interdisciplinary challenges. A primary focus will be building out a data engineering program, including ETL, data governance, sanitization, and data operations. This part of your responsibilities will be a balance of executing data operations, and building automation to make those operations scalable.You will also have the opportunity to join engineers on the frontend end (React Native and React.js), backend (Node.js Lambdas) and Salesforce to help build the Oshi platform. Experience with any of these technologies is a plus, but more important is an enthusiasm to adapt and learn the ones that are new to you.What you’ll do: build the Oshi data programImplement and maintain data pipelines using Stitch, Databricks, and other scripting as needed to feed a PostgreSQL schema supporting Tableau reportingSupport users of Tableau by updating data sources or modifying inbound inputs as needed deliver critical BI reportsOwn the Oshi data model, ensuring that new features built and new technologies adopted serve the needs of the clinical, commercial, product, and engineering teamsManage ETL of client eligibility files and other data, to make them available for Oshi use in a secure and timely manner. Wherever possible, replace bespoke processes with automationOnce you have a understanding of Oshi’s requirements, design and implement a data strategy, (with your recommendation of approach and products,) to meet the needs of Oshi’s analytics, commercial, and clinical business linesYour work will also include:AWS maintenance and administration Writing technical documentation to outline designs for forthcoming features, outlining the implementation across all technology layersMeeting with colleagues in Strategy, Product, and Clinical to support their needs from the Engineering group.Production support responsibilities (shared with the entire engineering team) responding to alerts in Datadog, reviewing and troubleshooting issuesOur tech stack:Mobile Platforms Supported: iOS & AndroidCross-Platform Mobile Language: React NativeOther Languages: React-js, HTML, CSS, Java (Salesforce Apex), Node.js (Lambda)Systems: Salesforce, AWS Amplify / Cognito / LambdaYour Profile:A minimum of 3+ years of professional experienceBachelor's Degree or equivalent experienceGood interpersonal and relationship skills that include a positive attitudeSelf-starter who can find a way forward even when the path is unclear.Team player AND a leader simultaneously.What You’ll Bring to the Team:Passionate about creating value that changes people's livesMake low-level decisions quickly while being patient and methodical with high-level onesAre curious and passionate about digging into new technologies with a knack for picking them up quicklyAdept at prioritizing value and shipping complex products while coordinating across multiple teamsLove working with a diverse set of engineers, product managers, designers, and business partnersStrive to excel, innovate and take pride in your workWork well with other leadersAre a positive culture driverExcited about working in a fast-paced, startup cultureExperience in a regulated industry (healthcare, finance, etc.) a plusand perks:We’re revolutionizing GI care — and our employees are driving the change. We’re a hard-working and fun-loving team, committed to always learning and improving, and dedicated to doing the right thing for our members. To achieve our mission, we invest in our people:We make healthcare more equitable and accessible:Mission-driven organization focused on innovative digestive careThrive on diversity with monthly DEIB discussions, activities, and moreVirtual-first culture: Work from home anywhere in the USLive our core values: Own the outcome, Do the right thing, Be direct and open, Learn and improve, Team, Thrive on diversity We take care of our people:Competitive compensation and meaningful equityEmployer-sponsored medical, dental and vision plans Access to a “Life Concierge” through Overalls, because we know life happensTailored professional development opportunities to learn and growWe rest, recharge and re-energize:Unlimited paid time off — take what you need, when you need it13 paid company holidays to power downTeam events, such as virtual cooking classes, games, and moreRecognition of professional and personal accomplishmentsOshi Health’s Core Values:Go For ItDo the Right ThingBe Direct & OpenLearn & ImproveTEAM - Together Everyone Achieves MoreOshi Health is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.Powered by JazzHRFRVWJuzRKn\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Systems Planning and Analysis, Inc. (SPA) delivers high-impact, technical solutions to complex national security issues. With over 50 years of business expertise and consistent growth, we are known for continuous innovation for our government customers, in both the US and abroad. Our exceptionally talented team is highly collaborative in spirit and practice, producing Results that Matter. Come work with the best! We offer opportunity, unique challenges, and clear-sighted commitment to the mission. SPA: Objective. Responsive. Trusted.SPA assists the Defense Threat Reduction Agency (DTRA) in developing leading edge technologies to counter WMD in support of CCMDs and transitioning these technologies to services and SOCOM. SPA provides expertise across the full range of chemical, biological, radiological, nuclear and high-yield explosives (CBRNE) WMD, Counter Improvised Threat (CIT) and Countering Threat Network (CTN) technologies to support understanding, detection, identification, characterization, denial, control, disabling, defeating, disposing, safeguarding the force, managing consequences, and test and evaluation in support of military and civilian operations.SPA has a near term need for a Jr. Data Engineer. The qualified candidate will provide Advisory and Assistance Support (A&AS) to the Defense Threat Reduction Agency (DTRA), Chemical and Biological Technologies Department, Digital Battlespace Management Division (RD-CBI). The candidate will provide subject matter expertise and support to the client for science and technology (S&T) projects aimed at developing software tools for Chemical, Biological, Radiological, Nuclear (CBRN) CBRN Support to Command and Control (CSC2) and other chemical and biological defense applications.The work is located in Lorton, VA.Travel is expected (~10%).Minimum QualificationsBachelor's degree in Operations Research, Mathematics, Chemical Sciences, or Biological Sciences with 2 to 5 years of experience.Building scalable and dependable Cloud-based and hybrid data solutions by leverage data models, process maps, ETL and data integration processes.Using Python, Java, or Scala Development to meet data quality and data management needs.Using both relational and NOSQL paradigms for data centric solutions.The design and development of data pipelines, enterprise data warehouse, such as Hadoop/Spark in a complex ecosystem.Active DoD Secret Clearance and the ability to maintain throughout time of employment.Preferred QualificationsExperience advising on all phases of the data science problem life-cycle, including use-case identification and formulation, stakeholder communication and management, and placing models into production.Experience advising / advocating for compute architecture decisions, including tools required for projects, ETL pipelines, and data storage and engineering topics as they influence data science activities.Master’s degree in Operations Research, Mathematics, Chemical Sciences, or Biological Sciences.Proven experience analyzing data to produce reports and recommendations on improving processes efficiency for US Military Projects.Knowledge of and/or experience with DTRA or Chemical/Biological Defense Program.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionAt Johnson & Johnson, we use technology and the power of teamwork to discover new ways to prevent and overcome the world’s the most significant healthcare challenges. Our Corporate, Consumer Health, Medical Devices, and Pharmaceutical teams leverage data, real-world insights, and creative minds to make life-changing healthcare products and medicines. We're disrupting outdated healthcare ecosystems and infusing them with transformative ideas to help people thrive throughout every stage of their lives. With a reach of more than a billion people every day, there’s no limit to the impact you can make here. Are you ready to reimagine healthcare?Here, your career breakthroughs will change the future of health, in all the best ways. And you’ll change, too. You’ll be inspired, and you’ll inspire people across the world to change how they care for themselves and those they love. Amplify your impact. Join us! Tasked with transforming data into a format that can be easily consumes by ML algorithms. Adept Database basics SQL, capable of basic data engineering techniques – data wrangling, data cleansing, data curation. Fluent in one of the programming languages R or Python.  Data Engineering skills, e.g., cleaning/organizing data, data preparation, data collection, data integration across different data sources, data storage, relational/non-relational database management.  Proficient in structured query language (SQL), NoSQL, MATLAB, and programming in Python or R.  Proficient in Applied Machine Learning – Experience with a variety of algorithms, Building Predictive Models, Cross-validating, Hypertuning and Deployment.  Experience with devising and implementing ML methods for protein or antibody modeling or design, or with deep learning methods that relate protein sequence, structure, property or function.  MD simulation software (e.g., Commercial tools like Schrodinger, or open-source software AMBER, GROMACS, etc.). Additionally, prior experience in homology modeling and structural refinement  Knowledgeable of AWS services including Redshift, RDS, EMR and EC2  Working knowledge using software and tools including big data tools like Kafka, Spark and Hadoop. At Johnson & Johnson, we’re on a mission to change the trajectory of health for humanity. That starts by creating the world’s healthiest workforce. Through cutting-edge programs and policies, we empower the physical, mental, emotional and financial health of our employees and the ones they love. As such, candidates offered employment must show proof of COVID-19 vaccination or secure an approved accommodation prior to the commencement of employment to support the well-being of our employees, their families and the communities in which we live and work.Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Primary LocationNA-US-Pennsylvania-Spring HouseOrganizationJanssen Research & Development, LLC (6084)Job FunctionAdministration\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatmentSchedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewMailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaigns, CRM, and analytics tools.The Data Platform team at Mailchimp is responsible for creating and managing our BI platform that enables peeps from across the company to make better decisions with data. What that actually looks like is working with folks from across the company to understand their needs and then surface data in a meaningful way, across tools and teams, to help them drive the business forward. Day to day you could be building an ETL pipeline, designing a data access tool, modeling out new data in Looker, or working with teams to develop better data governance practices. We have a lot of tools in our toolbelt, but all with the main goal helping Mailchimp to continue to use data more effectively.Intuit Mailchimp is a hybrid workplace , giving employees the opportunity to collaborate in person with team members in our Atlanta and Brooklyn offices two or more days per week.What You'll BringExperience with Python, Java, Go, or another OOP languageExperience with SQL and data analysis skillsExperience with data transformation tools like dbt or DataformExperience in visualization technologies like Looker, Tableau, or Qlik SenseExperience with Airflow or other ETL orchestration toolsSolid business intuition and ability to understand and work with cross-functional partnersExperience with GCP/AWS or other cloud providers is preferredBachelors degree is Computer Science or equivalent experience Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Mailchimp we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.How You Will LeadPartner with analysts, data scientists, business users, and other engineers to understand their needs and come up with data solutionsHelp build robust transformation pipelines to help clean up, normalize, and govern our data for broad consumptionHelp build scalable transformation pipelines that enables teams to easily clean up, normalize, and govern data for broad consumptionBuild tools and processes to help make the right data accessible to the right peopleModel data in Looker, to provide a collaborative data analytics platform for the companyWork with Data Stewards to better document our data\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Laguna Games is the developer of Crypto Unicorns, the #1 NFT project on Polygon, and now one of the fastest-growing games. We are looking to hire an experienced Data Engineer to join our team. You are self-motivated, goal-orientated, and a strong team player. As a Data Engineer, you will be responsible for designing, building, and maintaining the data infrastructure that supports our gaming platform. You will work closely with our product, engineering, and data science teams to collect, process, and analyze large amounts of data generated by our gaming platform to inform our business decisions and improve user experience. You will work and innovate at the forefront of web3 gaming, bringing together unique technologies to deliver a new gaming experience.As a Data Engineer at our Web3 Gaming Startup, Key Responsibilities:Develop and maintain the data pipeline that ingests, processes and stores large amounts of data generated by our gaming platformDesign and build scalable data solutions that support the real-time analytics and reporting needs of the businessCollaborate with the product, engineering and data science teams to identify and implement data-driven solutions to improve user engagement, retention and monetizationBuild and maintain data models, data warehouses and data marts to support business intelligence and reporting needsEnsure data quality, integrity and security across all data sources and systemsMonitor and optimize data performance and scalability, and identify and resolve any data-related issues and bottlenecksKeep up-to-date with the latest trends, tools and technologies in data engineering and apply them to improve our data infrastructureQualificationsBachelor's degree in Computer Science, Computer Engineering, or related field3+ years of experience in data engineering or related fieldExperience with big data technologies such as Hadoop, Spark, Kafka, and ElasticsearchStrong proficiency in SQL, Python and/or Java programming languagesExperience with cloud-based data solutions such as AWS, Azure or Google CloudFamiliarity with data modeling, ETL/ELT processes, data warehousing, and business intelligence toolsUnderstanding of blockchain technology and its use in gaming platforms is a plusExcellent communication skills, both written and verbal, and ability to collaborate with cross-functional teamsIf you are passionate about data engineering and excited about the opportunity to work in a fast-paced and dynamic startup environment, we would love to hear from you!Laguna Games is the developer of Crypto Unicorns, a new blockchain-based game centered around awesomely unique Unicorn NFTs that players use in a fun farming simulation and in a variety of exciting battle loops. As game developers, we are excited to move away from the extractive nature of Free-2-Play to foster and nurture community-run game economies. Crypto Unicorns is our first digital nation and we are extremely excited to build it in tandem with our player community!We are headquartered in San Francisco, CA but operate as a remote company with locations around the world. We offer competitive compensation along with health benefits (medical, dental, and vision), 401k retirement savings, open paid time off, and a remote work support stipend.Learn more here!https://laguna.gameshttps://www.cryptounicorns.fun\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Become a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Nike USA, Inc., located in Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into engineering designs and logical units of work. Profile and analyze data for the purpose of designing scalable solutions. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Implement complex automated routines using workflow orchestration tools. Anticipate, identify and tackle issues concerning data management to improve data quality. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks.Applicant must have a Bachelor’s degree in Data Science, Computer Engineering, Computer Science, or Computer Information Systems and five (5) years of progressive post-baccalaureate experience in the job offered or engineering-related occupation. Experience must include the following- Programming ability (Python, SQL);  Database related concept;  Big Data exposure;  Spark;  Airflow (Orchestration tools);  Cloud Solutions;  Software/Data design ability;  CI/CD understanding and implementation;  Code review;  Data Architecture; and  AWS, Azure. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.]]>\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Company OverviewPrivately owned and operated, Digible was founded in 2017 with a mission to bring sophisticated digital marketing solutions to the multifamily industry. We offer a comprehensive suite of digital services as well as a predictive analytics platform, Fiona, that is the first of its kind.At Digible, Inc. we love to celebrate our diverse group of hardworking employees – and it shows. We pride ourselves on our collaborative, transparent, and authentic culture. These values are pervasive throughout every step of a Digible employee\\'s journey. Starting with our interviews and continuing through our weekly All Hands Transparency Round-up, values are at the heart of working at Digible.We value diversity and believe forming teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds and different industries to apply. Come join us and find out what the best work of your career could look like here at Digible.The RoleDigible, Inc. is looking for an Junior Software Engineer to join our team!We are seeking a highly motivated and detail-oriented Junior Data Engineer to join our growing team. As a Junior Data Engineer, you will be responsible for assisting with the development, implementation, and maintenance of our data infrastructure. You will work closely with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources.Responsibilities:Assist with the design, development, and maintenance of our data infrastructure using Python, Prefect, Snowflake, Google Cloud, and AWS. Collaborate with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources. Develop and maintain ETL pipelines to extract, transform, and load data from various sources into our data warehouse. Assist with the implementation of data security and governance policies. Monitor and troubleshoot data issues as they arise. Continuously seek ways to improve our data infrastructure and processes. Requirements:Bachelor\\'s degree in Computer Science, Data Science, or a related field. Experience with Python, SQL, and data modeling. Familiarity with data warehousing concepts and ETL processes. Experience working with cloud-based platforms such as Google Cloud and AWS. Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Expectations:Ability to learn and adapt quickly to new technologies and processes. Work collaboratively with our Data Engineering team to meet project goals and deadlines. Demonstrate a high level of professionalism and dedication to quality work. Communicate effectively with cross-functional teams to ensure project success. Success Metrics:Deliver high-quality data infrastructure projects on time and within scope. Ensure data accuracy and completeness across all data sources. Maintain a high level of data security and governance. Continuously seek ways to improve our data infrastructure and processes. Collaborate effectively with cross-functional teams to meet project goals and objectives. Core ValuesAuthenticity - The commitment to be steadfast and genuine with our actions and communication toward everyone we touch.Curiosity - The belief that a deep and fundamental curiosity (the \"why\") in our work is vital to company innovation and evolution.Focus - The collective will to remain completely devoted and ultimately accountable to our deliverables.Humility - The recognition and daily practice that \"we\" is always greater than \"I\".Happiness - The decision to prioritize passion and love for what we do above everything else.Perks and such:4-Day Work Week (32 Hour Work Week)WFA (Work From Anywhere)Profit Sharing BonusWe offer 3 weeks of PTO as well as Sick leave, and Bereavement. We offer 10 paid holidays (New Years Eve, New Years Day, MLK day, Memorial Day, Independence Day, Labor Day, Thanksgiving + day after, Christmas Eve, and Christmas)401(k) + Match50% employer paid health benefits, including Medical, Dental, and Vision. We provide $75/ month reimbursement for Physical WellnessWe provide $75/ month reimbursement for Mental Wellness$1000/year travel fund for employees who have been with Digible 3+ yearsMonthly subscription for financial wellnessDog-Friendly OfficePaid Parental LeaveCompany Sponsored Social EventsCompany Provided Lunches, SnacksEmployee Development Program\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"As a Data Engineer for our Data Platform Engineering team you will join skilled Scala/ Spark engineers and core database developers responsible for developing hosted cloud analytics infrastructure (Apache Spark-based), distributed SQL processingframeworks, proprietary data science platforms, and core database optimization. This team is responsible for building the automated, intelligent, and highly performant query planner and execution engines, RPC calls between datawarehouse clusters, shared secondary cold storage, etc. This includes building new SQL features and customer-facing functionality, developing novel query optimization techniques for industry-leading performance, and building a databasesystem that's highly parallel, efficient and fault-tolerant. This is a vital role reporting to exec leadership and senior engineering leadershipRequirementsResponsibilities:Writing Scala code with tools like Apache Spark + Apache Arrow + Apache Kafka to build a hosted, multi-cluster data warehouse for Web3Developing database optimizers, query planners, query and data routing mechanisms, cluster-to-cluster communication, and workload management techniques.Scaling up from proof of concept to “cluster scale” (and eventually hundreds of clusters with hundreds of terabytes each), in terms of both infrastructure/architecture and problem structureCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate meta data capturing and managementManaging a team of software engineers writing new code to build a bigger, better, faster, more optimized HTAP database (using Apache Spark, Apache Arrow, Kafka, and a wealth of other open source data tools)Interacting with exec team and senior engineering leadership to define, prioritize, and ensure smooth deployments with other operational componentsHighly engaged with industry trends within analytics domain from a data acquisition processing, engineering, management perspectiveUnderstand data and analytics use cases across Web3 / blockchainsSkills & QualificationsBachelor’s degree in computer science or related technical field. Masters or PhD a plus.6+ years experience engineering software and data platforms / enterprise-scale data warehouses, preferably with knowledge of open source Apache stack (especially Apache Spark, Apache Arrow, Kafka, and others)3+ years experience with Scala and Apache Spark (or Kafka)A track record of recruiting and leading technical teams in a demanding talent marketRock solid engineering fundamentals; query planning, optimizing and distributed data warehouse systems experience is preferred but not requiredNice to have: Knowledge of blockchain indexing, web3 compute paradigms, Proofs and consensus mechanisms... is a strong plus but not requiredExperience with rapid development cycles in a web-based environmentStrong scripting and test automation knowledgeNice to have: Passionate about Web3, blockchain, decentralization, and a base understanding of how data/analytics plays into this\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'adQuadrant helps DTC (direct-to-consumer) brands dream bigger. We are a trusted advisor that provides holistic, strategic omni-channel digital marketing solutions by partnering with our clients to solve the biggest challenges in terms of customer acquisition and growth. Our efforts produce tangible results backed by measurable data. We have the strategic capabilities, quantitative chops, deep creative understanding, and world-class talent with the best tools to drive revenue and profits. We are not simply a vendor checking boxes — our seasoned team serves as an extension of the companies we work with, leading strategy and execution. Our goal is to be the go-to marketing consultants for solving the biggest challenges.adQuadrant is looking for a Data Engineer to support a growing team. This role is responsible for developing, testing, and maintaining data pipelines and data architectures. You will be building and optimizing our data pipeline architecture, as well as optimizing data flows and collections for cross functional teams. The ideal candidate will enjoy optimizing data systems and building them from the ground up, you must be ready for a challenge. This role will ensure optimal data delivery architecture is consistent throughout current and ongoing projects. You must be a self-starter and enjoy supporting multiple cross-functional teams.The Ideal Candidate must have: Experience in Snowflake, architecting and building a data warehouse from scratchData pipeline (ETL tools) development and deployment experienceExtensive experience deploying and maintaining a Tableau ServerRequirementsYour Responsibilities: Consulting with the data team to get a strong understanding of the organization’s data storage needsDesigning and constructing the data warehousing system to the organization’s specificationsDefining and implementing scalable data pipelines that ingest data from various external sources, storing it in the database system, and making it useful to our data analystsImplementing processes to monitor data quality, ensuring production data is always accurate and available for data analysts and business processes that rely on itRecognize, troubleshoot, and resolve unexpected performance and process fail issues, on an ongoing basisQualifications:Bachelor’s degree in computer science, information technology, or a related field5+ years experience in data warehousing, data modeling and building data pipelinesExtensive knowledge of SQL, and coding languages, such as PythonProficiency in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDWProven work experience as an ETL developerExperience working with online marketing dataStrong project management skills and experience with Agile engineering practicesAbility to analyze a company’s big-picture data needsClear communication skillsStrategic thought and extreme attention to detailAbility to troubleshoot and solve complex technical problemsComfortable supporting distributed remote individualsBenefitsOur people come first. No jerks. No egos. Just people who like to work hard and enjoy winning as a team.Annual Compensation: $95,000 - $120,000 per yearExcellent Health Benefits (health, dental, vision, and life insurance)401K + company matchUnlimited Vacation PolicyPaid Sick Leave2 Mindfulness Days Annually2PM Fridays each week$300/ year to equip your work space with new equipment$30/ month for home internetAn extremely supportive and fun company cultureWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionSkills (Must Have):Python – Ingestion/manipulation of large datasets to S3 using pandasPython – Consumption of data from REST APIs using requestsAny language (Most preferably Python) – Small automation tasks within AWS S3, Glue, AthenaExperience developing in AWS. Key services: S3, Lambda, Athena, Step Functions, GlueGeneral familiarity with a variety of other systems such as Oracle/Postgres, REST APIs, SplunkDeployment of resources to AWS using ServerlessGeneral understand of Infrastructure as CodeSkills (Nice To Have)AI/Client experience in SagemakerGeneral knowledge of cyber security practices and frameworksExperience writing complex queries in Presto/HadoopDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Sayari is looking for Data Engineers to join our growing team! We are hiring at all levels and encourage junior through senior level candidates to apply. As a member of Sayari's data team you will work with our Product and Software Engineering teams to collect data from around the globe, maintain existing ETL pipelines, and develop new pipelines that power Sayari Graph.About Sayari:Sayari is a venture-backed and founder-led global corporate data provider and commercial intelligence platform, serving financial institutions, legal & advisory service providers, multinationals, journalists, and governments. We are building world-class SaaS products that help our clients glean insights from vast datasets that we collect, extract, enrich, match and analyze using a highly scalable data pipeline. From financial intelligence to anti-counterfeiting, and from free trade zones to war zones, Sayari powers cross-border and cross-lingual insight into customers, counterparties, and competitors. Thousands of analysts and investigators in over 30 countries rely on our products to safely conduct cross-border trade, research front-page news stories, confidently enter new markets, and prevent financial crimes such as corruption and money laundering.Our company culture is defined by a dedication to our mission of using open data to prevent illicit commercial and financial activity, a passion for finding novel approaches to complex problems, and an understanding that diverse perspectives create optimal outcomes. We embrace cross-team collaboration, encourage training and learning opportunities, and reward initiative and innovation. If you enjoy working with supportive, high-performing, and curious teams, Sayari is the place for you.Position DescriptionSayari’s flagship product, Sayari Graph, provides instant access to structured business information from hundreds of millions of corporate, legal, and trade records. As a member of Sayari's data team you will work with our Product and Software Engineering teams to collect data from around the globe, maintain existing ETL pipelines, and develop new pipelines that power Sayari Graph.RequirementsWhat You Will Need:Professional experience with Python and a JVM language (e.g., Scala)2+ years of experience designing and maintaining ETL pipelinesExperience using Apache Spark and Apache AirflowExperience with SQL and NoSQL databases (e.g., columns stores, graph, etc.)Experience working on a cloud platform like GCP, AWS, or AzureExperience working collaboratively with gitWhat We Would Like:Understanding of Docker/KubernetesUnderstanding of or interest in knowledge graphsWho You Are:Experienced in supporting and working with cross-functional teams in a dynamic environmentInterested in learning from and mentoring team members Passionate about open source development and innovative technologyBenefitsA collaborative and positive culture - your team will be as smart and driven as youLimitless growth and learning opportunities A strong commitment to diversity, equity, and inclusion Performance and incentive bonuses Outstanding competitive compensation and comprehensive family-friendly benefits, including full healthcare coverage plans, commuter benefits, 401K matching, generous vacation, and parental leave.Conference & Continuing Education Coverage Team building events & opportunitiesSayari is an equal opportunity employer and strongly encourages diverse candidates to apply. We believe diversity and inclusion mean our team members should reflect the diversity of the United States. No employee or applicant will face discrimination or harassment based on race, color, ethnicity, religion, age, gender, gender identity or expression, sexual orientation, disability status, veteran status, genetics, or political affiliation. We strongly encourage applicants of all backgrounds to apply.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The Data Engineer (DE) position requires a creative problem solver who is passionate about client service. This role will work with the Project Manager and Senior Data Engineers to produce timely, best-in-class deliverables. This role specializes in obtaining, reconciling, analyzing, and preparing data for use in performing sales tax consulting engagements with emphasis on preparing audit ready data populations for the Service Delivery teams quickly and efficiently.PeopleDuties and Responsibilities:Creates a positive team member experience.Demonstrates strong written and verbal communication skills, displays a positive demeanor and team spirit.Plays a key role in driving collaboration across team members, other practices and outside entities.ClientAssists senior team members in retrieving data from client systems.Assists clients and Ryan consultants in data analysis and manipulation.Travels to client sites to assist client in gathering additional data and other necessary documentation.Collaborates with remote and local teammates to ensure efficient design and timely completion of deliverables.Assist senior team members in preparing client and project correspondence.ValueAssists in the acquisition, extraction, and transfer of client data.Analyzes data from client accounting systems to verify accuracy and completeness.Develops and deploys data extraction technologies to perform data extractions from client systems.Manipulates data using Microsoft® Access, SQL, and proprietary software.Assists with the installation of data extraction tools such as Ryan eExtract®, for various ERP systems.Analyzes large data at terabyte scale using modern database technologies.Develops code in Java or Python to support ETL process and contribute to existing code bases. Performs other duties as assigned.Education And ExperienceBS or MBA preferred in information systems or computer science. Other STEM degrees with relevant work experience or coursework are considered.1-3 years of full-time work experience is a plus. Client facing or consulting experience is considered a differentiator.Experience with an enterprise or NoSQL database is a plus.Implementation experience with a major ERP system is a plus.Computer SkillsThe candidate must have a strong command of SQL and uses ETL software such as Visual Studio to build and execute SSIS packages for data manipulation, loading, and processing as well as either Java or Python to perform successfully. Ability to work in the Microsoft Office suite is required.Certificates And LicensesValid driver’s license required.Supervisory ResponsibilitiesThe position requires no direct supervisory responsibilities.Work EnvironmentStandard indoor working environment.Occasional long periods of sitting while working at computer.Position requires regular interaction with employees and clients both in person and via e-mail and telephone.Independent travel requirement: 30 to 40%. Compensation For certain California based roles, the base salary hiring range for this position is $72,069 - $88,044For other California based locations, the base salary hiring range for this position is $66,033 - $80,707For Colorado based roles, the base salary hiring range for this position is $63,032 - $77,039For New York based roles, the base salary hiring range for this position is $72,036 - $88,044For Washington based roles, the base salary hiring range for this position is $66,033 - $80,707The Company makes offers based on many factors, including qualifications and experience.Equal Opportunity Employer: disability/veteran\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Do you love to work with data, finding ways to make it reportable, and building models that will add clinical and commercial value for the future?Do you want to bring your skills and experience to a growth stage engineering team, and help set us up for smart expansion?Are you excited by the prospect of having a high-visibility high-impact role in a fast-moving startup?Are you passionate about healthcare, and looking to create a revolutionary new approach to digestive healthcare with a radically better patient experience?If so, you could be a perfect fit for our team of like-minded professionals who share a common mission and passion for helping others and a desire to build a great company.Oshi Health is revolutionizing GI care with a virtual clinic that provides easy, convenient access to a multidisciplinary care team including a GI Physician, Registered Dietician, Mental Health Professional, and Health Coach that takes a whole-person approach to diagnosing, managing and treating digestive health conditions. Our care is built on the latest evidence-based protocols and is delivered virtually through an app, secure messaging and telehealth visits with the care team. NOTE: Oshi is a fully remote company, with team members all over the US.What You’ll Do:This role will be a perfect fit if you enjoy learning the entire stack and taking on interdisciplinary challenges. A primary focus will be building out a data engineering program, including ETL, data governance, sanitization, and data operations. This part of your responsibilities will be a balance of executing data operations, and building automation to make those operations scalable.You will also have the opportunity to join engineers on the frontend end (React Native and React.js), backend (Node.js Lambdas) and Salesforce to help build the Oshi platform. Experience with any of these technologies is a plus, but more important is an enthusiasm to adapt and learn the ones that are new to you.What you’ll do: build the Oshi data programImplement and maintain data pipelines using Stitch, Databricks, and other scripting as needed to feed a PostgreSQL schema supporting Tableau reportingSupport users of Tableau by updating data sources or modifying inbound inputs as needed deliver critical BI reportsOwn the Oshi data model, ensuring that new features built and new technologies adopted serve the needs of the clinical, commercial, product, and engineering teamsManage ETL of client eligibility files and other data, to make them available for Oshi use in a secure and timely manner. Wherever possible, replace bespoke processes with automationOnce you have a understanding of Oshi’s requirements, design and implement a data strategy, (with your recommendation of approach and products,) to meet the needs of Oshi’s analytics, commercial, and clinical business linesYour work will also include:AWS maintenance and administration Writing technical documentation to outline designs for forthcoming features, outlining the implementation across all technology layersMeeting with colleagues in Strategy, Product, and Clinical to support their needs from the Engineering group.Production support responsibilities (shared with the entire engineering team) responding to alerts in Datadog, reviewing and troubleshooting issuesOur tech stack:Mobile Platforms Supported: iOS & AndroidCross-Platform Mobile Language: React NativeOther Languages: React-js, HTML, CSS, Java (Salesforce Apex), Node.js (Lambda)Systems: Salesforce, AWS Amplify / Cognito / LambdaYour Profile:A minimum of 3+ years of professional experienceBachelor's Degree or equivalent experienceGood interpersonal and relationship skills that include a positive attitudeSelf-starter who can find a way forward even when the path is unclear.Team player AND a leader simultaneously.What You’ll Bring to the Team:Passionate about creating value that changes people's livesMake low-level decisions quickly while being patient and methodical with high-level onesAre curious and passionate about digging into new technologies with a knack for picking them up quicklyAdept at prioritizing value and shipping complex products while coordinating across multiple teamsLove working with a diverse set of engineers, product managers, designers, and business partnersStrive to excel, innovate and take pride in your workWork well with other leadersAre a positive culture driverExcited about working in a fast-paced, startup cultureExperience in a regulated industry (healthcare, finance, etc.) a plusand perks:We’re revolutionizing GI care — and our employees are driving the change. We’re a hard-working and fun-loving team, committed to always learning and improving, and dedicated to doing the right thing for our members. To achieve our mission, we invest in our people:We make healthcare more equitable and accessible:Mission-driven organization focused on innovative digestive careThrive on diversity with monthly DEIB discussions, activities, and moreVirtual-first culture: Work from home anywhere in the USLive our core values: Own the outcome, Do the right thing, Be direct and open, Learn and improve, Team, Thrive on diversity We take care of our people:Competitive compensation and meaningful equityEmployer-sponsored medical, dental and vision plans Access to a “Life Concierge” through Overalls, because we know life happensTailored professional development opportunities to learn and growWe rest, recharge and re-energize:Unlimited paid time off — take what you need, when you need it13 paid company holidays to power downTeam events, such as virtual cooking classes, games, and moreRecognition of professional and personal accomplishmentsOshi Health’s Core Values:Go For ItDo the Right ThingBe Direct & OpenLearn & ImproveTEAM - Together Everyone Achieves MoreOshi Health is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.Powered by JazzHRFRVWJuzRKn\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Systems Planning and Analysis, Inc. (SPA) delivers high-impact, technical solutions to complex national security issues. With over 50 years of business expertise and consistent growth, we are known for continuous innovation for our government customers, in both the US and abroad. Our exceptionally talented team is highly collaborative in spirit and practice, producing Results that Matter. Come work with the best! We offer opportunity, unique challenges, and clear-sighted commitment to the mission. SPA: Objective. Responsive. Trusted.SPA assists the Defense Threat Reduction Agency (DTRA) in developing leading edge technologies to counter WMD in support of CCMDs and transitioning these technologies to services and SOCOM. SPA provides expertise across the full range of chemical, biological, radiological, nuclear and high-yield explosives (CBRNE) WMD, Counter Improvised Threat (CIT) and Countering Threat Network (CTN) technologies to support understanding, detection, identification, characterization, denial, control, disabling, defeating, disposing, safeguarding the force, managing consequences, and test and evaluation in support of military and civilian operations.SPA has a near term need for a Jr. Data Engineer. The qualified candidate will provide Advisory and Assistance Support (A&AS) to the Defense Threat Reduction Agency (DTRA), Chemical and Biological Technologies Department, Digital Battlespace Management Division (RD-CBI). The candidate will provide subject matter expertise and support to the client for science and technology (S&T) projects aimed at developing software tools for Chemical, Biological, Radiological, Nuclear (CBRN) CBRN Support to Command and Control (CSC2) and other chemical and biological defense applications.The work is located in Lorton, VA.Travel is expected (~10%).Minimum QualificationsBachelor's degree in Operations Research, Mathematics, Chemical Sciences, or Biological Sciences with 2 to 5 years of experience.Building scalable and dependable Cloud-based and hybrid data solutions by leverage data models, process maps, ETL and data integration processes.Using Python, Java, or Scala Development to meet data quality and data management needs.Using both relational and NOSQL paradigms for data centric solutions.The design and development of data pipelines, enterprise data warehouse, such as Hadoop/Spark in a complex ecosystem.Active DoD Secret Clearance and the ability to maintain throughout time of employment.Preferred QualificationsExperience advising on all phases of the data science problem life-cycle, including use-case identification and formulation, stakeholder communication and management, and placing models into production.Experience advising / advocating for compute architecture decisions, including tools required for projects, ETL pipelines, and data storage and engineering topics as they influence data science activities.Master’s degree in Operations Research, Mathematics, Chemical Sciences, or Biological Sciences.Proven experience analyzing data to produce reports and recommendations on improving processes efficiency for US Military Projects.Knowledge of and/or experience with DTRA or Chemical/Biological Defense Program.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'To support internal and external clients via processing and handling of data. To generate data solutions for ongoing immediate day to day business needs.Essential FunctionsDay to day functions include the following:Design data models and develop database structures in Microsoft SQL server.Write various database objects like stored procedures, functions, views, triggers for various front end applications.Write SQL scripts, create SQL agent jobs to automate tasks like data importing, exporting, cleansing tasks.Create database deployment packages for deploying changes.Identify & repair inconsistencies in data, database tuning, query optimization.Able to generate ad hoc data on demand.Able to identify best practices, documentation, communicate all aspects of projects in a clear, concise mannerDevelop simple SSIS packages to perform various ETL functions including data cleansing, manipulating, importing, exporting.Develop & maintain client facing reports by using various data manipulation techniques in SSRS and Visual Studio.DocumentationOptimization recommendationsDay to day troubleshooting.NET Programming as neededEducation/ExperienceBA, BS, or Masters in computer science/related field preferred or an equivalent combination of education and experience derived from at least 2 years of professional work experienceSolid experience with various versions of MS SQL Server and TSQL programmingMicrosoft Certified DBA a plusSkills/KnowledgeStrong experience in writing efficient SQL codeWorking knowledge of SQL Server Management Studio (SSMS)Knowledge of SQL Server Reporting Services (SSRS)Knowledge of SQL Server Integration Services (SSIS)Knowledge of Red Gate DBA Tool Belt (SQL Compare, SQL Data Compare, SQL Source Control) a plusKnowledge of data science technologies is a plusClear, concise communication skills, excellent organizational skillsHighly self-motivated and directedKeen attention to detailHigh level of work intensity in a team environmentHigh integrity and values-drivenEager for professional developmentExperience and understanding of source control management a plusWhat We OfferAt Bloom, we offer an engaging, supportive work environment, great benefits, and the opportunity to build the career you always wanted. Benefits of working for Bloom include:Competitive compensation Comprehensive health benefits Long-term career growth and mentoring About BloomAs an insurance services company licensed in 48 contiguous U.S. states, Bloom focuses on enabling health plans to increase membership and improve the enrollee experience while reducing costs. We concentrate on two areas of service: technology services and call center services and are committed to ensuring our state-of-the-art software products and services provide greater efficiency and cost savings to clients.Ascend Technology ™Bloom provides advanced sales and enrollment automation technology to the insurance industry through our Ascend ™. Our Ascend™ technology platform focuses on sales automation efficiencies and optimizing the member experience from the first moment a prospect considers a health plan membership.Bloom is proud to be an Equal Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"OverviewPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.What PepsiCo Data Management and Operations does: Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders Increase awareness about available data and democratize access to it across the companyJob DescriptionAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company.As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, onpremise data sources as well as cloud and remote systems.ResponsibilitiesActive contributor to code development in projects and services.Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.Build and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.Responsible for implementing best practices around systems integration, security, performance and data management.Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape.Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.Develop and optimize procedures to “productionalize” data science models.Define and manage SLA’s for data products and processes running in production.Support large-scale experimentation done by data scientists.Prototype new approaches and build solutions at scale.Research in state-of-the-art methodologies.Create documentation for learnings and knowledge transfer.Create and audit reusable packages or libraries.Qualifications4+ years of overall technology experience that includes at least 3+ years of hands-on software development, data engineering, and systems architecture.3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.3+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).2+ years in cloud data engineering experience in Azure.Fluent with Azure cloud services. Azure Certification is a plus.Experience with integration of multi cloud services with on-premises technologies.Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines.Experience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.Experience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.Experience with version control systems like Github and deployment & CI tools.Experience with Azure Data Factory, Azure Databricks and Azure Machine learning tools is a plus.Experience with Statistical/ML techniques is a plus.Experience with building solutions in the retail or in the supply chain space is a plusUnderstanding of metadata management, data lineage, and data glossaries is a plus.Working knowledge of agile development, including DevOps and DataOps concepts. Familiarity with business intelligence tools (such as PowerBI).EducationBA/BS in Computer Science, Math, Physics, or other technical fields.Skills, Abilities, KnowledgeExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.Proven track record of leading, mentoring data teams.Strong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.Ability to understand and translate business requirements into data and technical requirements. High degree of organization and ability to manage multiple, competing projects and priorities simultaneously.Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment.Strong leadership, organizational and interpersonal skills; comfortable managing trade-offs.Foster a team culture of accountability, communication, and self-management.Proactively drives impact and engagement while bringing others along.Consistently attain/exceed individual and team goals.Ability to lead others without direct authority in a matrixed environment.CompetenciesHighly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.Understands both the engineering and business side of the Data Products released.Places the user in the center of decision making.Teams up and collaborates for speed, agility, and innovation.Experience with and embraces agile methodologies.Strong negotiation and decision-making skill.Experience managing and working with globally distributed teamsCOVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable lawEEO StatementAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender IdentityIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.Please view our Pay Transparency Statement\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Location:Bedford, MA; HybridThis Role:As a Data Engineer at LogixHealth, you will work with a globally distributed team of engineers to design, build and maintain cutting edge solutions that will directly improve the healthcare industry. You’ll contribute to our fast-paced, collaborative environment and will bring your expertise to continue delivering innovative technology solutions. The ideal candidate will be able to develop large scale, distributed data pipelines with an eye towards data security, availability and quality. The candidate should be experienced with modern data storage & transmission techniques, big data tools and distributed processes. The candidate should have excellent interpersonal communication and an aptitude to continue learning.Key Responsibilities:Design highly scalable, available and fault tolerant data processing systemsBuild out data quality proceduresCollaborate with other engineers on existing software and data integration solutionsKeep up with the latest technology industry trends and innovations Help other team members learn and adopt new technologies and practicesQuickly learn new and existing technologiesQualifications:To perform this job successfully, an individual must be able to perform each Key Responsibility satisfactorily. The following requirements are representative of the knowledge, skills, and/or ability required to perform this job successfully. Reasonable accommodation may be made to enable individuals with disabilities to perform the duties. Required:BS/MS in Computer Science, related technical field or equivalent experienceStrong programming and scripting skillsData modeling and data warehousing/lakesREST API servicesExpertise in data storage systems, including SQL & NoSQL database systems & file object storageAdvanced SQL and query performance tuning skillsUnderstanding of cloud computing technologies & platformsExperience with gitExcellent interpersonal communication skillsPreferred:Big data analysis techniquesBig data visualization solutionsDistributed systems design Healthcare industry knowledgeBenefits at LogixHealth:We offer a comprehensive benefits package including health, dental and vision, 401(k), PTO, paid holidays, life and disability insurance, on-site fitness center and company-wide social events.About LogixHealth:At LogixHealth we provide expert coding and billing services that allow physicians to focus on providing great clinical care. LogixHealth was founded in the 1990s by physicians to service their own practices and has grown to become the nation’s leading provider of unsurpassed software-enabled revenue cycle management services, offering a complete range of solutions, including coding and claims management and the latest business intelligence reporting dashboards for clients in 40 states.Since our first day, we have had a clear vision of a better healthcare system and have continually evolved to get there. In addition to providing expert revenue cycle services, we utilize proprietary software to provide valuable financial, clinical, and other data insights that directly improve the quality and efficiency of patient care.At LogixHealth, we’re committed to Making intelligence matter through our pillars of Physician-Inspired Knowledge, Unrivaled Technology and Impeccable Service.To learn more about us, visit our website https://www.logixhealth.com/.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAt Johnson & Johnson, we use technology and the power of teamwork to discover new ways to prevent and overcome the world’s the most significant healthcare challenges. Our Corporate, Consumer Health, Medical Devices, and Pharmaceutical teams leverage data, real-world insights, and creative minds to make life-changing healthcare products and medicines. We're disrupting outdated healthcare ecosystems and infusing them with transformative ideas to help people thrive throughout every stage of their lives. With a reach of more than a billion people every day, there’s no limit to the impact you can make here. Are you ready to reimagine healthcare?Here, your career breakthroughs will change the future of health, in all the best ways. And you’ll change, too. You’ll be inspired, and you’ll inspire people across the world to change how they care for themselves and those they love. Amplify your impact. Join us! Tasked with transforming data into a format that can be easily consumes by ML algorithms. Adept Database basics SQL, capable of basic data engineering techniques – data wrangling, data cleansing, data curation. Fluent in one of the programming languages R or Python.  Data Engineering skills, e.g., cleaning/organizing data, data preparation, data collection, data integration across different data sources, data storage, relational/non-relational database management.  Proficient in structured query language (SQL), NoSQL, MATLAB, and programming in Python or R.  Proficient in Applied Machine Learning – Experience with a variety of algorithms, Building Predictive Models, Cross-validating, Hypertuning and Deployment.  Experience with devising and implementing ML methods for protein or antibody modeling or design, or with deep learning methods that relate protein sequence, structure, property or function.  MD simulation software (e.g., Commercial tools like Schrodinger, or open-source software AMBER, GROMACS, etc.). Additionally, prior experience in homology modeling and structural refinement  Knowledgeable of AWS services including Redshift, RDS, EMR and EC2  Working knowledge using software and tools including big data tools like Kafka, Spark and Hadoop. At Johnson & Johnson, we’re on a mission to change the trajectory of health for humanity. That starts by creating the world’s healthiest workforce. Through cutting-edge programs and policies, we empower the physical, mental, emotional and financial health of our employees and the ones they love. As such, candidates offered employment must show proof of COVID-19 vaccination or secure an approved accommodation prior to the commencement of employment to support the well-being of our employees, their families and the communities in which we live and work.Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Primary LocationNA-US-Pennsylvania-Spring HouseOrganizationJanssen Research & Development, LLC (6084)Job FunctionAdministration\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Data Engineer (Mid/Jr Level)Pura has been revolutionizing the smart home experience for the past several years. We obsess over providing world-class experiences for our customers, partners, and vendors. We pride ourselves on maintaining a high standard of quality and innovation with our products, and continuous growth and development for our people.We are looking for a Data Engineer to help business users and analysts throughout the organization access the data they need to operate and grow the business.What you’ll own:In this high-impact role, you will:Work closely with the Data Science team to design and develop scalable data pipelines for processing and analyzing large volumes of dataBuild and maintain ETL processes using Python, SQL, Apache Airflow, and other technologiesDevelop and deploy data processing jobs on AWS or GCP using Docker and KubernetesWrite API wrappers to integrate with various external data sources and third-party toolsImplement and maintain best practices for data security, data quality, and data governanceCollaborate with other cross-functional teams to ensure data is available, reliable, and accessible to support business decisionsWrite clean, readable, and maintainable code and ensure code is thoroughly tested and documentedQualifications:Bachelor's degree in Computer Science, Software Engineering, or related field1-3 years of experience in data engineering or a related fieldProficiency in Python, SQL, Apache Airflow, and DockerExperience with AWS or GCP and some Kubernetes experienceStrong analytical and problem-solving skillsExcellent communication and collaboration skillsAbility to work independently and as part of a teamPassion for writing clean, readable code and ensuring code qualityIf you are passionate about data engineering and want to join a fast-paced, dynamic team that is making a real impact, we encourage you to apply today!.Pura’s StoryAt Pura, we’re pairing smart tech with premium fragrance to create a perfectly personalized and customized scenting experience for the individual. We partner with brands like Disney, Capri Blue, and Anthropologie to bring original and well-loved fragrances to homes in a modern, convenient, and safe way. We know we’ve only just begun to unlock the possibility of scent, and we’re excited for the opportunities that lie ahead.We’re quickly turning heads and getting noticed. We raised a seed round of 4.4M in February of 2020, was recognized by Inc. Magazine as a 2021 Best Workplace, won the Silicon Slopes Hall of Fame & Awards Advertising category in 2022, and we’re currently the 6th-fastest growing company in Utah. Check out our Instagram @pura and TikTok @trypura channels for a look into the excited, engaged community we’re building. We pride ourselves on being a human brand and in creating a culture worth talking about, and we have big goals for the future.Join the Pura Team!All candidates are subject to a background check.Pura provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.Powered by JazzHRPSRu221guI\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Attune is making it easier, faster, and more reliable for small businesses to access insurance (think, pizza place down the street or main street store). They all need insurance to protect their businesses, but when it comes time to get a policy, they're bogged down by hundreds of questions, lots of paperwork, and a seemingly never-ending timeline stretching for weeks or months.We are changing all that. By using data and technology expertise to understand risk, automating legacy processes, and creating a better user experience for brokers, we're able to provide policies that are more applicable and more transparent in just minutes.Simply put, we're pushing insurance into the future, focusing on accuracy, speed, and ease.Our mission and our team are growing. In staying true to our values, we've earned our spot on many workplace award lists. Attune is dedicated to creating a diverse team of curious, focused, and motivated people who are excited about changing the future of an entire industry.Job DescriptionAs a Data Engineer joining our growing Data team, you will help maintain our existing data pipelines and internal web applications. You will also work with team members across the organization to develop and test new pipelines as we launch new products and integrate with third-party data sources. We work with various tools including Python/Pandas, Postgresql, Bash, AWS EC2, and S3. We are always open to using whatever tool is best for the job.Responsibilities:Maintain and improve batch ETL jobs - including SQL query optimization, bug fixes and code improvementsWork with our data engineers, BI, and other teams across the business to develop/refine ETL processesUnderstand and answer questions on the data our team maintainsQualifications:3+ years experience in analytics, data science, or data engineering roleStrong Python and Postgresql skillsSolid understanding of relational database design and basic query optimization techniquesExperience working with git, and Gitlab or GithubNice to have:Experience with Linux CLI, shell programmingUnderstanding of CI/CDExperience with AWS EC2 and S3What we offer you:140-170k per yearUnlimited PTOGenerous parental and caregiver leave401K matchExcellent medical, dental, and vision plansRemote-first cultureAnd more!\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"OverviewMailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multichannel campaigns, CRM, and analytics tools.The Data Platform team at Mailchimp is responsible for creating and managing our BI platform that enables peeps from across the company to make better decisions with data. What that actually looks like is working with folks from across the company to understand their needs and then surface data in a meaningful way, across tools and teams, to help them drive the business forward. Day to day you could be building an ETL pipeline, designing a data access tool, modeling out new data in Looker, or working with teams to develop better data governance practices. We have a lot of tools in our toolbelt, but all with the main goal helping Mailchimp to continue to use data more effectively.Intuit Mailchimp is a hybrid workplace , giving employees the opportunity to collaborate in person with team members in our Atlanta and Brooklyn offices two or more days per week.What You'll BringExperience with Python, Java, Go, or another OOP languageExperience with SQL and data analysis skillsExperience with data transformation tools like dbt or DataformExperience in visualization technologies like Looker, Tableau, or Qlik SenseExperience with Airflow or other ETL orchestration toolsSolid business intuition and ability to understand and work with cross-functional partnersExperience with GCP/AWS or other cloud providers is preferredBachelors degree is Computer Science or equivalent experience Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Mailchimp we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.How You Will LeadPartner with analysts, data scientists, business users, and other engineers to understand their needs and come up with data solutionsHelp build robust transformation pipelines to help clean up, normalize, and govern our data for broad consumptionHelp build scalable transformation pipelines that enables teams to easily clean up, normalize, and govern data for broad consumptionBuild tools and processes to help make the right data accessible to the right peopleModel data in Looker, to provide a collaborative data analytics platform for the companyWork with Data Stewards to better document our data\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Well known NY based Non-Profit seeks a Data Engineer.An ideal candidate will have strong data engineering skills with both SQL and Python.This position can be based out of NYC or be 100% remote.Compensation includes salary, excellent medical, dental, vision benefits, pto, 401k, a quality of life oriented work life balance, and lots of other benefits.ResponsibilitiesThis position will work within the enterprise data engineering team to continuously build, maintain, and improve the design, performance, reliability, scalability, security, and architecture of enterprise data products.Responsibilities include:Develop robust database solutions, data integration (ETL, ELT) packages, automation, performance monitoring, SQL coding, database tuning and optimizations, security management, capacity planning, database HA, and database DR solutions across required data platforms.Conduct in-depth data analysis to support data product design.Identify and resolve production database and data integration issues.Collaborates closely with data quality, application, and visualization teams to deliver high-quality data products.Participate in code review, QA, release, and continuous deployment processes.Qualifications:Bachelors Degree in Computer Science or other quantitative disciplines such as Science, Statistics, Economics or Mathematics.5+ years of progressive database development experience with the Microsoft SQL Server family suite.Experience with data modeling and data architecture principles for both analytics and transactional systems.Hands-on experience with SQL Server, Oracle, or other RDBMS required.Python ScriptingExperience with Cloud Data PlatformsPreferred Experience:Scripting experience in Powershell, C#, Java, and/or R.Experience in the Microsoft Azure technology stack is a plus.Experience with data analytics and visualization is a plus.Preferred Knowledge:Intermediate knowledge of OLTP and OLAP database designIntermediate knowledge of data modeling (normalized and dimensional)Intermediate knowledge of ETL, ELT architecture especially for real and near-real-time scenariosIntermediate knowledge of Data Architecture implementation patternsAnticipated salary for candidates living in the NY Metro market in the 140,000 to 160,000 range.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Laguna Games is the developer of Crypto Unicorns, the #1 NFT project on Polygon, and now one of the fastest-growing games. We are looking to hire an experienced Data Engineer to join our team. You are self-motivated, goal-orientated, and a strong team player. As a Data Engineer, you will be responsible for designing, building, and maintaining the data infrastructure that supports our gaming platform. You will work closely with our product, engineering, and data science teams to collect, process, and analyze large amounts of data generated by our gaming platform to inform our business decisions and improve user experience. You will work and innovate at the forefront of web3 gaming, bringing together unique technologies to deliver a new gaming experience.As a Data Engineer at our Web3 Gaming Startup, Key Responsibilities:Develop and maintain the data pipeline that ingests, processes and stores large amounts of data generated by our gaming platformDesign and build scalable data solutions that support the real-time analytics and reporting needs of the businessCollaborate with the product, engineering and data science teams to identify and implement data-driven solutions to improve user engagement, retention and monetizationBuild and maintain data models, data warehouses and data marts to support business intelligence and reporting needsEnsure data quality, integrity and security across all data sources and systemsMonitor and optimize data performance and scalability, and identify and resolve any data-related issues and bottlenecksKeep up-to-date with the latest trends, tools and technologies in data engineering and apply them to improve our data infrastructureQualificationsBachelor's degree in Computer Science, Computer Engineering, or related field3+ years of experience in data engineering or related fieldExperience with big data technologies such as Hadoop, Spark, Kafka, and ElasticsearchStrong proficiency in SQL, Python and/or Java programming languagesExperience with cloud-based data solutions such as AWS, Azure or Google CloudFamiliarity with data modeling, ETL/ELT processes, data warehousing, and business intelligence toolsUnderstanding of blockchain technology and its use in gaming platforms is a plusExcellent communication skills, both written and verbal, and ability to collaborate with cross-functional teamsIf you are passionate about data engineering and excited about the opportunity to work in a fast-paced and dynamic startup environment, we would love to hear from you!Laguna Games is the developer of Crypto Unicorns, a new blockchain-based game centered around awesomely unique Unicorn NFTs that players use in a fun farming simulation and in a variety of exciting battle loops. As game developers, we are excited to move away from the extractive nature of Free-2-Play to foster and nurture community-run game economies. Crypto Unicorns is our first digital nation and we are extremely excited to build it in tandem with our player community!We are headquartered in San Francisco, CA but operate as a remote company with locations around the world. We offer competitive compensation along with health benefits (medical, dental, and vision), 401k retirement savings, open paid time off, and a remote work support stipend.Learn more here!https://laguna.gameshttps://www.cryptounicorns.fun\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Follow us on Linkedin: https://www.linkedin.com/company/pulivarthigroup/Pulivarthi Group LLC is a Global Staffing & IT Technology Solutions company, with our prime focus of providing world class solutions to our customers with the right talent. We combine the expertise of our team and the culture of your company to help you with the solution that is affordable and innovative using high quality standards and technologies.We’ve served some of the largest healthcare, financial services, and government entities in the U.S.Follow us on Linkedin: https://www.linkedin.com/company/pulivarthigroup/Data Engineer - Experience in data engineering and building applications; Experience in Python/PySpark; Experience in Typescript (Preferred) or JavascriptExperience in building applications or dashboards using no- and low-code tools.Coding Skills: Python complete language proficiency; SQL proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints);PySpark basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas);Typescript experience in TypeScript or Javascript;Application building working with no- and low-code tools to query databases, define variables, filters, cross-filters, responsive front-end and user based applications.Databases familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.; Git knowledge of version control / collaboration workflows and best practices; Agile familiarity with agile and iterative working methodology and rapid user feedback gathering concepts; UX design knowledge of best practices and applications; Data literacy data analysis and statistical basics to ensure correctness in data aggregation and visualization.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Applicants must be authorized to work for any employer in the United States. We are unable to sponsor, or take over sponsorship, of an employment visa at this time.About the roleReporting to the SVP, Data & Technology and Lead Data Engineer, the Data Engineer will play a critical role in supporting and advancing Geopath’s new audience measurement platform.Responsibilities:Build scalable functions, fault tolerant batch & real time data pipelines to validate/extract/transform/integrate large scale datasets inclusive of location and time series data, across multiple platformsReview current data processes to identify improvement areas: design and implement solutions to improve scalability, performance, cost efficiencies and data qualityExtend and optimize Geopath’s data platform, which spans across multiple cloud services, data warehouses, and applications in order to meet the industry’s evolving data needsResearch, evaluate, analyze and integrate new data sources and develop quick prototypes for new data productsWork closely with product owners, data architects, data scientists and application development teams to quickly define prototypes, and build new data productsDevelop a solid understanding of the nuances within Geopath’s foundational data sourcesSupport internal stakeholders including data, design, product and executive teams by assisting them with data-related technical issuesRequirements:Bachelor’s or master's degree in computer science, computer engineering, informatics, or equivalent fields3+ years of experience as a Data Engineer with demonstrated experience in data modeling, ETL, data warehouse/data lakes, and consolidating data from multiple data sources3+ years of experience with SQL, solid experience in writing stored procedures and UDFs, familiarity with Snowflake’s data warehouse a plus2+ years of experience in building and optimizing scalable and robust big data pipelines in Apache Airflow or other workflow engines and fluent in Python or Java programmingGood working knowledge in data partition and query optimizationExperience or desire to work in a start-up environment, good team player, and can work independently with minimal supervisionGreat analytical and problem-solving skills, eager to learn new technologies and willing to wear different hats in a small team settingGreat communication and organizational skillsExpected salary for this role is between $75,000-$140,000 per year, depending on experience.About Geopath Inc.Established in 1933, Geopath, (previously the Traffic Audit Bureau for Media Measurement Inc.,) has been the gold standard in providing media auditing and audience measurement services for the Out of Home industry in the US for 90 years. Geopath has now expanded its historical mission and is looking to the future by modernizing its mission critical, industry-standard media audience rating platform while embracing the digital era. In addition to being the industry’s media auditing solution, Geopath also analyzes people’s movement data, develops deep consumer insights, innovations and advanced media research methodologies to uncover critical insights about how consumers engage with Out of Home advertising across a multi-channel ecosystem and in the physical world.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We are currently hiring a Senior Data Platform Engineer to help grow our company and ensure our mission is achieved!This role is a work from home position and can be performed remotely anywhere in the continental US or in one of our corporate locations in Utah or Arizona.WE ARE: Our Data Platforms embodies the modernity and transformational vision that is core to our business evolution. As passionate and hungry technical experts, we progress through technology. We take pride in our engineering, daily progress, and bringing others along as we improve. We experiment, fail fast, and drive to delivery.YOU ARE: A self-starter mindset to proactively take ownership and execute work without daily oversight and excited to develop your data administration & data DevOps skills. We have a great team of engineers building next-generation data platforms. You are motivated by challenges and thrive with continuous innovation.YOUR DAY-TO-DAY:Coach and develop fellow team membersWorking in an agile-scrum development environmentWork with engineers and leaders to promote a shared vision of our data platform & architectureTrack operating metrics for our data platforms, driving improvements and making trade-offs among competing constraints. We use MS SQL Server, AWS RDS (Postgres, MariaDB) MongoDB, DynamoDB, Redis, Rabbit MQ, AWS managed messaging/eventing systems (Kafka, Kinesis, SQS, SNS) to name a few of our platformsBe a strategic player in designing enterprise-wide data infrastructureBuilds robust systems with an eye on the long-term maintenance and support of the applicationDiscover automation opportunities to replace manual processes using PowerShell, Terraform, Python etcBuild out frameworks for data administration /data deployment /monitoring where neededLeverage reusable code modules to solve problems across the team and organizationCreate and maintain automated pipelines to deploy changes via Octopus, CircleCI, Azure DevOps and JenkinsProactive and reactive performance analysis, monitoring, troubleshooting and resolution of escalated issuesParticipate in the team on-call rotationsYOU’LL BRING:Used multiple data platforms and can define which is optimal for a given scenario (such as document databases, RDBMS, caching, eventing, etc. On-prem or cloud)An engineering mindset when developing a solution using PowerShell / Python or SQL. In depth knowledge and use of tools such as dbatools and other modules is a plusUnderstand how to fully automate systems using infrastructure/configuration as code technologies (we use Terraform, CloudFormation, Ansible, SaltStack)Experience working with CI/CD pipeline and tools preferably Octopus, CircleCI, AzureDevOps and JenkinsProven ability to mentor and coach engineersThrive on a high level of autonomy and responsibility, while having the ability to dig into technical details to inform decisionsAdvanced Sql Server Knowledge and experience in performance analysis and tuning skills such as tracing and profiling and Dynamic Management Views and Functions (DMVs) and other third-party tools like SentryOne to ensure high levels of performance, availability, and securityKnowledge of database deployment using DACPAC via pipelinesExperience with enterprise features of SQL Server: AlwaysOn Availability Groups, clustering, Disaster RecoveryContribute to the management and reliability of database HA/DR processesYOU MIGHT ALSO HAVE:Ability to clearly articulate complex subjects to leadership and others not familiar with this spaceExperience with code-based data developmentA self-starter mindset to proactively take ownership and execute work without daily oversightExperience in AWS cloud-based solutionsWE OFFER: Competitive Compensation; Eligible for STI + LTIFull Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental LeaveCompany Matched 401kPaid Time Off + Paid Holidays + Paid Volunteer HoursEmployee Resource Groups (Black Inclusion Group, Women in Leadership, PRIDE, Adelante)Employee Stock Purchase ProgramTuition ReimbursementCharitable Gift MatchingJob required equipment and services\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our team relies on clean datasets accessible via the latest tools to answer questions that are often not simple or clear. You will be creating solutions that will help derive value from our rich datasets that will solve tough problems impacting consumers across geographies & industries (healthcare, retail/ consumer, telecom, industrial) driving technology transformation. At the core of our team, we believe data is best used to create transparency & generate communal value.  What You’ll Do: · Design, Build & ImplementDesign & build batch, event driven and real-time data pipelines using some of the latest technologies available on Microsoft Azure, Google Cloud Platform and AWSImplement large-scale data platforms to meet the analytical & operational needs across various organizationsBuild products & frameworks that can be re-used across different use-cases in increase efficiency in coding and agility in implementation of solutionsBuild streaming ingestion processes to efficiently read, process, analyze & publish data for real-time need of applications and data science modelsPerform analyses of large structured and unstructured data to solve multiple & complex business problemsInvestigate and prototype different task dependency frameworks to understand the most appropriate design for a given use case to assess & advise Understand business use cases to design engineering routines to affect the outcomesReview & assess data frameworks & technology platforms with the goal of suggesting & implementing improvements on the existing frameworks & platforms.Understand quality of data used in existing use cases to suggest process improvements & implement data quality routines   Who You Are : An Engineer interested in working in batch, event driven and streaming processing environments A tech-enthusiast excited to work with Cloud Based Technologies like GCP, Azure & AWSA data parser expert who gets excited about structuring and re-structuring datasets programmatically A doer who loves to produce meaningful analytic insights for an innovative, data-intensive productsAlways curious about analytics frameworks and you are well-versed in the advantages and limitations of various big data architectures and technologiesTechnologist who loves studying software platforms with an eye towards modernizing the architectureBeliever in transparency, communication, and teamworkLove to learn and not afraid to take ownershipNexus Staffing is committed to diversity, inclusion, and equal opportunity. We take affirmative steps to ensure that all programs and services are open to all Americans, free of discrimination based on protected class status, including race, religion/creed, color, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, national origin (including limited English proficiency), age, political affiliation or belief, military or veteran status, disability, predisposing genetic characteristics, marital or family status, domestic violence victim status, arrest record or criminal conviction history, or any other impermissible basis.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"At Ford Motor Company, we believe freedom of movement drives human progress. We also believe in providing you with the freedom to define and realize your dreams. With our incredible plans for the future of mobility, we have a wide variety of opportunities for you to accelerate your career potential as you help us define tomorrow's transportation.Ford Motor Company is proud to be an Emerald sponsor of the Grace Hopper Conference, and we are excited to be a part of this event. Whether you are in person in Orlando, or attending virtually, we would love to hear from you!As a Cloud Data Engineer, you will leverage your technical expertise in data, analytics, cloud technologies, and analytic software tools to identify best designs, improve business processes, and generate measurable business outcomes.What You'll Be Able To Do Develop EL/ELT/ETL pipelines to make data available in BigQuery analytical data store from disparate batch, streaming data sources for the Business Intelligence and Analytics teams  Work with on-prem data sources (Hadoop, SQL Server), understand the data model, business rules behind the data and build data pipelines (with GCP, Informatica) for one or more Ford verticals. This data will be landed in GCP BigQuery.  Build cloud-native services and APIs to support and expose data-driven solutions.  Partner closely with our data scientists to ensure the right data is made available in a timely manner to deliver compelling and insightful solutions.  Design, build and launch shared data services to be leveraged by the internal and external partner developer community.  Building out scalable data pipelines and choosing the right tools for the right job. Manage, optimize and monitor data pipelines.  Provide extensive technical, strategic advice and guidance to key stakeholders around data transformation efforts. Understand how data is useful to the enterprise. The Minimum Requirements We Seek Bachelor's Degree in Computer Science, Electrical Engineering or a related field, or a combination of education or equivalent experience.  2+ years of experience with SQL and Python  2+ years of experience with GCP or AWS cloud services; Strong candidates with 5+ years in a traditional data warehouse environment (ETL pipelines with Informatica) will be considered  2+ years of experience building out data pipelines from scratch in a highly distributed and fault-tolerant manner. Our Preferred Qualifications Master's degree in Computer Engineering, Computer Science, or a related field of study.  Experience with GCP cloud services including BigQuery, Cloud Composer, Dataflow, CloudSQL, GCS, Cloud Functions and Pub/Sub.  Inquisitive, proactive, and interested in learning new tools and techniques.  Familiarity with big data and machine learning tools and platforms. Comfortable with open-source technologies including Apache Spark, Hadoop, Kafka.  1+ year experience with Hive, Spark, Scala, JavaScript.  Strong oral, written and interpersonal communication skills  Comfortable working in a dynamic environment where problems are not always well-defined. What you will receive in return: As part of the Ford family, you will enjoy excellent compensation and a comprehensive benefits package that includes generous PTO, retirement, savings and stock investment plans, incentive compensation, and much more. You will also experience exciting opportunities for professional and personal growth and recognition. If you have what it takes to help us redefine the future of mobility, we would love to have you join us. Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire. Visa sponsorship is available for this position.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2022-benefits-and-comp-GSR-sal-plan-2.pdfAt Ford, the health and safety of our employees is our top priority. Vaccination has been proven to play a critical role in combating COVID-19. As a result, Ford has made the decision to require U.S. salaried employees to be fully vaccinated against COVID-19, unless employees require an accommodation for religious or medical reasons. Being fully vaccinated means that an individual is at least two weeks past their final dose of an authorized COVID-19 vaccine regimen. As a condition of employment, newly hired employees will be required to provide proof of their COVID-19 vaccination or an approved medical or religious exemption.About UsFord Motor Company is about more than making world-class vehicles – at Ford we Go Further to make people’s lives better.We do this in every corner of the globe. Ford is both an automotive and mobility company. Across six continents, our employees produce innovative products in our engineering and design centers, research labs and high-tech assembly plants.And in order to do that, we are looking to attract the top talent like you.Ford is a place where development is valued for all, and employees are encouraged to learn, build skills and continuously improve year-after-year. When you work at Ford, you and your team will Go Further each day to deliver great products, build a strong business and contribute to a better world.The distance between you and an amazing career has never been shorter!\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title: Python Data Engineer.Location:RemoteModule: Phone+SkypeJob Descriptionneed Only USC and GC.Data & Analytics Development Engineer Primary Role Definition: Data & Analytics developers are people who works with ETL (extract data, transform it, and load it) tools like DataStage, Autosys scheduling tools.Skills RequiredVery skilled in Python and DataStage coding and developmentVery skilled in performing Python/Data Stage Code reviewsVery skilled in SQLVery skilled in AutosysVery skilled in Data Modeling with both Oracle and SQL DatabasesDatabase query tuningCloud experience (AWS/GCP) is a plus.Hit ground running, self-starter, great communicator (verbally and written\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"New Opportunity Systems Engineer Greeneville, TN On-site $110-120k plus excellent benefits We are looking for an enthusiastic Systems Engineer to design, develop and install software solutions. The successful candidate will be able to review software applications standards and technical design. Implement new software platforms work with third party vendors. Support and/or install software applications/operating systems. Participate in the testing process through test review and analysis, test witnessing and certification of software. Requires a bachelor's degree in a related area and 2-5years of experience in the field or in a related area. Has knowledge of commonly used concepts, practices, and procedures within a particular field. Rely on instructions and pre-established guidelines to perform the functions of the job. Work as subject manner expert with minimum supervision. Primary job functions will exercise independent judgment when required. Typically reports to a department manager. Responsibilities: * Performance tuning, improvement, balancing, usability, automation * Support, maintain and document software functionality * Integrate new systems with existing systems * Evaluate and identify innovative technologies for implementation * Project planning and Project management * Maintain standards compliance * Implement new software platforms work with third party vendors * Document and demonstrates solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code * Improve operations by conducting systems analysis, recommending changes in policies and procedures * Protect operations by keeping information confidential * Provide information by collecting, analyzing, and summarizing development and service issues * Accomplish engineering and organization mission by completing related results as needed * Develop software/system solutions by studying information needs; conferring with users; studying systems flow, data usage and work processes; investigating problem areas; following the software/system development lifecycle. * Produce specifications and determine operational feasibility * Document and maintain software functionality * Serve as a subject matter expert * Comply with project plans and industry standards * * Requirements: Software Engineer top skills & proficiency: * Proven work experience in software engineering and/or Database Management * Firsthand experience in implementing and maintaining software/system applications * Firsthand experience in Relational Databases, SQL and etc. * Knowledge of ERP Systems * Experience with test-driven development * Ability to document requirements and specifications * Familiarity with software/system development methodology and release processes * Installing and configuring operating systems and application software * BS degree in Computer Science or relevant degree in Information Systems * Proficient in SQL Queries, stored procedures and working with in relational databases like SQL Server, MySQL, and ERP Systems * Analytical & Problem-Solving Skills * Ability to Learn Quickly * Team Player * Project Management * Written and Verbal Communication * Customer-Oriented * Analysis * General Programming Skills * SharePoint, MS Dynamics, HTML, and other related software a PLUS Company Description Each and every day RemX puts over 90,000 people to work, helping more than 15,000 companies find the talent they need in order to succeed. And, as a part of the 10th largest staffing company in the world, we understand that at the heart of every successful business are people. That's why we work hard to find you the right job at the right company. Explore all the exciting opportunities that RemX offers and find the right fit for you!Each and every day RemX puts over 90,000 people to work, helping more than 15,000 companies find the talent they need in order to succeed. And, as a part of the 10th largest staffing company in the world, we understand that at the heart of every successful business are people. That’s why we work hard to find you the right job at the right company. Explore all the exciting opportunities that RemX offers and find the right fit for you!\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company OverviewPrivately owned and operated, Digible was founded in 2017 with a mission to bring sophisticated digital marketing solutions to the multifamily industry. We offer a comprehensive suite of digital services as well as a predictive analytics platform, Fiona, that is the first of its kind.At Digible, Inc. we love to celebrate our diverse group of hardworking employees – and it shows. We pride ourselves on our collaborative, transparent, and authentic culture. These values are pervasive throughout every step of a Digible employee\\'s journey. Starting with our interviews and continuing through our weekly All Hands Transparency Round-up, values are at the heart of working at Digible.We value diversity and believe forming teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds and different industries to apply. Come join us and find out what the best work of your career could look like here at Digible.The RoleDigible, Inc. is looking for an Junior Software Engineer to join our team!We are seeking a highly motivated and detail-oriented Junior Data Engineer to join our growing team. As a Junior Data Engineer, you will be responsible for assisting with the development, implementation, and maintenance of our data infrastructure. You will work closely with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources.Responsibilities:Assist with the design, development, and maintenance of our data infrastructure using Python, Prefect, Snowflake, Google Cloud, and AWS. Collaborate with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources. Develop and maintain ETL pipelines to extract, transform, and load data from various sources into our data warehouse. Assist with the implementation of data security and governance policies. Monitor and troubleshoot data issues as they arise. Continuously seek ways to improve our data infrastructure and processes. Requirements:Bachelor\\'s degree in Computer Science, Data Science, or a related field. Experience with Python, SQL, and data modeling. Familiarity with data warehousing concepts and ETL processes. Experience working with cloud-based platforms such as Google Cloud and AWS. Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Expectations:Ability to learn and adapt quickly to new technologies and processes. Work collaboratively with our Data Engineering team to meet project goals and deadlines. Demonstrate a high level of professionalism and dedication to quality work. Communicate effectively with cross-functional teams to ensure project success. Success Metrics:Deliver high-quality data infrastructure projects on time and within scope. Ensure data accuracy and completeness across all data sources. Maintain a high level of data security and governance. Continuously seek ways to improve our data infrastructure and processes. Collaborate effectively with cross-functional teams to meet project goals and objectives. Core ValuesAuthenticity - The commitment to be steadfast and genuine with our actions and communication toward everyone we touch.Curiosity - The belief that a deep and fundamental curiosity (the \"why\") in our work is vital to company innovation and evolution.Focus - The collective will to remain completely devoted and ultimately accountable to our deliverables.Humility - The recognition and daily practice that \"we\" is always greater than \"I\".Happiness - The decision to prioritize passion and love for what we do above everything else.Perks and such:4-Day Work Week (32 Hour Work Week)WFA (Work From Anywhere)Profit Sharing BonusWe offer 3 weeks of PTO as well as Sick leave, and Bereavement. We offer 10 paid holidays (New Years Eve, New Years Day, MLK day, Memorial Day, Independence Day, Labor Day, Thanksgiving + day after, Christmas Eve, and Christmas)401(k) + Match50% employer paid health benefits, including Medical, Dental, and Vision. We provide $75/ month reimbursement for Physical WellnessWe provide $75/ month reimbursement for Mental Wellness$1000/year travel fund for employees who have been with Digible 3+ yearsMonthly subscription for financial wellnessDog-Friendly OfficePaid Parental LeaveCompany Sponsored Social EventsCompany Provided Lunches, SnacksEmployee Development Program\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Become a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Nike USA, Inc., located in Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into engineering designs and logical units of work. Profile and analyze data for the purpose of designing scalable solutions. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Implement complex automated routines using workflow orchestration tools. Anticipate, identify and tackle issues concerning data management to improve data quality. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks.Applicant must have a Bachelor’s degree in Data Science, Computer Engineering, Computer Science, or Computer Information Systems and five (5) years of progressive post-baccalaureate experience in the job offered or engineering-related occupation. Experience must include the following- Programming ability (Python, SQL);  Database related concept;  Big Data exposure;  Spark;  Airflow (Orchestration tools);  Cloud Solutions;  Software/Data design ability;  CI/CD understanding and implementation;  Code review;  Data Architecture; and  AWS, Azure. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.]]>\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We're looking for a forward-thinking, structured problem solver, and technical specialist passionate about building systems at scale. You will be among the first to tap into massive blockchain datasets, to construct data infrastructure that makes possible analytics, data science, machine learning, and AI workloads.As the data domain specialist, you will partner with a cross-functional team of product engineers, analytics specialists, and machine learning engineers to unify data infrastructure across Yakoa's product suite. Requirements may be vague, but the iterations will be rapid, and you must take thoughtful and calculated risks. Your work will take place at the interface of the AI, blockchain, and intellectual property domains, so you must be a quick learner with a thirst for many types of knowledge.ResponsibilitiesDesign, build, test, and maintain scalable data pipelines and microservices sourcing both first-party and third-party datasets and deploying distributed (cloud) structures and other applicable storage forms such as vector databases and relational databases.Index multiple blockchain data standards into responsive data environments, and tune those environments to power real-time query infrastructure.Design and optimize data storage schemas to make terabytes of data readily accessible to our API.Build utilities, user-defined functions, libraries, and frameworks to better enable data flow patterns.Utilize and advance continuous integration and deployment frameworks.Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing.Mentor other engineers while serving as technical lead, contributing to and directing the execution of complex projects.Requirements4+ years working as a data engineer.Proficient in database schema design, and analytical and operational data modeling.Proven experience working with large datasets and big data ecosystems for computing (spark, Kafka, Hive, or similar), orchestration tools (dagster, airflow, oozie, luigi), and storage(S3, Hadoop, DBFS).Experience with modern databases (PostgreSQL, Redshift, Dynamo DB, Mongo DB, or similar).Proficient in one or more programming languages such as Python, Java, Scala, etc., and rock-solid SQL skills.Experience building CI/CD pipelines with services like Bitbucket Pipelines or GitHub Actions.Proven analytical, communication, and organizational skills and the ability to prioritize multiple tasks at a given time.An open mind to try solutions that may seem astonishing at first.An MS in Computer Science or equivalent experience.Exceptional candidates also have:Experience with Web3 tooling.Experience with artificial intelligence, machine learning, and other big data techniques.B2B software design experience.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.BenefitsUnlimited PTO. Competitive compensation packages. Remote friendly & flexible hours. Wellness packages for mental and physical health.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Applicants must be authorized to work for any employer in the United States. We are unable to sponsor, or take over sponsorship, of an employment visa at this time.About the roleReporting to the SVP, Data & Technology and Lead Data Engineer, the Data Engineer will play a critical role in supporting and advancing Geopath’s new audience measurement platform.Responsibilities:Build scalable functions, fault tolerant batch & real time data pipelines to validate/extract/transform/integrate large scale datasets inclusive of location and time series data, across multiple platformsReview current data processes to identify improvement areas: design and implement solutions to improve scalability, performance, cost efficiencies and data qualityExtend and optimize Geopath’s data platform, which spans across multiple cloud services, data warehouses, and applications in order to meet the industry’s evolving data needsResearch, evaluate, analyze and integrate new data sources and develop quick prototypes for new data productsWork closely with product owners, data architects, data scientists and application development teams to quickly define prototypes, and build new data productsDevelop a solid understanding of the nuances within Geopath’s foundational data sourcesSupport internal stakeholders including data, design, product and executive teams by assisting them with data-related technical issuesRequirements:Bachelor’s or master's degree in computer science, computer engineering, informatics, or equivalent fields3+ years of experience as a Data Engineer with demonstrated experience in data modeling, ETL, data warehouse/data lakes, and consolidating data from multiple data sources3+ years of experience with SQL, solid experience in writing stored procedures and UDFs, familiarity with Snowflake’s data warehouse a plus2+ years of experience in building and optimizing scalable and robust big data pipelines in Apache Airflow or other workflow engines and fluent in Python or Java programmingGood working knowledge in data partition and query optimizationExperience or desire to work in a start-up environment, good team player, and can work independently with minimal supervisionGreat analytical and problem-solving skills, eager to learn new technologies and willing to wear different hats in a small team settingGreat communication and organizational skillsExpected salary for this role is between $75,000-$140,000 per year, depending on experience.About Geopath Inc.Established in 1933, Geopath, (previously the Traffic Audit Bureau for Media Measurement Inc.,) has been the gold standard in providing media auditing and audience measurement services for the Out of Home industry in the US for 90 years. Geopath has now expanded its historical mission and is looking to the future by modernizing its mission critical, industry-standard media audience rating platform while embracing the digital era. In addition to being the industry’s media auditing solution, Geopath also analyzes people’s movement data, develops deep consumer insights, innovations and advanced media research methodologies to uncover critical insights about how consumers engage with Out of Home advertising across a multi-channel ecosystem and in the physical world.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We are currently hiring a Senior Data Platform Engineer to help grow our company and ensure our mission is achieved!This role is a work from home position and can be performed remotely anywhere in the continental US or in one of our corporate locations in Utah or Arizona.WE ARE: Our Data Platforms embodies the modernity and transformational vision that is core to our business evolution. As passionate and hungry technical experts, we progress through technology. We take pride in our engineering, daily progress, and bringing others along as we improve. We experiment, fail fast, and drive to delivery.YOU ARE: A self-starter mindset to proactively take ownership and execute work without daily oversight and excited to develop your data administration & data DevOps skills. We have a great team of engineers building next-generation data platforms. You are motivated by challenges and thrive with continuous innovation.YOUR DAY-TO-DAY:Coach and develop fellow team membersWorking in an agile-scrum development environmentWork with engineers and leaders to promote a shared vision of our data platform & architectureTrack operating metrics for our data platforms, driving improvements and making trade-offs among competing constraints. We use MS SQL Server, AWS RDS (Postgres, MariaDB) MongoDB, DynamoDB, Redis, Rabbit MQ, AWS managed messaging/eventing systems (Kafka, Kinesis, SQS, SNS) to name a few of our platformsBe a strategic player in designing enterprise-wide data infrastructureBuilds robust systems with an eye on the long-term maintenance and support of the applicationDiscover automation opportunities to replace manual processes using PowerShell, Terraform, Python etcBuild out frameworks for data administration /data deployment /monitoring where neededLeverage reusable code modules to solve problems across the team and organizationCreate and maintain automated pipelines to deploy changes via Octopus, CircleCI, Azure DevOps and JenkinsProactive and reactive performance analysis, monitoring, troubleshooting and resolution of escalated issuesParticipate in the team on-call rotationsYOU’LL BRING:Used multiple data platforms and can define which is optimal for a given scenario (such as document databases, RDBMS, caching, eventing, etc. On-prem or cloud)An engineering mindset when developing a solution using PowerShell / Python or SQL. In depth knowledge and use of tools such as dbatools and other modules is a plusUnderstand how to fully automate systems using infrastructure/configuration as code technologies (we use Terraform, CloudFormation, Ansible, SaltStack)Experience working with CI/CD pipeline and tools preferably Octopus, CircleCI, AzureDevOps and JenkinsProven ability to mentor and coach engineersThrive on a high level of autonomy and responsibility, while having the ability to dig into technical details to inform decisionsAdvanced Sql Server Knowledge and experience in performance analysis and tuning skills such as tracing and profiling and Dynamic Management Views and Functions (DMVs) and other third-party tools like SentryOne to ensure high levels of performance, availability, and securityKnowledge of database deployment using DACPAC via pipelinesExperience with enterprise features of SQL Server: AlwaysOn Availability Groups, clustering, Disaster RecoveryContribute to the management and reliability of database HA/DR processesYOU MIGHT ALSO HAVE:Ability to clearly articulate complex subjects to leadership and others not familiar with this spaceExperience with code-based data developmentA self-starter mindset to proactively take ownership and execute work without daily oversightExperience in AWS cloud-based solutionsWE OFFER: Competitive Compensation; Eligible for STI + LTIFull Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental LeaveCompany Matched 401kPaid Time Off + Paid Holidays + Paid Volunteer HoursEmployee Resource Groups (Black Inclusion Group, Women in Leadership, PRIDE, Adelante)Employee Stock Purchase ProgramTuition ReimbursementCharitable Gift MatchingJob required equipment and services\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our team relies on clean datasets accessible via the latest tools to answer questions that are often not simple or clear. You will be creating solutions that will help derive value from our rich datasets that will solve tough problems impacting consumers across geographies & industries (healthcare, retail/ consumer, telecom, industrial) driving technology transformation. At the core of our team, we believe data is best used to create transparency & generate communal value.  What You’ll Do: · Design, Build & ImplementDesign & build batch, event driven and real-time data pipelines using some of the latest technologies available on Microsoft Azure, Google Cloud Platform and AWSImplement large-scale data platforms to meet the analytical & operational needs across various organizationsBuild products & frameworks that can be re-used across different use-cases in increase efficiency in coding and agility in implementation of solutionsBuild streaming ingestion processes to efficiently read, process, analyze & publish data for real-time need of applications and data science modelsPerform analyses of large structured and unstructured data to solve multiple & complex business problemsInvestigate and prototype different task dependency frameworks to understand the most appropriate design for a given use case to assess & advise Understand business use cases to design engineering routines to affect the outcomesReview & assess data frameworks & technology platforms with the goal of suggesting & implementing improvements on the existing frameworks & platforms.Understand quality of data used in existing use cases to suggest process improvements & implement data quality routines   Who You Are : An Engineer interested in working in batch, event driven and streaming processing environments A tech-enthusiast excited to work with Cloud Based Technologies like GCP, Azure & AWSA data parser expert who gets excited about structuring and re-structuring datasets programmatically A doer who loves to produce meaningful analytic insights for an innovative, data-intensive productsAlways curious about analytics frameworks and you are well-versed in the advantages and limitations of various big data architectures and technologiesTechnologist who loves studying software platforms with an eye towards modernizing the architectureBeliever in transparency, communication, and teamworkLove to learn and not afraid to take ownershipNexus Staffing is committed to diversity, inclusion, and equal opportunity. We take affirmative steps to ensure that all programs and services are open to all Americans, free of discrimination based on protected class status, including race, religion/creed, color, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, national origin (including limited English proficiency), age, political affiliation or belief, military or veteran status, disability, predisposing genetic characteristics, marital or family status, domestic violence victim status, arrest record or criminal conviction history, or any other impermissible basis.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Company OverviewPrivately owned and operated, Digible was founded in 2017 with a mission to bring sophisticated digital marketing solutions to the multifamily industry. We offer a comprehensive suite of digital services as well as a predictive analytics platform, Fiona, that is the first of its kind.At Digible, Inc. we love to celebrate our diverse group of hardworking employees – and it shows. We pride ourselves on our collaborative, transparent, and authentic culture. These values are pervasive throughout every step of a Digible employee\\'s journey. Starting with our interviews and continuing through our weekly All Hands Transparency Round-up, values are at the heart of working at Digible.We value diversity and believe forming teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds and different industries to apply. Come join us and find out what the best work of your career could look like here at Digible.The RoleDigible, Inc. is looking for an Junior Software Engineer to join our team!We are seeking a highly motivated and detail-oriented Junior Data Engineer to join our growing team. As a Junior Data Engineer, you will be responsible for assisting with the development, implementation, and maintenance of our data infrastructure. You will work closely with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources.Responsibilities:Assist with the design, development, and maintenance of our data infrastructure using Python, Prefect, Snowflake, Google Cloud, and AWS. Collaborate with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources. Develop and maintain ETL pipelines to extract, transform, and load data from various sources into our data warehouse. Assist with the implementation of data security and governance policies. Monitor and troubleshoot data issues as they arise. Continuously seek ways to improve our data infrastructure and processes. Requirements:Bachelor\\'s degree in Computer Science, Data Science, or a related field. Experience with Python, SQL, and data modeling. Familiarity with data warehousing concepts and ETL processes. Experience working with cloud-based platforms such as Google Cloud and AWS. Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Expectations:Ability to learn and adapt quickly to new technologies and processes. Work collaboratively with our Data Engineering team to meet project goals and deadlines. Demonstrate a high level of professionalism and dedication to quality work. Communicate effectively with cross-functional teams to ensure project success. Success Metrics:Deliver high-quality data infrastructure projects on time and within scope. Ensure data accuracy and completeness across all data sources. Maintain a high level of data security and governance. Continuously seek ways to improve our data infrastructure and processes. Collaborate effectively with cross-functional teams to meet project goals and objectives. Core ValuesAuthenticity - The commitment to be steadfast and genuine with our actions and communication toward everyone we touch.Curiosity - The belief that a deep and fundamental curiosity (the \"why\") in our work is vital to company innovation and evolution.Focus - The collective will to remain completely devoted and ultimately accountable to our deliverables.Humility - The recognition and daily practice that \"we\" is always greater than \"I\".Happiness - The decision to prioritize passion and love for what we do above everything else.Perks and such:4-Day Work Week (32 Hour Work Week)WFA (Work From Anywhere)Profit Sharing BonusWe offer 3 weeks of PTO as well as Sick leave, and Bereavement. We offer 10 paid holidays (New Years Eve, New Years Day, MLK day, Memorial Day, Independence Day, Labor Day, Thanksgiving + day after, Christmas Eve, and Christmas)401(k) + Match50% employer paid health benefits, including Medical, Dental, and Vision. We provide $75/ month reimbursement for Physical WellnessWe provide $75/ month reimbursement for Mental Wellness$1000/year travel fund for employees who have been with Digible 3+ yearsMonthly subscription for financial wellnessDog-Friendly OfficePaid Parental LeaveCompany Sponsored Social EventsCompany Provided Lunches, SnacksEmployee Development Program\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'R-27413Who Are We?Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.Compensation OverviewThe annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.Salary Range$102,600.00 - $169,200.00Target Openings1What Is the Opportunity?Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Personal Insurance Analytics and business intelligence/insights.What Will You Do?Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.Design data solutions.Analyze sources to determine value and recommend data to include in analytical processes.Incorporate core data management competencies including data governance, data security and data quality.Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.Test data movement, transformation code, and data components.Perform other duties as assigned.What Will Our Ideal Candidate Have?Bachelor’s Degree in STEM related field or equivalentSix years of related experienceProficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. Experience with Salesforce and Tealium Product Suite a plus.The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.Strong verbal and written communication skills with the ability to interact with team members and business partners.Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.What is a Must Have?Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.What Is in It for You?Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.Employment PracticesTravelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.Travelers reserves the right to fill this position at a level above or below the level included in this posting.To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role has a preference for a local Austin, TX candidate and will be a hybrid work environment meeting in-person a few times/month. Our client is a fast-growing, Private Equity backed GovTech company that provides SaaS Software solutions to the Public Sector (City / State Local Government) and is looking for a Data Engineer to join their team. Reporting to the Director of Analytics as their first hire, you will be responsible for the ongoing development and management of the data infrastructure of the business and will be providing essential support to internal customers. This pivotal role will be in the Analytics team reporting to Finance and is aimed to drive greater efficiency in data, processes, and tools, ultimately enhancing data-driven decision-making capabilities. For someone with an interest in more of the analytics side of things, this role could also serve as a hybrid Analytics / Dashboarding role as well. This role is great for someone who perhaps hasn't yet chosen a specific specialization or path in the data realm and wants to gain exposure or opportunity in different areas - Whether BI Front End, Business Strategy, Analytics / Dashboarding, or Data Engineering there are a plethora of opportunities to learn and jump in to help the business. One of the major projects you'll be working on is how to collect data on the usage of their underlying SaaS Software products and how to marry that with their CRM data. They have different products that were built at different times so getting to and extracting that data is going to be an especially interesting challenge for this team. ResponsibilitiesDesign, develop, and maintain scalable data pipelines and ETL processes to ingest and process data from various sourcesBuild and optimize the data warehouse in SnowflakeCollaborate with data users to understand requirements and create efficient data models and structures for seamless reporting and analysis using BI tools. Monitor and optimize data pipeline performanceImplement data governance and security best practices, manage user access, and ensure compliance is adhered toContinuously explore and evaluate new data engineering techniques and tools, including AI applications, to improve data processing and exploration capabilities. QualificationsExperience building or using data marts (sql heavy data modeling) and interacting with users that use the data. The ability to find the shortest path to making data available and widely usable. Experience building or extending a Data WarehouseStrong exposure to Data Warehouse patterns and the application of those patternsPrevious experience working with business stakeholdersStrong initiative to start new projects or take existing projects and make them better. Proficiency with Snowflake, Tableau, and Stitch, or similar data warehousing, BI, and ETL tools. Strong knowledge of SQL is required with database design and data modeling experience. Experience with Python or another programming language for data processing. Familiarity with data engineering best practices, including data quality, data governance, and data security. Interest in AI applications for data engineering and data exploration. Excellent problem-solving, communication, and collaboration skills. Extra informationCareer development opportunitiesCompetitive insurance (medical, dental, vision, and voluntary life & disability)Mental health benefits401(k) plan (company matching)Paid holidaysFlexible PTO - no accrualsPaid generous parental leaveBusiness casual environment #ZR\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"As a Data Engineer for our Data Platform Engineering team you will join skilled Scala/ Spark engineers and core database developers responsible for developing hosted cloud analytics infrastructure (Apache Spark-based), distributed SQL processingframeworks, proprietary data science platforms, and core database optimization. This team is responsible for building the automated, intelligent, and highly performant query planner and execution engines, RPC calls between datawarehouse clusters, shared secondary cold storage, etc. This includes building new SQL features and customer-facing functionality, developing novel query optimization techniques for industry-leading performance, and building a databasesystem that's highly parallel, efficient and fault-tolerant. This is a vital role reporting to exec leadership and senior engineering leadershipRequirementsResponsibilities:Writing Scala code with tools like Apache Spark + Apache Arrow + Apache Kafka to build a hosted, multi-cluster data warehouse for Web3Developing database optimizers, query planners, query and data routing mechanisms, cluster-to-cluster communication, and workload management techniques.Scaling up from proof of concept to “cluster scale” (and eventually hundreds of clusters with hundreds of terabytes each), in terms of both infrastructure/architecture and problem structureCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate meta data capturing and managementManaging a team of software engineers writing new code to build a bigger, better, faster, more optimized HTAP database (using Apache Spark, Apache Arrow, Kafka, and a wealth of other open source data tools)Interacting with exec team and senior engineering leadership to define, prioritize, and ensure smooth deployments with other operational componentsHighly engaged with industry trends within analytics domain from a data acquisition processing, engineering, management perspectiveUnderstand data and analytics use cases across Web3 / blockchainsSkills & QualificationsBachelor’s degree in computer science or related technical field. Masters or PhD a plus.6+ years experience engineering software and data platforms / enterprise-scale data warehouses, preferably with knowledge of open source Apache stack (especially Apache Spark, Apache Arrow, Kafka, and others)3+ years experience with Scala and Apache Spark (or Kafka)A track record of recruiting and leading technical teams in a demanding talent marketRock solid engineering fundamentals; query planning, optimizing and distributed data warehouse systems experience is preferred but not requiredNice to have: Knowledge of blockchain indexing, web3 compute paradigms, Proofs and consensus mechanisms... is a strong plus but not requiredExperience with rapid development cycles in a web-based environmentStrong scripting and test automation knowledgeNice to have: Passionate about Web3, blockchain, decentralization, and a base understanding of how data/analytics plays into this\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Data Engineer Qualifications7+ years of experience as a Database Developer3+ years of experience as a hands on Team LeadExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectureStrong data modeling skills (relational, dimensional and flattened)5-7 years of experience with SQL Server On-Prem and/or Azure cloud, required5-7 years of SSIS experience utilizing SQL Agent jobs and Integration Services Catalog, required3-4 years of experience running ETL/ELT SSIS projects independently from end to end, requiredExperience with DevOps Repository and Git, preferredAzure Data Lake storage experience, a plusAzure Data Factory and/or Databricks experience, a plusLocation: Denver, COEmployment Type: Direct HireDuration: Full TimeWork Location: Denver / HybridPay: Based on experienceOther: PTO, Medical, Dental, Vision, Disability, Life, 401k benefits available Thank you in advance for your interest in this opportunity!If you are able to work on a W2 basis without sponsorship for ANY US employer and fit the description above, please apply. Third-Party Applications Not Accepted.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Hi,Hope you are doing well,We at Software Technology Inc. hiring for a Data Engineer/Data Analyst, role, if you are interested and a good fit, feel free to reach me directly at ksuresh@stiorg.com or (609) 998-3431.Role : Data Engineer/Data AnalystLocation : RemoteSkillGCP Big Query, Python, SQL and knowledge of Healthcare domain\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'adQuadrant helps DTC (direct-to-consumer) brands dream bigger. We are a trusted advisor that provides holistic, strategic omni-channel digital marketing solutions by partnering with our clients to solve the biggest challenges in terms of customer acquisition and growth. Our efforts produce tangible results backed by measurable data. We have the strategic capabilities, quantitative chops, deep creative understanding, and world-class talent with the best tools to drive revenue and profits. We are not simply a vendor checking boxes — our seasoned team serves as an extension of the companies we work with, leading strategy and execution. Our goal is to be the go-to marketing consultants for solving the biggest challenges.adQuadrant is looking for a Data Engineer to support a growing team. This role is responsible for developing, testing, and maintaining data pipelines and data architectures. You will be building and optimizing our data pipeline architecture, as well as optimizing data flows and collections for cross functional teams. The ideal candidate will enjoy optimizing data systems and building them from the ground up, you must be ready for a challenge. This role will ensure optimal data delivery architecture is consistent throughout current and ongoing projects. You must be a self-starter and enjoy supporting multiple cross-functional teams.The Ideal Candidate must have: Experience in Snowflake, architecting and building a data warehouse from scratchData pipeline (ETL tools) development and deployment experienceExtensive experience deploying and maintaining a Tableau ServerRequirementsYour Responsibilities: Consulting with the data team to get a strong understanding of the organization’s data storage needsDesigning and constructing the data warehousing system to the organization’s specificationsDefining and implementing scalable data pipelines that ingest data from various external sources, storing it in the database system, and making it useful to our data analystsImplementing processes to monitor data quality, ensuring production data is always accurate and available for data analysts and business processes that rely on itRecognize, troubleshoot, and resolve unexpected performance and process fail issues, on an ongoing basisQualifications:Bachelor’s degree in computer science, information technology, or a related field5+ years experience in data warehousing, data modeling and building data pipelinesExtensive knowledge of SQL, and coding languages, such as PythonProficiency in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDWProven work experience as an ETL developerExperience working with online marketing dataStrong project management skills and experience with Agile engineering practicesAbility to analyze a company’s big-picture data needsClear communication skillsStrategic thought and extreme attention to detailAbility to troubleshoot and solve complex technical problemsComfortable supporting distributed remote individualsBenefitsOur people come first. No jerks. No egos. Just people who like to work hard and enjoy winning as a team.Annual Compensation: $95,000 - $120,000 per yearExcellent Health Benefits (health, dental, vision, and life insurance)401K + company matchUnlimited Vacation PolicyPaid Sick Leave2 Mindfulness Days Annually2PM Fridays each week$300/ year to equip your work space with new equipment$30/ month for home internetAn extremely supportive and fun company cultureWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionSkills (Must Have):Python – Ingestion/manipulation of large datasets to S3 using pandasPython – Consumption of data from REST APIs using requestsAny language (Most preferably Python) – Small automation tasks within AWS S3, Glue, AthenaExperience developing in AWS. Key services: S3, Lambda, Athena, Step Functions, GlueGeneral familiarity with a variety of other systems such as Oracle/Postgres, REST APIs, SplunkDeployment of resources to AWS using ServerlessGeneral understand of Infrastructure as CodeSkills (Nice To Have)AI/Client experience in SagemakerGeneral knowledge of cyber security practices and frameworksExperience writing complex queries in Presto/HadoopDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'The Data Engineer (DE) position requires a creative problem solver who is passionate about client service. This role will work with the Project Manager and Senior Data Engineers to produce timely, best-in-class deliverables. This role specializes in obtaining, reconciling, analyzing, and preparing data for use in performing sales tax consulting engagements with emphasis on preparing audit ready data populations for the Service Delivery teams quickly and efficiently.PeopleDuties and Responsibilities:Creates a positive team member experience.Demonstrates strong written and verbal communication skills, displays a positive demeanor and team spirit.Plays a key role in driving collaboration across team members, other practices and outside entities.ClientAssists senior team members in retrieving data from client systems.Assists clients and Ryan consultants in data analysis and manipulation.Travels to client sites to assist client in gathering additional data and other necessary documentation.Collaborates with remote and local teammates to ensure efficient design and timely completion of deliverables.Assist senior team members in preparing client and project correspondence.ValueAssists in the acquisition, extraction, and transfer of client data.Analyzes data from client accounting systems to verify accuracy and completeness.Develops and deploys data extraction technologies to perform data extractions from client systems.Manipulates data using Microsoft® Access, SQL, and proprietary software.Assists with the installation of data extraction tools such as Ryan eExtract®, for various ERP systems.Analyzes large data at terabyte scale using modern database technologies.Develops code in Java or Python to support ETL process and contribute to existing code bases. Performs other duties as assigned.Education And ExperienceBS or MBA preferred in information systems or computer science. Other STEM degrees with relevant work experience or coursework are considered.1-3 years of full-time work experience is a plus. Client facing or consulting experience is considered a differentiator.Experience with an enterprise or NoSQL database is a plus.Implementation experience with a major ERP system is a plus.Computer SkillsThe candidate must have a strong command of SQL and uses ETL software such as Visual Studio to build and execute SSIS packages for data manipulation, loading, and processing as well as either Java or Python to perform successfully. Ability to work in the Microsoft Office suite is required.Certificates And LicensesValid driver’s license required.Supervisory ResponsibilitiesThe position requires no direct supervisory responsibilities.Work EnvironmentStandard indoor working environment.Occasional long periods of sitting while working at computer.Position requires regular interaction with employees and clients both in person and via e-mail and telephone.Independent travel requirement: 30 to 40%. Compensation For certain California based roles, the base salary hiring range for this position is $72,069 - $88,044For other California based locations, the base salary hiring range for this position is $66,033 - $80,707For Colorado based roles, the base salary hiring range for this position is $63,032 - $77,039For New York based roles, the base salary hiring range for this position is $72,036 - $88,044For Washington based roles, the base salary hiring range for this position is $66,033 - $80,707The Company makes offers based on many factors, including qualifications and experience.Equal Opportunity Employer: disability/veteran\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Well known NY based Non-Profit seeks a Data Engineer.An ideal candidate will have strong data engineering skills with both SQL and Python.This position can be based out of NYC or be 100% remote.Compensation includes salary, excellent medical, dental, vision benefits, pto, 401k, a quality of life oriented work life balance, and lots of other benefits.ResponsibilitiesThis position will work within the enterprise data engineering team to continuously build, maintain, and improve the design, performance, reliability, scalability, security, and architecture of enterprise data products.Responsibilities include:Develop robust database solutions, data integration (ETL, ELT) packages, automation, performance monitoring, SQL coding, database tuning and optimizations, security management, capacity planning, database HA, and database DR solutions across required data platforms.Conduct in-depth data analysis to support data product design.Identify and resolve production database and data integration issues.Collaborates closely with data quality, application, and visualization teams to deliver high-quality data products.Participate in code review, QA, release, and continuous deployment processes.Qualifications:Bachelors Degree in Computer Science or other quantitative disciplines such as Science, Statistics, Economics or Mathematics.5+ years of progressive database development experience with the Microsoft SQL Server family suite.Experience with data modeling and data architecture principles for both analytics and transactional systems.Hands-on experience with SQL Server, Oracle, or other RDBMS required.Python ScriptingExperience with Cloud Data PlatformsPreferred Experience:Scripting experience in Powershell, C#, Java, and/or R.Experience in the Microsoft Azure technology stack is a plus.Experience with data analytics and visualization is a plus.Preferred Knowledge:Intermediate knowledge of OLTP and OLAP database designIntermediate knowledge of data modeling (normalized and dimensional)Intermediate knowledge of ETL, ELT architecture especially for real and near-real-time scenariosIntermediate knowledge of Data Architecture implementation patternsAnticipated salary for candidates living in the NY Metro market in the 140,000 to 160,000 range.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'We are currently hiring a Senior Data Platform Engineer to help grow our company and ensure our mission is achieved!This role is a work from home position and can be performed remotely anywhere in the continental US or in one of our corporate locations in Utah or Arizona.WE ARE: Our Data Platforms embodies the modernity and transformational vision that is core to our business evolution. As passionate and hungry technical experts, we progress through technology. We take pride in our engineering, daily progress, and bringing others along as we improve. We experiment, fail fast, and drive to delivery.YOU ARE: A self-starter mindset to proactively take ownership and execute work without daily oversight and excited to develop your data administration & data DevOps skills. We have a great team of engineers building next-generation data platforms. You are motivated by challenges and thrive with continuous innovation.YOUR DAY-TO-DAY:Coach and develop fellow team membersWorking in an agile-scrum development environmentWork with engineers and leaders to promote a shared vision of our data platform & architectureTrack operating metrics for our data platforms, driving improvements and making trade-offs among competing constraints. We use MS SQL Server, AWS RDS (Postgres, MariaDB) MongoDB, DynamoDB, Redis, Rabbit MQ, AWS managed messaging/eventing systems (Kafka, Kinesis, SQS, SNS) to name a few of our platformsBe a strategic player in designing enterprise-wide data infrastructureBuilds robust systems with an eye on the long-term maintenance and support of the applicationDiscover automation opportunities to replace manual processes using PowerShell, Terraform, Python etcBuild out frameworks for data administration /data deployment /monitoring where neededLeverage reusable code modules to solve problems across the team and organizationCreate and maintain automated pipelines to deploy changes via Octopus, CircleCI, Azure DevOps and JenkinsProactive and reactive performance analysis, monitoring, troubleshooting and resolution of escalated issuesParticipate in the team on-call rotationsYOU’LL BRING:Used multiple data platforms and can define which is optimal for a given scenario (such as document databases, RDBMS, caching, eventing, etc. On-prem or cloud)An engineering mindset when developing a solution using PowerShell / Python or SQL. In depth knowledge and use of tools such as dbatools and other modules is a plusUnderstand how to fully automate systems using infrastructure/configuration as code technologies (we use Terraform, CloudFormation, Ansible, SaltStack)Experience working with CI/CD pipeline and tools preferably Octopus, CircleCI, AzureDevOps and JenkinsProven ability to mentor and coach engineersThrive on a high level of autonomy and responsibility, while having the ability to dig into technical details to inform decisionsAdvanced Sql Server Knowledge and experience in performance analysis and tuning skills such as tracing and profiling and Dynamic Management Views and Functions (DMVs) and other third-party tools like SentryOne to ensure high levels of performance, availability, and securityKnowledge of database deployment using DACPAC via pipelinesExperience with enterprise features of SQL Server: AlwaysOn Availability Groups, clustering, Disaster RecoveryContribute to the management and reliability of database HA/DR processesYOU MIGHT ALSO HAVE:Ability to clearly articulate complex subjects to leadership and others not familiar with this spaceExperience with code-based data developmentA self-starter mindset to proactively take ownership and execute work without daily oversightExperience in AWS cloud-based solutionsWE OFFER: Competitive Compensation; Eligible for STI + LTIFull Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental LeaveCompany Matched 401kPaid Time Off + Paid Holidays + Paid Volunteer HoursEmployee Resource Groups (Black Inclusion Group, Women in Leadership, PRIDE, Adelante)Employee Stock Purchase ProgramTuition ReimbursementCharitable Gift MatchingJob required equipment and services\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Applicants must be authorized to work for any employer in the United States. We are unable to sponsor, or take over sponsorship, of an employment visa at this time.About the roleReporting to the SVP, Data & Technology and Lead Data Engineer, the Data Engineer will play a critical role in supporting and advancing Geopath’s new audience measurement platform.Responsibilities:Build scalable functions, fault tolerant batch & real time data pipelines to validate/extract/transform/integrate large scale datasets inclusive of location and time series data, across multiple platformsReview current data processes to identify improvement areas: design and implement solutions to improve scalability, performance, cost efficiencies and data qualityExtend and optimize Geopath’s data platform, which spans across multiple cloud services, data warehouses, and applications in order to meet the industry’s evolving data needsResearch, evaluate, analyze and integrate new data sources and develop quick prototypes for new data productsWork closely with product owners, data architects, data scientists and application development teams to quickly define prototypes, and build new data productsDevelop a solid understanding of the nuances within Geopath’s foundational data sourcesSupport internal stakeholders including data, design, product and executive teams by assisting them with data-related technical issuesRequirements:Bachelor’s or master's degree in computer science, computer engineering, informatics, or equivalent fields3+ years of experience as a Data Engineer with demonstrated experience in data modeling, ETL, data warehouse/data lakes, and consolidating data from multiple data sources3+ years of experience with SQL, solid experience in writing stored procedures and UDFs, familiarity with Snowflake’s data warehouse a plus2+ years of experience in building and optimizing scalable and robust big data pipelines in Apache Airflow or other workflow engines and fluent in Python or Java programmingGood working knowledge in data partition and query optimizationExperience or desire to work in a start-up environment, good team player, and can work independently with minimal supervisionGreat analytical and problem-solving skills, eager to learn new technologies and willing to wear different hats in a small team settingGreat communication and organizational skillsExpected salary for this role is between $75,000-$140,000 per year, depending on experience.About Geopath Inc.Established in 1933, Geopath, (previously the Traffic Audit Bureau for Media Measurement Inc.,) has been the gold standard in providing media auditing and audience measurement services for the Out of Home industry in the US for 90 years. Geopath has now expanded its historical mission and is looking to the future by modernizing its mission critical, industry-standard media audience rating platform while embracing the digital era. In addition to being the industry’s media auditing solution, Geopath also analyzes people’s movement data, develops deep consumer insights, innovations and advanced media research methodologies to uncover critical insights about how consumers engage with Out of Home advertising across a multi-channel ecosystem and in the physical world.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our team relies on clean datasets accessible via the latest tools to answer questions that are often not simple or clear. You will be creating solutions that will help derive value from our rich datasets that will solve tough problems impacting consumers across geographies & industries (healthcare, retail/ consumer, telecom, industrial) driving technology transformation. At the core of our team, we believe data is best used to create transparency & generate communal value.  What You’ll Do: · Design, Build & ImplementDesign & build batch, event driven and real-time data pipelines using some of the latest technologies available on Microsoft Azure, Google Cloud Platform and AWSImplement large-scale data platforms to meet the analytical & operational needs across various organizationsBuild products & frameworks that can be re-used across different use-cases in increase efficiency in coding and agility in implementation of solutionsBuild streaming ingestion processes to efficiently read, process, analyze & publish data for real-time need of applications and data science modelsPerform analyses of large structured and unstructured data to solve multiple & complex business problemsInvestigate and prototype different task dependency frameworks to understand the most appropriate design for a given use case to assess & advise Understand business use cases to design engineering routines to affect the outcomesReview & assess data frameworks & technology platforms with the goal of suggesting & implementing improvements on the existing frameworks & platforms.Understand quality of data used in existing use cases to suggest process improvements & implement data quality routines   Who You Are : An Engineer interested in working in batch, event driven and streaming processing environments A tech-enthusiast excited to work with Cloud Based Technologies like GCP, Azure & AWSA data parser expert who gets excited about structuring and re-structuring datasets programmatically A doer who loves to produce meaningful analytic insights for an innovative, data-intensive productsAlways curious about analytics frameworks and you are well-versed in the advantages and limitations of various big data architectures and technologiesTechnologist who loves studying software platforms with an eye towards modernizing the architectureBeliever in transparency, communication, and teamworkLove to learn and not afraid to take ownershipNexus Staffing is committed to diversity, inclusion, and equal opportunity. We take affirmative steps to ensure that all programs and services are open to all Americans, free of discrimination based on protected class status, including race, religion/creed, color, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, national origin (including limited English proficiency), age, political affiliation or belief, military or veteran status, disability, predisposing genetic characteristics, marital or family status, domestic violence victim status, arrest record or criminal conviction history, or any other impermissible basis.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Company OverviewPrivately owned and operated, Digible was founded in 2017 with a mission to bring sophisticated digital marketing solutions to the multifamily industry. We offer a comprehensive suite of digital services as well as a predictive analytics platform, Fiona, that is the first of its kind.At Digible, Inc. we love to celebrate our diverse group of hardworking employees – and it shows. We pride ourselves on our collaborative, transparent, and authentic culture. These values are pervasive throughout every step of a Digible employee\\'s journey. Starting with our interviews and continuing through our weekly All Hands Transparency Round-up, values are at the heart of working at Digible.We value diversity and believe forming teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds and different industries to apply. Come join us and find out what the best work of your career could look like here at Digible.The RoleDigible, Inc. is looking for an Junior Software Engineer to join our team!We are seeking a highly motivated and detail-oriented Junior Data Engineer to join our growing team. As a Junior Data Engineer, you will be responsible for assisting with the development, implementation, and maintenance of our data infrastructure. You will work closely with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources.Responsibilities:Assist with the design, development, and maintenance of our data infrastructure using Python, Prefect, Snowflake, Google Cloud, and AWS. Collaborate with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources. Develop and maintain ETL pipelines to extract, transform, and load data from various sources into our data warehouse. Assist with the implementation of data security and governance policies. Monitor and troubleshoot data issues as they arise. Continuously seek ways to improve our data infrastructure and processes. Requirements:Bachelor\\'s degree in Computer Science, Data Science, or a related field. Experience with Python, SQL, and data modeling. Familiarity with data warehousing concepts and ETL processes. Experience working with cloud-based platforms such as Google Cloud and AWS. Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Expectations:Ability to learn and adapt quickly to new technologies and processes. Work collaboratively with our Data Engineering team to meet project goals and deadlines. Demonstrate a high level of professionalism and dedication to quality work. Communicate effectively with cross-functional teams to ensure project success. Success Metrics:Deliver high-quality data infrastructure projects on time and within scope. Ensure data accuracy and completeness across all data sources. Maintain a high level of data security and governance. Continuously seek ways to improve our data infrastructure and processes. Collaborate effectively with cross-functional teams to meet project goals and objectives. Core ValuesAuthenticity - The commitment to be steadfast and genuine with our actions and communication toward everyone we touch.Curiosity - The belief that a deep and fundamental curiosity (the \"why\") in our work is vital to company innovation and evolution.Focus - The collective will to remain completely devoted and ultimately accountable to our deliverables.Humility - The recognition and daily practice that \"we\" is always greater than \"I\".Happiness - The decision to prioritize passion and love for what we do above everything else.Perks and such:4-Day Work Week (32 Hour Work Week)WFA (Work From Anywhere)Profit Sharing BonusWe offer 3 weeks of PTO as well as Sick leave, and Bereavement. We offer 10 paid holidays (New Years Eve, New Years Day, MLK day, Memorial Day, Independence Day, Labor Day, Thanksgiving + day after, Christmas Eve, and Christmas)401(k) + Match50% employer paid health benefits, including Medical, Dental, and Vision. We provide $75/ month reimbursement for Physical WellnessWe provide $75/ month reimbursement for Mental Wellness$1000/year travel fund for employees who have been with Digible 3+ yearsMonthly subscription for financial wellnessDog-Friendly OfficePaid Parental LeaveCompany Sponsored Social EventsCompany Provided Lunches, SnacksEmployee Development Program\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionAssists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needsApplies understanding of key business drivers to accomplish own workUses expertise, judgment and precedents to contribute to the resolution of moderately complex problemsLeads portions of initiatives of limited scope, with guidance and directionWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processingCollaborates with client team to transform data and integrate algorithms and models into automated processesUses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelinesUses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systemsBuilds data marts and data models to support clients and other internal customersIntegrates data from a variety of sources, assuring that they adhere to data quality and accessibility standardsPay RangeThe typical pay range for this role is:Minimum: $ 70,000Maximum: $ 140,000Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will take into account a wide range of factors, including location.Required Qualifications1+ years of progressively complex related experienceExperience with bash shell scripts, UNIX utilities & UNIX CommandsPreferred QualificationsAbility to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sourcesAbility to understand complex systems and solve challenging analytical problemsStrong problem-solving skills and critical thinking abilityStrong collaboration and communication skills within and across teamsKnowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similarKnowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environmentExperience building data transformation and processing solutionsHas strong knowledge of large-scale search applications and building high volume data pipelinesEducationBachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related disciplineMaster’s degree or PhD preferredBusiness OverviewBring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an affirmative action employer, and is an equal opportunity employer, as are the physician-owned businesses for which CVS Health provides management services. We do not discriminate in recruiting, hiring, promotion, or any other personnel action based on race, ethnicity, color, national origin, sex/gender, sexual orientation, gender identity or expression, religion, age, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'R-27413Who Are We?Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.Compensation OverviewThe annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.Salary Range$102,600.00 - $169,200.00Target Openings1What Is the Opportunity?Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Personal Insurance Analytics and business intelligence/insights.What Will You Do?Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.Design data solutions.Analyze sources to determine value and recommend data to include in analytical processes.Incorporate core data management competencies including data governance, data security and data quality.Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.Test data movement, transformation code, and data components.Perform other duties as assigned.What Will Our Ideal Candidate Have?Bachelor’s Degree in STEM related field or equivalentSix years of related experienceProficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. Experience with Salesforce and Tealium Product Suite a plus.The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.Strong verbal and written communication skills with the ability to interact with team members and business partners.Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.What is a Must Have?Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.What Is in It for You?Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.Employment PracticesTravelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.Travelers reserves the right to fill this position at a level above or below the level included in this posting.To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role has a preference for a local Austin, TX candidate and will be a hybrid work environment meeting in-person a few times/month. Our client is a fast-growing, Private Equity backed GovTech company that provides SaaS Software solutions to the Public Sector (City / State Local Government) and is looking for a Data Engineer to join their team. Reporting to the Director of Analytics as their first hire, you will be responsible for the ongoing development and management of the data infrastructure of the business and will be providing essential support to internal customers. This pivotal role will be in the Analytics team reporting to Finance and is aimed to drive greater efficiency in data, processes, and tools, ultimately enhancing data-driven decision-making capabilities. For someone with an interest in more of the analytics side of things, this role could also serve as a hybrid Analytics / Dashboarding role as well. This role is great for someone who perhaps hasn't yet chosen a specific specialization or path in the data realm and wants to gain exposure or opportunity in different areas - Whether BI Front End, Business Strategy, Analytics / Dashboarding, or Data Engineering there are a plethora of opportunities to learn and jump in to help the business. One of the major projects you'll be working on is how to collect data on the usage of their underlying SaaS Software products and how to marry that with their CRM data. They have different products that were built at different times so getting to and extracting that data is going to be an especially interesting challenge for this team. ResponsibilitiesDesign, develop, and maintain scalable data pipelines and ETL processes to ingest and process data from various sourcesBuild and optimize the data warehouse in SnowflakeCollaborate with data users to understand requirements and create efficient data models and structures for seamless reporting and analysis using BI tools. Monitor and optimize data pipeline performanceImplement data governance and security best practices, manage user access, and ensure compliance is adhered toContinuously explore and evaluate new data engineering techniques and tools, including AI applications, to improve data processing and exploration capabilities. QualificationsExperience building or using data marts (sql heavy data modeling) and interacting with users that use the data. The ability to find the shortest path to making data available and widely usable. Experience building or extending a Data WarehouseStrong exposure to Data Warehouse patterns and the application of those patternsPrevious experience working with business stakeholdersStrong initiative to start new projects or take existing projects and make them better. Proficiency with Snowflake, Tableau, and Stitch, or similar data warehousing, BI, and ETL tools. Strong knowledge of SQL is required with database design and data modeling experience. Experience with Python or another programming language for data processing. Familiarity with data engineering best practices, including data quality, data governance, and data security. Interest in AI applications for data engineering and data exploration. Excellent problem-solving, communication, and collaboration skills. Extra informationCareer development opportunitiesCompetitive insurance (medical, dental, vision, and voluntary life & disability)Mental health benefits401(k) plan (company matching)Paid holidaysFlexible PTO - no accrualsPaid generous parental leaveBusiness casual environment #ZR\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Data Engineer Qualifications7+ years of experience as a Database Developer3+ years of experience as a hands on Team LeadExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectureStrong data modeling skills (relational, dimensional and flattened)5-7 years of experience with SQL Server On-Prem and/or Azure cloud, required5-7 years of SSIS experience utilizing SQL Agent jobs and Integration Services Catalog, required3-4 years of experience running ETL/ELT SSIS projects independently from end to end, requiredExperience with DevOps Repository and Git, preferredAzure Data Lake storage experience, a plusAzure Data Factory and/or Databricks experience, a plusLocation: Denver, COEmployment Type: Direct HireDuration: Full TimeWork Location: Denver / HybridPay: Based on experienceOther: PTO, Medical, Dental, Vision, Disability, Life, 401k benefits available Thank you in advance for your interest in this opportunity!If you are able to work on a W2 basis without sponsorship for ANY US employer and fit the description above, please apply. Third-Party Applications Not Accepted.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Hi,Hope you are doing well,We at Software Technology Inc. hiring for a Data Engineer/Data Analyst, role, if you are interested and a good fit, feel free to reach me directly at ksuresh@stiorg.com or (609) 998-3431.Role : Data Engineer/Data AnalystLocation : RemoteSkillGCP Big Query, Python, SQL and knowledge of Healthcare domain\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'adQuadrant helps DTC (direct-to-consumer) brands dream bigger. We are a trusted advisor that provides holistic, strategic omni-channel digital marketing solutions by partnering with our clients to solve the biggest challenges in terms of customer acquisition and growth. Our efforts produce tangible results backed by measurable data. We have the strategic capabilities, quantitative chops, deep creative understanding, and world-class talent with the best tools to drive revenue and profits. We are not simply a vendor checking boxes — our seasoned team serves as an extension of the companies we work with, leading strategy and execution. Our goal is to be the go-to marketing consultants for solving the biggest challenges.adQuadrant is looking for a Data Engineer to support a growing team. This role is responsible for developing, testing, and maintaining data pipelines and data architectures. You will be building and optimizing our data pipeline architecture, as well as optimizing data flows and collections for cross functional teams. The ideal candidate will enjoy optimizing data systems and building them from the ground up, you must be ready for a challenge. This role will ensure optimal data delivery architecture is consistent throughout current and ongoing projects. You must be a self-starter and enjoy supporting multiple cross-functional teams.The Ideal Candidate must have: Experience in Snowflake, architecting and building a data warehouse from scratchData pipeline (ETL tools) development and deployment experienceExtensive experience deploying and maintaining a Tableau ServerRequirementsYour Responsibilities: Consulting with the data team to get a strong understanding of the organization’s data storage needsDesigning and constructing the data warehousing system to the organization’s specificationsDefining and implementing scalable data pipelines that ingest data from various external sources, storing it in the database system, and making it useful to our data analystsImplementing processes to monitor data quality, ensuring production data is always accurate and available for data analysts and business processes that rely on itRecognize, troubleshoot, and resolve unexpected performance and process fail issues, on an ongoing basisQualifications:Bachelor’s degree in computer science, information technology, or a related field5+ years experience in data warehousing, data modeling and building data pipelinesExtensive knowledge of SQL, and coding languages, such as PythonProficiency in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDWProven work experience as an ETL developerExperience working with online marketing dataStrong project management skills and experience with Agile engineering practicesAbility to analyze a company’s big-picture data needsClear communication skillsStrategic thought and extreme attention to detailAbility to troubleshoot and solve complex technical problemsComfortable supporting distributed remote individualsBenefitsOur people come first. No jerks. No egos. Just people who like to work hard and enjoy winning as a team.Annual Compensation: $95,000 - $120,000 per yearExcellent Health Benefits (health, dental, vision, and life insurance)401K + company matchUnlimited Vacation PolicyPaid Sick Leave2 Mindfulness Days Annually2PM Fridays each week$300/ year to equip your work space with new equipment$30/ month for home internetAn extremely supportive and fun company cultureWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Attune is making it easier, faster, and more reliable for small businesses to access insurance (think, pizza place down the street or main street store). They all need insurance to protect their businesses, but when it comes time to get a policy, they're bogged down by hundreds of questions, lots of paperwork, and a seemingly never-ending timeline stretching for weeks or months.We are changing all that. By using data and technology expertise to understand risk, automating legacy processes, and creating a better user experience for brokers, we're able to provide policies that are more applicable and more transparent in just minutes.Simply put, we're pushing insurance into the future, focusing on accuracy, speed, and ease.Our mission and our team are growing. In staying true to our values, we've earned our spot on many workplace award lists. Attune is dedicated to creating a diverse team of curious, focused, and motivated people who are excited about changing the future of an entire industry.Job DescriptionAs a Data Engineer joining our growing Data team, you will help maintain our existing data pipelines and internal web applications. You will also work with team members across the organization to develop and test new pipelines as we launch new products and integrate with third-party data sources. We work with various tools including Python/Pandas, Postgresql, Bash, AWS EC2, and S3. We are always open to using whatever tool is best for the job.Responsibilities:Maintain and improve batch ETL jobs - including SQL query optimization, bug fixes and code improvementsWork with our data engineers, BI, and other teams across the business to develop/refine ETL processesUnderstand and answer questions on the data our team maintainsQualifications:3+ years experience in analytics, data science, or data engineering roleStrong Python and Postgresql skillsSolid understanding of relational database design and basic query optimization techniquesExperience working with git, and Gitlab or GithubNice to have:Experience with Linux CLI, shell programmingUnderstanding of CI/CDExperience with AWS EC2 and S3What we offer you:140-170k per yearUnlimited PTOGenerous parental and caregiver leave401K matchExcellent medical, dental, and vision plansRemote-first cultureAnd more!\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionSkills (Must Have):Python – Ingestion/manipulation of large datasets to S3 using pandasPython – Consumption of data from REST APIs using requestsAny language (Most preferably Python) – Small automation tasks within AWS S3, Glue, AthenaExperience developing in AWS. Key services: S3, Lambda, Athena, Step Functions, GlueGeneral familiarity with a variety of other systems such as Oracle/Postgres, REST APIs, SplunkDeployment of resources to AWS using ServerlessGeneral understand of Infrastructure as CodeSkills (Nice To Have)AI/Client experience in SagemakerGeneral knowledge of cyber security practices and frameworksExperience writing complex queries in Presto/HadoopDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Sayari is looking for Data Engineers to join our growing team! We are hiring at all levels and encourage junior through senior level candidates to apply. As a member of Sayari's data team you will work with our Product and Software Engineering teams to collect data from around the globe, maintain existing ETL pipelines, and develop new pipelines that power Sayari Graph.About Sayari:Sayari is a venture-backed and founder-led global corporate data provider and commercial intelligence platform, serving financial institutions, legal & advisory service providers, multinationals, journalists, and governments. We are building world-class SaaS products that help our clients glean insights from vast datasets that we collect, extract, enrich, match and analyze using a highly scalable data pipeline. From financial intelligence to anti-counterfeiting, and from free trade zones to war zones, Sayari powers cross-border and cross-lingual insight into customers, counterparties, and competitors. Thousands of analysts and investigators in over 30 countries rely on our products to safely conduct cross-border trade, research front-page news stories, confidently enter new markets, and prevent financial crimes such as corruption and money laundering.Our company culture is defined by a dedication to our mission of using open data to prevent illicit commercial and financial activity, a passion for finding novel approaches to complex problems, and an understanding that diverse perspectives create optimal outcomes. We embrace cross-team collaboration, encourage training and learning opportunities, and reward initiative and innovation. If you enjoy working with supportive, high-performing, and curious teams, Sayari is the place for you.Position DescriptionSayari’s flagship product, Sayari Graph, provides instant access to structured business information from hundreds of millions of corporate, legal, and trade records. As a member of Sayari's data team you will work with our Product and Software Engineering teams to collect data from around the globe, maintain existing ETL pipelines, and develop new pipelines that power Sayari Graph.RequirementsWhat You Will Need:Professional experience with Python and a JVM language (e.g., Scala)2+ years of experience designing and maintaining ETL pipelinesExperience using Apache Spark and Apache AirflowExperience with SQL and NoSQL databases (e.g., columns stores, graph, etc.)Experience working on a cloud platform like GCP, AWS, or AzureExperience working collaboratively with gitWhat We Would Like:Understanding of Docker/KubernetesUnderstanding of or interest in knowledge graphsWho You Are:Experienced in supporting and working with cross-functional teams in a dynamic environmentInterested in learning from and mentoring team members Passionate about open source development and innovative technologyBenefitsA collaborative and positive culture - your team will be as smart and driven as youLimitless growth and learning opportunities A strong commitment to diversity, equity, and inclusion Performance and incentive bonuses Outstanding competitive compensation and comprehensive family-friendly benefits, including full healthcare coverage plans, commuter benefits, 401K matching, generous vacation, and parental leave.Conference & Continuing Education Coverage Team building events & opportunitiesSayari is an equal opportunity employer and strongly encourages diverse candidates to apply. We believe diversity and inclusion mean our team members should reflect the diversity of the United States. No employee or applicant will face discrimination or harassment based on race, color, ethnicity, religion, age, gender, gender identity or expression, sexual orientation, disability status, veteran status, genetics, or political affiliation. We strongly encourage applicants of all backgrounds to apply.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The Data Engineer (DE) position requires a creative problem solver who is passionate about client service. This role will work with the Project Manager and Senior Data Engineers to produce timely, best-in-class deliverables. This role specializes in obtaining, reconciling, analyzing, and preparing data for use in performing sales tax consulting engagements with emphasis on preparing audit ready data populations for the Service Delivery teams quickly and efficiently.PeopleDuties and Responsibilities:Creates a positive team member experience.Demonstrates strong written and verbal communication skills, displays a positive demeanor and team spirit.Plays a key role in driving collaboration across team members, other practices and outside entities.ClientAssists senior team members in retrieving data from client systems.Assists clients and Ryan consultants in data analysis and manipulation.Travels to client sites to assist client in gathering additional data and other necessary documentation.Collaborates with remote and local teammates to ensure efficient design and timely completion of deliverables.Assist senior team members in preparing client and project correspondence.ValueAssists in the acquisition, extraction, and transfer of client data.Analyzes data from client accounting systems to verify accuracy and completeness.Develops and deploys data extraction technologies to perform data extractions from client systems.Manipulates data using Microsoft® Access, SQL, and proprietary software.Assists with the installation of data extraction tools such as Ryan eExtract®, for various ERP systems.Analyzes large data at terabyte scale using modern database technologies.Develops code in Java or Python to support ETL process and contribute to existing code bases. Performs other duties as assigned.Education And ExperienceBS or MBA preferred in information systems or computer science. Other STEM degrees with relevant work experience or coursework are considered.1-3 years of full-time work experience is a plus. Client facing or consulting experience is considered a differentiator.Experience with an enterprise or NoSQL database is a plus.Implementation experience with a major ERP system is a plus.Computer SkillsThe candidate must have a strong command of SQL and uses ETL software such as Visual Studio to build and execute SSIS packages for data manipulation, loading, and processing as well as either Java or Python to perform successfully. Ability to work in the Microsoft Office suite is required.Certificates And LicensesValid driver’s license required.Supervisory ResponsibilitiesThe position requires no direct supervisory responsibilities.Work EnvironmentStandard indoor working environment.Occasional long periods of sitting while working at computer.Position requires regular interaction with employees and clients both in person and via e-mail and telephone.Independent travel requirement: 30 to 40%. Compensation For certain California based roles, the base salary hiring range for this position is $72,069 - $88,044For other California based locations, the base salary hiring range for this position is $66,033 - $80,707For Colorado based roles, the base salary hiring range for this position is $63,032 - $77,039For New York based roles, the base salary hiring range for this position is $72,036 - $88,044For Washington based roles, the base salary hiring range for this position is $66,033 - $80,707The Company makes offers based on many factors, including qualifications and experience.Equal Opportunity Employer: disability/veteran\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Do you love to work with data, finding ways to make it reportable, and building models that will add clinical and commercial value for the future?Do you want to bring your skills and experience to a growth stage engineering team, and help set us up for smart expansion?Are you excited by the prospect of having a high-visibility high-impact role in a fast-moving startup?Are you passionate about healthcare, and looking to create a revolutionary new approach to digestive healthcare with a radically better patient experience?If so, you could be a perfect fit for our team of like-minded professionals who share a common mission and passion for helping others and a desire to build a great company.Oshi Health is revolutionizing GI care with a virtual clinic that provides easy, convenient access to a multidisciplinary care team including a GI Physician, Registered Dietician, Mental Health Professional, and Health Coach that takes a whole-person approach to diagnosing, managing and treating digestive health conditions. Our care is built on the latest evidence-based protocols and is delivered virtually through an app, secure messaging and telehealth visits with the care team. NOTE: Oshi is a fully remote company, with team members all over the US.What You’ll Do:This role will be a perfect fit if you enjoy learning the entire stack and taking on interdisciplinary challenges. A primary focus will be building out a data engineering program, including ETL, data governance, sanitization, and data operations. This part of your responsibilities will be a balance of executing data operations, and building automation to make those operations scalable.You will also have the opportunity to join engineers on the frontend end (React Native and React.js), backend (Node.js Lambdas) and Salesforce to help build the Oshi platform. Experience with any of these technologies is a plus, but more important is an enthusiasm to adapt and learn the ones that are new to you.What you’ll do: build the Oshi data programImplement and maintain data pipelines using Stitch, Databricks, and other scripting as needed to feed a PostgreSQL schema supporting Tableau reportingSupport users of Tableau by updating data sources or modifying inbound inputs as needed deliver critical BI reportsOwn the Oshi data model, ensuring that new features built and new technologies adopted serve the needs of the clinical, commercial, product, and engineering teamsManage ETL of client eligibility files and other data, to make them available for Oshi use in a secure and timely manner. Wherever possible, replace bespoke processes with automationOnce you have a understanding of Oshi’s requirements, design and implement a data strategy, (with your recommendation of approach and products,) to meet the needs of Oshi’s analytics, commercial, and clinical business linesYour work will also include:AWS maintenance and administration Writing technical documentation to outline designs for forthcoming features, outlining the implementation across all technology layersMeeting with colleagues in Strategy, Product, and Clinical to support their needs from the Engineering group.Production support responsibilities (shared with the entire engineering team) responding to alerts in Datadog, reviewing and troubleshooting issuesOur tech stack:Mobile Platforms Supported: iOS & AndroidCross-Platform Mobile Language: React NativeOther Languages: React-js, HTML, CSS, Java (Salesforce Apex), Node.js (Lambda)Systems: Salesforce, AWS Amplify / Cognito / LambdaYour Profile:A minimum of 3+ years of professional experienceBachelor's Degree or equivalent experienceGood interpersonal and relationship skills that include a positive attitudeSelf-starter who can find a way forward even when the path is unclear.Team player AND a leader simultaneously.What You’ll Bring to the Team:Passionate about creating value that changes people's livesMake low-level decisions quickly while being patient and methodical with high-level onesAre curious and passionate about digging into new technologies with a knack for picking them up quicklyAdept at prioritizing value and shipping complex products while coordinating across multiple teamsLove working with a diverse set of engineers, product managers, designers, and business partnersStrive to excel, innovate and take pride in your workWork well with other leadersAre a positive culture driverExcited about working in a fast-paced, startup cultureExperience in a regulated industry (healthcare, finance, etc.) a plusand perks:We’re revolutionizing GI care — and our employees are driving the change. We’re a hard-working and fun-loving team, committed to always learning and improving, and dedicated to doing the right thing for our members. To achieve our mission, we invest in our people:We make healthcare more equitable and accessible:Mission-driven organization focused on innovative digestive careThrive on diversity with monthly DEIB discussions, activities, and moreVirtual-first culture: Work from home anywhere in the USLive our core values: Own the outcome, Do the right thing, Be direct and open, Learn and improve, Team, Thrive on diversity We take care of our people:Competitive compensation and meaningful equityEmployer-sponsored medical, dental and vision plans Access to a “Life Concierge” through Overalls, because we know life happensTailored professional development opportunities to learn and growWe rest, recharge and re-energize:Unlimited paid time off — take what you need, when you need it13 paid company holidays to power downTeam events, such as virtual cooking classes, games, and moreRecognition of professional and personal accomplishmentsOshi Health’s Core Values:Go For ItDo the Right ThingBe Direct & OpenLearn & ImproveTEAM - Together Everyone Achieves MoreOshi Health is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.Powered by JazzHRFRVWJuzRKn\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Applicants must be authorized to work for any employer in the United States. We are unable to sponsor, or take over sponsorship, of an employment visa at this time.About the roleReporting to the SVP, Data & Technology and Lead Data Engineer, the Data Engineer will play a critical role in supporting and advancing Geopath’s new audience measurement platform.Responsibilities:Build scalable functions, fault tolerant batch & real time data pipelines to validate/extract/transform/integrate large scale datasets inclusive of location and time series data, across multiple platformsReview current data processes to identify improvement areas: design and implement solutions to improve scalability, performance, cost efficiencies and data qualityExtend and optimize Geopath’s data platform, which spans across multiple cloud services, data warehouses, and applications in order to meet the industry’s evolving data needsResearch, evaluate, analyze and integrate new data sources and develop quick prototypes for new data productsWork closely with product owners, data architects, data scientists and application development teams to quickly define prototypes, and build new data productsDevelop a solid understanding of the nuances within Geopath’s foundational data sourcesSupport internal stakeholders including data, design, product and executive teams by assisting them with data-related technical issuesRequirements:Bachelor’s or master's degree in computer science, computer engineering, informatics, or equivalent fields3+ years of experience as a Data Engineer with demonstrated experience in data modeling, ETL, data warehouse/data lakes, and consolidating data from multiple data sources3+ years of experience with SQL, solid experience in writing stored procedures and UDFs, familiarity with Snowflake’s data warehouse a plus2+ years of experience in building and optimizing scalable and robust big data pipelines in Apache Airflow or other workflow engines and fluent in Python or Java programmingGood working knowledge in data partition and query optimizationExperience or desire to work in a start-up environment, good team player, and can work independently with minimal supervisionGreat analytical and problem-solving skills, eager to learn new technologies and willing to wear different hats in a small team settingGreat communication and organizational skillsExpected salary for this role is between $75,000-$140,000 per year, depending on experience.About Geopath Inc.Established in 1933, Geopath, (previously the Traffic Audit Bureau for Media Measurement Inc.,) has been the gold standard in providing media auditing and audience measurement services for the Out of Home industry in the US for 90 years. Geopath has now expanded its historical mission and is looking to the future by modernizing its mission critical, industry-standard media audience rating platform while embracing the digital era. In addition to being the industry’s media auditing solution, Geopath also analyzes people’s movement data, develops deep consumer insights, innovations and advanced media research methodologies to uncover critical insights about how consumers engage with Out of Home advertising across a multi-channel ecosystem and in the physical world.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We are currently hiring a Senior Data Platform Engineer to help grow our company and ensure our mission is achieved!This role is a work from home position and can be performed remotely anywhere in the continental US or in one of our corporate locations in Utah or Arizona.WE ARE: Our Data Platforms embodies the modernity and transformational vision that is core to our business evolution. As passionate and hungry technical experts, we progress through technology. We take pride in our engineering, daily progress, and bringing others along as we improve. We experiment, fail fast, and drive to delivery.YOU ARE: A self-starter mindset to proactively take ownership and execute work without daily oversight and excited to develop your data administration & data DevOps skills. We have a great team of engineers building next-generation data platforms. You are motivated by challenges and thrive with continuous innovation.YOUR DAY-TO-DAY:Coach and develop fellow team membersWorking in an agile-scrum development environmentWork with engineers and leaders to promote a shared vision of our data platform & architectureTrack operating metrics for our data platforms, driving improvements and making trade-offs among competing constraints. We use MS SQL Server, AWS RDS (Postgres, MariaDB) MongoDB, DynamoDB, Redis, Rabbit MQ, AWS managed messaging/eventing systems (Kafka, Kinesis, SQS, SNS) to name a few of our platformsBe a strategic player in designing enterprise-wide data infrastructureBuilds robust systems with an eye on the long-term maintenance and support of the applicationDiscover automation opportunities to replace manual processes using PowerShell, Terraform, Python etcBuild out frameworks for data administration /data deployment /monitoring where neededLeverage reusable code modules to solve problems across the team and organizationCreate and maintain automated pipelines to deploy changes via Octopus, CircleCI, Azure DevOps and JenkinsProactive and reactive performance analysis, monitoring, troubleshooting and resolution of escalated issuesParticipate in the team on-call rotationsYOU’LL BRING:Used multiple data platforms and can define which is optimal for a given scenario (such as document databases, RDBMS, caching, eventing, etc. On-prem or cloud)An engineering mindset when developing a solution using PowerShell / Python or SQL. In depth knowledge and use of tools such as dbatools and other modules is a plusUnderstand how to fully automate systems using infrastructure/configuration as code technologies (we use Terraform, CloudFormation, Ansible, SaltStack)Experience working with CI/CD pipeline and tools preferably Octopus, CircleCI, AzureDevOps and JenkinsProven ability to mentor and coach engineersThrive on a high level of autonomy and responsibility, while having the ability to dig into technical details to inform decisionsAdvanced Sql Server Knowledge and experience in performance analysis and tuning skills such as tracing and profiling and Dynamic Management Views and Functions (DMVs) and other third-party tools like SentryOne to ensure high levels of performance, availability, and securityKnowledge of database deployment using DACPAC via pipelinesExperience with enterprise features of SQL Server: AlwaysOn Availability Groups, clustering, Disaster RecoveryContribute to the management and reliability of database HA/DR processesYOU MIGHT ALSO HAVE:Ability to clearly articulate complex subjects to leadership and others not familiar with this spaceExperience with code-based data developmentA self-starter mindset to proactively take ownership and execute work without daily oversightExperience in AWS cloud-based solutionsWE OFFER: Competitive Compensation; Eligible for STI + LTIFull Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental LeaveCompany Matched 401kPaid Time Off + Paid Holidays + Paid Volunteer HoursEmployee Resource Groups (Black Inclusion Group, Women in Leadership, PRIDE, Adelante)Employee Stock Purchase ProgramTuition ReimbursementCharitable Gift MatchingJob required equipment and services\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer (ETL, Python)Location: Dallas, TX (Hybrid)Duration: 6+ MonthsResponsibilitiesJob DescriptionStrong Experience With ETL, Python And Data EngineerHybrid: 2 days office, 3 days remote and need only local candidatesWork with business stakeholders, Business Systems Analysts and Developers to ensure quality delivery of software.Interact with key business functions to confirm data quality policies and governed attributes.Follow quality management best practices and processes to bring consistency and completeness to integration service testingDesigning and managing the testing AWS environments of data workflows during development and deployment of data productsProvide assistance to the team in Test Estimation & Test PlanningDesign, development of Reports and dashboards.Analyzing and evaluating data sources, data volume, and business rules.Proficiency with SQL, familiarity with Python, Scala, Athena, EMR, Redshift and AWS.No SQL data and unstructured data experience.Extensive experience in programming tools like Map Reduce to HIVEQLExperience in data science platforms like Sage Maker/Machine Learning Studio/ H2O.Should be well versed with the Data flow and Test Strategy for Cloud/ On Prem ETL Testing.Interpret and analyses data from various source systems to support data integration and data reporting needs.Experience in testing Database Application to validate source to destination data movement and transformation.Work with team leads to prioritize business and information needs.Develop complex SQL scripts (Primarily Advanced SQL) for Cloud ETL and On prem.Develop and summarize Data Quality analysis and dashboards.Knowledge of Data modeling and Data warehousing concepts with emphasis on Cloud/ On Prem ETL.Execute testing of data analytic and data integration on time and within budget.Work with team leads to prioritize business and information needsTroubleshoot & determine best resolution for data issues and anomaliesExperience in Functional Testing, Regression Testing, System Testing, Integration Testing & End to End testing.Has deep understanding of data architecture & data modeling best practices and guidelines for different data and analytic platformsRequirementsExperienced in large-scale application development testing Cloud/ On Prem Data warehouse, Data Lake, Data scienceExperience with multi-year, large-scale projectsExpert technical skills with hands-on testing experience using SQL queries.Extensive experience with both data migration and data transformation testingExtensive experience DBMS like Oracle, Teradata, SQL Server, DB2, Redshift, Postgres and Sybase.Extensive testing Experience with SQL/Unix/Linux.Extensive experience testing Cloud/On Prem ETL (e.g. Abinito, Informatica, SSIS, DataStage, Alteryx, Glu)Extensive experience using Python scripting and AWS and Cloud Technologies.Extensive experience using Athena, EMR , Redshift and AWS and Cloud TechnologiesAPI/RESTAssured automation, building reusable frameworks, and good technical expertise/acumenJava/Java Script - Implement core Java, Integration, Core Java and API.Functional/UI/ Selenium - BDD/Cucumber, Specflow, Data Validation/Kafka, Big Data, also automation experience using Cypress.AWS/Cloud - Jenkins/ Gitlab/ EC2 machine, S3 and building Jenkins and CI/CD pipelines, SauceLabs.API/Rest API - Rest API and Micro Services using JSON, SoapUIExtensive experience in DevOps/Data Ops space.Strong experience in working with DevOps and build pipelines.Strong experience of AWS data services including Redshift, Glue, Kinesis, Kafka (MSK) and EMR/ Spark, Sage Maker etcExperience with technologies like Kubeflow, EKS, DockerExtensive experience using No SQL data and unstructured data experience like MongoDB, Cassandra, Redis, Zookeeper.Extensive experience in Map reduce using tools like Hadoop, Hive, Pig, Kafka, S4, Map R.Experience using Jenkins and GitlabExperience using both Waterfall and Agile methodologies.Experience in testing storage tools like S3, HDFSExperience with one or more industry-standard defect or Test Case management ToolsGreat communication skills (regularly interacts with cross functional team members)Good To HaveGood to have Java knowledgeKnowledge of integrating with Test Management ToolsKnowledge in Salesforce\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Our team relies on clean datasets accessible via the latest tools to answer questions that are often not simple or clear. You will be creating solutions that will help derive value from our rich datasets that will solve tough problems impacting consumers across geographies & industries (healthcare, retail/ consumer, telecom, industrial) driving technology transformation. At the core of our team, we believe data is best used to create transparency & generate communal value.  What You’ll Do: · Design, Build & ImplementDesign & build batch, event driven and real-time data pipelines using some of the latest technologies available on Microsoft Azure, Google Cloud Platform and AWSImplement large-scale data platforms to meet the analytical & operational needs across various organizationsBuild products & frameworks that can be re-used across different use-cases in increase efficiency in coding and agility in implementation of solutionsBuild streaming ingestion processes to efficiently read, process, analyze & publish data for real-time need of applications and data science modelsPerform analyses of large structured and unstructured data to solve multiple & complex business problemsInvestigate and prototype different task dependency frameworks to understand the most appropriate design for a given use case to assess & advise Understand business use cases to design engineering routines to affect the outcomesReview & assess data frameworks & technology platforms with the goal of suggesting & implementing improvements on the existing frameworks & platforms.Understand quality of data used in existing use cases to suggest process improvements & implement data quality routines   Who You Are : An Engineer interested in working in batch, event driven and streaming processing environments A tech-enthusiast excited to work with Cloud Based Technologies like GCP, Azure & AWSA data parser expert who gets excited about structuring and re-structuring datasets programmatically A doer who loves to produce meaningful analytic insights for an innovative, data-intensive productsAlways curious about analytics frameworks and you are well-versed in the advantages and limitations of various big data architectures and technologiesTechnologist who loves studying software platforms with an eye towards modernizing the architectureBeliever in transparency, communication, and teamworkLove to learn and not afraid to take ownershipNexus Staffing is committed to diversity, inclusion, and equal opportunity. We take affirmative steps to ensure that all programs and services are open to all Americans, free of discrimination based on protected class status, including race, religion/creed, color, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, national origin (including limited English proficiency), age, political affiliation or belief, military or veteran status, disability, predisposing genetic characteristics, marital or family status, domestic violence victim status, arrest record or criminal conviction history, or any other impermissible basis.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionPOSITION TITLE: Data Engineer InternPosition SummaryThe Data Engineer Intern will help to enable data as the forefront of all business process and decisions. You will be part of a team of strong technologists passionate about our roadmap to deliver highly available and scalable data pipelines and solutions in the Google Cloud Platform (GCP) allowing teams across Digital, Stores, Marketing, Supply Chain, Finance, and Human Resources to make real-time decisions based on consistent, complete, and correct data using Data Quality rules. Your contributions will include supporting improvements in our data platform, building frameworks for security, automation and optimization, and curating data to be consumed by Data Science, Data Insights, and Advanced Analytics teams across the organization using a suite of sophisticated cloud tools and open-source technologies.Responsibilities Guided work using Google Cloud Platform (GCP) environment to perform the following:Develop highly available, scalable data pipelines and applications to support business decisions Pipeline development and orchestration using Cloud Data Fusion/CDAP, Cloud Composer/Airflow/Python, DataflowBig Query table creation and query optimizationCloud Function’s for event-based triggeringCloud Monitoring and AlertingPub/Sub for real-time messagingCloud Data Catalog build-outWork in an agile environment applying SDLC principles and SCRUM methodologies utilizing tools such as Jira, Wiki, Bitbucket/GitHub and BambooGuided work around software and product security, scalability, general data warehousing principles, documentation practices, refactoring and testing techniquesUse Terraform for infrastructure automation and provisioning.QualificationsBachelor/Master’s degree in MIS, Computer Science, or a related discipline Experience / training using Java or PythonUnderstanding of Big Data ETL Pipelines and familiar with Dataproc, Dataflow, Spark, or HadoopProficient ANSI SQL skills Pay/Benefits InformationActual starting pay is determined by various factors, including but not limited to relevant experience and location.Subject to eligibility requirements, associates may receive health care benefits (including medical, vision, and dental); wellness benefits; 401(k) retirement benefits; life and disability insurance; employee stock purchase program; paid time off; paid sick leave; and parental leave and benefitsPaid Time Off, paid sick leave, and holiday pay vary by job level and type, job location, employment classification (part-time or full-time / exempt or non-exempt), and years of service. For additional information, please click here .AEO may also provide discretionary bonuses and other incentives at its discretion.About UsAmerican Eagle - We\\'re an American jeans and apparel brand that\\'s true in everything we do. Rooted in authenticity, powered by positivity, and inspired by our community – we welcome all and believe that putting on a really great pair of #AEjeans gives you the freedom to be true to you. Because when you\\'re at your best, you put good vibes out there, and get good things back in return. AE. True to you.American Eagle Outfitters® (NYSE: AEO) is a leading global specialty retailer offering high-quality, on-trend clothing, accessories and personal care products at affordable prices under its American Eagle® and Aerie® brands.The company operates stores in the United States, Canada, Mexico, and Hong Kong, and ships to 81 countries worldwide through its websites. American Eagle and Aerie merchandise also is available at more than 200 international locations operated by licensees in 24 countries.AEO is an Equal Opportunity Employer and is committed to complying with all federal, state and local equal employment opportunity (\"EEO\") laws. AEO prohibits discrimination against associates and applicants for employment because of the individual\\'s race or color, religion or creed, alienage or citizenship status, sex (including pregnancy), national origin, age, sexual orientation, disability, gender identity or expression, marital or partnership status, domestic violence or stalking victim status, genetic information or predisposing genetic characteristics, military or veteran status, or any other characteristic protected by law. This applies to all AEO activities, including, but not limited to, recruitment, hiring, compensation, assignment, training, promotion, performance evaluation, discipline and discharge. AEO also provides reasonable accommodation of religion and disability in accordance with applicable law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Role: Data Engineer with SQLLocation: Bellevue, WA/Remote (PST zone)/CanadaDuration: 6+ MonthsJob Description Data engineer + SQL masteryData normalization and denormalization principles and practiceAggregates, Common Table Expressions, Window FunctionsMulti-column joins, self joins, preventing row explosionsExperience with Postgres is a plusNeeds to understand database connectivityHow to connect to a databaseHow to explore a databaseHow to perform multiple operation in a single transactionNeeds to know how to do the basics with gitEnough familiarity with Azure cloud computing concepts to get things doneExperience with Databricks and/or Delta Lake a plusExperience with Azure Data Factory a plusSome level of scripting (preferably in python) is beneficialSome level of geospatial knowledge a plusSome level of geospatial SQL knowledge an extra special plus\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Company OverviewPrivately owned and operated, Digible was founded in 2017 with a mission to bring sophisticated digital marketing solutions to the multifamily industry. We offer a comprehensive suite of digital services as well as a predictive analytics platform, Fiona, that is the first of its kind.At Digible, Inc. we love to celebrate our diverse group of hardworking employees – and it shows. We pride ourselves on our collaborative, transparent, and authentic culture. These values are pervasive throughout every step of a Digible employee\\'s journey. Starting with our interviews and continuing through our weekly All Hands Transparency Round-up, values are at the heart of working at Digible.We value diversity and believe forming teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds and different industries to apply. Come join us and find out what the best work of your career could look like here at Digible.The RoleDigible, Inc. is looking for an Junior Software Engineer to join our team!We are seeking a highly motivated and detail-oriented Junior Data Engineer to join our growing team. As a Junior Data Engineer, you will be responsible for assisting with the development, implementation, and maintenance of our data infrastructure. You will work closely with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources.Responsibilities:Assist with the design, development, and maintenance of our data infrastructure using Python, Prefect, Snowflake, Google Cloud, and AWS. Collaborate with our Data Engineering team to ensure data quality, accuracy, and completeness across all of our data sources. Develop and maintain ETL pipelines to extract, transform, and load data from various sources into our data warehouse. Assist with the implementation of data security and governance policies. Monitor and troubleshoot data issues as they arise. Continuously seek ways to improve our data infrastructure and processes. Requirements:Bachelor\\'s degree in Computer Science, Data Science, or a related field. Experience with Python, SQL, and data modeling. Familiarity with data warehousing concepts and ETL processes. Experience working with cloud-based platforms such as Google Cloud and AWS. Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Expectations:Ability to learn and adapt quickly to new technologies and processes. Work collaboratively with our Data Engineering team to meet project goals and deadlines. Demonstrate a high level of professionalism and dedication to quality work. Communicate effectively with cross-functional teams to ensure project success. Success Metrics:Deliver high-quality data infrastructure projects on time and within scope. Ensure data accuracy and completeness across all data sources. Maintain a high level of data security and governance. Continuously seek ways to improve our data infrastructure and processes. Collaborate effectively with cross-functional teams to meet project goals and objectives. Core ValuesAuthenticity - The commitment to be steadfast and genuine with our actions and communication toward everyone we touch.Curiosity - The belief that a deep and fundamental curiosity (the \"why\") in our work is vital to company innovation and evolution.Focus - The collective will to remain completely devoted and ultimately accountable to our deliverables.Humility - The recognition and daily practice that \"we\" is always greater than \"I\".Happiness - The decision to prioritize passion and love for what we do above everything else.Perks and such:4-Day Work Week (32 Hour Work Week)WFA (Work From Anywhere)Profit Sharing BonusWe offer 3 weeks of PTO as well as Sick leave, and Bereavement. We offer 10 paid holidays (New Years Eve, New Years Day, MLK day, Memorial Day, Independence Day, Labor Day, Thanksgiving + day after, Christmas Eve, and Christmas)401(k) + Match50% employer paid health benefits, including Medical, Dental, and Vision. We provide $75/ month reimbursement for Physical WellnessWe provide $75/ month reimbursement for Mental Wellness$1000/year travel fund for employees who have been with Digible 3+ yearsMonthly subscription for financial wellnessDog-Friendly OfficePaid Parental LeaveCompany Sponsored Social EventsCompany Provided Lunches, SnacksEmployee Development Program\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The Data Engineer develops data acquisition, storage, processing, and integration solutions for operational, reporting, and analytical purposes. This person is often called upon to generate production data solutions to support new rate analyses, operational reports, integrations with external entities, and new functionality in transactional systems. The Data Engineer will employ sound data management fundamentals and best practices to transform raw data resources into enterprise assets. Duties and responsibilities include the following:Design data structures and solutions to support transactional data processing, batch and real-time data movement, and data warehousingPerform ad-hoc query and analysis on structured and unstructured data from a variety of sourcesDevelop queries, data marts, and data files to support reporting and analytics efforts in IT and business unit customers. Recommend and implement data solutions to improve the usage of data assets across the organizationOptimize and operationalize prototype solutions developed by other team members or business analysts. Participate in the design and development of data services (REST, SOAP, etc.) as neededMap existing solutions developed in legacy technology to new architecture and implement modernized solutions in target-state technology stackPerform peer review and occasional QA support for solutions developed by other associates within the Data Management group or other functional areasInvestigate and document current data flow processes between corporate systems, business partners, and downstream data consumersCreate data models and technical metadata using modeling tools such as ER Studio or ErwinDocument and disseminate system interactions and data process flowsParticipate in the design and development of target-state analytics ecosystem using traditional and big data tools, as well as a mix of on-premises and cloud infrastructure Qualifications and Requirements5+ years' work experience developing high-performing data systems, adhering to established best-practicesStrong SQL development skills , creating complex queries, views, and stored proceduresSolid understanding of SQL best practicesExperience interfacing with business stakeholders to understand data and analytics needs and deliver solutionsExperience with ETL tools such as SSIS, Azure Data Factory and SQL Server (required)Experience in a variety of data technologies such as SQL Server, DB2, MongoDB (nice to have)Strong experience with relational data structures, theories, principles, and practicesExperience in Agile Scrum and / or Kanban project management frameworksExperience in creating data specifications, data catalogs, and process flow diagramsExperience developing REST or SOAP services preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'R-27413Who Are We?Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.Compensation OverviewThe annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.Salary Range$102,600.00 - $169,200.00Target Openings1What Is the Opportunity?Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Personal Insurance Analytics and business intelligence/insights.What Will You Do?Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.Design data solutions.Analyze sources to determine value and recommend data to include in analytical processes.Incorporate core data management competencies including data governance, data security and data quality.Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.Test data movement, transformation code, and data components.Perform other duties as assigned.What Will Our Ideal Candidate Have?Bachelor’s Degree in STEM related field or equivalentSix years of related experienceProficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices. Experience with Salesforce and Tealium Product Suite a plus.The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.Strong verbal and written communication skills with the ability to interact with team members and business partners.Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.What is a Must Have?Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.Four years of data engineering or equivalent experience.What Is in It for You?Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.Employment PracticesTravelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.Travelers reserves the right to fill this position at a level above or below the level included in this posting.To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role has a preference for a local Austin, TX candidate and will be a hybrid work environment meeting in-person a few times/month. Our client is a fast-growing, Private Equity backed GovTech company that provides SaaS Software solutions to the Public Sector (City / State Local Government) and is looking for a Data Engineer to join their team. Reporting to the Director of Analytics as their first hire, you will be responsible for the ongoing development and management of the data infrastructure of the business and will be providing essential support to internal customers. This pivotal role will be in the Analytics team reporting to Finance and is aimed to drive greater efficiency in data, processes, and tools, ultimately enhancing data-driven decision-making capabilities. For someone with an interest in more of the analytics side of things, this role could also serve as a hybrid Analytics / Dashboarding role as well. This role is great for someone who perhaps hasn't yet chosen a specific specialization or path in the data realm and wants to gain exposure or opportunity in different areas - Whether BI Front End, Business Strategy, Analytics / Dashboarding, or Data Engineering there are a plethora of opportunities to learn and jump in to help the business. One of the major projects you'll be working on is how to collect data on the usage of their underlying SaaS Software products and how to marry that with their CRM data. They have different products that were built at different times so getting to and extracting that data is going to be an especially interesting challenge for this team. ResponsibilitiesDesign, develop, and maintain scalable data pipelines and ETL processes to ingest and process data from various sourcesBuild and optimize the data warehouse in SnowflakeCollaborate with data users to understand requirements and create efficient data models and structures for seamless reporting and analysis using BI tools. Monitor and optimize data pipeline performanceImplement data governance and security best practices, manage user access, and ensure compliance is adhered toContinuously explore and evaluate new data engineering techniques and tools, including AI applications, to improve data processing and exploration capabilities. QualificationsExperience building or using data marts (sql heavy data modeling) and interacting with users that use the data. The ability to find the shortest path to making data available and widely usable. Experience building or extending a Data WarehouseStrong exposure to Data Warehouse patterns and the application of those patternsPrevious experience working with business stakeholdersStrong initiative to start new projects or take existing projects and make them better. Proficiency with Snowflake, Tableau, and Stitch, or similar data warehousing, BI, and ETL tools. Strong knowledge of SQL is required with database design and data modeling experience. Experience with Python or another programming language for data processing. Familiarity with data engineering best practices, including data quality, data governance, and data security. Interest in AI applications for data engineering and data exploration. Excellent problem-solving, communication, and collaboration skills. Extra informationCareer development opportunitiesCompetitive insurance (medical, dental, vision, and voluntary life & disability)Mental health benefits401(k) plan (company matching)Paid holidaysFlexible PTO - no accrualsPaid generous parental leaveBusiness casual environment #ZR\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"As a Data Engineer for our Data Platform Engineering team you will join skilled Scala/ Spark engineers and core database developers responsible for developing hosted cloud analytics infrastructure (Apache Spark-based), distributed SQL processingframeworks, proprietary data science platforms, and core database optimization. This team is responsible for building the automated, intelligent, and highly performant query planner and execution engines, RPC calls between datawarehouse clusters, shared secondary cold storage, etc. This includes building new SQL features and customer-facing functionality, developing novel query optimization techniques for industry-leading performance, and building a databasesystem that's highly parallel, efficient and fault-tolerant. This is a vital role reporting to exec leadership and senior engineering leadershipRequirementsResponsibilities:Writing Scala code with tools like Apache Spark + Apache Arrow + Apache Kafka to build a hosted, multi-cluster data warehouse for Web3Developing database optimizers, query planners, query and data routing mechanisms, cluster-to-cluster communication, and workload management techniques.Scaling up from proof of concept to “cluster scale” (and eventually hundreds of clusters with hundreds of terabytes each), in terms of both infrastructure/architecture and problem structureCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate meta data capturing and managementManaging a team of software engineers writing new code to build a bigger, better, faster, more optimized HTAP database (using Apache Spark, Apache Arrow, Kafka, and a wealth of other open source data tools)Interacting with exec team and senior engineering leadership to define, prioritize, and ensure smooth deployments with other operational componentsHighly engaged with industry trends within analytics domain from a data acquisition processing, engineering, management perspectiveUnderstand data and analytics use cases across Web3 / blockchainsSkills & QualificationsBachelor’s degree in computer science or related technical field. Masters or PhD a plus.6+ years experience engineering software and data platforms / enterprise-scale data warehouses, preferably with knowledge of open source Apache stack (especially Apache Spark, Apache Arrow, Kafka, and others)3+ years experience with Scala and Apache Spark (or Kafka)A track record of recruiting and leading technical teams in a demanding talent marketRock solid engineering fundamentals; query planning, optimizing and distributed data warehouse systems experience is preferred but not requiredNice to have: Knowledge of blockchain indexing, web3 compute paradigms, Proofs and consensus mechanisms... is a strong plus but not requiredExperience with rapid development cycles in a web-based environmentStrong scripting and test automation knowledgeNice to have: Passionate about Web3, blockchain, decentralization, and a base understanding of how data/analytics plays into this\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Data Engineer Qualifications7+ years of experience as a Database Developer3+ years of experience as a hands on Team LeadExperience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectureStrong data modeling skills (relational, dimensional and flattened)5-7 years of experience with SQL Server On-Prem and/or Azure cloud, required5-7 years of SSIS experience utilizing SQL Agent jobs and Integration Services Catalog, required3-4 years of experience running ETL/ELT SSIS projects independently from end to end, requiredExperience with DevOps Repository and Git, preferredAzure Data Lake storage experience, a plusAzure Data Factory and/or Databricks experience, a plusLocation: Denver, COEmployment Type: Direct HireDuration: Full TimeWork Location: Denver / HybridPay: Based on experienceOther: PTO, Medical, Dental, Vision, Disability, Life, 401k benefits available Thank you in advance for your interest in this opportunity!If you are able to work on a W2 basis without sponsorship for ANY US employer and fit the description above, please apply. Third-Party Applications Not Accepted.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Hi,Hope you are doing well,We at Software Technology Inc. hiring for a Data Engineer/Data Analyst, role, if you are interested and a good fit, feel free to reach me directly at ksuresh@stiorg.com or (609) 998-3431.Role : Data Engineer/Data AnalystLocation : RemoteSkillGCP Big Query, Python, SQL and knowledge of Healthcare domain\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'adQuadrant helps DTC (direct-to-consumer) brands dream bigger. We are a trusted advisor that provides holistic, strategic omni-channel digital marketing solutions by partnering with our clients to solve the biggest challenges in terms of customer acquisition and growth. Our efforts produce tangible results backed by measurable data. We have the strategic capabilities, quantitative chops, deep creative understanding, and world-class talent with the best tools to drive revenue and profits. We are not simply a vendor checking boxes — our seasoned team serves as an extension of the companies we work with, leading strategy and execution. Our goal is to be the go-to marketing consultants for solving the biggest challenges.adQuadrant is looking for a Data Engineer to support a growing team. This role is responsible for developing, testing, and maintaining data pipelines and data architectures. You will be building and optimizing our data pipeline architecture, as well as optimizing data flows and collections for cross functional teams. The ideal candidate will enjoy optimizing data systems and building them from the ground up, you must be ready for a challenge. This role will ensure optimal data delivery architecture is consistent throughout current and ongoing projects. You must be a self-starter and enjoy supporting multiple cross-functional teams.The Ideal Candidate must have: Experience in Snowflake, architecting and building a data warehouse from scratchData pipeline (ETL tools) development and deployment experienceExtensive experience deploying and maintaining a Tableau ServerRequirementsYour Responsibilities: Consulting with the data team to get a strong understanding of the organization’s data storage needsDesigning and constructing the data warehousing system to the organization’s specificationsDefining and implementing scalable data pipelines that ingest data from various external sources, storing it in the database system, and making it useful to our data analystsImplementing processes to monitor data quality, ensuring production data is always accurate and available for data analysts and business processes that rely on itRecognize, troubleshoot, and resolve unexpected performance and process fail issues, on an ongoing basisQualifications:Bachelor’s degree in computer science, information technology, or a related field5+ years experience in data warehousing, data modeling and building data pipelinesExtensive knowledge of SQL, and coding languages, such as PythonProficiency in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDWProven work experience as an ETL developerExperience working with online marketing dataStrong project management skills and experience with Agile engineering practicesAbility to analyze a company’s big-picture data needsClear communication skillsStrategic thought and extreme attention to detailAbility to troubleshoot and solve complex technical problemsComfortable supporting distributed remote individualsBenefitsOur people come first. No jerks. No egos. Just people who like to work hard and enjoy winning as a team.Annual Compensation: $95,000 - $120,000 per yearExcellent Health Benefits (health, dental, vision, and life insurance)401K + company matchUnlimited Vacation PolicyPaid Sick Leave2 Mindfulness Days Annually2PM Fridays each week$300/ year to equip your work space with new equipment$30/ month for home internetAn extremely supportive and fun company cultureWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Attune is making it easier, faster, and more reliable for small businesses to access insurance (think, pizza place down the street or main street store). They all need insurance to protect their businesses, but when it comes time to get a policy, they're bogged down by hundreds of questions, lots of paperwork, and a seemingly never-ending timeline stretching for weeks or months.We are changing all that. By using data and technology expertise to understand risk, automating legacy processes, and creating a better user experience for brokers, we're able to provide policies that are more applicable and more transparent in just minutes.Simply put, we're pushing insurance into the future, focusing on accuracy, speed, and ease.Our mission and our team are growing. In staying true to our values, we've earned our spot on many workplace award lists. Attune is dedicated to creating a diverse team of curious, focused, and motivated people who are excited about changing the future of an entire industry.Job DescriptionAs a Data Engineer joining our growing Data team, you will help maintain our existing data pipelines and internal web applications. You will also work with team members across the organization to develop and test new pipelines as we launch new products and integrate with third-party data sources. We work with various tools including Python/Pandas, Postgresql, Bash, AWS EC2, and S3. We are always open to using whatever tool is best for the job.Responsibilities:Maintain and improve batch ETL jobs - including SQL query optimization, bug fixes and code improvementsWork with our data engineers, BI, and other teams across the business to develop/refine ETL processesUnderstand and answer questions on the data our team maintainsQualifications:3+ years experience in analytics, data science, or data engineering roleStrong Python and Postgresql skillsSolid understanding of relational database design and basic query optimization techniquesExperience working with git, and Gitlab or GithubNice to have:Experience with Linux CLI, shell programmingUnderstanding of CI/CDExperience with AWS EC2 and S3What we offer you:140-170k per yearUnlimited PTOGenerous parental and caregiver leave401K matchExcellent medical, dental, and vision plansRemote-first cultureAnd more!\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Do you love to work with data, finding ways to make it reportable, and building models that will add clinical and commercial value for the future?Do you want to bring your skills and experience to a growth stage engineering team, and help set us up for smart expansion?Are you excited by the prospect of having a high-visibility high-impact role in a fast-moving startup?Are you passionate about healthcare, and looking to create a revolutionary new approach to digestive healthcare with a radically better patient experience?If so, you could be a perfect fit for our team of like-minded professionals who share a common mission and passion for helping others and a desire to build a great company.Oshi Health is revolutionizing GI care with a virtual clinic that provides easy, convenient access to a multidisciplinary care team including a GI Physician, Registered Dietician, Mental Health Professional, and Health Coach that takes a whole-person approach to diagnosing, managing and treating digestive health conditions. Our care is built on the latest evidence-based protocols and is delivered virtually through an app, secure messaging and telehealth visits with the care team. NOTE: Oshi is a fully remote company, with team members all over the US.What You’ll Do:This role will be a perfect fit if you enjoy learning the entire stack and taking on interdisciplinary challenges. A primary focus will be building out a data engineering program, including ETL, data governance, sanitization, and data operations. This part of your responsibilities will be a balance of executing data operations, and building automation to make those operations scalable.You will also have the opportunity to join engineers on the frontend end (React Native and React.js), backend (Node.js Lambdas) and Salesforce to help build the Oshi platform. Experience with any of these technologies is a plus, but more important is an enthusiasm to adapt and learn the ones that are new to you.What you’ll do: build the Oshi data programImplement and maintain data pipelines using Stitch, Databricks, and other scripting as needed to feed a PostgreSQL schema supporting Tableau reportingSupport users of Tableau by updating data sources or modifying inbound inputs as needed deliver critical BI reportsOwn the Oshi data model, ensuring that new features built and new technologies adopted serve the needs of the clinical, commercial, product, and engineering teamsManage ETL of client eligibility files and other data, to make them available for Oshi use in a secure and timely manner. Wherever possible, replace bespoke processes with automationOnce you have a understanding of Oshi’s requirements, design and implement a data strategy, (with your recommendation of approach and products,) to meet the needs of Oshi’s analytics, commercial, and clinical business linesYour work will also include:AWS maintenance and administration Writing technical documentation to outline designs for forthcoming features, outlining the implementation across all technology layersMeeting with colleagues in Strategy, Product, and Clinical to support their needs from the Engineering group.Production support responsibilities (shared with the entire engineering team) responding to alerts in Datadog, reviewing and troubleshooting issuesOur tech stack:Mobile Platforms Supported: iOS & AndroidCross-Platform Mobile Language: React NativeOther Languages: React-js, HTML, CSS, Java (Salesforce Apex), Node.js (Lambda)Systems: Salesforce, AWS Amplify / Cognito / LambdaYour Profile:A minimum of 3+ years of professional experienceBachelor's Degree or equivalent experienceGood interpersonal and relationship skills that include a positive attitudeSelf-starter who can find a way forward even when the path is unclear.Team player AND a leader simultaneously.What You’ll Bring to the Team:Passionate about creating value that changes people's livesMake low-level decisions quickly while being patient and methodical with high-level onesAre curious and passionate about digging into new technologies with a knack for picking them up quicklyAdept at prioritizing value and shipping complex products while coordinating across multiple teamsLove working with a diverse set of engineers, product managers, designers, and business partnersStrive to excel, innovate and take pride in your workWork well with other leadersAre a positive culture driverExcited about working in a fast-paced, startup cultureExperience in a regulated industry (healthcare, finance, etc.) a plusand perks:We’re revolutionizing GI care — and our employees are driving the change. We’re a hard-working and fun-loving team, committed to always learning and improving, and dedicated to doing the right thing for our members. To achieve our mission, we invest in our people:We make healthcare more equitable and accessible:Mission-driven organization focused on innovative digestive careThrive on diversity with monthly DEIB discussions, activities, and moreVirtual-first culture: Work from home anywhere in the USLive our core values: Own the outcome, Do the right thing, Be direct and open, Learn and improve, Team, Thrive on diversity We take care of our people:Competitive compensation and meaningful equityEmployer-sponsored medical, dental and vision plans Access to a “Life Concierge” through Overalls, because we know life happensTailored professional development opportunities to learn and growWe rest, recharge and re-energize:Unlimited paid time off — take what you need, when you need it13 paid company holidays to power downTeam events, such as virtual cooking classes, games, and moreRecognition of professional and personal accomplishmentsOshi Health’s Core Values:Go For ItDo the Right ThingBe Direct & OpenLearn & ImproveTEAM - Together Everyone Achieves MoreOshi Health is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.Powered by JazzHRFRVWJuzRKn\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Position SummaryThe position will focus on helping build and maintain backend integrations of our various systems (e.g., Financial System, HR System, CRM System), including Data Warehouse archiving and synchronizing. The position will also work with our Business Intelligence team to develop views/queries/tables to power Tableau Dashboards used throughout various venture capital investment lifecycle stages. Secondarily, the position will also maintain custom internal applications utilizing data from our Data Warehouse and various systems.Basic Job ResponsibilitiesImplementing processes that are fault-tolerant, resilient, and efficient in Databricks and AWS LambdaWriting clean code that is maintainable and easy to understandParticipate in code reviewsMaintain custom application plugins in WordPressUpdate our project management system, JIRA, with notes, questions, and feedback on current and future tasksBasic Job RequirementsRecent Graduate with a degree or related studies in computer science, math, or other technical field (e.g., applied mathematics, statistics, physics or engineering)Prior internship experience in similar field will be highly preferred Experience with programming languages such as Python or PHPExperience with SQL databases such as MySQL or PostgreSQLExperience with a source control system, such as GitOptional experience with Databricks, WordPress, JIRA, Cloud Computing, such as AWS Lambda/S3Ability to working in a variety of code bases and production environments.Good problem-solving skills and the ability to think of solutions.Good verbal/writing skills for explaining your work to others.Passion to grow in the role to take on AI/ML projectsCuriosity for technology and a desire to learn new skills, frameworks, and programming languages.Interest in learning financial terminology and concepts used in the Venture Capital MarketWe offer hybrid work, where most of the time will be done remote, although you are required to go into the office once a week or soThis role can be based in Los Angeles, New York and San FranciscoAt B Capital, the health and safety of our people is our number one priority. As a condition of employment all new hires are required to be fully vaccinated against Covid-19 and must show proof of such vaccination. About b CapitalB Capital is a multi-stage global investment firm that partners with extraordinary entrepreneurs to shape the future through technology. With $6.3 billion in assets under management across multiple funds, the firm focuses on seed to late-stage venture growth investments, primarily in the enterprise, financial technology and healthcare sectors. Founded in 2015, B Capital leverages an integrated team across eight locations in the US and Asia, as well as a strategic partnership with BCG, to provide the value-added support entrepreneurs need to scale fast and efficiently, expand into new markets and build exceptional companies. For more information, click here.b Capital Group Core ValuesB Honest & Trustworthy - Our people and our culture are the heart of our business. We are self-aware, supportive, and trust ourselves and each other. We speak the truth with positive intent. We hold ourselves accountable, are intellectually open, and are constantly learning and growing.B Open & Inclusive - Our diverse composition gives us broad and varied perspectives that drive better investments. We find ways to better ourselves and our communities, increasing transparency, fairness, and respect in every interaction. We thrive on the unique qualities of our people, and how together, these qualities make us special.B Collaborative - We believe in we vs I, and operate as one global team. We know that no one person has all the answers, and that we are better together. Our successes and failures are equally shared.B Bold - We take risks and understand that at times we may fail. We learn from our failures; we don’t repeat them and are constantly striving to be better.B Humble - We are humble and believe in winning together with gratitude, knowing that every finish line is the beginning of a new race. We are low ego, and lift each other up.B Persistent - When we get knocked down, we rise back up. We persevere, with the enduring perspective that only grit can help us overcome. We know our individual and collective goals and won’t stop short of achieving them.B Evolving - We innovate and advocate with boundless curiosity and creativity. We always have a startup mentality.Salary Range for NY & CA Candidates only. The actual salary will commensurate according to relevant experience. Salary expected range: $80,000 - $110,000\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Computer vision plays an indispensable role in modern VR experiences, providing headset and controller tracking, eye and hand tracking, 3D environment understanding, amongst others. Computer vision engineers at Valve are working on all those areas to help us achieve the next steps in VR with millions of customers world-wide.Across the computer vision engineering group, we contribute in a variety of ways: Collaborate to define product goals  Participate in conceiving, designing, and evaluating VR hardware  Develop software (in particular computer vision related) Computer vision engineers at Valve have significant industry experience. Members of our team typically have proven professional software development experience in C/C++, and have both deep understanding and hands-on experience in 3D vision algorithms, SLAM tracking, amongst others. Our team includes and looks for individuals with expertise in one or more of the following areas: SLAM/VIO/sensor fusion, visual positioning or other related directions 3D vision algorithms (traditional, deep learning based, or both - including SFM, MVS(Net), NeRF or other 3D reconstruction methods.  Object detection and tracking, 3D pose estimation or other related directions Human subject awareness, including hand tracking, eye tracking, and body tracking  Apply now!What We OfferAn organization where 100% of time is dedicated as groups see fitThe opportunity to collaborate with experts across a range of disciplinesA work environment and flexible schedule in support of families and domestic partnershipsA culture eager to become stronger through diversity of all formsExceptional health insurance coverageUnrivaled employer match for our 401(k) retirement planGenerous vacation and family leaveOn-site amenities in support of health and efficiencyFertility and adoption assistanceReimbursement for child care during interviews\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Machine Learning Engineer , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job Requirements2 years of experience, or an advanced degree (MSc).Experience in applied Deep Learning (DL) and Computer Vision (CV) concepts including but are not limited to: CNNs, RNNs, Autoencoders, Transfer Learning.Hands-on experience (academic and/or industrial) in 3D Pose Estimation and Motion reconstruction from images and videosProficiency in general purpose programming languages: Python, and C++.Experience with ML frameworks such as: PyTorch, Tensorflow, etc.The ideal candidate would be very well acquainted with Computer Graphics techniques, Neural Rendering, and Numerical Optimization(Optional) Knowledge of 3D packages such as Blender, Maya, or any game engine technologyBSc in Computer Science, Mathematics, Electrical Engineering, or related technical field.Ability to speak and write in English fluently and idiomatically.Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatment.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Build the Path ForwardAt Path Robotics, we're attacking a trillion dollar opportunity - doing things that have never been done before to support an industry hurting from a lack of skilled labor. Big, hard problems are what Path tackles every day and our people are our greatest asset to get that job done. Our intelligent, hardworking team of people do the impossible every single day, yet remain incredibly kind, humble, and always ready to support one another.Our Computer Vision Engineers work to develop, evaluate, and release computer vision algorithms into production software. The role will focus on object recognition, localization, and adaptive filtering. You will report to the CV Team Lead and will join a team of dedicated, supportive, and enthusiastic people to help create the future of manufacturing. Come solve the hardest problems with the best team on the planet!What You'll DoDevelop and implement methods to quickly and accurately localize highly occluded objectsTest and evaluate current state-of-the-art methods used for scene segmentationWork towards learning based approaches requiring less data3D Point cloud matching and manipulation Stay abreast of new research and novel findings in the fields of computer vision and machine learningPartner with our other engineering teams in artificial intelligence, robotics, and software engineeringWho You AreYou have a PhD or MS in computer vision, deep learning, or something strongly relatedYou have 5+ years of research experience in developing novel computer vision algorithms or similar methods based on deep learning in such topics as image recognition, image segmentation, stereo pixel matching, geometric deep learning, object recognition using 3D spatial data. You have a solid understanding of 3D reconstruction and meshingYou have 2+ publications in computer vision fieldYou are proficient in Python and C/C++You have hands-on experience in computer vision and deep learning frameworks such as OpenCV, Tensorflow, and PytorchYou are comfortable with Git and Linux You are familiar with parallel computing, such as GPU/CUDA programmingYou are familiar with structure from motion and visual odometryYou are familiar with Kalman filter and particle filterYou are excited by the opportunity to be a part of a venture-backed company early on, where your work will have an immediate and direct impactYou are passionate about what you do and enjoy working in a collaborative environmentWho We AreAt Path Robotics we love coming to work to solve interesting and tough challenges but also because our ideas are welcomed and valued. We encourage unique thinking and are dedicated to creating a diverse and inclusive environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.To continue to keep our team safe as we navigate the pandemic, we are requiring all in office staff to submit and validate their vaccination status. Why You'll Love It HereFree lunch every dayFlexible PTOMedical, Dental and Vision insurance 6 weeks 100% paid parental leave plus an additional 6-8 weeks maternity leave for the birthing parent (12-14 weeks total)401K through EmpowerPaid Referral BonusJob Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning engineer to work closely with our product and research teams to develop SOTA deep learning software. This person will work closely with our technical and research teams to develop training and deployment pipelines, implement model compression algorithms, and productize deep learning research. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to build machine learning productsPrototype and implement appropriate ML algorithms, tools, and pipelinesCreate and manage training and deployment pipelinesCollaborate with a cross-functional team about market requirements and best practicesKeep abreast of developments in the fieldRequirementsProven experience as a machine learning engineer or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityBachelor's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Computer Vision / ML Engineer (All Levels)AIM is a well-funded, mission oriented startup focused on radically scaling our civilization’s capabilities to build planetary-scale infrastructure and reverse negative effects of climate change. ( https://aim.vision )We are growing the team with motivated individuals with a passion for landing great products built with a strong engineering culture. If you find massive robots making a positive impact in the real world tantalizing, get in touch! ( https://www.aim.engineer )AIM has been built by a team of engineers, scientists, and serial entrepreneurs who previously led development of ML systems at Google, Waymo, Tesla, Apple, Google[x], Quora, Facebook and Microsoft, and are backed by General Catalyst, Human Capital, Elad Gil, Qasar Younis, Ironspring Ventures, DCVC, among other great allies.Responsibilities:Advance AIM’s perception stack and sensor fusion algorithmsThis involves breaking new ground as earth moving machines don’t merely navigate on existing mapped roads – they modify and build the environment as they work which poses interesting novel challengesResearch and development of state-of-the-art machine learning methodsComfortable with hands-on applications on machines deployed in the fieldQualifications: Proven track record of deployed ML-based perception systems, ideally on autonomous vehiclesExcellent grasp of machine perception methods and concepts, involving 2D and depth sensingExperience shipping production modelsSolid mathematical foundation of machine learningExcellent software development skills in pythonProficiency in Tensorflow and PyTorchCreativity and curiosity for solving complex problemsIdeal candidate will have expertise in reinforcement learning, and robotics, and C++What we offer:Opportunity for rapid growth and have a large voice on the direction of the companyMedical, dental, vision, 401k matching & life insuranceA position with AIM is a hybrid remote and onsite flexible expectation with a strong preference for onsiteOpportunity to travel to deployment sites around the world (US, Australia & more!)AIM is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status.AIM Intelligent Machine's General Privacy Policy: https://aim.vision/privacy/index.html\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"We are looking for an immediate hire for a computer vision engineer. Must be comfortable working on fast-paced environment and exhibit ability to balance a sense of urgency moving from R&D to deployment. You will be actively involved on one or more of these areas:Explore new vision algorithms/strategies for proof of concept assessment using vision development environmentHelp to develop more tools to enhance the capability of existing automated vision software test frameworkHelp conceive proof-of-concept prototypes that establish overall system performance You have...Bachelor's degree in Computer Science/Electrical Engineering. Master's/PhD is a plusAt-least 1+ experience in building production computer vision and imaging algorithms for image processingExpertise in at least one area of computer vision, machine learning, and computer graphics (e.g. object detection, tracking, segmentation, AR/VR, image and video processing, 3D geometry, multi- view geometry, simulation, graphics rendering)Must have strong fundamentals in computer vision concepts like intrinsic and extrinsic calibrations, homogeneous coordinates, projection matrices, and epipolar geometry. Strong coding skills in Python or C/C++Total comfort working in a Linux environmentsYou have extensive experience in OpenCV or other computer vision libraries. Preferred:Track record of publishing in top-tier computer vision or machine learning conferences or/and journals. Prior industrial experience in retail environment. Exposure to CUDA or OpenCL is preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ML - Handson Tensorflow Dev -ML pipeline and process -Strong python coding skills -Experience in deploying models -API development -Flask or Django experience\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'BioMap is a platform company that integrates AI technology with cutting-edge biotechnology. We are committed to achieving breakthroughs in target discovery and drug design, and bringing global first-in-class medicine for unmet medical needs in the areas of immune-oncology, autoimmune diseases, fibrosis, and aging-related diseases.Location: Menlo Park. This role is preferably based in The Bay Area, but we are open to discussing other locations in the United States.Keywords: drug/protein design, structural biology, computational biology, protein folding, protein design, protein-ligand interactionYou will:Utilize bioinformatics tools into drug/protein design workflow and develop computing protocols for drug/ protein design Transforming research work research, open-source models, and prototypes into production-level pipelineDesign and apply innovative computational/ statistical algorithms (including classic, statistical, ML, and AI techniques) to generate actionable biological insightWork closely with the department lead to design and optimize protein design-related algorithms Requirements:PhD degree with research experience in bioinformatics, protein folding, protein design, protein-ligand integration is highly preferred; Or MS degree in computational biology, structural biology, or related fields, plus 2+ years of industry experienceProficient in at least one programming language, including but not limited to Python, C/C++, Java, etc. Familiar with machine learning and deep learning frameworks (e.g. Pytorch, Tensorflow, etc.)Familiar with Alphatfold, ESMfold, RFdesign, and ProteinMPNNGreat communication skills, including code documentation, oral presentation, with excellent attention to details What we offer:The opportunity to work on high-impact tools and products that are immediately deployed to accelerate the discovery of new medicinesA strong team in AI, software, and biochemistryCompetitive salary and equity401(k) plan with generous employer matching for contributionsExcellent medical, dental, and vision coverageDaily lunch and a full snack stationCommuter benefitsBioMap is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Software Engineer - Machine Vision Application - (C#, C++,Python, OpenCV) (Onsite position in Auburn Hills, Michigan) Founded in 1994, Inovision offers automation and robotics products for automating manufacturing processes using AI, Industrial Internet of Things (IIoT) devices, and Big Data analysis. We are developing new applications to scan and analyze automobiles and other surface inspections during the automation process. Our automotive applications control factories for Tesla, Ford, Toyota, and Mercedes using IoT methods paired with AI algorithms. This position is for a strong image processing and AI software engineer. We are developing new products to scan and analyze automobiles and other surface inspection during the automation process. This job involves an understanding of cameras, lights, image processing and large scale software design. The candidate should have a solid electrical engineering or computer science background with strong image processing/AI skills. You must love to write code in C++, OpenCV, C# and Python. Highly motivated individuals who are good at working in a group or alone are desired. We use the latest technologies, OpenCV, Python, WPF, C#, C++. This is a great opportunity to stay up to date with the latest development tools. Job Description * Onsite position in Auburn Hills, MI. Some travel will be required to factories for debug. * Develop software in Microsoft C#/C++, OpenCV based on project requirements * Develop image processing algorithms in multi threaded windows environment Requirements * Solid engineering or computer science background * Motivated, intelligent, and hard-working * Excellent communication skills * Willingness to travel occasionally * Attention to detail * Legally authorized to work full-time in the United States and travel internationally as needed * Must be skilled in C#/C++ and OpenCV and multi threaded real time application development * Development may include some embedded system development, windows application development, multi-thread applications, and AI. To show your interest in this position, please explain why you would like to relocated to Michigan and which of the skills above you have expertise in to make you successful in this position! Health Benefits with Blue Cross Blue Shield PPO and matching IRA contributions are just some of our benefits! We offer great pay with 1.5x when working overtime! Other Information * Inovision is an equal opportunity employer. * Candidates must be able to perform the essential job functions with reasonable accommodation. * Employees must maintain a mobile phone and valid driver's license. * Candidates will be required to write a sample program during the interview process. * All candidate information will be kept confidential according to EEO guidelines. Company Description Growing leader in industrial vision and robotic integration for automotive and general industry.Growing leader in industrial vision and robotic integration for automotive and general industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Mujin's new US office is expanding rapidly, and to sustain that growth we're building a whole new branch of our world-class computer vision team.As a Computer Vision Engineer, you will be a part of the Mujin R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition. You will work directly with and expand on the world’s first 3D vision system for factory automation and logistics solutions.You will work directly with global leaders in applied computer vision, solving the kind of problems that haven't even been asked on Stack Overflow yet -- let alone answered.ResponsibilitiesSolve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenariosAnalyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from both academic and industrial research, and implement and enhance them in a production environmentDesign, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications in Python and C/C++Perform detailed tests, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithmsMinimum RequirementsGraduating/graduated from Computer Science or relevant faculty with a BS, MSc or Ph.DBS or MS with computer vision experience, or Ph.D. in Computer Vision related topicsAbility to develop applications and tools in Python and/or C++Technical communication skills in English (reading and writing)Preferred Experience3D pose estimation of textured and texture-less objects in cluttered scenesExtensive Python and C++ development experienceBroad experience with computer vision librariesMathematical backgroundPrevious contributions to open source projectsIt would be amazing if you have experience in: object tracking, SLAM, computer graphics, augmented reality, machine learning, or robotics projectsAbout The RoleYou'll work directly with researchers from the world’s top-tier universities and labs in robotics, computer vision, and image and signal processing. The team includes Ph. D. and MSc grads from Carnegie Mellon, Stanford, and more. Mujin has the most active real-world deployments of industrial computer vision systems. That means you won't be working in a vacuum--you'll have access to the largest set of customer feedback data in this industry globallyOur computer vision algorithms are robust enough to run on 24/7 systems, handling thousands of items per customer, for diverse customers and applications. The challenges of enlarging its capabilities toward more autonomy, scalability, and diversity of applications mean you will never stop learning at MujinWe're a well-established startup entering a global scale-up phase. That means we have enough structure so you can focus on computer vision, but not so much structure that you can't spread your wings. Come grow with us!If you would like to apply real-time computer vision algorithms to robotics and join the industrial automation revolution, this role is for you!Check out our blog for more information about Mujin's work culture! You can meet our dual-Ph. D. Computer Vision team manager, Jeronimo, here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"WHO ARE WE?Our team is the first in the world to use autonomous vehicles on public roads using end-to-end deep learning, computer vision and reinforcement learning. Leveraging our multi-national world-class research team we're focusing on using less data to learn more intelligent algorithms to bring autonomy for everyone, everywhere. We aim to be the future of self-driving cars, not vehicles that are told how to drive through hand-coded rules and maps, but ones which learn from experience and data.WHERE YOU'LL HAVE AN IMPACTWe're looking for bold, talented and creative people to join our journey in developing next-generation autonomous vehicles. We're a growing start-up, building our first cohort of engineers and you can be at the heart of this!We are looking for ML Engineers to help productionize an end-to-end self driving neural network for autonomous driving. You'll be working closely with Platform and Research teams to integrate, test and scale ML features for production. Productionizing and scaling our ML models by working across Data, Validation, Platform and Research is a core component of this role and why we need you!What You'll Bring To WayveExperience in shipping ML features and in applied researchPassion to take research ideas to productionGood grasp of machine learning literatureExperience in working in platform teams and working with research teamsGood insight into the training, validation, testing and metrics for deep learning features/modelsAbility to write high quality, well-structured and tested Python codeSolid experience working with concurrent, parallel and distributed computingComfortable working with and visualising huge data setsKnowledge of computing fundamentals - what makes code fast, secure and reliableBS or MS in Machine Learning, Computer Science, Engineering, or a related technical discipline or equivalent experienceWhat We Offer YouAttractive compensation with salary and equityImmersion in a team of world-class researchers, engineers and entrepreneursA unique position to shape the future of autonomous driving and to tackle the biggest challenge of our timeBespoke learning and development opportunitiesRelocation support with visa sponsorshipFlexible working hours - we trust you to do your job well, at times that suit you and your teamPrivate on-site chef, in-house bar, lots of socials, and more!Wayve is built by people from all walks of life. We believe that it is our differences that make us stronger, and our unique perspectives and backgrounds that allow us to build something different. We are proud to be an equal opportunities workplace, where we don't just embrace diversity but nurture it - so that we all thrive and grow.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Fast-growing AI company is seeking highly-qualified scientists and engineers with experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to address real-world challenges in the Health Care industry. If you have a successful track record in software development, knowledge of current software technologies and methodologies, and excellent communication and interpersonal skills, we want to talk with you. Experience with image processing technologies is a plus.Desired skills:Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsExperience working with Xray images (medical/dental) or in the medical domain a plus.Familiarity with Java and Python a plusProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusComfortable working within a team as well as heading up your own research initiativesResponsibilities may include:Understanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing DL algorithms that could be used to solve a given problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themWhy work for NovoDynamics?Be part of a dynamic team that designs disruptive technologies for the Health Care industryReceive great compensation and benefitsWork in downtown Ann Arbor near the University of Michigan campusEnjoy free parking, popcorn, coffee, tea and soft drinks Delight in an amazing work environment with interesting and engaged teammatesRelax with generous and flexible time off\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This position is participating in our  External Referral Program. If you know somebody who may be a fit, click here to submit a referral. If your referral is hired, you'll receive a $3,000 payment!code-extreferThere are people who say some ideas are impossible, unattainable or unrealistic. Then there are those of us who work at Lockheed Martin Rotary and Mission Systems. As a part of the Lockheed Martin community, we take on the biggest, baddest challenges in the world and find solutions using creativity and collaboration.AND WHERE THE SOLUTIONS DON’T EXIST? WE INVENT THEM.So, if you’re looking for the challenge of a lifetime and a team of the brightest minds in the world, Rotary and Mission Systems is the place for you. If you’re looking for a place where learning is a way of life, Rotary and Mission Systems is the place for you. And if you’re looking for a career that’s just as fun as it is hard work, well…you know.Join us today and let’s make a difference together.Lockheed Martin. Your Mission is Ours.ABOUT OUR MISSION (https://www.lockheedmartin.com/en-us/who-we-are/business-areas/rotary-and-mission-systems.)At Lockheed Martin Rotary and Mission Systems, Cyber & Intelligence, we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and forward-thinking, everything is within our reach – and yours as Lockheed Martin employee. Lockheed Martin values your skills, training and education. Come and experience your future!The Software Engineer develops, maintains, and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of very large data sets, real-time systems, and business management information systems) based upon documented requirements. Works individually or as part of a team. Reviews and tests software components for alignment to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific guidance to the software components of system design to include hardware/software trade- offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new.NOTE: This position requires an active Department of Defense TS/SCI W/ Security and US citizenship for selection.Benefits Of EmploymentWe may not know what's going to change the world next, but chances are we're already working on it, and you can, too. As part of our culture of innovation, you’ll have excellent benefits and amenities, an inclusive work environment, ongoing career development and support, rewards and recognition to honor your hard work, and more.Here Are Some Of The Benefits You Can Enjoy Medical Dental 401k Paid time off Work/life balance Career development Mentorship opportunities Rewards & recognitionLearn more about Lockheed Martin’s competitive and comprehensive benefits package.Lockheed Martin’s competitive and comprehensive benefits package. (https://www.lockheedmartinjobs.com/working-here#benefits)We support our employees, so they can support our mission.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityResponsibilities:As the Geometric Computer Vision Engineer you will need to develop computer vision algorithms for object detection, tracking, and classifications that are robust to lighting and weather changes. This work requires that you collaborate with state estimation engineers and assist in developing powerful feature detectors/ descriptors and large-scale 3D maps. Furthermore, it is expected that you stay organized and communicative with others to ensure that goals and objectives are being met on time. To guarantee the consistency of projects, you will participate in end-to-end development and training in Cloud to optimize development on embedded platforms.Required Qualifications:3-5+ years' significant industry experience and/or publications at venues such as ICRA, RSS, IROS, or CVPR in one or more areas- Image Processing Geometric Computer Vision Deep Learning (ideally CNNs) Classical machine learning such as SVM, decision trees, boosting, graphical models, sequential prediction, or sampling methodsStrong C++ programming and software design skillsFamiliarity with a deep learning framework such as PyTorch, TensorFlow, Caffe, or TheanoBS, MS, or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering, a related field, or equivalent experienceDesired Qualifications: Experience deploying CV/ML in a robot or real-time applicationUnderstanding of optimization of DL models and deployment on embedded platforms such as the Nvidia JetsonExperience in designing large-scale machine learning pipelinesCompensation:90,000-220,000Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Computer vision plays an indispensable role in modern VR experiences, providing headset and controller tracking, eye and hand tracking, 3D environment understanding, amongst others. Computer vision engineers at Valve are working on all those areas to help us achieve the next steps in VR with millions of customers world-wide.Across the computer vision engineering group, we contribute in a variety of ways: Collaborate to define product goals  Participate in conceiving, designing, and evaluating VR hardware  Develop software (in particular computer vision related) Computer vision engineers at Valve have significant industry experience. Members of our team typically have proven professional software development experience in C/C++, and have both deep understanding and hands-on experience in 3D vision algorithms, SLAM tracking, amongst others. Our team includes and looks for individuals with expertise in one or more of the following areas: SLAM/VIO/sensor fusion, visual positioning or other related directions 3D vision algorithms (traditional, deep learning based, or both - including SFM, MVS(Net), NeRF or other 3D reconstruction methods.  Object detection and tracking, 3D pose estimation or other related directions Human subject awareness, including hand tracking, eye tracking, and body tracking  Apply now!What We OfferAn organization where 100% of time is dedicated as groups see fitThe opportunity to collaborate with experts across a range of disciplinesA work environment and flexible schedule in support of families and domestic partnershipsA culture eager to become stronger through diversity of all formsExceptional health insurance coverageUnrivaled employer match for our 401(k) retirement planGenerous vacation and family leaveOn-site amenities in support of health and efficiencyFertility and adoption assistanceReimbursement for child care during interviews\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'About The CompanyFocused on the future of filmmaking, Wonder Dynamics is an LA-based start up founded by Actor/Producer, Tye Sheridan who’s starred in films like Ready Player One, X-Men: Apocalypse, Mud and VFX Supervisor/Filmmaker Nikola Todorovic. Their mission is to revolutionize the production and post-production process by leveraging state-of-the-art AI. They are striving to democratize the use of visual effects which will pave the way for the next generation of filmmakers. That mission attracted some of the most influential individuals in the film and tech industry that are now involved in their team.Wonder Dynamics is backed by Epic Games, Samsung, Horizons Ventures (a Hong Kong VC firm with early investments in Skype, Siri, Facebook and more) and Founders Fund, a leading Silicon Valley VC that funded some giants like Space X, Facebook, Spotify, DeepMind, etc.)Their Advisory Board consists of leaders in Hollywood and Silicon Valley:Joshua Baer, founder/CEO of Capital Factory;Terry Dougas, Producer and financier of Film and TV. Founder of Rhea Films,1821 MediaAngjoo Kanazawa, assistant professor at UC Berkeley and Google research scientist;Joe Russo Director, screenwriter, and Producer (directed Avengers: Infinity War and Avengers: Endgame)Robert Schwab - Private equity investor, President, and CEO of R&L Properties.Steven Spielberg - Film director, producer, and screenwriterAntonio Torralba - Professor and Head of AI and Decision making, EECS, Massachusetts Institute of Technology (MIT).Gregory Trattner - President, Film Finances Inc. (World leader in completion guarantees and film services)About The RoleThe ideal candidate will bring passion for AI, innovative technologies, the film industry, and experience in the fields of computer vision and computer graphics with a focus on machine learning. You will design and implement cutting-edge machine learning algorithms in the fields of visual effects, motion capturing, rendering, as well as in many other film production areas.What We Are Looking For2 years of experience, or an advanced degree (MSc).Experience in applied Deep Learning (DL) and Computer Vision (CV) concepts including but are not limited to: CNNs, RNNs, Autoencoders, Transfer Learning.Hands-on experience (academic and/or industrial) in 3D Pose Estimation and Motion reconstruction from images and videos Proficiency in general purpose programming languages: Python, and C++.Experience with ML frameworks such as: PyTorch, Tensorflow, etc.The ideal candidate would be very well acquainted with Computer Graphics techniques, Neural Rendering, and Numerical Optimization(Optional) Knowledge of 3D packages such as Blender, Maya, or any game engine technologyBSc in Computer Science, Mathematics, Electrical Engineering, or related technical field.Ability to speak and write in English fluently and idiomatically.Why should you consider joining us?At the intersection of film and technology, this job will offer a very unique experience, and you will be exposed to a diverse set of fields spanning from film production and visual effects to AI, machine learning, and computer vision. Because we are operating in the state-of-the-art territory, there will always be something new to learn on the horizon. We highly value our team and the support of our co-workers and strive to create the best environment to work in.This is a mid- or senior-level engineering role and we offer a competitive salary, valuable stock options, and comprehensive benefits that allow individual flexibility for all employees to choose what makes the most sense for their personal situation.Wonder Dynamics is committed to a culture of flexibility, diversity, and fun for all of our employees. We are working on some of the most challenging technical problems and we know the solutions will come from all of us working together in an inclusive, transparent, and open manner.Powered by JazzHRvMco3jZC00\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Machine Learning Engineer , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job Requirements2 years of experience, or an advanced degree (MSc).Experience in applied Deep Learning (DL) and Computer Vision (CV) concepts including but are not limited to: CNNs, RNNs, Autoencoders, Transfer Learning.Hands-on experience (academic and/or industrial) in 3D Pose Estimation and Motion reconstruction from images and videosProficiency in general purpose programming languages: Python, and C++.Experience with ML frameworks such as: PyTorch, Tensorflow, etc.The ideal candidate would be very well acquainted with Computer Graphics techniques, Neural Rendering, and Numerical Optimization(Optional) Knowledge of 3D packages such as Blender, Maya, or any game engine technologyBSc in Computer Science, Mathematics, Electrical Engineering, or related technical field.Ability to speak and write in English fluently and idiomatically.Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatment.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Build the Path ForwardAt Path Robotics, we're attacking a trillion dollar opportunity - doing things that have never been done before to support an industry hurting from a lack of skilled labor. Big, hard problems are what Path tackles every day and our people are our greatest asset to get that job done. Our intelligent, hardworking team of people do the impossible every single day, yet remain incredibly kind, humble, and always ready to support one another.Our Computer Vision Engineers work to develop, evaluate, and release computer vision algorithms into production software. The role will focus on object recognition, localization, and adaptive filtering. You will report to the CV Team Lead and will join a team of dedicated, supportive, and enthusiastic people to help create the future of manufacturing. Come solve the hardest problems with the best team on the planet!What You'll DoDevelop and implement methods to quickly and accurately localize highly occluded objectsTest and evaluate current state-of-the-art methods used for scene segmentationWork towards learning based approaches requiring less data3D Point cloud matching and manipulation Stay abreast of new research and novel findings in the fields of computer vision and machine learningPartner with our other engineering teams in artificial intelligence, robotics, and software engineeringWho You AreYou have a PhD or MS in computer vision, deep learning, or something strongly relatedYou have 5+ years of research experience in developing novel computer vision algorithms or similar methods based on deep learning in such topics as image recognition, image segmentation, stereo pixel matching, geometric deep learning, object recognition using 3D spatial data. You have a solid understanding of 3D reconstruction and meshingYou have 2+ publications in computer vision fieldYou are proficient in Python and C/C++You have hands-on experience in computer vision and deep learning frameworks such as OpenCV, Tensorflow, and PytorchYou are comfortable with Git and Linux You are familiar with parallel computing, such as GPU/CUDA programmingYou are familiar with structure from motion and visual odometryYou are familiar with Kalman filter and particle filterYou are excited by the opportunity to be a part of a venture-backed company early on, where your work will have an immediate and direct impactYou are passionate about what you do and enjoy working in a collaborative environmentWho We AreAt Path Robotics we love coming to work to solve interesting and tough challenges but also because our ideas are welcomed and valued. We encourage unique thinking and are dedicated to creating a diverse and inclusive environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.To continue to keep our team safe as we navigate the pandemic, we are requiring all in office staff to submit and validate their vaccination status. Why You'll Love It HereFree lunch every dayFlexible PTOMedical, Dental and Vision insurance 6 weeks 100% paid parental leave plus an additional 6-8 weeks maternity leave for the birthing parent (12-14 weeks total)401K through EmpowerPaid Referral BonusJob Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Fresh Consulting is a design-led, software development and hardware engineering company, offering end-to-end digital services to help companies innovate. We bring together amazing UX designers, sophisticated developers, digital strategists, and top-notch engineers to help companies create fresh experiences that connect humans, systems, and machines. We’ve been growing fast and need someone to help us continue to manage the delivery of high-quality work in a fast-paced environment.See more at freshconsulting.com Visit freshconsulting.com/portfolio to see our project work across several industries.View and apply to all jobs - https://freshconsulting.applytojob.com/apply/ or visit freshconsulting.com/careersTitle: Computer Vision EngineerDuration: 1 year with possible extensionLocation: Onsite Redmond, WABenefits: Employee benefits at 100% including Medical, PTO, Holiday Pay, 401K Plan, and much more!Hours: Minimum 40 Hours/WeekRole Develop and implement computer vision algorithms that meet specific requirements. Define data collection methods and manage data acquisition for use in developing algorithms. Perform statistical analysis and use simulation or test datasets to validate the algorithm. Debug, test, and validate algorithms to ensure high-quality results. Develop geometric calibration algorithms including SLAM camera calibration, eye tracking camera calibration, inertial measurement unit calibration, and other sensors to be modeled. Use C++ to develop and optimize algorithms for real-time applications. Communicate effectively with cross-functional teams, including software engineers, hardware engineers, and data scientists. Participate in the design, development, and deployment of computer vision applications.Skills At least 3-5 years of experience in computer vision engineering or a related field. Proficiency in C++ and Python. Experience with 2D image processing, 3D geometry, and/or bundle adjustment. Experience with statistical analysis. Excellent communication skills, both verbal and written. Ability to work independently and in a team environment.Education: BSCSE or related.FRESH-- Work on engineering and research assignments with F500 companies and startups. The relationships that we have created with our clients are one of a kind. We help solve problems in many technologies focusing on R&D, product development, and manufacturing. We work with the most cutting-edge and latest technologies from AR/VR to Autonomous technologies. Closely working with our clients, we believe that long-term investments are extremely important to maintain the culture we together have created.We’re a handpicked team of Engineers, digital strategists, designers, and developers united together in creating a fresh experience. Whether we are strategizing, designing, developing, or analyzing, our integrated team works as an extension of yours to improve your impact, your usability, and your customer conversion. In the process, we collaborate with you to get to know your business, understand your industry, and incorporate your big ideas into memorable experiences that keep your customers coming back for more.Equal employment opportunity: All qualified persons will be considered for employment without regard to race, color, religion, sex, national origin, age, marital status, familial status, gender identity, sexual orientation, disability for which a reasonable accommodation can be made or any other status protected by law. Assistance will be gladly provided upon request for any applicant with sensory or non-sensory disabilities.Fresh Consulting is a participating E-Verify company.freshconsulting.comCompensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Range $75/hr - $85/hr.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"DescriptionHere at Hugging Face, we’re on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.We have built the fastest-growing, open-source, library of pre-trained models in the world. With over 130K+ models and 110K+ stars on GitHub, over 10 thousand companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, and Grammarly.About The RoleAs an ML engineer in vision, you will work mainly into existing open-source libraries, such as Transformers and Datasets to boost the support for vision or multi-modal models and datasets. You will bring your computer vision expertise to provide the best computer-vision tool stack in the machine learning ecosystem and work with us to provide the best, simplest, and most intuitive computer-vision library in the industry.You'll get to foster one of the most active machine learning communities, helping users contribute to and use the tools that you build. You'll interact with Researchers, ML practitioners and data scientists on a daily basis through GitHub, our forums, or slack.RequirementsAbout youIf you love open-source, are passionate about the new development of Transformers models in computer vision, have experience building, optimizing, and training such models in PyTorch and/or TensorFlow, serving them in production, and want to contribute to one of the fastest-growing ML libraries, then we can't wait to see your application!If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and backgrounds complement one another. We're happy to consider where you might be able to make the biggest impact.BenefitsMore about Hugging FaceWe are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer 12 weeks of parental leave (20 for birthing mothers) and unlimited paid time off.We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $100,000 - $125,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Software Engineer - Machine Vision Application - (C#, C++,Python, OpenCV) (Onsite position in Auburn Hills, Michigan) Founded in 1994, Inovision offers automation and robotics products for automating manufacturing processes using AI, Industrial Internet of Things (IIoT) devices, and Big Data analysis. We are developing new applications to scan and analyze automobiles and other surface inspections during the automation process. Our automotive applications control factories for Tesla, Ford, Toyota, and Mercedes using IoT methods paired with AI algorithms. This position is for a strong image processing and AI software engineer. We are developing new products to scan and analyze automobiles and other surface inspection during the automation process. This job involves an understanding of cameras, lights, image processing and large scale software design. The candidate should have a solid electrical engineering or computer science background with strong image processing/AI skills. You must love to write code in C++, OpenCV, C# and Python. Highly motivated individuals who are good at working in a group or alone are desired. We use the latest technologies, OpenCV, Python, WPF, C#, C++. This is a great opportunity to stay up to date with the latest development tools. Job Description * Onsite position in Auburn Hills, MI. Some travel will be required to factories for debug. * Develop software in Microsoft C#/C++, OpenCV based on project requirements * Develop image processing algorithms in multi threaded windows environment Requirements * Solid engineering or computer science background * Motivated, intelligent, and hard-working * Excellent communication skills * Willingness to travel occasionally * Attention to detail * Legally authorized to work full-time in the United States and travel internationally as needed * Must be skilled in C#/C++ and OpenCV and multi threaded real time application development * Development may include some embedded system development, windows application development, multi-thread applications, and AI. To show your interest in this position, please explain why you would like to relocated to Michigan and which of the skills above you have expertise in to make you successful in this position! Health Benefits with Blue Cross Blue Shield PPO and matching IRA contributions are just some of our benefits! We offer great pay with 1.5x when working overtime! Other Information * Inovision is an equal opportunity employer. * Candidates must be able to perform the essential job functions with reasonable accommodation. * Employees must maintain a mobile phone and valid driver's license. * Candidates will be required to write a sample program during the interview process. * All candidate information will be kept confidential according to EEO guidelines. Company Description Growing leader in industrial vision and robotic integration for automotive and general industry.Growing leader in industrial vision and robotic integration for automotive and general industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About AppliedAutonomy is one of the leading technological advances of this century that will come to impact our lives. The work you'll do at Applied will meaningfully accelerate the efforts of the top autonomy teams in the world. At Applied, you will have a unique perspective on the development of cutting-edge technology while working with major players across the industry and the globe.Applied Intuition provides software solutions to safely develop, test, and deploy autonomous vehicles at scale. The company's suite of simulation, validation, and drive log management software enables development teams to create thousands of scenarios in minutes, run simulations at scale, and verify and validate algorithms for production deployment. Headquartered in Silicon Valley with offices in Los Angeles, Detroit, Washington, D.C., Munich, Stockholm, Seoul, and Tokyo, Applied consists of software, robotics, and automotive experts with experiences from top global companies. Leading autonomy programs and 17 of the top 20 global OEMs use Applied's solutions to bring autonomy to market faster.About The RoleWe are looking for bright engineers interested in designing elegant solutions to difficult problems in the autonomy space. Our software engineers work across our suite of products, tackling a variety of full-stack, infrastructure, robotics, and graphics challenges. At Applied, we encourage engineers to take ownership over technical and product decisions, closely interact with users to collect feedback, and contribute to a thoughtful, dynamic team culture.At Applied you will:Work across our entire stack to develop new products, features, and tools for our customers' autonomy development workflowsHave an unparalleled opportunity to work with domain experts across a variety of fields: infrastructure, robotics, and graphics engineers, as well as startup veteransCarve out your own area of expertise and influence product decisionsCollaborate with other members in the autonomy ecosystem and learn about different approaches to solving core issues in autonomyWe're looking for someone who:Is a self-starter and can quickly become comfortable with new technical toolsDesigns efficient and effective solutions to a wide range of engineering challengesTakes initiative in a fast-paced environmentNice to have:Working knowledge of frontend, API layer, database ORM, containerization, or cluster orchestration frameworks (such as React, GraphQL, SQLAlchemy, Docker, or Kubernetes)Experience working with simulation tools, modeling physical problems, or using robotics middleware (such as ROS)Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Mujin's new US office is expanding rapidly, and to sustain that growth we're building a whole new branch of our world-class computer vision team.As a Computer Vision Engineer, you will be a part of the Mujin R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition. You will work directly with and expand on the world’s first 3D vision system for factory automation and logistics solutions.You will work directly with global leaders in applied computer vision, solving the kind of problems that haven't even been asked on Stack Overflow yet -- let alone answered.ResponsibilitiesSolve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenariosAnalyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from both academic and industrial research, and implement and enhance them in a production environmentDesign, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications in Python and C/C++Perform detailed tests, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithmsMinimum RequirementsGraduating/graduated from Computer Science or relevant faculty with a BS, MSc or Ph.DBS or MS with computer vision experience, or Ph.D. in Computer Vision related topicsAbility to develop applications and tools in Python and/or C++Technical communication skills in English (reading and writing)Preferred Experience3D pose estimation of textured and texture-less objects in cluttered scenesExtensive Python and C++ development experienceBroad experience with computer vision librariesMathematical backgroundPrevious contributions to open source projectsIt would be amazing if you have experience in: object tracking, SLAM, computer graphics, augmented reality, machine learning, or robotics projectsAbout The RoleYou'll work directly with researchers from the world’s top-tier universities and labs in robotics, computer vision, and image and signal processing. The team includes Ph. D. and MSc grads from Carnegie Mellon, Stanford, and more. Mujin has the most active real-world deployments of industrial computer vision systems. That means you won't be working in a vacuum--you'll have access to the largest set of customer feedback data in this industry globallyOur computer vision algorithms are robust enough to run on 24/7 systems, handling thousands of items per customer, for diverse customers and applications. The challenges of enlarging its capabilities toward more autonomy, scalability, and diversity of applications mean you will never stop learning at MujinWe're a well-established startup entering a global scale-up phase. That means we have enough structure so you can focus on computer vision, but not so much structure that you can't spread your wings. Come grow with us!If you would like to apply real-time computer vision algorithms to robotics and join the industrial automation revolution, this role is for you!Check out our blog for more information about Mujin's work culture! You can meet our dual-Ph. D. Computer Vision team manager, Jeronimo, here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"WHO ARE WE?Our team is the first in the world to use autonomous vehicles on public roads using end-to-end deep learning, computer vision and reinforcement learning. Leveraging our multi-national world-class research team we're focusing on using less data to learn more intelligent algorithms to bring autonomy for everyone, everywhere. We aim to be the future of self-driving cars, not vehicles that are told how to drive through hand-coded rules and maps, but ones which learn from experience and data.WHERE YOU'LL HAVE AN IMPACTWe're looking for bold, talented and creative people to join our journey in developing next-generation autonomous vehicles. We're a growing start-up, building our first cohort of engineers and you can be at the heart of this!We are looking for ML Engineers to help productionize an end-to-end self driving neural network for autonomous driving. You'll be working closely with Platform and Research teams to integrate, test and scale ML features for production. Productionizing and scaling our ML models by working across Data, Validation, Platform and Research is a core component of this role and why we need you!What You'll Bring To WayveExperience in shipping ML features and in applied researchPassion to take research ideas to productionGood grasp of machine learning literatureExperience in working in platform teams and working with research teamsGood insight into the training, validation, testing and metrics for deep learning features/modelsAbility to write high quality, well-structured and tested Python codeSolid experience working with concurrent, parallel and distributed computingComfortable working with and visualising huge data setsKnowledge of computing fundamentals - what makes code fast, secure and reliableBS or MS in Machine Learning, Computer Science, Engineering, or a related technical discipline or equivalent experienceWhat We Offer YouAttractive compensation with salary and equityImmersion in a team of world-class researchers, engineers and entrepreneursA unique position to shape the future of autonomous driving and to tackle the biggest challenge of our timeBespoke learning and development opportunitiesRelocation support with visa sponsorshipFlexible working hours - we trust you to do your job well, at times that suit you and your teamPrivate on-site chef, in-house bar, lots of socials, and more!Wayve is built by people from all walks of life. We believe that it is our differences that make us stronger, and our unique perspectives and backgrounds that allow us to build something different. We are proud to be an equal opportunities workplace, where we don't just embrace diversity but nurture it - so that we all thrive and grow.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'about the senior machine learning engineer role:soona is looking for a senior. machine learning engineer who will assume the primary responsibility of embedding our various machine learning models related to decision science, computer vision, and logistics optimization into robust production systems accessed by our internal stakeholders and external customers alike. you will work closely with our data scientists and engineers to build and maintain these products and services. to be successful in this role, you will understand the general methods of training machine learning models, how to serialize and deploy those models, and how to leverage the necessary architecture (e.g. Kubernetes and GPUs) to make model inference performant for the consumers’ needs.this is a full time position that will report directly to the senior director of data science.about soona:soona makes it possible for brands to create professional photo and video starting at $39. our studios give customers a playground for creating their content and our online platform makes it possible for any product company in the world to experience a remote shoot. we are creating a fast casual content revolution!soona is currently supporting a US remote work environment for this role with opportunity for a flex hybrid work environment within our operating cities--Denver and Minneapolis, if that’s your thing.about tech at soona:at soona, we’re focused on building a world-class engineering and data organization. we’re developing a highly-scalable platform for real-time customer engagement with our studio creatives and technology that optimizes the content they create. our typical engineering and data projects blend SaaS with e-commerce, providing opportunities to work on everything from app engineering and cloud/server architecture to computer vision and logistics/routing optimization. our tech stack consists primarily of ruby on rails, javascript vue, and python. we pride ourselves on our culture of innovation, community engagement, technical mentorship, and caring for the individual.our hiring philosophy:at soona, we look for representation across all intersectionalities of identities, specifically within underrepresented groups. it is these differences that push us towards innovation, curiosity, and success in our business. we believe in providing equal employment opportunities without regard to race, color, religion, age, sex, national origin, disability status, protected veteran status, genetics, sexual orientation, gender identity or expression, or any other characteristic protected by laws or regulations in the locations we operate. this means that timelines of processes may be impacted, depending on our applicant pools.Requirementsan ideal candidate can:deploy machine learning models into production services and environmentsbuild architecture required to efficiently operate our data science services (including computer vision, analytics, and optimization systems)create and maintain telemetry/observability systems to monitor app performancethink for themselves and discover new and insightful ways to solve difficult problemsdeliver quality code in an agile framework that ships to a production environmentcommunicate with data and engineering teams as well as business stakeholdershas experience in:effectively communicating and coding in a remote work environmentpython – the core language of the data organizationdata science, data engineering, or backend engineering, specifically in building data science products and services in a production environmentaws or equivalent cloud environmentleveraging GPUs/CUDA vis-à-vis pytorch (or similar)kubernetes, docker, flask/fastAPI (or similar)infrastructure-as-code tooling like terraform (preferred)designing and building machine learning models (preferred)sql, dbt – our data layer platform (preferred)looker, segment, airbyte (preferred)working in a startup environment (preferred)Benefitswe can offer:starting salary: $170,000 - $200,000stock options in a booming startupbenefits & perks + unlimited pto + intentional culturereally badass headshots\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Build the Path ForwardAt Path Robotics, we're attacking a trillion dollar opportunity - doing things that have never been done before to support an industry hurting from a lack of skilled labor. Big, hard problems are what Path tackles every day and our people are our greatest asset to get that job done. Our intelligent, hardworking team of people do the impossible every single day, yet remain incredibly kind, humble, and always ready to support one another.Our Computer Vision Engineers work to develop, evaluate, and release computer vision algorithms into production software. The role will focus on object recognition, localization, and adaptive filtering. You will report to the CV Team Lead and will join a team of dedicated, supportive, and enthusiastic people to help create the future of manufacturing. Come solve the hardest problems with the best team on the planet!What You'll DoDevelop and implement methods to quickly and accurately localize highly occluded objectsTest and evaluate current state-of-the-art methods used for scene segmentationWork towards learning based approaches requiring less data3D Point cloud matching and manipulation Stay abreast of new research and novel findings in the fields of computer vision and machine learningPartner with our other engineering teams in artificial intelligence, robotics, and software engineeringWho You AreYou have a PhD or MS in computer vision, deep learning, or something strongly relatedYou have 5+ years of research experience in developing novel computer vision algorithms or similar methods based on deep learning in such topics as image recognition, image segmentation, stereo pixel matching, geometric deep learning, object recognition using 3D spatial data. You have a solid understanding of 3D reconstruction and meshingYou have 2+ publications in computer vision fieldYou are proficient in Python and C/C++You have hands-on experience in computer vision and deep learning frameworks such as OpenCV, Tensorflow, and PytorchYou are comfortable with Git and Linux You are familiar with parallel computing, such as GPU/CUDA programmingYou are familiar with structure from motion and visual odometryYou are familiar with Kalman filter and particle filterYou are excited by the opportunity to be a part of a venture-backed company early on, where your work will have an immediate and direct impactYou are passionate about what you do and enjoy working in a collaborative environmentWho We AreAt Path Robotics we love coming to work to solve interesting and tough challenges but also because our ideas are welcomed and valued. We encourage unique thinking and are dedicated to creating a diverse and inclusive environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.To continue to keep our team safe as we navigate the pandemic, we are requiring all in office staff to submit and validate their vaccination status. Why You'll Love It HereFree lunch every dayFlexible PTOMedical, Dental and Vision insurance 6 weeks 100% paid parental leave plus an additional 6-8 weeks maternity leave for the birthing parent (12-14 weeks total)401K through EmpowerPaid Referral BonusJob Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning engineer to work closely with our product and research teams to develop SOTA deep learning software. This person will work closely with our technical and research teams to develop training and deployment pipelines, implement model compression algorithms, and productize deep learning research. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to build machine learning productsPrototype and implement appropriate ML algorithms, tools, and pipelinesCreate and manage training and deployment pipelinesCollaborate with a cross-functional team about market requirements and best practicesKeep abreast of developments in the fieldRequirementsProven experience as a machine learning engineer or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityBachelor's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Computer Vision / ML Engineer (All Levels)AIM is a well-funded, mission oriented startup focused on radically scaling our civilization’s capabilities to build planetary-scale infrastructure and reverse negative effects of climate change. ( https://aim.vision )We are growing the team with motivated individuals with a passion for landing great products built with a strong engineering culture. If you find massive robots making a positive impact in the real world tantalizing, get in touch! ( https://www.aim.engineer )AIM has been built by a team of engineers, scientists, and serial entrepreneurs who previously led development of ML systems at Google, Waymo, Tesla, Apple, Google[x], Quora, Facebook and Microsoft, and are backed by General Catalyst, Human Capital, Elad Gil, Qasar Younis, Ironspring Ventures, DCVC, among other great allies.Responsibilities:Advance AIM’s perception stack and sensor fusion algorithmsThis involves breaking new ground as earth moving machines don’t merely navigate on existing mapped roads – they modify and build the environment as they work which poses interesting novel challengesResearch and development of state-of-the-art machine learning methodsComfortable with hands-on applications on machines deployed in the fieldQualifications: Proven track record of deployed ML-based perception systems, ideally on autonomous vehiclesExcellent grasp of machine perception methods and concepts, involving 2D and depth sensingExperience shipping production modelsSolid mathematical foundation of machine learningExcellent software development skills in pythonProficiency in Tensorflow and PyTorchCreativity and curiosity for solving complex problemsIdeal candidate will have expertise in reinforcement learning, and robotics, and C++What we offer:Opportunity for rapid growth and have a large voice on the direction of the companyMedical, dental, vision, 401k matching & life insuranceA position with AIM is a hybrid remote and onsite flexible expectation with a strong preference for onsiteOpportunity to travel to deployment sites around the world (US, Australia & more!)AIM is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status.AIM Intelligent Machine's General Privacy Policy: https://aim.vision/privacy/index.html\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"We are looking for an immediate hire for a computer vision engineer. Must be comfortable working on fast-paced environment and exhibit ability to balance a sense of urgency moving from R&D to deployment. You will be actively involved on one or more of these areas:Explore new vision algorithms/strategies for proof of concept assessment using vision development environmentHelp to develop more tools to enhance the capability of existing automated vision software test frameworkHelp conceive proof-of-concept prototypes that establish overall system performance You have...Bachelor's degree in Computer Science/Electrical Engineering. Master's/PhD is a plusAt-least 1+ experience in building production computer vision and imaging algorithms for image processingExpertise in at least one area of computer vision, machine learning, and computer graphics (e.g. object detection, tracking, segmentation, AR/VR, image and video processing, 3D geometry, multi- view geometry, simulation, graphics rendering)Must have strong fundamentals in computer vision concepts like intrinsic and extrinsic calibrations, homogeneous coordinates, projection matrices, and epipolar geometry. Strong coding skills in Python or C/C++Total comfort working in a Linux environmentsYou have extensive experience in OpenCV or other computer vision libraries. Preferred:Track record of publishing in top-tier computer vision or machine learning conferences or/and journals. Prior industrial experience in retail environment. Exposure to CUDA or OpenCL is preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BioMap is a platform company that integrates AI technology with cutting-edge biotechnology. We are committed to achieving breakthroughs in target discovery and drug design, and bringing global first-in-class medicine for unmet medical needs in the areas of immune-oncology, autoimmune diseases, fibrosis, and aging-related diseases.Location: Menlo Park. This role is preferably based in The Bay Area, but we are open to discussing other locations in the United States.Keywords: drug/protein design, structural biology, computational biology, protein folding, protein design, protein-ligand interactionYou will:Utilize bioinformatics tools into drug/protein design workflow and develop computing protocols for drug/ protein design Transforming research work research, open-source models, and prototypes into production-level pipelineDesign and apply innovative computational/ statistical algorithms (including classic, statistical, ML, and AI techniques) to generate actionable biological insightWork closely with the department lead to design and optimize protein design-related algorithms Requirements:PhD degree with research experience in bioinformatics, protein folding, protein design, protein-ligand integration is highly preferred; Or MS degree in computational biology, structural biology, or related fields, plus 2+ years of industry experienceProficient in at least one programming language, including but not limited to Python, C/C++, Java, etc. Familiar with machine learning and deep learning frameworks (e.g. Pytorch, Tensorflow, etc.)Familiar with Alphatfold, ESMfold, RFdesign, and ProteinMPNNGreat communication skills, including code documentation, oral presentation, with excellent attention to details What we offer:The opportunity to work on high-impact tools and products that are immediately deployed to accelerate the discovery of new medicinesA strong team in AI, software, and biochemistryCompetitive salary and equity401(k) plan with generous employer matching for contributionsExcellent medical, dental, and vision coverageDaily lunch and a full snack stationCommuter benefitsBioMap is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About AppliedAutonomy is one of the leading technological advances of this century that will come to impact our lives. The work you'll do at Applied will meaningfully accelerate the efforts of the top autonomy teams in the world. At Applied, you will have a unique perspective on the development of cutting-edge technology while working with major players across the industry and the globe.Applied Intuition provides software solutions to safely develop, test, and deploy autonomous vehicles at scale. The company's suite of simulation, validation, and drive log management software enables development teams to create thousands of scenarios in minutes, run simulations at scale, and verify and validate algorithms for production deployment. Headquartered in Silicon Valley with offices in Los Angeles, Detroit, Washington, D.C., Munich, Stockholm, Seoul, and Tokyo, Applied consists of software, robotics, and automotive experts with experiences from top global companies. Leading autonomy programs and 17 of the top 20 global OEMs use Applied's solutions to bring autonomy to market faster.About The RoleWe are looking for bright engineers interested in designing elegant solutions to difficult problems in the autonomy space. Our software engineers work across our suite of products, tackling a variety of full-stack, infrastructure, robotics, and graphics challenges. At Applied, we encourage engineers to take ownership over technical and product decisions, closely interact with users to collect feedback, and contribute to a thoughtful, dynamic team culture.At Applied you will:Work across our entire stack to develop new products, features, and tools for our customers' autonomy development workflowsHave an unparalleled opportunity to work with domain experts across a variety of fields: infrastructure, robotics, and graphics engineers, as well as startup veteransCarve out your own area of expertise and influence product decisionsCollaborate with other members in the autonomy ecosystem and learn about different approaches to solving core issues in autonomyWe're looking for someone who:Is a self-starter and can quickly become comfortable with new technical toolsDesigns efficient and effective solutions to a wide range of engineering challengesTakes initiative in a fast-paced environmentNice to have:Working knowledge of frontend, API layer, database ORM, containerization, or cluster orchestration frameworks (such as React, GraphQL, SQLAlchemy, Docker, or Kubernetes)Experience working with simulation tools, modeling physical problems, or using robotics middleware (such as ROS)Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Mujin's new US office is expanding rapidly, and to sustain that growth we're building a whole new branch of our world-class computer vision team.As a Computer Vision Engineer, you will be a part of the Mujin R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition. You will work directly with and expand on the world’s first 3D vision system for factory automation and logistics solutions.You will work directly with global leaders in applied computer vision, solving the kind of problems that haven't even been asked on Stack Overflow yet -- let alone answered.ResponsibilitiesSolve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenariosAnalyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from both academic and industrial research, and implement and enhance them in a production environmentDesign, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications in Python and C/C++Perform detailed tests, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithmsMinimum RequirementsGraduating/graduated from Computer Science or relevant faculty with a BS, MSc or Ph.DBS or MS with computer vision experience, or Ph.D. in Computer Vision related topicsAbility to develop applications and tools in Python and/or C++Technical communication skills in English (reading and writing)Preferred Experience3D pose estimation of textured and texture-less objects in cluttered scenesExtensive Python and C++ development experienceBroad experience with computer vision librariesMathematical backgroundPrevious contributions to open source projectsIt would be amazing if you have experience in: object tracking, SLAM, computer graphics, augmented reality, machine learning, or robotics projectsAbout The RoleYou'll work directly with researchers from the world’s top-tier universities and labs in robotics, computer vision, and image and signal processing. The team includes Ph. D. and MSc grads from Carnegie Mellon, Stanford, and more. Mujin has the most active real-world deployments of industrial computer vision systems. That means you won't be working in a vacuum--you'll have access to the largest set of customer feedback data in this industry globallyOur computer vision algorithms are robust enough to run on 24/7 systems, handling thousands of items per customer, for diverse customers and applications. The challenges of enlarging its capabilities toward more autonomy, scalability, and diversity of applications mean you will never stop learning at MujinWe're a well-established startup entering a global scale-up phase. That means we have enough structure so you can focus on computer vision, but not so much structure that you can't spread your wings. Come grow with us!If you would like to apply real-time computer vision algorithms to robotics and join the industrial automation revolution, this role is for you!Check out our blog for more information about Mujin's work culture! You can meet our dual-Ph. D. Computer Vision team manager, Jeronimo, here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"This position is participating in our  External Referral Program. If you know somebody who may be a fit, click here to submit a referral. If your referral is hired, you'll receive a $3,000 payment!code-extreferThere are people who say some ideas are impossible, unattainable or unrealistic. Then there are those of us who work at Lockheed Martin Rotary and Mission Systems. As a part of the Lockheed Martin community, we take on the biggest, baddest challenges in the world and find solutions using creativity and collaboration.AND WHERE THE SOLUTIONS DON’T EXIST? WE INVENT THEM.So, if you’re looking for the challenge of a lifetime and a team of the brightest minds in the world, Rotary and Mission Systems is the place for you. If you’re looking for a place where learning is a way of life, Rotary and Mission Systems is the place for you. And if you’re looking for a career that’s just as fun as it is hard work, well…you know.Join us today and let’s make a difference together.Lockheed Martin. Your Mission is Ours.ABOUT OUR MISSION (https://www.lockheedmartin.com/en-us/who-we-are/business-areas/rotary-and-mission-systems.)At Lockheed Martin Rotary and Mission Systems, Cyber & Intelligence, we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and forward-thinking, everything is within our reach – and yours as Lockheed Martin employee. Lockheed Martin values your skills, training and education. Come and experience your future!The Software Engineer develops, maintains, and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of very large data sets, real-time systems, and business management information systems) based upon documented requirements. Works individually or as part of a team. Reviews and tests software components for alignment to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific guidance to the software components of system design to include hardware/software trade- offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new.NOTE: This position requires an active Department of Defense TS/SCI W/ Security and US citizenship for selection.Benefits Of EmploymentWe may not know what's going to change the world next, but chances are we're already working on it, and you can, too. As part of our culture of innovation, you’ll have excellent benefits and amenities, an inclusive work environment, ongoing career development and support, rewards and recognition to honor your hard work, and more.Here Are Some Of The Benefits You Can Enjoy Medical Dental 401k Paid time off Work/life balance Career development Mentorship opportunities Rewards & recognitionLearn more about Lockheed Martin’s competitive and comprehensive benefits package.Lockheed Martin’s competitive and comprehensive benefits package. (https://www.lockheedmartinjobs.com/working-here#benefits)We support our employees, so they can support our mission.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'ML/NLP/deep learning expertise. Strong engineering background with end-to-end ownership of projects.You will: - Have critical impact on Sapling growing its set of enterprise customers. - Build components of the data, pre-processing, training, evaluation, and guardrail pipeline for Transformer models. - Work closely with the founders. - Have a flexible work schedule. - Learn about early stage startups and machine learning/deep learning from Berkeley/Stanford AI grads.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are searching for an engineer with medical image analysis experience as well as experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to join a fast-growing AI company that is addressing real-world challenges in the Health Care industry.Our client has beautiful offices in downtown Ann Arbor. Employees are well compensated, promoted from within and taught new programming languages, techniques and disciplines as part of their jobs. The culture is relaxed. The PTO is generous.The ideal candidate has worked on a commercial product and has had their work released to customers.LOCATIONAnn Arbor MichiganSince this role deals with Personal Health Information, candidates are required to perform the majority of their work onsite.At this time, our client is not able to accommodate any type of work visa other than TN Visas.Compensation$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.EDUCATIONComputer Science or engineering degreeRequired Skills For Machine Learning ScientistMinimum of 3 years' commercial experience using machine learningProficiency with Python development.Solid experience with Image Analysis (preferably x-ray images)Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themTAGSMachine Learning | ML | Deep Learning | DL | Computer Vision | Image Analysis | Java | Python | PyTorch | TensorFlow | Keras | 3909-WPlease submit resume and cover letter to recruit@stoutsystems.com with the job title/number in the email.We have a bunch of technology jobs available! View more jobs at https://www.stoutsystems.com/jobsWe host free career webinars every week at https://www.stoutsystems.com/eventsRequirementsEDUCATIONComputer Science or engineering degreeResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themBenefitsCOMPENSATION$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job DescriptionShtudy's company mission is to allow ethnically diverse tech talent to confidently connect with companies that prioritize workplace inclusion and growth. We have many clients who are looking for machine learning engineers with experience in using cutting-edge ML techniques to drive efficient product optimization. This is your chance to collaborate and work with a highly talented and globally-diverse team to engineer innovative, revolutionary solutions.How to Apply:To be eligible to apply, create your profile here (it takes 2-5 minutes):Job responsibilitiesReinforce our product by developing a strong back-end architecture with high-processing data pipelines or machine learning modelsDevelop efficient ML models using various programming languages, data structures, and algorithms with information retrieval and distributed computing conceptsAutomate pipeline modeling and develop operational ranking models for classificationTest the effectiveness of ML models via thorough end-user research and experimentationGenerate solutions for data management issues through feature implementationMinimum RequirementsBachelor’s or Master’s degree in Computer Science, Information Technology, Engineering, or a related discipline2+ years of machine learning and engineering experienceComprehensive knowledge in engineering, data science, statistics, and applied ML techniques for model production, deployment, and testingHands-on experience in SQL and NoSQLProficiency in PythonPreferred QualificationsMLOps experience in model monitoring, CI/CD, and DVCKnowledge of ML techniques and algorithms such as supervised/unsupervised/reinforcement learning, classification, etc.Knowledge of ML systems such as recommendation or ranking systemsHow to Apply:To be eligible to apply, create your profile here (it takes 2-5 minutes):At Shtudy, we only connect you with companies that have been pre-vetted for workplace culture, diversity, and inclusion standards. We partner with employers who genuinely care about the welfare and happiness of their employees, and we will always remain free for our candidates.How to Apply:To be eligible to apply, create your profile here (it takes 2-5 minutes):Powered by JazzHROmW1JDIMmr\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We are looking for a mentor to work with resources within and outside of existing Customer Experience (CX) team to leverage our data and provide an enhanced experience for our community. This role will need to collaborate and work with key groups and stakeholders across IT Services and the university. Representing ITS, the successful candidate will have strong collaboration, communication, and customer service skills to successfully partner with members across the community (at various levels).To ensure that essential services are provided to the university community, a flexible schedule is required. The employee may be required to work outside his/her regular working hours and on university holidays.Qualifications Proficiency with a deep learning framework such as TensorFlow or Keras Proficiency with languages such as JavaScript, HTML, Python, SQL, and C++. Expertise in visualizing and manipulating big datasets (pulling from AWS, CRMs, etc) Proficiency with OpenCV Familiarity with Linux Ability to select hardware to run an ML model with the required latency Familiarity with ServiceNow and/or Microsoft Azure Bot Services preferredExcellent interpersonal, communication and organizational skills are required. Excellent analytical and troubleshooting skills are necessary.Strong written communication skills are preferred, as is the ability to adapt to and follow an organization’s voice, tone, and style.Powered by JazzHRLAwzdnPJdy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'This Senior Machine Learning Engineer position is a high-impact role. We are looking for an experienced machine learning practitioner with high-standards to help scale and expand high-value business initiatives.You will be joining a top-tier team that understands the real-world business opportunity that machine learning enables and how it can transform businesses. We iterate with A/B testing to fail fast and learn quickly. The result is real, measurable revenue and profit impact.The ideal candidate will have a passion for technology with a clear, solid background in computer science. If you have a proven ability to learn, explore, and quickly turn the latest technologies into value, then you are the perfect candidate.Our team of experienced engineers has deep industry experience in search/information retrieval. The team is highly collaborative while also being self-sufficient enough to turn any idea into a business win. As a high impact teammate, you will help with everything from data ETLs to modeling to model serving to test reporting. This unique opportunity will expose you to deep insights into the technology and the business. On a day-to-day basis, expect roughly 20% of your time to be on the serving/inference layer, 20% data science modeling, and the rest will be around data cleaning, ETL, and analytics.What we are looking for in a highly qualified candidate:Big Data processing – Apache Spark is the key to our data pipelines that create our insights. Understanding SQL is a must in this environment. For maximum performance, we utilize Scala.Search technologies – our Lucene/Solr inverse index powers billions of our queries every month.High-performance web services – our non-blocking microservices scale with Java technologies while providing sub-millisecond response times.Machine learning – our latest wins have come from deep learning (TensorFlow, Keras). Python is the preferred language here.Most importantly, the highly qualified candidate has the initiative and ability to quickly learn and apply the above.RequirementsMinimum Requirements:You Must have a Bachelor’s in Computer Science from a top-ranking university.Three (3) to seven (7) years of computer programming work experience with proven, high-value results.One (1) years of data science, machine learning, or data engineering work experience.Must reside in the greater Austin metro area or be willing to relocate to the Austin area (Relocation Reimbursement will be offered.BenefitsHighly competitive salaryCompany-paid gym membershipComprehensive, company-paid health, vision, and dental insurance premiums for you and your dependents401(k) retirement plan with 3% employer contributionPaid company holidays & Unlimited PTOAwesome company events\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'BioMap is a platform company that integrates AI technology with cutting-edge biotechnology. We are committed to achieving breakthroughs in target discovery and drug design, and bringing global first-in-class medicine for unmet medical needs in the areas of immune-oncology, autoimmune diseases, fibrosis, and aging-related diseases.Location: Menlo Park. This role is preferably based in The Bay Area, but we are open to discussing other locations in the United States.Keywords: drug/protein design, structural biology, computational biology, protein folding, protein design, protein-ligand interactionYou will:Utilize bioinformatics tools into drug/protein design workflow and develop computing protocols for drug/ protein design Transforming research work research, open-source models, and prototypes into production-level pipelineDesign and apply innovative computational/ statistical algorithms (including classic, statistical, ML, and AI techniques) to generate actionable biological insightWork closely with the department lead to design and optimize protein design-related algorithms Requirements:PhD degree with research experience in bioinformatics, protein folding, protein design, protein-ligand integration is highly preferred; Or MS degree in computational biology, structural biology, or related fields, plus 2+ years of industry experienceProficient in at least one programming language, including but not limited to Python, C/C++, Java, etc. Familiar with machine learning and deep learning frameworks (e.g. Pytorch, Tensorflow, etc.)Familiar with Alphatfold, ESMfold, RFdesign, and ProteinMPNNGreat communication skills, including code documentation, oral presentation, with excellent attention to details What we offer:The opportunity to work on high-impact tools and products that are immediately deployed to accelerate the discovery of new medicinesA strong team in AI, software, and biochemistryCompetitive salary and equity401(k) plan with generous employer matching for contributionsExcellent medical, dental, and vision coverageDaily lunch and a full snack stationCommuter benefitsBioMap is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Position title: Machine Learning Engineer for Computer Vision ApplicationsDepartment: TechnologyFLSA Classification: Exempt Reports to: Engineering Development LeadSupervisory position: NoJob DescriptionSummary/objectiveThe Machine Learning (ML) Engineer is responsible for developing, implementing and refining products that improve their performance through the automation of predictive models. The ML Engineer has a sturdy foundation in mathematics, statistics, and programming, including modern (deep learning) and classical machine learning. They have a pragmatic view of ML system development, including model selection, training, testing, validation and deployment. The ML engineer applies their advanced knowledge to work independently on computer vision initiatives with limited supervision.Essential FunctionsReasonable accommodations may be made to enable individuals with disabilities to perform these essential functions.Design, prototype, and implement machine learning algorithms utilizing common ML frameworks. Demonstrate ability to develop custom extensions to available frameworks.Process, transform, visualize, and analyze data to guide the design and training processes of machine learning algorithms. Stay up to date with state-of-the-art methods for solving complex machine learning problems (e.g. computer vision, language modeling, multi-modal models)Collaborate with ML and Software engineers to produce software/data deliverables. This may include algorithm/software design documents, end-user guides, and status reports for customers.Contribute to solution development for project proposals.Generate content for status meetings with customers as a technical contributor. Responsibly and respectfully interact with customers and suppliers to ensure customer satisfaction and project alignment.Provide subject matter expertise on other projects pertaining to machine learning concept development and algorithm design.Perform other duties as required. Required Skills/AbilitiesPossess and maintain US Citizenship. Maintain Security Clearance.Experience with the Python programming language and ML frameworks like PyTorch, TensorFlow, and Scikit-Learn. Knowledge of other languages (C++, Java) and frameworks for scientific computing is ideal.Experience with computer vision and image analysis. Experience with natural language processing is a plus.Research experience is a plus.Strong problem-solving and organization skills.Curiosity, the willingness to be flexible, and the desire to learn new concepts and technologies on the job. Effectively manage ambiguous project requirements and mitigate their effect on software deliverables.Work independently given minimal guidance, including the ability to research methods that best suit project requirements.A deep understanding of machine learning system design concepts.Work effectively with senior engineers, and translate results from complex analytics into elegant data products. Work effectively and comfortably with multidisciplinary teams of engineers and support staff. Excellent communication skills. Education/Training/ExperienceM.S. in Computer Science, Computer Engineering, or a related field with up to 5 years of experience.Proven record of technical leadership in their job area. Physical demandsProlonged periods of sitting at a desk and working on a computer. Must be able to lift 15 pounds at times.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'LVIS is a leader in cutting edge neural information analysis technology that decodes brain networks and provides visualizations assisting neurological disease diagnosis. LVIS owns patented technologies and our team includes leaders with strong expertise in neuroscience and engineering. LVIS has been selected to be a member of the Stanford StartX community and the NVIDIA inception program. We are an international team with our headquarter located in Palo Alto, California, USA and an office in Gangnam, Seoul, South Korea. We are looking for talented individuals to join us in transforming the neurology health care industry.ResponsibilitiesDeep learning model deployment for medical web applications.Machine learning system stability testing and optimization.Model compression with pruning, quantization and distillation.Collaborate with data scientists and software engineers to optimize deep learning model performance.RequirementsMinimum Required QualificationsMS or PHD in Computer Science, Statistics, Electrical Engineering, Applied Math, and other similar fields.Deep understanding of the machine learning algorithms and systems, especially convolutional neural networks.Proficient in python and python machine learning packages, such as numpy, scikit learn, pytorch, keras, etc.Preferred To HaveHands-on experience of model deployment in the cloud (AWS, Azure or GCP).Experience of model compression techniques.Experiences in medical image/signal processing and data analysis.Other InformationJob type: Full-time.U.S. citizens, green card holders, and those authorized to work in the U.S. for any employer will be considered.Willing to work onsite at our Palo Alto location.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"SOFTWARE ENGINEER The Software Engineer will be part of the team responsible for designing, developing, and operating the applications that make Throtle’s data onboarding solution work. The ideal candidate can work with teammates in troubleshooting problems, designing solutions, and assessing situations in real-time. Our team is empowered to keep our fast-paced, high-volume processing environment operational for our clients and partners.Primary ResponsibilitiesCreate tools and solutions to manage and monitor our rapidly growing operations.Be involved in real-time assessment of issues and help develop solutionsBuild and design solutions that mitigate risk and increase efficienciesAutomate processes and sub-processes to enable greater scale and speedMaintaining our existing code. Take part in performance & capacity monitoring and planningKNOWLEDGE AND SKILL REQUIREMENTSAt least 2-3 years of experience Significant proficiency in one or more of these languages- Java, Python, GolangExperience with databases – PostgreSQL, Oracle, or Microsoft SQL Server.Proficiency in Restful API Development Experience interacting with AWS CLI and AWS ConsoleKnowledge of software architecture, data structures, modern design patterns and network protocols Ability to identify problems, and effectively communicate solutions to peers and managementOTHER VALUABLE SKILLSExperience with data flow and queue management using tools like Kafka and Flume Experience in front end technologies including JavaScript, CSS3 and HTML5 to include libraries such as React Js and Angular. Experience in Linux SysAdminExposure to NoSQL/Big Data: Hadoop, HBase, Cassandra, MongoDBHands on experience with a CI/CD environmentExperience with configuration management and automation tools like Ansible, Chef, or Puppet. Benefits:Throtle offers a competitive benefits package that includes:Medical DentalVisionLife InsuranceLong Term Disability401k company matchPerks:Fridays: The office closes at 3 p.m. /Memorial Day – Labor Day the office closes at 1p.m.!The office is closed between Christmas and New Year's.Hybrid Scheudle-works from home on Mondays and Fridays.We sponsor office lunches 1x a month (sometimes more!).We always have fun company swag coming your way.Throtle, Inc..is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.Flexible work from home options available.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Meta is embarking on the most transformative change to its business and technology in company history, and our Machine Learning Engineers are at the forefront of this evolution. By leading crucial projects and initiatives that have never been done before, you have an opportunity to help us advance the way people connect around the world. The ideal candidate will have industry experience working on a range of recommendation, classification, and optimization problems. You will bring the ability to own the whole ML life cycle, define projects and drive excellence across teams. You will work alongside the world’s leading engineers and researchers to solve some of the most exciting and massive social data and prediction problems that exist on the web.Generative AI represents a huge opportunity to unleash the creativity of the billions of people globally who use our technologies. For years, teams at Meta have been leading the industry in AI research. We are uniquely positioned to adopt an end-to-end approach to generative AI that few organizations can offer through building breakthrough product experiences using generative AI, generative AI research across all modalities, world-class applied AI/ML product engineering, building scalable, high-performance AI infrastructure and deep experience building tools that enable social connection and expression.As a/an Software Engineer on the generative AI team at Meta, you can help bring the transformative potential of generative AI to people and businesses around the world as we build a new class of generative AI experiences.Software Engineer, Machine Learning - Generative AI Responsibilities:Play a critical role in setting the direction and goals for a sizable team, in terms of project impact, ML system design, and ML excellenceAdapt standard machine learning methods to best exploit modern parallel environments (e.g., distributed clusters, multicore SMP, and GPU)Re-evaluate the trade-offs of already shipped features/ML systems, and you are able to drive large efforts across multiple teams to reduce technical debt, designing from first principles when appropriateLeading a team from a technical perspective to develop ML best practices and influence engineering cultureBe a go-to person to escalate the most complex online/production performance and evaluation issues, that require an in-depth knowledge of how the machine learning system interacts with systems around itDevelop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based modelsSuggest, collect and synthesize requirements and create effective feature roadmapCode deliverables in tandem with the engineering teamMinimum Qualifications:6+ years of experience in software engineering, or a relevant field or 4+ years of experience if you have a PhD2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining, artificial intelligence, or related technical fieldExperience with developing machine learning models at scale from inception to business impactKnowledge developing and debugging in C/C++ and Java, or experience with scripting languages such as Python, Perl, PHP, and/or shell scriptsExperience demonstrating technical leadership working with teams, owning projects, defining and setting technical direction for projectsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Masters degree or PhD in Computer Science or a related technical fieldExposure to architectural patterns of large scale software applicationsMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"This position is participating in our External Referral Program. If you know somebody who may be a fit, click here to submit a referral. If your referral is hired, you'll receive a payment!code-extreferAt Lockheed Martin Rotary and Mission Systems, Cyber & Intelligence, we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and forward-thinking, everything is within our reach – and yours as Lockheed Martin employee. Lockheed Martin values your skills, training and education. Come and experience your future!The Software Engineer develops, maintains, and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of very large data sets, real-time systems, and business management information systems) based upon documented requirements. Works individually or as part of a team. Reviews and tests software components for alignment to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific guidance to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.Our Program Is Seeking Innovative Engineers To Support a Critical Application Centered In The Analytic Mission As Well As Modernize The Legacy System Using a Microservices-based Architecture And Cutting-edge Technologies Agile development and delivery of software Monolithic Application Support and Maintenance Microservices Architecture migration User Interface and User Experience with enhanced workflows DevSecOps and Automation of CI/CD pipeline Help Desk and 24X7 system call-in and on-call support/maintenanceNOTE: This position requires an active security with polygraph and US citizenship for selection.Benefits Of EmploymentWe may not know what's going to change the world next, but chances are we're already working on it, and you can, too. As part of our culture of innovation, you’ll have excellent benefits and amenities, an inclusive work environment, ongoing career development and support, rewards and recognition to honor your hard work, and more.Here Are Some Of The Benefits You Can Enjoy Medical Dental 401k Paid time off Work/life balance Career development and mentorship opportunities Rewards & recognitionLearn more about Lockheed Martin’s competitive and comprehensive benefits package.Lockheed Martin’s competitive and comprehensive benefits package. (https://www.lockheedmartinjobs.com/working-here#benefits)We support our employees, so they can support our mission.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Description:By bringing together people that use their passion for purposeful innovation, at Lockheed Martin we keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work.With our employees as our priority, we provide diverse career opportunities designed to propel development and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work.At Lockheed Martin, we place an emphasis on empowering our employees by fostering innovation, integrity, and exemplifying the epitome of corporate responsibility.Your Mission is Ours.The coolest jobs on this planet… or any other… are with Lockheed Martin Space.Lockheed Martin Space in Littleton, CO is seeking a full-time Early Career Software Engineer. Consolidated Analysis Orchestration Services (CAOS) is the preeminent Geospatial-Intelligence program in the world – over 10,000 intelligence analysts and decision-makers worldwide daily rely on CAOS for critical intelligence and geospatial data management. In addition to meeting today’s critical intelligence mission needs, we are working on evolving exciting future automation and artificial intelligence solutions for the National Geospatial-Intelligence Agency (NGA). We need the best engineers on our team to ensure mission success! Think you have the skills, come join the CAOS Team that builds software for the next generation of geospatial intelligence.Must be a US Citizen ; this position will require a government security clearance. This position is located at a facility that requires special access.Basic Qualifications Acceptable bachelors degree programs will include only science and technology (STEM) related programs such as Computer Science, Systems Engineering, Electrical Engineering, Computer Engineering, Physics, Mathematics etc. Must be a US Citizen ; this position will require a government security clearance. This position is located at a facility that requires special access.Desired SkillsProficiency with one or more of the following software languages: Java, C++, C#. Candidate will have knowledge of basic software practices such as coding standards, unit testing and configuration management, database and System administration. Good communication skills. Strong team player. Candidate will work in a team environment utilizing software methodologies and processes. Familiarity with Agile Development Process a plus. Strong communication skills a results oriented team player, creative thinker and problem-solver and follow all ethical standards of the Lockheed Martin Corporation.Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.Clearance Level: TS/SCIOther Important Information You Should KnowExpression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.Ability to Work Remotely: Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.Schedule for this Position: 9x80 every other Friday offPay RateThe annual base salary range for this position in Colorado or Washington is $57,800 - $110,800. Please note that the salary information is a general guideline only. Lockheed Martin considers factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience, education/ training, key skills as well as market and business considerations when extending an offer.Benefits offered: Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Flexible Spending Accounts, EAP, Education Assistance, Parental Leave, Paid time off, and Holidays.(Washington state applicants only) Non-represented full time employees: accrue 10 hours per month of Paid Time Off (PTO); receive 40 hours of Granted PTO annually for incidental absences; receive at least 90 hours for holidays. Represented full time employees accrue 6.67 hours of PTO per month; accrue up to 52 hours of sick leave annually; receive at least 96 hours for holidays. PTO is prorated based on hours worked and start date during the calendar year.This position is incentive plan eligible.Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.Experience Level: 4 yr and up CollegeBusiness Unit: SPACERelocation Available: PossibleCareer Area: Software EngineeringType: Full-TimeShift: First\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityResponsibilities:As the Geometric Computer Vision Engineer you will need to develop computer vision algorithms for object detection, tracking, and classifications that are robust to lighting and weather changes. This work requires that you collaborate with state estimation engineers and assist in developing powerful feature detectors/ descriptors and large-scale 3D maps. Furthermore, it is expected that you stay organized and communicative with others to ensure that goals and objectives are being met on time. To guarantee the consistency of projects, you will participate in end-to-end development and training in Cloud to optimize development on embedded platforms.Required Qualifications:3-5+ years' significant industry experience and/or publications at venues such as ICRA, RSS, IROS, or CVPR in one or more areas- Image Processing Geometric Computer Vision Deep Learning (ideally CNNs) Classical machine learning such as SVM, decision trees, boosting, graphical models, sequential prediction, or sampling methodsStrong C++ programming and software design skillsFamiliarity with a deep learning framework such as PyTorch, TensorFlow, Caffe, or TheanoBS, MS, or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering, a related field, or equivalent experienceDesired Qualifications: Experience deploying CV/ML in a robot or real-time applicationUnderstanding of optimization of DL models and deployment on embedded platforms such as the Nvidia JetsonExperience in designing large-scale machine learning pipelinesCompensation:90,000-220,000Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Beacon AI is looking for experienced software engineers in the San Francisco Bay Area to develop perception and object-tracking robotic software that can reliably perform complex tasks in aviation environments. You will help design, integrate, test, deploy, and maintain new software functionality in aircraft across the globe. We seek a team player who is excited to solve challenging problems; the products you work on will fuse massive amounts of data in order to increase aviation safety and performance, with a focus on reliability and optimization. You will join a diverse team that is dedicated to making a real-world impact using advanced, creative technologies. This is a full-time, salaried position.What you’ll do:Create object detection and tracking software for a variety of novel use casesCollaborate proactively with a distributed team to deliver software features using modern middleware technologiesWrite high-quality, extensible code that is well tested and documentedContribute quality code reviews for internal and external engineersIdentify and fix security vulnerabilities in open source codeHelp mentor new hiresAdvance modern, agile, secure software development practices which enhance excellent engineer practicesWhat will make you successful:Technical degree (CS or related) preferred, but demonstrated ability in productionized environments is key3-8 years, or more, of experience with middleware technologies such as ROS2, DDS, Zeromq, etcExpert knowledge of Linux and C++, bonus points if also proficient with PythonExperience building parts of a robotic software stack like Perception, Prediction, Behavior, Planning, or Control modulesExperience working with computer vision, sensor fusion, object tracking, sensor calibration, and localizationYour experience with self-driving mobility solutions, drone software, ADAS, or similar challenging robotics problems will help you succeed in this roleBonus points:Experience with pose/gaze estimationPassion for advanced mobility and aviationExperience working on advanced machine learning problemsExperience working with Nvidia GPUs/IoT devices or similarExperience working with embedded systems, sensors, and driversFor many roles, the following may apply. To conform to U.S. Government aerospace technology export regulations (EAR / ITAR), an applicant must be a U.S. citizen, lawful permanent resident of the U.S., protected individual as defined by 8 U.S.C. 1324b(a)(3), or eligible to obtain the required authorizations from the U.S. Department of State. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the U.S. and to complete the required employment eligibility verification form upon hire. Employer provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. In addition to federal law requirements, employer complies with applicable state and local laws governing nondiscrimination in employment. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. Employer expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of employees to perform their job duties may result in discipline up to and including discharge.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'The software engineer I position will design, develop and debug desktop/web applications that function in a hybrid environment.Participate in all aspects of the application development life cycle, includingBusiness requirements translationTechnical designTest case creation (unit test)Coding/developmentUnit testingDebug/troubleshootingPeer-reviewDeploymentPost-deploy supportCreate clear and accurate technical documentationStrong discipline of accountability and task managementRequired SkillsWorking knowledge of one or more object-oriented languagesBe motivated to continue to learn new skillsHave strong interpersonal skills to facilitate working within a team Effective verbal and written communication skillsEffective time management skillsQualificationsBachelor’s degree in Software Engineering, Computer Science or related degreeExperience with PHP, HTML5, CSS, Javascript, Java, C#, SQL/TSQLExperience developing stateless web applications, RESTful web services and APIsExperience with AWS environments and SDKs including S3, SNS, SQS, SES, ElasticCache, Lambda, CloudSearchUnderstanding of source control practices with TFS and GitExperience with databases, including working knowledge of MS SQL, PostgreSQL and MongoDBExperience with transactional web development, RESTFul APIs, ecommerce or related applicationsExcellent communication skillsMINIMUM 3+ years of software development experienceEqual Opportunity and Non-DiscriminationTranscat is an equal-opportunity employer and prohibits discrimination on the basis of any protected status. All qualified applicants will receive consideration for employment without regard to age, color, creed, disability, domestic violence victim status, gender identity, genetic predisposition or carrier status, marital status, national origin, pregnancy, race, religion, sex, sexual orientation, status as a protected veteran or as a member of any other protected group or activity.We will make reasonable accommodations for personnel with disabilities to enable them to perform the essential functions of this position unless doing so poses an undue hardship on the company or a direct threat to health or safety.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Position: Sr. Software EngineerCompany Location: Orem, UT ( Fully remote)Target Salary: $115,000 - $150,000 + great benefitsTerm: Full Time - RemoteWork Authorization: US Citizen or Permanent Resident only at this time.Join us in our mission to bring clean, current, and complete data to healthcare. We believe this will change the way government, doctors, administrators, and payers interact with patients. We constantly seek to find new ways to delight and inspire our customers to do more with data. We are committed to the success of our users and seek to build the best solution.We are indexing billions of records every month, from more than 30 M patients. We are seeking an exceptional Senior Python Software Engineer to help us revamp how we ETL and bring in our data. We keep data on patient care, healthcare trends, data readiness, and data security so that our customers can ask the right questions about their patients and healthcare practices through data.In this role you will focus on building an intuitive data ingestion engine user experience. Your work encompasses the intersection of data, engineering, and design, utilizing modern development technologies to help our customers make informed decisions and find answers to their business questions.What you'll doHelp us design and build a world-class data ingestion engine.You’ll develop and maintain an ETL pipeline engine that's easy enough for an end user including physicians, payers, and healthcare administrators.Collaborate closely with PM and backend engineers to understand customer needs and translate them into product features.Participate in the development of project timelines, implementation design specifications, system flow diagrams, documentation, testing, and ongoing support of systems.Maintain and improve existing code with a pride of ownership.Help with the decisions to build or buyMigrate our current ETL pipelineWhat you'll need5+ years of related experience with a Bachelor’s degree, or equivalent practical experienceYou are passionate about data, code reusability, componentization, and building for scale.Excellent problem solving and analytical thinking skillsYou have great skills in Python and have experience developing full-featured client-side applications using state-of-the-art Python technologies, and familiar with customer feedback, and SaaS environments.Knowledge of working with large data and some of the challenges that come with distributed processing, and an ability to tune code for the best performance.You have experience with server-side data processing, threading model performance, and supporting python libraries.You're comfortable with command-line applications, source control, testing frameworks, and other aspects of developing in a distributed software team.Bonus- NOT a must: Experience with Kubernetes, Docker, ETL Engines (Nifi, Airflow, Cribl ect), and Kafka\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for ENTRY LEVEL MACHINE LEARNING ENGINEER with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech Industry Please Also Check The Below Linkshttps://www.synergisticit.com/candidate-outcomes/https://www.synergisticit.com/java-track/https://www.synergisticit.com/data-science-track/https://www.synergisticit.com/which-is-the-best-option-for-tech-job-seekers-staffing-companies-consulting-companies-bootcamps-or-synergisticit/https://www.synergisticit.com/contact-us/If the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skills For data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skills Preferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company OverviewFounded in 2010, Lynx Analytics is a predictive analytics company run by world-class quantitative marketing scientists and industry-experienced data scientists. Our focus is to become a leading analytics solution provider in our chosen fields of expertise (telecom, retail, life sciences, and financial services) while advancing graph analytics technology.Lynx is headquartered in Singapore with operations in Hong Kong, Germany, USA, Hungary, South Africa, Indonesia, and several other Southeast Asian countries. We work with some of the world's largest companies and are constantly looking to expand our knowledge base and geographical footprint. Lynx Analytics' technology is deployed with various Clients across Asia and has significant growth potential.We have a diverse and inclusive global team comprising Professors, PhDs, MSc's, and MBAs from Ivy Leagues, INSEAD and NUS with a broad spectrum of experience in start-ups and blue-chip companies (Google, SAP, Vodafone, GE, Morgan Stanley, Barclays, HSBC to name but a few). It is the combination of our industry insight and experience, scalable proprietary technology, and highly qualified people that drives our compelling value proposition.Key ResponsibilitiesEstablish scalable, efficient, automated processes for data analyses, model development, validation and implementationWork closely with data scientists and analysts to create and deploy new featuresWrite efficient and well-organized software to ship products in an iterative, continual-release environmentMonitor and plan out core infrastructure enhancementsAbility to optimize model performance, push model into performance, track and test, refactor codeContribute to and promote good software engineering practices across the teamCommunicate clearly and effectively to technical and non-technical audiencesActively contribute to and re-use community best practicesRequirementsRelevant tertiary qualification2 to 4+ years of experience with at least 1 year of experience in Machine Learning EngineeringStrong knowledge of Python and SQL Good problem-solving skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About The CompanyFocused on the future of filmmaking, Wonder Dynamics is an LA-based start up founded by Actor/Producer, Tye Sheridan who’s starred in films like Ready Player One, X-Men: Apocalypse, Mud and VFX Supervisor/Filmmaker Nikola Todorovic. Their mission is to revolutionize the production and post-production process by leveraging state-of-the-art AI. They are striving to democratize the use of visual effects which will pave the way for the next generation of filmmakers. That mission attracted some of the most influential individuals in the film and tech industry that are now involved in their team.Wonder Dynamics is backed by Epic Games, Samsung, Horizons Ventures (a Hong Kong VC firm with early investments in Skype, Siri, Facebook and more) and Founders Fund, a leading Silicon Valley VC that funded some giants like Space X, Facebook, Spotify, DeepMind, etc.)Their Advisory Board consists of leaders in Hollywood and Silicon Valley:Joshua Baer, founder/CEO of Capital Factory;Terry Dougas, Producer and financier of Film and TV. Founder of Rhea Films,1821 MediaAngjoo Kanazawa, assistant professor at UC Berkeley and Google research scientist;Joe Russo Director, screenwriter, and Producer (directed Avengers: Infinity War and Avengers: Endgame)Robert Schwab - Private equity investor, President, and CEO of R&L Properties.Steven Spielberg - Film director, producer, and screenwriterAntonio Torralba - Professor and Head of AI and Decision making, EECS, Massachusetts Institute of Technology (MIT).Gregory Trattner - President, Film Finances Inc. (World leader in completion guarantees and film services)About The RoleThe ideal candidate will bring passion for AI, innovative technologies, the film industry, and experience in the fields of computer vision and computer graphics with a focus on machine learning. You will design and implement cutting-edge machine learning algorithms in the fields of visual effects, motion capturing, rendering, as well as in many other film production areas.What We Are Looking For2 years of experience, or an advanced degree (MSc).Experience in applied Deep Learning (DL) and Computer Vision (CV) concepts including but are not limited to: CNNs, RNNs, Autoencoders, Transfer Learning.Hands-on experience (academic and/or industrial) in 3D Pose Estimation and Motion reconstruction from images and videos Proficiency in general purpose programming languages: Python, and C++.Experience with ML frameworks such as: PyTorch, Tensorflow, etc.The ideal candidate would be very well acquainted with Computer Graphics techniques, Neural Rendering, and Numerical Optimization(Optional) Knowledge of 3D packages such as Blender, Maya, or any game engine technologyBSc in Computer Science, Mathematics, Electrical Engineering, or related technical field.Ability to speak and write in English fluently and idiomatically.Why should you consider joining us?At the intersection of film and technology, this job will offer a very unique experience, and you will be exposed to a diverse set of fields spanning from film production and visual effects to AI, machine learning, and computer vision. Because we are operating in the state-of-the-art territory, there will always be something new to learn on the horizon. We highly value our team and the support of our co-workers and strive to create the best environment to work in.This is a mid- or senior-level engineering role and we offer a competitive salary, valuable stock options, and comprehensive benefits that allow individual flexibility for all employees to choose what makes the most sense for their personal situation.Wonder Dynamics is committed to a culture of flexibility, diversity, and fun for all of our employees. We are working on some of the most challenging technical problems and we know the solutions will come from all of us working together in an inclusive, transparent, and open manner.Powered by JazzHRvMco3jZC00\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"At MNTN, we've built a culture based on quality, trust, ambition, and accountability – but most importantly, we really enjoy working here. We pride ourselves on our self-service platform and are constantly seeking to improve the user experience for our customers and scale for efficiency. Our startup spirit powers our growth mindset and supports our teammates as they build the future of ConnectedTV. We're looking for people who naturally want to do more, own more, and make an impact in their careers – and we're seeking someone to be part of our next stage of growth.As a Machine Learning Engineer on our Attribution team, you will ideate, train, test, deploy, evaluate and monitor matching systems in a large scale production environment to maximize advertiser goals while respecting consumer privacy. As a core contributor to how we best match ads, you will work with data science, software engineers, product managers, infrastructure teams, and data teams. Relevant experience includes propensity modeling, ranking, predictive modeling, spam detection, clustering, segmentation, and similar.What You'll Do:Use MNTN proprietary and third party data sources to conceive and lead machine learning projects that maximize goals for advertising marketers while protecting consumer privacy. Be a hands-on builder of needed components in software and infrastructure. Become the end to end expert on matching ad opportunities to potential audiences in an ambiguous and privacy-focused ecosphere. Identify opportunities and gaps in data and insights for both internal and external stakeholders. Work with product and engineering teams to create and evaluate your model designs. Lead discussions with other technical and non-technical functions. Investigate critical incidents and provide insights to data ambiguity. What You'll Bring:1-3 years of experience of real-world problem solving related to developing and using machine learning models on large scale data. Advanced degrees in Computer Science, Mathematics, Electrical Engineering, Statistics or similar may be substituted for some years of experience. Experience in SQL, Python, Spark, R, or similar languages. Experience in machine learning libraries and platforms such as scikit-learn, tensorflow, sagemaker, or similar. Written and verbal communication skills to convey complex technical topics to a variety of audiences. MNTN Perks100% remote Open-ended vacation policy with an annual vacation allowanceThree-day weekend every month of the yearCompetitive compensation100% healthcare coverage401k planFlexible Spending Account (FSA) for dependent, medical, and dental careAccess to coaching, therapy, and professional developmentAbout MNTN:MNTN provides advertising software for brands to reach their audience across Connected TV, web, and mobile. MNTN Performance TV has redefined what it means to advertise on television, transforming Connected TV into a direct-response, performance marketing channel. Our web retargeting has been leveraged by thousands of top brands for over a decade, driving billions of dollars in revenue.Our solutions give advertisers total transparency and complete control over their campaigns – all with the fastest go-live in the industry. As a result, thousands of top brands have partnered with MNTN, including, Petsmart, Build with Ferguson Master, Simplisafe, Yieldstreet and National University.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Meta is embarking on the most transformative change to its business and technology in company history, and our Machine Learning Engineers are at the forefront of this evolution. By leading crucial projects and initiatives that have never been done before, you have an opportunity to help us advance the way people connect around the world. The ideal candidate will have industry experience working on a range of recommendation, classification, and optimization problems. You will bring the ability to own the whole ML life cycle, define projects and drive excellence across teams. You will work alongside the world’s leading engineers and researchers to solve some of the most exciting and massive social data and prediction problems that exist on the web.Generative AI represents a huge opportunity to unleash the creativity of the billions of people globally who use our technologies. For years, teams at Meta have been leading the industry in AI research. We are uniquely positioned to adopt an end-to-end approach to generative AI that few organizations can offer, through building breakthrough product experiences using generative AI, generative AI research across all modalities, world-class applied AI/ML product engineering, scalable, high-performance AI infrastructure and deep experience building tools that enable social connection and expression.As a Software Engineer on the generative AI team at Meta, you can help bring the transformative potential of generative AI to people and businesses around the world as we build a new class of generative AI experiences.Software Engineer, Machine Learning - Generative AI Responsibilities:Leading projects or small teams of people to help them unblock, advocating for ML excellenceAdapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based modelsSuggest, collect and synthesize requirements and create effective feature roadmapsCode deliverables in tandem with the engineering teamMinimum Qualifications:5+ years of experience in software engineering or a relevant field. 3+ years of experience if you have a PhD1+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining, artificial intelligence, or a related technical fieldExperience with developing machine learning models at scale from inception to business impactKnowledge developing and debugging in C/C++ and Java, or experience with scripting languages such as Python, Perl, PHP, and/or shell scriptsTrack record of setting technical direction for a team, driving consensus and successful cross-functional partnershipsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Masters degree or PhD in Computer Science or a related technical fieldExposure to architectural patterns of large scale software applicationsMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for NLP SCIENTIST with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java. Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer  Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack Experience Have had a break in careers Lack Technical Competency candidates who want to get employed and make a career in the Tech Industry Please Also Check The Below Links https://www.synergisticit.com/candidate-outcomes/ https://www.synergisticit.com/java-track/ https://www.synergisticit.com/data-science-track/ https://www.synergisticit.com/which-is-the-best-option-for-tech-job-seekers-staffing-companies-consulting-companies-bootcamps-or-synergisticit/ https://www.synergisticit.com/contact-us/If the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software Programmers Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT Highly motivated, self-learner, and technically inquisitive Experience in programming language Java and understanding of the software development life cycle Knowledge of Core Java , javascript , C++ or software programming Spring boot, Microservices and REST API's experience Excellent written and verbal communication skills  For data Science/Machine learningRequired Skills Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT Highly motivated, self-learner, and technically inquisitive Experience in programming language Java and understanding of the software development life cycle Knowledge of Statistics, Python, data visualization tools Excellent written and verbal communication skills  Preferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills. No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Hours: Full-timeLocation: Molg HQ in Chantilly, VA (Northern Virginia)Salary: Competitive compensation, including salary, equity, and full healthcare benefitsOUR MISSIONTackle the fast growing e-waste problem by making electronics manufacturing circular.Molg builds robotics microfactories and software to autonomously assemble and disassemble complex electronic products like laptop PCs, servers, and battery packs. Working with some of the leading computer + server manufacturers as well as industrial companies like Stanley Black and Decker, we are building the circular manufacturing technology to recover existing in-market devices for reuse and recycling as well as helping develop the next generation of circular-focused devices at the design level.IN THIS ROLE YOU WILL:Work with a talented cross-functional team of software, mechanical, electrical, and robotics engineers to develop our core technologies in computer vision as it relates to our robotics and microfactories. As a Computer Vision Engineer, you will be responsible for:Continuous design, development, testing, and deployment of 2D and 3D vision capabilities incorporated into the Molg Microfactories.Testing and verifying accuracy and precision of off-the-shelf and novel in-house vision feedback systems as it relates to robotic motion planning and grasping.Collaborating with robotic, mechanical, and software engineers on design and packaging of vision systems inside Molg Microfactory designs. WHO YOU ARE:3+ years of industry experience in computer vision, machine vision, or image processing in manufacturing environmentsProficient in modern software development (e.g. python, ROS, github, docker, etc)Passionate about robotics, automation, and control systemsAbility to communicate effectively and efficiently both verbally and in writingWHO WE ARE:We spend our days building robotic systems, developing complex assembly intelligence software, and designing the next generation of circular products for our customers. Given the importance of working hands-on with physical systems, we are a 100% in-person team collaboratively working in our industrial space in Chantilly, VA, down the road from the largest data center market in the world. Our facility includes a variety of robots, CNC milling machines, 3D printers, and all the tools needed to build and test our products. It is important to us that anyone on our team that is interested in learning how to use our various pieces of equipment and machinery is taught and can gain the skills and appreciation for making physical things.While we are primarily funded by our work with Fortune 100 companies, we are also supported by amazing backers like Elemental Excelerator and Techstars.THINGS TO KNOW:We’re a small collaborative team with big ambitions, and there’s a good amount of context-switching. We expect people to be autonomous and drive their own work to completion.We are a profitable business that is primarily funded from customer revenue, which means we are scrappy and looking to build a great sustainable company for years to come.As a growing company and startup, priorities may shift as customer or business requirements change. We strive to empower individuals with context and decision-making power to meet this need.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Computer Vision / ML Engineer (All Levels)AIM is a well-funded, mission oriented startup focused on radically scaling our civilization’s capabilities to build planetary-scale infrastructure and reverse negative effects of climate change. ( https://aim.vision )We are growing the team with motivated individuals with a passion for landing great products built with a strong engineering culture. If you find massive robots making a positive impact in the real world tantalizing, get in touch! ( https://www.aim.engineer )AIM has been built by a team of engineers, scientists, and serial entrepreneurs who previously led development of ML systems at Google, Waymo, Tesla, Apple, Google[x], Quora, Facebook and Microsoft, and are backed by General Catalyst, Human Capital, Elad Gil, Qasar Younis, Ironspring Ventures, DCVC, among other great allies.Responsibilities:Advance AIM’s perception stack and sensor fusion algorithmsThis involves breaking new ground as earth moving machines don’t merely navigate on existing mapped roads – they modify and build the environment as they work which poses interesting novel challengesResearch and development of state-of-the-art machine learning methodsComfortable with hands-on applications on machines deployed in the fieldQualifications: Proven track record of deployed ML-based perception systems, ideally on autonomous vehiclesExcellent grasp of machine perception methods and concepts, involving 2D and depth sensingExperience shipping production modelsSolid mathematical foundation of machine learningExcellent software development skills in pythonProficiency in Tensorflow and PyTorchCreativity and curiosity for solving complex problemsIdeal candidate will have expertise in reinforcement learning, and robotics, and C++What we offer:Opportunity for rapid growth and have a large voice on the direction of the companyMedical, dental, vision, 401k matching & life insuranceA position with AIM is a hybrid remote and onsite flexible expectation with a strong preference for onsiteOpportunity to travel to deployment sites around the world (US, Australia & more!)AIM is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status.AIM Intelligent Machine's General Privacy Policy: https://aim.vision/privacy/index.html\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"We are looking for an immediate hire for a computer vision engineer. Must be comfortable working on fast-paced environment and exhibit ability to balance a sense of urgency moving from R&D to deployment. You will be actively involved on one or more of these areas:Explore new vision algorithms/strategies for proof of concept assessment using vision development environmentHelp to develop more tools to enhance the capability of existing automated vision software test frameworkHelp conceive proof-of-concept prototypes that establish overall system performance You have...Bachelor's degree in Computer Science/Electrical Engineering. Master's/PhD is a plusAt-least 1+ experience in building production computer vision and imaging algorithms for image processingExpertise in at least one area of computer vision, machine learning, and computer graphics (e.g. object detection, tracking, segmentation, AR/VR, image and video processing, 3D geometry, multi- view geometry, simulation, graphics rendering)Must have strong fundamentals in computer vision concepts like intrinsic and extrinsic calibrations, homogeneous coordinates, projection matrices, and epipolar geometry. Strong coding skills in Python or C/C++Total comfort working in a Linux environmentsYou have extensive experience in OpenCV or other computer vision libraries. Preferred:Track record of publishing in top-tier computer vision or machine learning conferences or/and journals. Prior industrial experience in retail environment. Exposure to CUDA or OpenCL is preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ML - Handson Tensorflow Dev -ML pipeline and process -Strong python coding skills -Experience in deploying models -API development -Flask or Django experience\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Software Engineer - Machine Vision Application - (C#, C++,Python, OpenCV) (Onsite position in Auburn Hills, Michigan) Founded in 1994, Inovision offers automation and robotics products for automating manufacturing processes using AI, Industrial Internet of Things (IIoT) devices, and Big Data analysis. We are developing new applications to scan and analyze automobiles and other surface inspections during the automation process. Our automotive applications control factories for Tesla, Ford, Toyota, and Mercedes using IoT methods paired with AI algorithms. This position is for a strong image processing and AI software engineer. We are developing new products to scan and analyze automobiles and other surface inspection during the automation process. This job involves an understanding of cameras, lights, image processing and large scale software design. The candidate should have a solid electrical engineering or computer science background with strong image processing/AI skills. You must love to write code in C++, OpenCV, C# and Python. Highly motivated individuals who are good at working in a group or alone are desired. We use the latest technologies, OpenCV, Python, WPF, C#, C++. This is a great opportunity to stay up to date with the latest development tools. Job Description * Onsite position in Auburn Hills, MI. Some travel will be required to factories for debug. * Develop software in Microsoft C#/C++, OpenCV based on project requirements * Develop image processing algorithms in multi threaded windows environment Requirements * Solid engineering or computer science background * Motivated, intelligent, and hard-working * Excellent communication skills * Willingness to travel occasionally * Attention to detail * Legally authorized to work full-time in the United States and travel internationally as needed * Must be skilled in C#/C++ and OpenCV and multi threaded real time application development * Development may include some embedded system development, windows application development, multi-thread applications, and AI. To show your interest in this position, please explain why you would like to relocated to Michigan and which of the skills above you have expertise in to make you successful in this position! Health Benefits with Blue Cross Blue Shield PPO and matching IRA contributions are just some of our benefits! We offer great pay with 1.5x when working overtime! Other Information * Inovision is an equal opportunity employer. * Candidates must be able to perform the essential job functions with reasonable accommodation. * Employees must maintain a mobile phone and valid driver's license. * Candidates will be required to write a sample program during the interview process. * All candidate information will be kept confidential according to EEO guidelines. Company Description Growing leader in industrial vision and robotic integration for automotive and general industry.Growing leader in industrial vision and robotic integration for automotive and general industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BioMap is a platform company that integrates AI technology with cutting-edge biotechnology. We are committed to achieving breakthroughs in target discovery and drug design, and bringing global first-in-class medicine for unmet medical needs in the areas of immune-oncology, autoimmune diseases, fibrosis, and aging-related diseases.Location: Menlo Park. This role is preferably based in The Bay Area, but we are open to discussing other locations in the United States.Keywords: drug/protein design, structural biology, computational biology, protein folding, protein design, protein-ligand interactionYou will:Utilize bioinformatics tools into drug/protein design workflow and develop computing protocols for drug/ protein design Transforming research work research, open-source models, and prototypes into production-level pipelineDesign and apply innovative computational/ statistical algorithms (including classic, statistical, ML, and AI techniques) to generate actionable biological insightWork closely with the department lead to design and optimize protein design-related algorithms Requirements:PhD degree with research experience in bioinformatics, protein folding, protein design, protein-ligand integration is highly preferred; Or MS degree in computational biology, structural biology, or related fields, plus 2+ years of industry experienceProficient in at least one programming language, including but not limited to Python, C/C++, Java, etc. Familiar with machine learning and deep learning frameworks (e.g. Pytorch, Tensorflow, etc.)Familiar with Alphatfold, ESMfold, RFdesign, and ProteinMPNNGreat communication skills, including code documentation, oral presentation, with excellent attention to details What we offer:The opportunity to work on high-impact tools and products that are immediately deployed to accelerate the discovery of new medicinesA strong team in AI, software, and biochemistryCompetitive salary and equity401(k) plan with generous employer matching for contributionsExcellent medical, dental, and vision coverageDaily lunch and a full snack stationCommuter benefitsBioMap is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"WHO ARE WE?Our team is the first in the world to use autonomous vehicles on public roads using end-to-end deep learning, computer vision and reinforcement learning. Leveraging our multi-national world-class research team we're focusing on using less data to learn more intelligent algorithms to bring autonomy for everyone, everywhere. We aim to be the future of self-driving cars, not vehicles that are told how to drive through hand-coded rules and maps, but ones which learn from experience and data.WHERE YOU'LL HAVE AN IMPACTWe're looking for bold, talented and creative people to join our journey in developing next-generation autonomous vehicles. We're a growing start-up, building our first cohort of engineers and you can be at the heart of this!We are looking for ML Engineers to help productionize an end-to-end self driving neural network for autonomous driving. You'll be working closely with Platform and Research teams to integrate, test and scale ML features for production. Productionizing and scaling our ML models by working across Data, Validation, Platform and Research is a core component of this role and why we need you!What You'll Bring To WayveExperience in shipping ML features and in applied researchPassion to take research ideas to productionGood grasp of machine learning literatureExperience in working in platform teams and working with research teamsGood insight into the training, validation, testing and metrics for deep learning features/modelsAbility to write high quality, well-structured and tested Python codeSolid experience working with concurrent, parallel and distributed computingComfortable working with and visualising huge data setsKnowledge of computing fundamentals - what makes code fast, secure and reliableBS or MS in Machine Learning, Computer Science, Engineering, or a related technical discipline or equivalent experienceWhat We Offer YouAttractive compensation with salary and equityImmersion in a team of world-class researchers, engineers and entrepreneursA unique position to shape the future of autonomous driving and to tackle the biggest challenge of our timeBespoke learning and development opportunitiesRelocation support with visa sponsorshipFlexible working hours - we trust you to do your job well, at times that suit you and your teamPrivate on-site chef, in-house bar, lots of socials, and more!Wayve is built by people from all walks of life. We believe that it is our differences that make us stronger, and our unique perspectives and backgrounds that allow us to build something different. We are proud to be an equal opportunities workplace, where we don't just embrace diversity but nurture it - so that we all thrive and grow.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Fast-growing AI company is seeking highly-qualified scientists and engineers with experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to address real-world challenges in the Health Care industry. If you have a successful track record in software development, knowledge of current software technologies and methodologies, and excellent communication and interpersonal skills, we want to talk with you. Experience with image processing technologies is a plus.Desired skills:Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsExperience working with Xray images (medical/dental) or in the medical domain a plus.Familiarity with Java and Python a plusProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusComfortable working within a team as well as heading up your own research initiativesResponsibilities may include:Understanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing DL algorithms that could be used to solve a given problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themWhy work for NovoDynamics?Be part of a dynamic team that designs disruptive technologies for the Health Care industryReceive great compensation and benefitsWork in downtown Ann Arbor near the University of Michigan campusEnjoy free parking, popcorn, coffee, tea and soft drinks Delight in an amazing work environment with interesting and engaged teammatesRelax with generous and flexible time off\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityResponsibilities:As the Geometric Computer Vision Engineer you will need to develop computer vision algorithms for object detection, tracking, and classifications that are robust to lighting and weather changes. This work requires that you collaborate with state estimation engineers and assist in developing powerful feature detectors/ descriptors and large-scale 3D maps. Furthermore, it is expected that you stay organized and communicative with others to ensure that goals and objectives are being met on time. To guarantee the consistency of projects, you will participate in end-to-end development and training in Cloud to optimize development on embedded platforms.Required Qualifications:3-5+ years' significant industry experience and/or publications at venues such as ICRA, RSS, IROS, or CVPR in one or more areas- Image Processing Geometric Computer Vision Deep Learning (ideally CNNs) Classical machine learning such as SVM, decision trees, boosting, graphical models, sequential prediction, or sampling methodsStrong C++ programming and software design skillsFamiliarity with a deep learning framework such as PyTorch, TensorFlow, Caffe, or TheanoBS, MS, or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering, a related field, or equivalent experienceDesired Qualifications: Experience deploying CV/ML in a robot or real-time applicationUnderstanding of optimization of DL models and deployment on embedded platforms such as the Nvidia JetsonExperience in designing large-scale machine learning pipelinesCompensation:90,000-220,000Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"This position is participating in our  External Referral Program. If you know somebody who may be a fit, click here to submit a referral. If your referral is hired, you'll receive a $3,000 payment!code-extreferThere are people who say some ideas are impossible, unattainable or unrealistic. Then there are those of us who work at Lockheed Martin Rotary and Mission Systems. As a part of the Lockheed Martin community, we take on the biggest, baddest challenges in the world and find solutions using creativity and collaboration.AND WHERE THE SOLUTIONS DON’T EXIST? WE INVENT THEM.So, if you’re looking for the challenge of a lifetime and a team of the brightest minds in the world, Rotary and Mission Systems is the place for you. If you’re looking for a place where learning is a way of life, Rotary and Mission Systems is the place for you. And if you’re looking for a career that’s just as fun as it is hard work, well…you know.Join us today and let’s make a difference together.Lockheed Martin. Your Mission is Ours.ABOUT OUR MISSION (https://www.lockheedmartin.com/en-us/who-we-are/business-areas/rotary-and-mission-systems.)At Lockheed Martin Rotary and Mission Systems, Cyber & Intelligence, we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and forward-thinking, everything is within our reach – and yours as Lockheed Martin employee. Lockheed Martin values your skills, training and education. Come and experience your future!The Software Engineer develops, maintains, and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of very large data sets, real-time systems, and business management information systems) based upon documented requirements. Works individually or as part of a team. Reviews and tests software components for alignment to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific guidance to the software components of system design to include hardware/software trade- offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new.NOTE: This position requires an active Department of Defense TS/SCI W/ Security and US citizenship for selection.Benefits Of EmploymentWe may not know what's going to change the world next, but chances are we're already working on it, and you can, too. As part of our culture of innovation, you’ll have excellent benefits and amenities, an inclusive work environment, ongoing career development and support, rewards and recognition to honor your hard work, and more.Here Are Some Of The Benefits You Can Enjoy Medical Dental 401k Paid time off Work/life balance Career development Mentorship opportunities Rewards & recognitionLearn more about Lockheed Martin’s competitive and comprehensive benefits package.Lockheed Martin’s competitive and comprehensive benefits package. (https://www.lockheedmartinjobs.com/working-here#benefits)We support our employees, so they can support our mission.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are searching for an engineer with medical image analysis experience as well as experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to join a fast-growing AI company that is addressing real-world challenges in the Health Care industry.Our client has beautiful offices in downtown Ann Arbor. Employees are well compensated, promoted from within and taught new programming languages, techniques and disciplines as part of their jobs. The culture is relaxed. The PTO is generous.The ideal candidate has worked on a commercial product and has had their work released to customers.LOCATIONAnn Arbor MichiganSince this role deals with Personal Health Information, candidates are required to perform the majority of their work onsite.At this time, our client is not able to accommodate any type of work visa other than TN Visas.Compensation$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.EDUCATIONComputer Science or engineering degreeRequired Skills For Machine Learning ScientistMinimum of 3 years' commercial experience using machine learningProficiency with Python development.Solid experience with Image Analysis (preferably x-ray images)Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themTAGSMachine Learning | ML | Deep Learning | DL | Computer Vision | Image Analysis | Java | Python | PyTorch | TensorFlow | Keras | 3909-WPlease submit resume and cover letter to recruit@stoutsystems.com with the job title/number in the email.We have a bunch of technology jobs available! View more jobs at https://www.stoutsystems.com/jobsWe host free career webinars every week at https://www.stoutsystems.com/eventsRequirementsEDUCATIONComputer Science or engineering degreeResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themBenefitsCOMPENSATION$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'RequirementsEdgetensor is a well-funded startup based in the USA and we are looking to hire exceptional candidates in Dallas, Texas with the following requirementsComputer Vision and Machine Learning engineer with in-depth technical background, 1-2 years of C++11 and python coding experience along with hands-on experience in CV/ML algorithm development and optimization.Must have a good grasp of the fundamentals of low-level computer vision.Must be familiar with deep learning architectures, understand computational complexity of network architectures and each layer, loss functions, and evaluation metrics.Familiarity with Linear Algebra and various loss functions used in machine learning/computer vision domains.Excellent C++11/14 coding skills with best practices, knowledge of STL library and features, data structures, programming pattern, experience with debugging and build tools.Please visit edgetensor.com and send your CV to contact@edgetensor.comAbout EdgetensorWe are an edge computing startup focused on building a data2deploy pipeline for delivering fast and efficient AI applications for commodity and custom hardware. Our applications cater to a wide variety of markets such as fleet/mobility, automotive, retail, and video intelligence in both retail and enterprise domains. At the core of our applications is the edge sensor AI SDK that is powered by our proprietary inference engine that runs on platforms ranging from low-power ARM devices to x64 servers.We work on a wide range of problems: (a) auto data labeling, (b) developing CV/ML algorithms using deep learning technique, (c) inference engine for fast inference of deep learning algorithms, (d) cross-platform (CPU and OS) AI applications, (e) application license management (online and offline), (g) health monitoring of applications and dashboard analytics on the cloud.If this excites you and you are one who thinks critically to raise the bar continuously we welcome you to be part of this exciting journey.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning engineer to work closely with our product and research teams to develop SOTA deep learning software. This person will work closely with our technical and research teams to develop training and deployment pipelines, implement model compression algorithms, and productize deep learning research. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to build machine learning productsPrototype and implement appropriate ML algorithms, tools, and pipelinesCreate and manage training and deployment pipelinesCollaborate with a cross-functional team about market requirements and best practicesKeep abreast of developments in the fieldRequirementsProven experience as a machine learning engineer or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityBachelor's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Computer Vision / ML Engineer (All Levels)AIM is a well-funded, mission oriented startup focused on radically scaling our civilization’s capabilities to build planetary-scale infrastructure and reverse negative effects of climate change. ( https://aim.vision )We are growing the team with motivated individuals with a passion for landing great products built with a strong engineering culture. If you find massive robots making a positive impact in the real world tantalizing, get in touch! ( https://www.aim.engineer )AIM has been built by a team of engineers, scientists, and serial entrepreneurs who previously led development of ML systems at Google, Waymo, Tesla, Apple, Google[x], Quora, Facebook and Microsoft, and are backed by General Catalyst, Human Capital, Elad Gil, Qasar Younis, Ironspring Ventures, DCVC, among other great allies.Responsibilities:Advance AIM’s perception stack and sensor fusion algorithmsThis involves breaking new ground as earth moving machines don’t merely navigate on existing mapped roads – they modify and build the environment as they work which poses interesting novel challengesResearch and development of state-of-the-art machine learning methodsComfortable with hands-on applications on machines deployed in the fieldQualifications: Proven track record of deployed ML-based perception systems, ideally on autonomous vehiclesExcellent grasp of machine perception methods and concepts, involving 2D and depth sensingExperience shipping production modelsSolid mathematical foundation of machine learningExcellent software development skills in pythonProficiency in Tensorflow and PyTorchCreativity and curiosity for solving complex problemsIdeal candidate will have expertise in reinforcement learning, and robotics, and C++What we offer:Opportunity for rapid growth and have a large voice on the direction of the companyMedical, dental, vision, 401k matching & life insuranceA position with AIM is a hybrid remote and onsite flexible expectation with a strong preference for onsiteOpportunity to travel to deployment sites around the world (US, Australia & more!)AIM is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status.AIM Intelligent Machine's General Privacy Policy: https://aim.vision/privacy/index.html\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Fresh Consulting is a design-led, software development and hardware engineering company, offering end-to-end digital services to help companies innovate. We bring together amazing UX designers, sophisticated developers, digital strategists, and top-notch engineers to help companies create fresh experiences that connect humans, systems, and machines. We’ve been growing fast and need someone to help us continue to manage the delivery of high-quality work in a fast-paced environment.See more at freshconsulting.com Visit freshconsulting.com/portfolio to see our project work across several industries.View and apply to all jobs - https://freshconsulting.applytojob.com/apply/ or visit freshconsulting.com/careersTitle: Computer Vision EngineerDuration: 1 year with possible extensionLocation: Onsite Redmond, WABenefits: Employee benefits at 100% including Medical, PTO, Holiday Pay, 401K Plan, and much more!Hours: Minimum 40 Hours/WeekRole Develop and implement computer vision algorithms that meet specific requirements. Define data collection methods and manage data acquisition for use in developing algorithms. Perform statistical analysis and use simulation or test datasets to validate the algorithm. Debug, test, and validate algorithms to ensure high-quality results. Develop geometric calibration algorithms including SLAM camera calibration, eye tracking camera calibration, inertial measurement unit calibration, and other sensors to be modeled. Use C++ to develop and optimize algorithms for real-time applications. Communicate effectively with cross-functional teams, including software engineers, hardware engineers, and data scientists. Participate in the design, development, and deployment of computer vision applications.Skills At least 3-5 years of experience in computer vision engineering or a related field. Proficiency in C++ and Python. Experience with 2D image processing, 3D geometry, and/or bundle adjustment. Experience with statistical analysis. Excellent communication skills, both verbal and written. Ability to work independently and in a team environment.Education: BSCSE or related.FRESH-- Work on engineering and research assignments with F500 companies and startups. The relationships that we have created with our clients are one of a kind. We help solve problems in many technologies focusing on R&D, product development, and manufacturing. We work with the most cutting-edge and latest technologies from AR/VR to Autonomous technologies. Closely working with our clients, we believe that long-term investments are extremely important to maintain the culture we together have created.We’re a handpicked team of Engineers, digital strategists, designers, and developers united together in creating a fresh experience. Whether we are strategizing, designing, developing, or analyzing, our integrated team works as an extension of yours to improve your impact, your usability, and your customer conversion. In the process, we collaborate with you to get to know your business, understand your industry, and incorporate your big ideas into memorable experiences that keep your customers coming back for more.Equal employment opportunity: All qualified persons will be considered for employment without regard to race, color, religion, sex, national origin, age, marital status, familial status, gender identity, sexual orientation, disability for which a reasonable accommodation can be made or any other status protected by law. Assistance will be gladly provided upon request for any applicant with sensory or non-sensory disabilities.Fresh Consulting is a participating E-Verify company.freshconsulting.comCompensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Range $75/hr - $85/hr.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"DescriptionHere at Hugging Face, we’re on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.We have built the fastest-growing, open-source, library of pre-trained models in the world. With over 130K+ models and 110K+ stars on GitHub, over 10 thousand companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, and Grammarly.About The RoleAs an ML engineer in vision, you will work mainly into existing open-source libraries, such as Transformers and Datasets to boost the support for vision or multi-modal models and datasets. You will bring your computer vision expertise to provide the best computer-vision tool stack in the machine learning ecosystem and work with us to provide the best, simplest, and most intuitive computer-vision library in the industry.You'll get to foster one of the most active machine learning communities, helping users contribute to and use the tools that you build. You'll interact with Researchers, ML practitioners and data scientists on a daily basis through GitHub, our forums, or slack.RequirementsAbout youIf you love open-source, are passionate about the new development of Transformers models in computer vision, have experience building, optimizing, and training such models in PyTorch and/or TensorFlow, serving them in production, and want to contribute to one of the fastest-growing ML libraries, then we can't wait to see your application!If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and backgrounds complement one another. We're happy to consider where you might be able to make the biggest impact.BenefitsMore about Hugging FaceWe are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer 12 weeks of parental leave (20 for birthing mothers) and unlimited paid time off.We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Meta is seeking Software Engineer, Machine Learning to join our Generative AI. The ideal candidate will have industry experience working on a range of classification and optimization problems, e.g. payment fraud, click-through rate prediction, click-fraud detection, search ranking, text/sentiment classification, collaborative filtering/recommendation, or spam detection. The position will involve taking these skills and applying them to some of the most exciting and massive social data and prediction problems that exist on the web.Generative AI represents a huge opportunity to unleash the creativity of the billions of people globally who use our technologies. For years, teams at Meta have been leading the industry in AI research. We are uniquely positioned to adopt an end-to-end approach to generative AI that few organizations can offer through building breakthrough product experiences using generative AI, generative AI research across all modalities, world-class applied AI/ML product engineering, building scalable, high-performance AI infrastructure and our deep experience building tools that enable social connection and expression.As a Software Engineer on the generative AI team at Meta, you can help bring the transformative potential of generative AI to people and businesses around the world as we build a new class of generative AI experiences.Software Engineer, Machine Learning - Generative AI Responsibilities:Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based modelsSuggest, collect and synthesize requirements and create effective feature roadmapCode deliverables in tandem with the engineering teamAdapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)Minimum Qualifications:2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining or artificial intelligenceProven experience to translate insights into business recommendationsExperience with Hadoop/HBase/Pig or MapReduce/Sawzall/BigtableKnowledge developing and debugging in C/C++ and JavaExperience with scripting languages such as Perl, Python, PHP, and shell scriptsCurrently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.Preferred Qualifications:Experience with filesystems, server architectures, and distributed systemsMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BioMap is a platform company that integrates AI technology with cutting-edge biotechnology. We are committed to achieving breakthroughs in target discovery and drug design, and bringing global first-in-class medicine for unmet medical needs in the areas of immune-oncology, autoimmune diseases, fibrosis, and aging-related diseases.Location: Menlo Park. This role is preferably based in The Bay Area, but we are open to discussing other locations in the United States.Keywords: drug/protein design, structural biology, computational biology, protein folding, protein design, protein-ligand interactionYou will:Utilize bioinformatics tools into drug/protein design workflow and develop computing protocols for drug/ protein design Transforming research work research, open-source models, and prototypes into production-level pipelineDesign and apply innovative computational/ statistical algorithms (including classic, statistical, ML, and AI techniques) to generate actionable biological insightWork closely with the department lead to design and optimize protein design-related algorithms Requirements:PhD degree with research experience in bioinformatics, protein folding, protein design, protein-ligand integration is highly preferred; Or MS degree in computational biology, structural biology, or related fields, plus 2+ years of industry experienceProficient in at least one programming language, including but not limited to Python, C/C++, Java, etc. Familiar with machine learning and deep learning frameworks (e.g. Pytorch, Tensorflow, etc.)Familiar with Alphatfold, ESMfold, RFdesign, and ProteinMPNNGreat communication skills, including code documentation, oral presentation, with excellent attention to details What we offer:The opportunity to work on high-impact tools and products that are immediately deployed to accelerate the discovery of new medicinesA strong team in AI, software, and biochemistryCompetitive salary and equity401(k) plan with generous employer matching for contributionsExcellent medical, dental, and vision coverageDaily lunch and a full snack stationCommuter benefitsBioMap is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Software Engineer - Machine Vision Application - (C#, C++,Python, OpenCV) (Onsite position in Auburn Hills, Michigan) Founded in 1994, Inovision offers automation and robotics products for automating manufacturing processes using AI, Industrial Internet of Things (IIoT) devices, and Big Data analysis. We are developing new applications to scan and analyze automobiles and other surface inspections during the automation process. Our automotive applications control factories for Tesla, Ford, Toyota, and Mercedes using IoT methods paired with AI algorithms. This position is for a strong image processing and AI software engineer. We are developing new products to scan and analyze automobiles and other surface inspection during the automation process. This job involves an understanding of cameras, lights, image processing and large scale software design. The candidate should have a solid electrical engineering or computer science background with strong image processing/AI skills. You must love to write code in C++, OpenCV, C# and Python. Highly motivated individuals who are good at working in a group or alone are desired. We use the latest technologies, OpenCV, Python, WPF, C#, C++. This is a great opportunity to stay up to date with the latest development tools. Job Description * Onsite position in Auburn Hills, MI. Some travel will be required to factories for debug. * Develop software in Microsoft C#/C++, OpenCV based on project requirements * Develop image processing algorithms in multi threaded windows environment Requirements * Solid engineering or computer science background * Motivated, intelligent, and hard-working * Excellent communication skills * Willingness to travel occasionally * Attention to detail * Legally authorized to work full-time in the United States and travel internationally as needed * Must be skilled in C#/C++ and OpenCV and multi threaded real time application development * Development may include some embedded system development, windows application development, multi-thread applications, and AI. To show your interest in this position, please explain why you would like to relocated to Michigan and which of the skills above you have expertise in to make you successful in this position! Health Benefits with Blue Cross Blue Shield PPO and matching IRA contributions are just some of our benefits! We offer great pay with 1.5x when working overtime! Other Information * Inovision is an equal opportunity employer. * Candidates must be able to perform the essential job functions with reasonable accommodation. * Employees must maintain a mobile phone and valid driver's license. * Candidates will be required to write a sample program during the interview process. * All candidate information will be kept confidential according to EEO guidelines. Company Description Growing leader in industrial vision and robotic integration for automotive and general industry.Growing leader in industrial vision and robotic integration for automotive and general industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Mujin's new US office is expanding rapidly, and to sustain that growth we're building a whole new branch of our world-class computer vision team.As a Computer Vision Engineer, you will be a part of the Mujin R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition. You will work directly with and expand on the world’s first 3D vision system for factory automation and logistics solutions.You will work directly with global leaders in applied computer vision, solving the kind of problems that haven't even been asked on Stack Overflow yet -- let alone answered.ResponsibilitiesSolve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenariosAnalyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from both academic and industrial research, and implement and enhance them in a production environmentDesign, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications in Python and C/C++Perform detailed tests, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithmsMinimum RequirementsGraduating/graduated from Computer Science or relevant faculty with a BS, MSc or Ph.DBS or MS with computer vision experience, or Ph.D. in Computer Vision related topicsAbility to develop applications and tools in Python and/or C++Technical communication skills in English (reading and writing)Preferred Experience3D pose estimation of textured and texture-less objects in cluttered scenesExtensive Python and C++ development experienceBroad experience with computer vision librariesMathematical backgroundPrevious contributions to open source projectsIt would be amazing if you have experience in: object tracking, SLAM, computer graphics, augmented reality, machine learning, or robotics projectsAbout The RoleYou'll work directly with researchers from the world’s top-tier universities and labs in robotics, computer vision, and image and signal processing. The team includes Ph. D. and MSc grads from Carnegie Mellon, Stanford, and more. Mujin has the most active real-world deployments of industrial computer vision systems. That means you won't be working in a vacuum--you'll have access to the largest set of customer feedback data in this industry globallyOur computer vision algorithms are robust enough to run on 24/7 systems, handling thousands of items per customer, for diverse customers and applications. The challenges of enlarging its capabilities toward more autonomy, scalability, and diversity of applications mean you will never stop learning at MujinWe're a well-established startup entering a global scale-up phase. That means we have enough structure so you can focus on computer vision, but not so much structure that you can't spread your wings. Come grow with us!If you would like to apply real-time computer vision algorithms to robotics and join the industrial automation revolution, this role is for you!Check out our blog for more information about Mujin's work culture! You can meet our dual-Ph. D. Computer Vision team manager, Jeronimo, here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About AppliedAutonomy is one of the leading technological advances of this century that will come to impact our lives. The work you'll do at Applied will meaningfully accelerate the efforts of the top autonomy teams in the world. At Applied, you will have a unique perspective on the development of cutting-edge technology while working with major players across the industry and the globe.Applied Intuition provides software solutions to safely develop, test, and deploy autonomous vehicles at scale. The company's suite of simulation, validation, and drive log management software enables development teams to create thousands of scenarios in minutes, run simulations at scale, and verify and validate algorithms for production deployment. Headquartered in Silicon Valley with offices in Los Angeles, Detroit, Washington, D.C., Munich, Stockholm, Seoul, and Tokyo, Applied consists of software, robotics, and automotive experts with experiences from top global companies. Leading autonomy programs and 17 of the top 20 global OEMs use Applied's solutions to bring autonomy to market faster.About The RoleWe are looking for bright engineers interested in designing elegant solutions to difficult problems in the autonomy space. Our software engineers work across our suite of products, tackling a variety of full-stack, infrastructure, robotics, and graphics challenges. At Applied, we encourage engineers to take ownership over technical and product decisions, closely interact with users to collect feedback, and contribute to a thoughtful, dynamic team culture.At Applied you will:Work across our entire stack to develop new products, features, and tools for our customers' autonomy development workflowsHave an unparalleled opportunity to work with domain experts across a variety of fields: infrastructure, robotics, and graphics engineers, as well as startup veteransCarve out your own area of expertise and influence product decisionsCollaborate with other members in the autonomy ecosystem and learn about different approaches to solving core issues in autonomyWe're looking for someone who:Is a self-starter and can quickly become comfortable with new technical toolsDesigns efficient and effective solutions to a wide range of engineering challengesTakes initiative in a fast-paced environmentNice to have:Working knowledge of frontend, API layer, database ORM, containerization, or cluster orchestration frameworks (such as React, GraphQL, SQLAlchemy, Docker, or Kubernetes)Experience working with simulation tools, modeling physical problems, or using robotics middleware (such as ROS)Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"WHO ARE WE?Our team is the first in the world to use autonomous vehicles on public roads using end-to-end deep learning, computer vision and reinforcement learning. Leveraging our multi-national world-class research team we're focusing on using less data to learn more intelligent algorithms to bring autonomy for everyone, everywhere. We aim to be the future of self-driving cars, not vehicles that are told how to drive through hand-coded rules and maps, but ones which learn from experience and data.WHERE YOU'LL HAVE AN IMPACTWe're looking for bold, talented and creative people to join our journey in developing next-generation autonomous vehicles. We're a growing start-up, building our first cohort of engineers and you can be at the heart of this!We are looking for ML Engineers to help productionize an end-to-end self driving neural network for autonomous driving. You'll be working closely with Platform and Research teams to integrate, test and scale ML features for production. Productionizing and scaling our ML models by working across Data, Validation, Platform and Research is a core component of this role and why we need you!What You'll Bring To WayveExperience in shipping ML features and in applied researchPassion to take research ideas to productionGood grasp of machine learning literatureExperience in working in platform teams and working with research teamsGood insight into the training, validation, testing and metrics for deep learning features/modelsAbility to write high quality, well-structured and tested Python codeSolid experience working with concurrent, parallel and distributed computingComfortable working with and visualising huge data setsKnowledge of computing fundamentals - what makes code fast, secure and reliableBS or MS in Machine Learning, Computer Science, Engineering, or a related technical discipline or equivalent experienceWhat We Offer YouAttractive compensation with salary and equityImmersion in a team of world-class researchers, engineers and entrepreneursA unique position to shape the future of autonomous driving and to tackle the biggest challenge of our timeBespoke learning and development opportunitiesRelocation support with visa sponsorshipFlexible working hours - we trust you to do your job well, at times that suit you and your teamPrivate on-site chef, in-house bar, lots of socials, and more!Wayve is built by people from all walks of life. We believe that it is our differences that make us stronger, and our unique perspectives and backgrounds that allow us to build something different. We are proud to be an equal opportunities workplace, where we don't just embrace diversity but nurture it - so that we all thrive and grow.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'about the senior machine learning engineer role:soona is looking for a senior. machine learning engineer who will assume the primary responsibility of embedding our various machine learning models related to decision science, computer vision, and logistics optimization into robust production systems accessed by our internal stakeholders and external customers alike. you will work closely with our data scientists and engineers to build and maintain these products and services. to be successful in this role, you will understand the general methods of training machine learning models, how to serialize and deploy those models, and how to leverage the necessary architecture (e.g. Kubernetes and GPUs) to make model inference performant for the consumers’ needs.this is a full time position that will report directly to the senior director of data science.about soona:soona makes it possible for brands to create professional photo and video starting at $39. our studios give customers a playground for creating their content and our online platform makes it possible for any product company in the world to experience a remote shoot. we are creating a fast casual content revolution!soona is currently supporting a US remote work environment for this role with opportunity for a flex hybrid work environment within our operating cities--Denver and Minneapolis, if that’s your thing.about tech at soona:at soona, we’re focused on building a world-class engineering and data organization. we’re developing a highly-scalable platform for real-time customer engagement with our studio creatives and technology that optimizes the content they create. our typical engineering and data projects blend SaaS with e-commerce, providing opportunities to work on everything from app engineering and cloud/server architecture to computer vision and logistics/routing optimization. our tech stack consists primarily of ruby on rails, javascript vue, and python. we pride ourselves on our culture of innovation, community engagement, technical mentorship, and caring for the individual.our hiring philosophy:at soona, we look for representation across all intersectionalities of identities, specifically within underrepresented groups. it is these differences that push us towards innovation, curiosity, and success in our business. we believe in providing equal employment opportunities without regard to race, color, religion, age, sex, national origin, disability status, protected veteran status, genetics, sexual orientation, gender identity or expression, or any other characteristic protected by laws or regulations in the locations we operate. this means that timelines of processes may be impacted, depending on our applicant pools.Requirementsan ideal candidate can:deploy machine learning models into production services and environmentsbuild architecture required to efficiently operate our data science services (including computer vision, analytics, and optimization systems)create and maintain telemetry/observability systems to monitor app performancethink for themselves and discover new and insightful ways to solve difficult problemsdeliver quality code in an agile framework that ships to a production environmentcommunicate with data and engineering teams as well as business stakeholdershas experience in:effectively communicating and coding in a remote work environmentpython – the core language of the data organizationdata science, data engineering, or backend engineering, specifically in building data science products and services in a production environmentaws or equivalent cloud environmentleveraging GPUs/CUDA vis-à-vis pytorch (or similar)kubernetes, docker, flask/fastAPI (or similar)infrastructure-as-code tooling like terraform (preferred)designing and building machine learning models (preferred)sql, dbt – our data layer platform (preferred)looker, segment, airbyte (preferred)working in a startup environment (preferred)Benefitswe can offer:starting salary: $170,000 - $200,000stock options in a booming startupbenefits & perks + unlimited pto + intentional culturereally badass headshots\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Internship PeriodSummer 2023Our CompanyMiso Robotics is transforming the restaurant industry and making a real impact on the world. We've developed a robotic kitchen assistant, Flippy, that can perform a variety of kitchen tasks including running the deep fryer. Our product is a robotic arm on a rail that fits into existing kitchens along existing cook lines and is designed to work with existing equipment alongside kitchen workers. Under the hood, Flippy relies on our platform which combines deep learning and other computer vision technologies with optimization-based scheduling and nonlinear control to adapt quickly to a variety of kitchen workflows, while achieving graceful and efficient motion.The challenge of bringing robotics into commercial kitchens requires many disciplines to come together. The compositions of teams at Miso Robotics reflect this multidisciplinary nature of our work. We have built a world-class team and we are looking for more exceptional people to join us. If you believe, like we do, that the future of the kitchen involves robotics and artificial intelligence (HINT: It definitely does) and if you want to count yourself among the handful of lucky people who've found themselves with the opportunity to solve this problem, then Miso Robotics might be the right place for you!Our ValuesWe live with a TEAM mindset - we win together. Individual performance serves the bigger goal of working as a team.We are easy on people, hard on problems. We work relentlessly to solve issues.We use Candor - ego has no place here. Always polite and extremely direct.We operate with Rigor - superb execution is a core skill.We are bought in - each of us is dedicated to the mission.Innovation is in our blood - we are intrepid. We think big - we’re here to make an impact. Miso plays large ball.RoleAs a Software Engineer Intern, you will explore the potential of Large Language Models (LLMs) in improving code quality here at Miso Robotics. You will collaborate with the robot platform team, while having access to the organization’s tools and resources, and development opportunities. This project has the potential to make a significant contribution to the improvement of the codebase of our organization.Additional Information: The pay range for this position is $25 - $40 per hour. Our salary ranges are determined by the experience and education required, and level of responsibility. The range posted for this role represents a range that Miso Robotics, in good faith, believes it is willing to pay at the time of this posting. The pay is determined by job related skills, training, education, and experience.ResponsibilitiesOn a day to day basis, you will:Investigate the use of LLMs for improving code qualityExplore the potential of LLMs in generating missing unit testsInvestigate the use of LLMs in adding docstrings to the codebaseEvaluate the effectiveness of LLM-generated unit tests and docstrings in improving code quality metrics, such as code maintainability and readability.Document the development process and present findings and results to the teamQualificationsEnrolled in Bachelor's degree in Computer Science or related Engineering with strong programming skillsHands-on experience with Large Language ModelsAbility to navigate Linux environmentsExperience in Python and C++Understanding of algorithms and data structuresExcellent Research and collaboration skillsStrong analytical skills and ability to learn at hyperspeedStrong attention to detailEffective oral and written communication skillsSelf-motivated and able to solve problems independentlyAbility to work in our HQ in Pasadena, CA.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Fast-growing AI company is seeking highly-qualified scientists and engineers with experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to address real-world challenges in the Health Care industry. If you have a successful track record in software development, knowledge of current software technologies and methodologies, and excellent communication and interpersonal skills, we want to talk with you. Experience with image processing technologies is a plus.Desired skills:Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsExperience working with Xray images (medical/dental) or in the medical domain a plus.Familiarity with Java and Python a plusProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusComfortable working within a team as well as heading up your own research initiativesResponsibilities may include:Understanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing DL algorithms that could be used to solve a given problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themWhy work for NovoDynamics?Be part of a dynamic team that designs disruptive technologies for the Health Care industryReceive great compensation and benefitsWork in downtown Ann Arbor near the University of Michigan campusEnjoy free parking, popcorn, coffee, tea and soft drinks Delight in an amazing work environment with interesting and engaged teammatesRelax with generous and flexible time off\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityResponsibilities:As the Geometric Computer Vision Engineer you will need to develop computer vision algorithms for object detection, tracking, and classifications that are robust to lighting and weather changes. This work requires that you collaborate with state estimation engineers and assist in developing powerful feature detectors/ descriptors and large-scale 3D maps. Furthermore, it is expected that you stay organized and communicative with others to ensure that goals and objectives are being met on time. To guarantee the consistency of projects, you will participate in end-to-end development and training in Cloud to optimize development on embedded platforms.Required Qualifications:3-5+ years' significant industry experience and/or publications at venues such as ICRA, RSS, IROS, or CVPR in one or more areas- Image Processing Geometric Computer Vision Deep Learning (ideally CNNs) Classical machine learning such as SVM, decision trees, boosting, graphical models, sequential prediction, or sampling methodsStrong C++ programming and software design skillsFamiliarity with a deep learning framework such as PyTorch, TensorFlow, Caffe, or TheanoBS, MS, or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering, a related field, or equivalent experienceDesired Qualifications: Experience deploying CV/ML in a robot or real-time applicationUnderstanding of optimization of DL models and deployment on embedded platforms such as the Nvidia JetsonExperience in designing large-scale machine learning pipelinesCompensation:90,000-220,000Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Computer Vision / ML Engineer (All Levels)AIM is a well-funded, mission oriented startup focused on radically scaling our civilization’s capabilities to build planetary-scale infrastructure and reverse negative effects of climate change. ( https://aim.vision )We are growing the team with motivated individuals with a passion for landing great products built with a strong engineering culture. If you find massive robots making a positive impact in the real world tantalizing, get in touch! ( https://www.aim.engineer )AIM has been built by a team of engineers, scientists, and serial entrepreneurs who previously led development of ML systems at Google, Waymo, Tesla, Apple, Google[x], Quora, Facebook and Microsoft, and are backed by General Catalyst, Human Capital, Elad Gil, Qasar Younis, Ironspring Ventures, DCVC, among other great allies.Responsibilities:Advance AIM’s perception stack and sensor fusion algorithmsThis involves breaking new ground as earth moving machines don’t merely navigate on existing mapped roads – they modify and build the environment as they work which poses interesting novel challengesResearch and development of state-of-the-art machine learning methodsComfortable with hands-on applications on machines deployed in the fieldQualifications: Proven track record of deployed ML-based perception systems, ideally on autonomous vehiclesExcellent grasp of machine perception methods and concepts, involving 2D and depth sensingExperience shipping production modelsSolid mathematical foundation of machine learningExcellent software development skills in pythonProficiency in Tensorflow and PyTorchCreativity and curiosity for solving complex problemsIdeal candidate will have expertise in reinforcement learning, and robotics, and C++What we offer:Opportunity for rapid growth and have a large voice on the direction of the companyMedical, dental, vision, 401k matching & life insuranceA position with AIM is a hybrid remote and onsite flexible expectation with a strong preference for onsiteOpportunity to travel to deployment sites around the world (US, Australia & more!)AIM is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status.AIM Intelligent Machine's General Privacy Policy: https://aim.vision/privacy/index.html\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Fresh Consulting is a design-led, software development and hardware engineering company, offering end-to-end digital services to help companies innovate. We bring together amazing UX designers, sophisticated developers, digital strategists, and top-notch engineers to help companies create fresh experiences that connect humans, systems, and machines. We’ve been growing fast and need someone to help us continue to manage the delivery of high-quality work in a fast-paced environment.See more at freshconsulting.com Visit freshconsulting.com/portfolio to see our project work across several industries.View and apply to all jobs - https://freshconsulting.applytojob.com/apply/ or visit freshconsulting.com/careersTitle: Computer Vision EngineerDuration: 1 year with possible extensionLocation: Onsite Redmond, WABenefits: Employee benefits at 100% including Medical, PTO, Holiday Pay, 401K Plan, and much more!Hours: Minimum 40 Hours/WeekRole Develop and implement computer vision algorithms that meet specific requirements. Define data collection methods and manage data acquisition for use in developing algorithms. Perform statistical analysis and use simulation or test datasets to validate the algorithm. Debug, test, and validate algorithms to ensure high-quality results. Develop geometric calibration algorithms including SLAM camera calibration, eye tracking camera calibration, inertial measurement unit calibration, and other sensors to be modeled. Use C++ to develop and optimize algorithms for real-time applications. Communicate effectively with cross-functional teams, including software engineers, hardware engineers, and data scientists. Participate in the design, development, and deployment of computer vision applications.Skills At least 3-5 years of experience in computer vision engineering or a related field. Proficiency in C++ and Python. Experience with 2D image processing, 3D geometry, and/or bundle adjustment. Experience with statistical analysis. Excellent communication skills, both verbal and written. Ability to work independently and in a team environment.Education: BSCSE or related.FRESH-- Work on engineering and research assignments with F500 companies and startups. The relationships that we have created with our clients are one of a kind. We help solve problems in many technologies focusing on R&D, product development, and manufacturing. We work with the most cutting-edge and latest technologies from AR/VR to Autonomous technologies. Closely working with our clients, we believe that long-term investments are extremely important to maintain the culture we together have created.We’re a handpicked team of Engineers, digital strategists, designers, and developers united together in creating a fresh experience. Whether we are strategizing, designing, developing, or analyzing, our integrated team works as an extension of yours to improve your impact, your usability, and your customer conversion. In the process, we collaborate with you to get to know your business, understand your industry, and incorporate your big ideas into memorable experiences that keep your customers coming back for more.Equal employment opportunity: All qualified persons will be considered for employment without regard to race, color, religion, sex, national origin, age, marital status, familial status, gender identity, sexual orientation, disability for which a reasonable accommodation can be made or any other status protected by law. Assistance will be gladly provided upon request for any applicant with sensory or non-sensory disabilities.Fresh Consulting is a participating E-Verify company.freshconsulting.comCompensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Range $75/hr - $85/hr.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"DescriptionHere at Hugging Face, we’re on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.We have built the fastest-growing, open-source, library of pre-trained models in the world. With over 130K+ models and 110K+ stars on GitHub, over 10 thousand companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, and Grammarly.About The RoleAs an ML engineer in vision, you will work mainly into existing open-source libraries, such as Transformers and Datasets to boost the support for vision or multi-modal models and datasets. You will bring your computer vision expertise to provide the best computer-vision tool stack in the machine learning ecosystem and work with us to provide the best, simplest, and most intuitive computer-vision library in the industry.You'll get to foster one of the most active machine learning communities, helping users contribute to and use the tools that you build. You'll interact with Researchers, ML practitioners and data scientists on a daily basis through GitHub, our forums, or slack.RequirementsAbout youIf you love open-source, are passionate about the new development of Transformers models in computer vision, have experience building, optimizing, and training such models in PyTorch and/or TensorFlow, serving them in production, and want to contribute to one of the fastest-growing ML libraries, then we can't wait to see your application!If you're interested in joining us, but don't tick every box above, we still encourage you to apply! We're building a diverse team whose skills, experiences, and backgrounds complement one another. We're happy to consider where you might be able to make the biggest impact.BenefitsMore about Hugging FaceWe are actively working to build a culture that values diversity, equity, and inclusivity. We are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.We care about your well-being. We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer 12 weeks of parental leave (20 for birthing mothers) and unlimited paid time off.We support our employees wherever they are. While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.We want our teammates to be shareholders. All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.We support the community. We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Meta is seeking Software Engineer, Machine Learning to join our Generative AI. The ideal candidate will have industry experience working on a range of classification and optimization problems, e.g. payment fraud, click-through rate prediction, click-fraud detection, search ranking, text/sentiment classification, collaborative filtering/recommendation, or spam detection. The position will involve taking these skills and applying them to some of the most exciting and massive social data and prediction problems that exist on the web.Generative AI represents a huge opportunity to unleash the creativity of the billions of people globally who use our technologies. For years, teams at Meta have been leading the industry in AI research. We are uniquely positioned to adopt an end-to-end approach to generative AI that few organizations can offer through building breakthrough product experiences using generative AI, generative AI research across all modalities, world-class applied AI/ML product engineering, building scalable, high-performance AI infrastructure and our deep experience building tools that enable social connection and expression.As a Software Engineer on the generative AI team at Meta, you can help bring the transformative potential of generative AI to people and businesses around the world as we build a new class of generative AI experiences.Software Engineer, Machine Learning - Generative AI Responsibilities:Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based modelsSuggest, collect and synthesize requirements and create effective feature roadmapCode deliverables in tandem with the engineering teamAdapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)Minimum Qualifications:2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining or artificial intelligenceProven experience to translate insights into business recommendationsExperience with Hadoop/HBase/Pig or MapReduce/Sawzall/BigtableKnowledge developing and debugging in C/C++ and JavaExperience with scripting languages such as Perl, Python, PHP, and shell scriptsCurrently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.Preferred Qualifications:Experience with filesystems, server architectures, and distributed systemsMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ML - Handson Tensorflow Dev -ML pipeline and process -Strong python coding skills -Experience in deploying models -API development -Flask or Django experience\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BioMap is a platform company that integrates AI technology with cutting-edge biotechnology. We are committed to achieving breakthroughs in target discovery and drug design, and bringing global first-in-class medicine for unmet medical needs in the areas of immune-oncology, autoimmune diseases, fibrosis, and aging-related diseases.Location: Menlo Park. This role is preferably based in The Bay Area, but we are open to discussing other locations in the United States.Keywords: drug/protein design, structural biology, computational biology, protein folding, protein design, protein-ligand interactionYou will:Utilize bioinformatics tools into drug/protein design workflow and develop computing protocols for drug/ protein design Transforming research work research, open-source models, and prototypes into production-level pipelineDesign and apply innovative computational/ statistical algorithms (including classic, statistical, ML, and AI techniques) to generate actionable biological insightWork closely with the department lead to design and optimize protein design-related algorithms Requirements:PhD degree with research experience in bioinformatics, protein folding, protein design, protein-ligand integration is highly preferred; Or MS degree in computational biology, structural biology, or related fields, plus 2+ years of industry experienceProficient in at least one programming language, including but not limited to Python, C/C++, Java, etc. Familiar with machine learning and deep learning frameworks (e.g. Pytorch, Tensorflow, etc.)Familiar with Alphatfold, ESMfold, RFdesign, and ProteinMPNNGreat communication skills, including code documentation, oral presentation, with excellent attention to details What we offer:The opportunity to work on high-impact tools and products that are immediately deployed to accelerate the discovery of new medicinesA strong team in AI, software, and biochemistryCompetitive salary and equity401(k) plan with generous employer matching for contributionsExcellent medical, dental, and vision coverageDaily lunch and a full snack stationCommuter benefitsBioMap is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Software Engineer - Machine Vision Application - (C#, C++,Python, OpenCV) (Onsite position in Auburn Hills, Michigan) Founded in 1994, Inovision offers automation and robotics products for automating manufacturing processes using AI, Industrial Internet of Things (IIoT) devices, and Big Data analysis. We are developing new applications to scan and analyze automobiles and other surface inspections during the automation process. Our automotive applications control factories for Tesla, Ford, Toyota, and Mercedes using IoT methods paired with AI algorithms. This position is for a strong image processing and AI software engineer. We are developing new products to scan and analyze automobiles and other surface inspection during the automation process. This job involves an understanding of cameras, lights, image processing and large scale software design. The candidate should have a solid electrical engineering or computer science background with strong image processing/AI skills. You must love to write code in C++, OpenCV, C# and Python. Highly motivated individuals who are good at working in a group or alone are desired. We use the latest technologies, OpenCV, Python, WPF, C#, C++. This is a great opportunity to stay up to date with the latest development tools. Job Description * Onsite position in Auburn Hills, MI. Some travel will be required to factories for debug. * Develop software in Microsoft C#/C++, OpenCV based on project requirements * Develop image processing algorithms in multi threaded windows environment Requirements * Solid engineering or computer science background * Motivated, intelligent, and hard-working * Excellent communication skills * Willingness to travel occasionally * Attention to detail * Legally authorized to work full-time in the United States and travel internationally as needed * Must be skilled in C#/C++ and OpenCV and multi threaded real time application development * Development may include some embedded system development, windows application development, multi-thread applications, and AI. To show your interest in this position, please explain why you would like to relocated to Michigan and which of the skills above you have expertise in to make you successful in this position! Health Benefits with Blue Cross Blue Shield PPO and matching IRA contributions are just some of our benefits! We offer great pay with 1.5x when working overtime! Other Information * Inovision is an equal opportunity employer. * Candidates must be able to perform the essential job functions with reasonable accommodation. * Employees must maintain a mobile phone and valid driver's license. * Candidates will be required to write a sample program during the interview process. * All candidate information will be kept confidential according to EEO guidelines. Company Description Growing leader in industrial vision and robotic integration for automotive and general industry.Growing leader in industrial vision and robotic integration for automotive and general industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About AppliedAutonomy is one of the leading technological advances of this century that will come to impact our lives. The work you'll do at Applied will meaningfully accelerate the efforts of the top autonomy teams in the world. At Applied, you will have a unique perspective on the development of cutting-edge technology while working with major players across the industry and the globe.Applied Intuition provides software solutions to safely develop, test, and deploy autonomous vehicles at scale. The company's suite of simulation, validation, and drive log management software enables development teams to create thousands of scenarios in minutes, run simulations at scale, and verify and validate algorithms for production deployment. Headquartered in Silicon Valley with offices in Los Angeles, Detroit, Washington, D.C., Munich, Stockholm, Seoul, and Tokyo, Applied consists of software, robotics, and automotive experts with experiences from top global companies. Leading autonomy programs and 17 of the top 20 global OEMs use Applied's solutions to bring autonomy to market faster.About The RoleWe are looking for bright engineers interested in designing elegant solutions to difficult problems in the autonomy space. Our software engineers work across our suite of products, tackling a variety of full-stack, infrastructure, robotics, and graphics challenges. At Applied, we encourage engineers to take ownership over technical and product decisions, closely interact with users to collect feedback, and contribute to a thoughtful, dynamic team culture.At Applied you will:Work across our entire stack to develop new products, features, and tools for our customers' autonomy development workflowsHave an unparalleled opportunity to work with domain experts across a variety of fields: infrastructure, robotics, and graphics engineers, as well as startup veteransCarve out your own area of expertise and influence product decisionsCollaborate with other members in the autonomy ecosystem and learn about different approaches to solving core issues in autonomyWe're looking for someone who:Is a self-starter and can quickly become comfortable with new technical toolsDesigns efficient and effective solutions to a wide range of engineering challengesTakes initiative in a fast-paced environmentNice to have:Working knowledge of frontend, API layer, database ORM, containerization, or cluster orchestration frameworks (such as React, GraphQL, SQLAlchemy, Docker, or Kubernetes)Experience working with simulation tools, modeling physical problems, or using robotics middleware (such as ROS)Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"WHO ARE WE?Our team is the first in the world to use autonomous vehicles on public roads using end-to-end deep learning, computer vision and reinforcement learning. Leveraging our multi-national world-class research team we're focusing on using less data to learn more intelligent algorithms to bring autonomy for everyone, everywhere. We aim to be the future of self-driving cars, not vehicles that are told how to drive through hand-coded rules and maps, but ones which learn from experience and data.WHERE YOU'LL HAVE AN IMPACTWe're looking for bold, talented and creative people to join our journey in developing next-generation autonomous vehicles. We're a growing start-up, building our first cohort of engineers and you can be at the heart of this!We are looking for ML Engineers to help productionize an end-to-end self driving neural network for autonomous driving. You'll be working closely with Platform and Research teams to integrate, test and scale ML features for production. Productionizing and scaling our ML models by working across Data, Validation, Platform and Research is a core component of this role and why we need you!What You'll Bring To WayveExperience in shipping ML features and in applied researchPassion to take research ideas to productionGood grasp of machine learning literatureExperience in working in platform teams and working with research teamsGood insight into the training, validation, testing and metrics for deep learning features/modelsAbility to write high quality, well-structured and tested Python codeSolid experience working with concurrent, parallel and distributed computingComfortable working with and visualising huge data setsKnowledge of computing fundamentals - what makes code fast, secure and reliableBS or MS in Machine Learning, Computer Science, Engineering, or a related technical discipline or equivalent experienceWhat We Offer YouAttractive compensation with salary and equityImmersion in a team of world-class researchers, engineers and entrepreneursA unique position to shape the future of autonomous driving and to tackle the biggest challenge of our timeBespoke learning and development opportunitiesRelocation support with visa sponsorshipFlexible working hours - we trust you to do your job well, at times that suit you and your teamPrivate on-site chef, in-house bar, lots of socials, and more!Wayve is built by people from all walks of life. We believe that it is our differences that make us stronger, and our unique perspectives and backgrounds that allow us to build something different. We are proud to be an equal opportunities workplace, where we don't just embrace diversity but nurture it - so that we all thrive and grow.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Internship PeriodSummer 2023Our CompanyMiso Robotics is transforming the restaurant industry and making a real impact on the world. We've developed a robotic kitchen assistant, Flippy, that can perform a variety of kitchen tasks including running the deep fryer. Our product is a robotic arm on a rail that fits into existing kitchens along existing cook lines and is designed to work with existing equipment alongside kitchen workers. Under the hood, Flippy relies on our platform which combines deep learning and other computer vision technologies with optimization-based scheduling and nonlinear control to adapt quickly to a variety of kitchen workflows, while achieving graceful and efficient motion.The challenge of bringing robotics into commercial kitchens requires many disciplines to come together. The compositions of teams at Miso Robotics reflect this multidisciplinary nature of our work. We have built a world-class team and we are looking for more exceptional people to join us. If you believe, like we do, that the future of the kitchen involves robotics and artificial intelligence (HINT: It definitely does) and if you want to count yourself among the handful of lucky people who've found themselves with the opportunity to solve this problem, then Miso Robotics might be the right place for you!Our ValuesWe live with a TEAM mindset - we win together. Individual performance serves the bigger goal of working as a team.We are easy on people, hard on problems. We work relentlessly to solve issues.We use Candor - ego has no place here. Always polite and extremely direct.We operate with Rigor - superb execution is a core skill.We are bought in - each of us is dedicated to the mission.Innovation is in our blood - we are intrepid. We think big - we’re here to make an impact. Miso plays large ball.RoleAs a Software Engineer Intern, you will explore the potential of Large Language Models (LLMs) in improving code quality here at Miso Robotics. You will collaborate with the robot platform team, while having access to the organization’s tools and resources, and development opportunities. This project has the potential to make a significant contribution to the improvement of the codebase of our organization.Additional Information: The pay range for this position is $25 - $40 per hour. Our salary ranges are determined by the experience and education required, and level of responsibility. The range posted for this role represents a range that Miso Robotics, in good faith, believes it is willing to pay at the time of this posting. The pay is determined by job related skills, training, education, and experience.ResponsibilitiesOn a day to day basis, you will:Investigate the use of LLMs for improving code qualityExplore the potential of LLMs in generating missing unit testsInvestigate the use of LLMs in adding docstrings to the codebaseEvaluate the effectiveness of LLM-generated unit tests and docstrings in improving code quality metrics, such as code maintainability and readability.Document the development process and present findings and results to the teamQualificationsEnrolled in Bachelor's degree in Computer Science or related Engineering with strong programming skillsHands-on experience with Large Language ModelsAbility to navigate Linux environmentsExperience in Python and C++Understanding of algorithms and data structuresExcellent Research and collaboration skillsStrong analytical skills and ability to learn at hyperspeedStrong attention to detailEffective oral and written communication skillsSelf-motivated and able to solve problems independentlyAbility to work in our HQ in Pasadena, CA.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Fast-growing AI company is seeking highly-qualified scientists and engineers with experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to address real-world challenges in the Health Care industry. If you have a successful track record in software development, knowledge of current software technologies and methodologies, and excellent communication and interpersonal skills, we want to talk with you. Experience with image processing technologies is a plus.Desired skills:Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsExperience working with Xray images (medical/dental) or in the medical domain a plus.Familiarity with Java and Python a plusProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusComfortable working within a team as well as heading up your own research initiativesResponsibilities may include:Understanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing DL algorithms that could be used to solve a given problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themWhy work for NovoDynamics?Be part of a dynamic team that designs disruptive technologies for the Health Care industryReceive great compensation and benefitsWork in downtown Ann Arbor near the University of Michigan campusEnjoy free parking, popcorn, coffee, tea and soft drinks Delight in an amazing work environment with interesting and engaged teammatesRelax with generous and flexible time off\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityResponsibilities:As the Geometric Computer Vision Engineer you will need to develop computer vision algorithms for object detection, tracking, and classifications that are robust to lighting and weather changes. This work requires that you collaborate with state estimation engineers and assist in developing powerful feature detectors/ descriptors and large-scale 3D maps. Furthermore, it is expected that you stay organized and communicative with others to ensure that goals and objectives are being met on time. To guarantee the consistency of projects, you will participate in end-to-end development and training in Cloud to optimize development on embedded platforms.Required Qualifications:3-5+ years' significant industry experience and/or publications at venues such as ICRA, RSS, IROS, or CVPR in one or more areas- Image Processing Geometric Computer Vision Deep Learning (ideally CNNs) Classical machine learning such as SVM, decision trees, boosting, graphical models, sequential prediction, or sampling methodsStrong C++ programming and software design skillsFamiliarity with a deep learning framework such as PyTorch, TensorFlow, Caffe, or TheanoBS, MS, or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering, a related field, or equivalent experienceDesired Qualifications: Experience deploying CV/ML in a robot or real-time applicationUnderstanding of optimization of DL models and deployment on embedded platforms such as the Nvidia JetsonExperience in designing large-scale machine learning pipelinesCompensation:90,000-220,000Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are searching for an engineer with medical image analysis experience as well as experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to join a fast-growing AI company that is addressing real-world challenges in the Health Care industry.Our client has beautiful offices in downtown Ann Arbor. Employees are well compensated, promoted from within and taught new programming languages, techniques and disciplines as part of their jobs. The culture is relaxed. The PTO is generous.The ideal candidate has worked on a commercial product and has had their work released to customers.LOCATIONAnn Arbor MichiganSince this role deals with Personal Health Information, candidates are required to perform the majority of their work onsite.At this time, our client is not able to accommodate any type of work visa other than TN Visas.Compensation$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.EDUCATIONComputer Science or engineering degreeRequired Skills For Machine Learning ScientistMinimum of 3 years' commercial experience using machine learningProficiency with Python development.Solid experience with Image Analysis (preferably x-ray images)Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themTAGSMachine Learning | ML | Deep Learning | DL | Computer Vision | Image Analysis | Java | Python | PyTorch | TensorFlow | Keras | 3909-WPlease submit resume and cover letter to recruit@stoutsystems.com with the job title/number in the email.We have a bunch of technology jobs available! View more jobs at https://www.stoutsystems.com/jobsWe host free career webinars every week at https://www.stoutsystems.com/eventsRequirementsEDUCATIONComputer Science or engineering degreeResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themBenefitsCOMPENSATION$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Software Engineer - Machine Vision Application - (C#, C++,Python, OpenCV) (Onsite position in Auburn Hills, Michigan) Founded in 1994, Inovision offers automation and robotics products for automating manufacturing processes using AI, Industrial Internet of Things (IIoT) devices, and Big Data analysis. We are developing new applications to scan and analyze automobiles and other surface inspections during the automation process. Our automotive applications control factories for Tesla, Ford, Toyota, and Mercedes using IoT methods paired with AI algorithms. This position is for a strong image processing and AI software engineer. We are developing new products to scan and analyze automobiles and other surface inspection during the automation process. This job involves an understanding of cameras, lights, image processing and large scale software design. The candidate should have a solid electrical engineering or computer science background with strong image processing/AI skills. You must love to write code in C++, OpenCV, C# and Python. Highly motivated individuals who are good at working in a group or alone are desired. We use the latest technologies, OpenCV, Python, WPF, C#, C++. This is a great opportunity to stay up to date with the latest development tools. Job Description * Onsite position in Auburn Hills, MI. Some travel will be required to factories for debug. * Develop software in Microsoft C#/C++, OpenCV based on project requirements * Develop image processing algorithms in multi threaded windows environment Requirements * Solid engineering or computer science background * Motivated, intelligent, and hard-working * Excellent communication skills * Willingness to travel occasionally * Attention to detail * Legally authorized to work full-time in the United States and travel internationally as needed * Must be skilled in C#/C++ and OpenCV and multi threaded real time application development * Development may include some embedded system development, windows application development, multi-thread applications, and AI. To show your interest in this position, please explain why you would like to relocated to Michigan and which of the skills above you have expertise in to make you successful in this position! Health Benefits with Blue Cross Blue Shield PPO and matching IRA contributions are just some of our benefits! We offer great pay with 1.5x when working overtime! Other Information * Inovision is an equal opportunity employer. * Candidates must be able to perform the essential job functions with reasonable accommodation. * Employees must maintain a mobile phone and valid driver's license. * Candidates will be required to write a sample program during the interview process. * All candidate information will be kept confidential according to EEO guidelines. Company Description Growing leader in industrial vision and robotic integration for automotive and general industry.Growing leader in industrial vision and robotic integration for automotive and general industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"WHO ARE WE?Our team is the first in the world to use autonomous vehicles on public roads using end-to-end deep learning, computer vision and reinforcement learning. Leveraging our multi-national world-class research team we're focusing on using less data to learn more intelligent algorithms to bring autonomy for everyone, everywhere. We aim to be the future of self-driving cars, not vehicles that are told how to drive through hand-coded rules and maps, but ones which learn from experience and data.WHERE YOU'LL HAVE AN IMPACTWe're looking for bold, talented and creative people to join our journey in developing next-generation autonomous vehicles. We're a growing start-up, building our first cohort of engineers and you can be at the heart of this!We are looking for ML Engineers to help productionize an end-to-end self driving neural network for autonomous driving. You'll be working closely with Platform and Research teams to integrate, test and scale ML features for production. Productionizing and scaling our ML models by working across Data, Validation, Platform and Research is a core component of this role and why we need you!What You'll Bring To WayveExperience in shipping ML features and in applied researchPassion to take research ideas to productionGood grasp of machine learning literatureExperience in working in platform teams and working with research teamsGood insight into the training, validation, testing and metrics for deep learning features/modelsAbility to write high quality, well-structured and tested Python codeSolid experience working with concurrent, parallel and distributed computingComfortable working with and visualising huge data setsKnowledge of computing fundamentals - what makes code fast, secure and reliableBS or MS in Machine Learning, Computer Science, Engineering, or a related technical discipline or equivalent experienceWhat We Offer YouAttractive compensation with salary and equityImmersion in a team of world-class researchers, engineers and entrepreneursA unique position to shape the future of autonomous driving and to tackle the biggest challenge of our timeBespoke learning and development opportunitiesRelocation support with visa sponsorshipFlexible working hours - we trust you to do your job well, at times that suit you and your teamPrivate on-site chef, in-house bar, lots of socials, and more!Wayve is built by people from all walks of life. We believe that it is our differences that make us stronger, and our unique perspectives and backgrounds that allow us to build something different. We are proud to be an equal opportunities workplace, where we don't just embrace diversity but nurture it - so that we all thrive and grow.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Application Deadline:  9 May 2023Department: Software DevelopmentEmployment Type: Full TimeLocation: Remote, USAReporting To: Senior ArchitectDescriptionYOUR OPPORTUNITYWho wants to build cool stuff? Here at InMoment you'll have the opportunity to work with some of the best experts in software development, plus learn some really fun tech along the way.In this particular role, you will work on including cutting edge technologies into our SaaS and embedded software platforms, such as object recognition, AI-enhanced data analysis, and ChatGPT-enhanced CX interactions.If you're interested in an exceptionally collaborative environment and sharing what you know with others, then this is the right place. We hire enthusiastic, committed individuals who are interested in building some of the best cross-platform software in the industry.We believe in diversity and inclusion and welcome anyone with the right skills and experience as listed below to be a part of the team—even if you're a Last Jedi fan. (We hire those, too.)Interested? Come chat with us!Who We AreAt InMoment, we have a saying: #OwnTheMomentsThatMatter. And we live it! As a team, we recognize that every moment offers a new opportunity to make an impact and leave our mark. We take deliberate action to make the lives of our families, teammates, clients, and communities better with every interaction.We are dedicated to our game-changing mission of Experience Improvement (XI), helping our clients improve experiences at the intersection of value—where customer, employee, and business needs come together. We consistently challenge the status quo in the customer experience (CX), employee experience (EX), market research (MX), and product experience (PX) industries with our hyper-modern technology platform, decades of domain authority, and global teams of experts. And we have more innovation in store!Are you ready to #OwnTheMomentsThatMatter with us?Who You Are3-5 years of experience working in an enterprise software development environmentBachelors or Masters in Computer Science, Computer Engineering, or other related technical fieldInterested in adding AI technologies into human workflowsHave experience integrating with cloud servicesAble to interact with business stakeholders and product management to participate in technical product directionExperience with Python and machine learning libraries (Tensorflow, OpenCV, etc)You have excellent communication and interpersonal skills and a collaborative team playerYou care about how your work and attitude affects those around you and want to help maintain our positive culture at InMomentYou like to experiment: you're comfortable with trying things, occasionally failing, and trying something elseYou like to learn new technologies and use them in the real worldYou are self-motivated. You will need to have your self-motivation kicked into high gearYou are experienced working with a remote team. We use Slack, Zoom, Google Meet, JIRA and other technologies to make this as painless as possibleWhat You'll DoEvaluate and help select AI and ML technologiesHelp set standards for markup and annotation as well as evaluate the resultsWrite code to integrate SaaS services such as Amazon Rekognition, Open-AI or Google Translate into the existing InMoment platformsWhat You'll GainAutonomy - We trust our employees and offer an extremely flexible work scheduleUnlimited PTO - We encourage all employees to recharge!Medical with HSA (which includes generous employer match & contribution) and FSA optionsDental and vision insurance401(k) with a generous company match, access to a personal financial planner, and both legal and life insuranceGenerous Parental leave programLegal, ID theft, and employer-paid disability and life insuranceAccess to wellbeing initiatives and offerings such as our Employee Assistance ProgramFun, innovative, collaborative, supportive working environmentInclusion and Diversity teams - Women of InMoment and InMovementEmployee rewards and referral programs with generous payoutsLOCATIONUSA - RemoteAt InMoment, inclusion, and diversity are at the core of who we are. InMoment prides itself on an inclusive culture that promotes, encourages, and supports the diverse voices of our employees and clients. We strive to create workplaces that reflect the communities we serve and believe that different perspectives, interests, and backgrounds foster a stronger and more creative work environment.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are searching for an engineer with medical image analysis experience as well as experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to join a fast-growing AI company that is addressing real-world challenges in the Health Care industry.Our client has beautiful offices in downtown Ann Arbor. Employees are well compensated, promoted from within and taught new programming languages, techniques and disciplines as part of their jobs. The culture is relaxed. The PTO is generous.The ideal candidate has worked on a commercial product and has had their work released to customers.LOCATIONAnn Arbor MichiganSince this role deals with Personal Health Information, candidates are required to perform the majority of their work onsite.At this time, our client is not able to accommodate any type of work visa other than TN Visas.Compensation$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.EDUCATIONComputer Science or engineering degreeRequired Skills For Machine Learning ScientistMinimum of 3 years' commercial experience using machine learningProficiency with Python development.Solid experience with Image Analysis (preferably x-ray images)Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themTAGSMachine Learning | ML | Deep Learning | DL | Computer Vision | Image Analysis | Java | Python | PyTorch | TensorFlow | Keras | 3909-WPlease submit resume and cover letter to recruit@stoutsystems.com with the job title/number in the email.We have a bunch of technology jobs available! View more jobs at https://www.stoutsystems.com/jobsWe host free career webinars every week at https://www.stoutsystems.com/eventsRequirementsEDUCATIONComputer Science or engineering degreeResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themBenefitsCOMPENSATION$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionJob Role : Software Engineer (Python &plus; Machine learning)Job Location: Mountain View CAFull Time Only Job DescriptionStrong experience with Python.Strong debugging skills working in diversified environments.Knowledge on Tensorflow and its various sub components.Experience with GitHub and Stackoverflow.Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Allozymes is a deep tech company based in Singapore. We are revolutionising the way industry uses enzymes for manufacturing chemicals and natural compounds. Our rapid discovery and evolution of custom-designed enzymes enables breakthrough developments for sustainable production of ingredients for pharmaceuticals, cosmetics, chemical, food and beverages.We’re hiring a highly capable Machine Learning Engineer into our Data team. This team is responsible for developing and implementing state-of-the-art approaches for evolving enzymes and microbes to enhance the production of chemicals and natural compounds. The engineer will integrate the development of our cloud-based artificial intelligence platform for enhancing Allozymes’ enzyme optimization capabilities. Working in a highly collaborative and dynamic environment, this role has the opportunity to interact with other scientists, automation and process engineers to achieve these goals. Responsibilities:Contribute to the design and improvement of Allozymes cloud-based AI platform.Scope project requirements, assess data quality, process data and perform feature engineering.Build, train and deploy ML/DL models, using state-of-the-art technologies and proprietary data to accurately perform predictions and generate new, high performing, enzymes.Perform model evaluation and statistical analysis to improve model quality.Enhance the performance and deployment environment of implemented solutions.Qualifications:MS or PhD in mathematics, statistics, computer science, engineering or a related quantitative field with a focus on AI and Machine Learning.2+ years of relevant industry experience.Expertise in building, training and deploying Machine and Deep Learning models.Proficiency in Python.Expertise in using ML/DS specific python libraries (Pandas, Numpy, Scipy, Scikit-learn, PyTorch, Keras).Experience with ML life-cycle management and code/data version control tools.Familiarity working with Cloud computing.Ability to work in a fast-paced, collaborative and cross-functional environment and communicate results effectively to management.Experience with supervised and unsupervised learning algorithms, clustering, feature selection methods, evaluation, dimensionality reduction, Bayesian inference, hyper-parameter tuning and model optimization is a plusExperience with Language models, Encoders, Transformers, Attention, Generative models and GANs is a plusExperience in biology, bioinformatics or computational biology.Experience using AWS/SageMaker is a plusExperience with containers and container orchestration tools is a plusExperience writing production-ready code (version-controlled, scalable, well-documented, testable, deployment-ready) is a plusNumber of Vacancies: 1\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"At MNTN, we've built a culture based on quality, trust, ambition, and accountability – but most importantly, we really enjoy working here. We pride ourselves on our self-service platform and are constantly seeking to improve the user experience for our customers and scale for efficiency. Our startup spirit powers our growth mindset and supports our teammates as they build the future of ConnectedTV. We're looking for people who naturally want to do more, own more, and make an impact in their careers – and we're seeking someone to be part of our next stage of growth.As a Machine Learning Engineer on our Attribution team, you will ideate, train, test, deploy, evaluate and monitor matching systems in a large scale production environment to maximize advertiser goals while respecting consumer privacy. As a core contributor to how we best match ads, you will work with data science, software engineers, product managers, infrastructure teams, and data teams. Relevant experience includes propensity modeling, ranking, predictive modeling, spam detection, clustering, segmentation, and similar.What You'll Do:Use MNTN proprietary and third party data sources to conceive and lead machine learning projects that maximize goals for advertising marketers while protecting consumer privacy. Be a hands-on builder of needed components in software and infrastructure. Become the end to end expert on matching ad opportunities to potential audiences in an ambiguous and privacy-focused ecosphere. Identify opportunities and gaps in data and insights for both internal and external stakeholders. Work with product and engineering teams to create and evaluate your model designs. Lead discussions with other technical and non-technical functions. Investigate critical incidents and provide insights to data ambiguity. What You'll Bring:1-3 years of experience of real-world problem solving related to developing and using machine learning models on large scale data. Advanced degrees in Computer Science, Mathematics, Electrical Engineering, Statistics or similar may be substituted for some years of experience. Experience in SQL, Python, Spark, R, or similar languages. Experience in machine learning libraries and platforms such as scikit-learn, tensorflow, sagemaker, or similar. Written and verbal communication skills to convey complex technical topics to a variety of audiences. MNTN Perks100% remote Open-ended vacation policy with an annual vacation allowanceThree-day weekend every month of the yearCompetitive compensation100% healthcare coverage401k planFlexible Spending Account (FSA) for dependent, medical, and dental careAccess to coaching, therapy, and professional developmentAbout MNTN:MNTN provides advertising software for brands to reach their audience across Connected TV, web, and mobile. MNTN Performance TV has redefined what it means to advertise on television, transforming Connected TV into a direct-response, performance marketing channel. Our web retargeting has been leveraged by thousands of top brands for over a decade, driving billions of dollars in revenue.Our solutions give advertisers total transparency and complete control over their campaigns – all with the fastest go-live in the industry. As a result, thousands of top brands have partnered with MNTN, including, Petsmart, Build with Ferguson Master, Simplisafe, Yieldstreet and National University.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company OverviewIdea Evolver specializes in audience research and consumer insights as well as designing and engineering Software as a Medical Device applications.Our primary verticals are healthcare, food, and retail. Our client list includes American Express, Dannon, AstraZeneca, United Therapeutics, Blue Origin, and K. Hovnanian Homes.Position OverviewWe are looking for a highly skilled Machine Learning Engineer to join as a leader on our Product team. This person will collaborate closely with our Executive leadership team, data scientists, and software engineers.ResponsibilitiesSupport the creation of our machine learning workflow processes, including data collection and preprocessing, model design and training, and deployment of models into production.Serve as the subject matter expert and the key driver on machine learning and its application to SaMD products.Work with product developers (tech regulatory, data scientists, engineers) on incorporating machine learning algorithms into development and data processing pipelines.Collaborate with cross-functional teams, including product managers and marketers, to understand business problems and develop comprehensive machine learning solutions.Continuously monitor the performance of machine learning implementations and identify opportunities for improvement.Stay current with the latest machine learning techniques and technologies to continuously improve the quality of our products and knowledge of our team.QualificationsUndergraduate degree in a quantitative field (computer science, engineering, mathematics, physics, machine learning, statistics), Masters degree preferred3+ years of industry experience designing, developing, and deploying machine learning models including classification, clustering, prediction, deep learning, etc.Experience with cloud-based ecosystems (GCP preferred)Experience with Python and relevant libraries (NumPy, Pandas, Scikit-learn)Experience using common machine learning and deep learning libraries and techniques, including TensorFlowExperience with, or willingness to learn Julia/FluxExperience with Git in a team environmentExperience with data visualization tools such as Looker, Tableau, or Power BIGeneral knowledge of Docker, Jenkins, Kubernetes, and other DevOps toolsExcellent verbal and written communication skillsCompensation and Benefits:Competitive SalaryHealth and wellness benefits401k with company matching20 paid days off plus holidaysPowered by JazzHRGZqXAnSS9N\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"North Point Defense (NPD) is seeking a Machine Learning Engineer to join its team in Rome, NY. In addition to continued development of its core intelligence products, NPD often provides rapidly prototyped systems that are spiraled into larger more comprehensive efforts. Successful candidates must be able to work in a small team or independently on simultaneous projects efficiently when required. This position will be responsible for designing and implementing AI/ML algorithms and models and researching and developing scalable solutions while collaborating with data/RF/DSP engineers to build data generation pipelines.RequirementsFacility with Tensorflow, KerasExperience with frameworks such as PyTorch, sci-kit, onnx, matlab and tensorRT is beneficialResearch areas of interest include: computer vision, reinforcement learning, transformers (sequence-to-sequence modeling), data augmentation, multi-modal learning, few-shot learning, semi-supervised learning, unsupervised learningRF/DSP Experience Preferred, But Not RequiredEducation Requirements:2 -3 years of experience in Artificial Intelligence and Machine Learning research and model deployment.Bachelor's Degree in Computer Science, Software Engineering, Data Science or related discipline with requisite experience (Graduate degree strongly preferred).Other Requirements:Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.Current TS/SCI a strong plus.BenefitsCasual team-oriented work environment.Flexible work schedule.Competitive salary, with special considerations for cleared individuals.Pay for every hour you are authorized to work.Individual Benefit Account (IBA) with an employer contribution equal to 15% of an employee’s annual salary. IBA funds can be used toward:Health InsuranceDental/Vision InsuranceHealth Savings Account – Employee ContributionsPaid Time Off - up to 34 days of PTO per year plus 6 paid holidaysGroup Term Life InsuranceAccidental Death InsuranceGenerous 401(k) programCompany paid short-term disability insuranceCompany paid long-term disability insuranceNorth Point Defense, Inc. is an equal opportunity and affirmative action employer that does not discriminate in employment.All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Role: Machine Learning EngineerLocation: San Francisco, CAType: Full TimeAbout This RoleYou will build the machine learning systems that power our general artificial intelligence for capital allocation. We are looking for researchers who want to discover elegant deep learning concepts and then put them into production as solutions to high-stakes, real-world problems.Ideal candidate traits3+ years of professional experience as a software engineer or machine learning researcherHistory of generating new ideas in AI, evidenced by published works or personal projectsExceptional engineering abilities, with a track record of putting complex systems into productionResearch leadership skills, with the capacity to own projects end-to-end, from idea generation through executionEnergized by fast-paced, intense work environmentsExceptional independence of thought and grittiness in the pursuit of success\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"We are looking for an immediate hire for a computer vision engineer. Must be comfortable working on fast-paced environment and exhibit ability to balance a sense of urgency moving from R&D to deployment. You will be actively involved on one or more of these areas:Explore new vision algorithms/strategies for proof of concept assessment using vision development environmentHelp to develop more tools to enhance the capability of existing automated vision software test frameworkHelp conceive proof-of-concept prototypes that establish overall system performance You have...Bachelor's degree in Computer Science/Electrical Engineering. Master's/PhD is a plusAt-least 1+ experience in building production computer vision and imaging algorithms for image processingExpertise in at least one area of computer vision, machine learning, and computer graphics (e.g. object detection, tracking, segmentation, AR/VR, image and video processing, 3D geometry, multi- view geometry, simulation, graphics rendering)Must have strong fundamentals in computer vision concepts like intrinsic and extrinsic calibrations, homogeneous coordinates, projection matrices, and epipolar geometry. Strong coding skills in Python or C/C++Total comfort working in a Linux environmentsYou have extensive experience in OpenCV or other computer vision libraries. Preferred:Track record of publishing in top-tier computer vision or machine learning conferences or/and journals. Prior industrial experience in retail environment. Exposure to CUDA or OpenCL is preferred\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ML - Handson Tensorflow Dev -ML pipeline and process -Strong python coding skills -Experience in deploying models -API development -Flask or Django experience\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Mujin's new US office is expanding rapidly, and to sustain that growth we're building a whole new branch of our world-class computer vision team.As a Computer Vision Engineer, you will be a part of the Mujin R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition. You will work directly with and expand on the world’s first 3D vision system for factory automation and logistics solutions.You will work directly with global leaders in applied computer vision, solving the kind of problems that haven't even been asked on Stack Overflow yet -- let alone answered.ResponsibilitiesSolve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenariosAnalyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from both academic and industrial research, and implement and enhance them in a production environmentDesign, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications in Python and C/C++Perform detailed tests, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithmsMinimum RequirementsGraduating/graduated from Computer Science or relevant faculty with a BS, MSc or Ph.DBS or MS with computer vision experience, or Ph.D. in Computer Vision related topicsAbility to develop applications and tools in Python and/or C++Technical communication skills in English (reading and writing)Preferred Experience3D pose estimation of textured and texture-less objects in cluttered scenesExtensive Python and C++ development experienceBroad experience with computer vision librariesMathematical backgroundPrevious contributions to open source projectsIt would be amazing if you have experience in: object tracking, SLAM, computer graphics, augmented reality, machine learning, or robotics projectsAbout The RoleYou'll work directly with researchers from the world’s top-tier universities and labs in robotics, computer vision, and image and signal processing. The team includes Ph. D. and MSc grads from Carnegie Mellon, Stanford, and more. Mujin has the most active real-world deployments of industrial computer vision systems. That means you won't be working in a vacuum--you'll have access to the largest set of customer feedback data in this industry globallyOur computer vision algorithms are robust enough to run on 24/7 systems, handling thousands of items per customer, for diverse customers and applications. The challenges of enlarging its capabilities toward more autonomy, scalability, and diversity of applications mean you will never stop learning at MujinWe're a well-established startup entering a global scale-up phase. That means we have enough structure so you can focus on computer vision, but not so much structure that you can't spread your wings. Come grow with us!If you would like to apply real-time computer vision algorithms to robotics and join the industrial automation revolution, this role is for you!Check out our blog for more information about Mujin's work culture! You can meet our dual-Ph. D. Computer Vision team manager, Jeronimo, here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Fast-growing AI company is seeking highly-qualified scientists and engineers with experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to address real-world challenges in the Health Care industry. If you have a successful track record in software development, knowledge of current software technologies and methodologies, and excellent communication and interpersonal skills, we want to talk with you. Experience with image processing technologies is a plus.Desired skills:Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsExperience working with Xray images (medical/dental) or in the medical domain a plus.Familiarity with Java and Python a plusProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusComfortable working within a team as well as heading up your own research initiativesResponsibilities may include:Understanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing DL algorithms that could be used to solve a given problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themWhy work for NovoDynamics?Be part of a dynamic team that designs disruptive technologies for the Health Care industryReceive great compensation and benefitsWork in downtown Ann Arbor near the University of Michigan campusEnjoy free parking, popcorn, coffee, tea and soft drinks Delight in an amazing work environment with interesting and engaged teammatesRelax with generous and flexible time off\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This position is participating in our  External Referral Program. If you know somebody who may be a fit, click here to submit a referral. If your referral is hired, you'll receive a $3,000 payment!code-extreferThere are people who say some ideas are impossible, unattainable or unrealistic. Then there are those of us who work at Lockheed Martin Rotary and Mission Systems. As a part of the Lockheed Martin community, we take on the biggest, baddest challenges in the world and find solutions using creativity and collaboration.AND WHERE THE SOLUTIONS DON’T EXIST? WE INVENT THEM.So, if you’re looking for the challenge of a lifetime and a team of the brightest minds in the world, Rotary and Mission Systems is the place for you. If you’re looking for a place where learning is a way of life, Rotary and Mission Systems is the place for you. And if you’re looking for a career that’s just as fun as it is hard work, well…you know.Join us today and let’s make a difference together.Lockheed Martin. Your Mission is Ours.ABOUT OUR MISSION (https://www.lockheedmartin.com/en-us/who-we-are/business-areas/rotary-and-mission-systems.)At Lockheed Martin Rotary and Mission Systems, Cyber & Intelligence, we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and forward-thinking, everything is within our reach – and yours as Lockheed Martin employee. Lockheed Martin values your skills, training and education. Come and experience your future!The Software Engineer develops, maintains, and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of very large data sets, real-time systems, and business management information systems) based upon documented requirements. Works individually or as part of a team. Reviews and tests software components for alignment to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific guidance to the software components of system design to include hardware/software trade- offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new.NOTE: This position requires an active Department of Defense TS/SCI W/ Security and US citizenship for selection.Benefits Of EmploymentWe may not know what's going to change the world next, but chances are we're already working on it, and you can, too. As part of our culture of innovation, you’ll have excellent benefits and amenities, an inclusive work environment, ongoing career development and support, rewards and recognition to honor your hard work, and more.Here Are Some Of The Benefits You Can Enjoy Medical Dental 401k Paid time off Work/life balance Career development Mentorship opportunities Rewards & recognitionLearn more about Lockheed Martin’s competitive and comprehensive benefits package.Lockheed Martin’s competitive and comprehensive benefits package. (https://www.lockheedmartinjobs.com/working-here#benefits)We support our employees, so they can support our mission.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityResponsibilities:As the Geometric Computer Vision Engineer you will need to develop computer vision algorithms for object detection, tracking, and classifications that are robust to lighting and weather changes. This work requires that you collaborate with state estimation engineers and assist in developing powerful feature detectors/ descriptors and large-scale 3D maps. Furthermore, it is expected that you stay organized and communicative with others to ensure that goals and objectives are being met on time. To guarantee the consistency of projects, you will participate in end-to-end development and training in Cloud to optimize development on embedded platforms.Required Qualifications:3-5+ years' significant industry experience and/or publications at venues such as ICRA, RSS, IROS, or CVPR in one or more areas- Image Processing Geometric Computer Vision Deep Learning (ideally CNNs) Classical machine learning such as SVM, decision trees, boosting, graphical models, sequential prediction, or sampling methodsStrong C++ programming and software design skillsFamiliarity with a deep learning framework such as PyTorch, TensorFlow, Caffe, or TheanoBS, MS, or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering, a related field, or equivalent experienceDesired Qualifications: Experience deploying CV/ML in a robot or real-time applicationUnderstanding of optimization of DL models and deployment on embedded platforms such as the Nvidia JetsonExperience in designing large-scale machine learning pipelinesCompensation:90,000-220,000Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are searching for an engineer with medical image analysis experience as well as experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to join a fast-growing AI company that is addressing real-world challenges in the Health Care industry.Our client has beautiful offices in downtown Ann Arbor. Employees are well compensated, promoted from within and taught new programming languages, techniques and disciplines as part of their jobs. The culture is relaxed. The PTO is generous.The ideal candidate has worked on a commercial product and has had their work released to customers.LOCATIONAnn Arbor MichiganSince this role deals with Personal Health Information, candidates are required to perform the majority of their work onsite.At this time, our client is not able to accommodate any type of work visa other than TN Visas.Compensation$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.EDUCATIONComputer Science or engineering degreeRequired Skills For Machine Learning ScientistMinimum of 3 years' commercial experience using machine learningProficiency with Python development.Solid experience with Image Analysis (preferably x-ray images)Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themTAGSMachine Learning | ML | Deep Learning | DL | Computer Vision | Image Analysis | Java | Python | PyTorch | TensorFlow | Keras | 3909-WPlease submit resume and cover letter to recruit@stoutsystems.com with the job title/number in the email.We have a bunch of technology jobs available! View more jobs at https://www.stoutsystems.com/jobsWe host free career webinars every week at https://www.stoutsystems.com/eventsRequirementsEDUCATIONComputer Science or engineering degreeResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themBenefitsCOMPENSATION$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'RequirementsEdgetensor is a well-funded startup based in the USA and we are looking to hire exceptional candidates in Dallas, Texas with the following requirementsComputer Vision and Machine Learning engineer with in-depth technical background, 1-2 years of C++11 and python coding experience along with hands-on experience in CV/ML algorithm development and optimization.Must have a good grasp of the fundamentals of low-level computer vision.Must be familiar with deep learning architectures, understand computational complexity of network architectures and each layer, loss functions, and evaluation metrics.Familiarity with Linear Algebra and various loss functions used in machine learning/computer vision domains.Excellent C++11/14 coding skills with best practices, knowledge of STL library and features, data structures, programming pattern, experience with debugging and build tools.Please visit edgetensor.com and send your CV to contact@edgetensor.comAbout EdgetensorWe are an edge computing startup focused on building a data2deploy pipeline for delivering fast and efficient AI applications for commodity and custom hardware. Our applications cater to a wide variety of markets such as fleet/mobility, automotive, retail, and video intelligence in both retail and enterprise domains. At the core of our applications is the edge sensor AI SDK that is powered by our proprietary inference engine that runs on platforms ranging from low-power ARM devices to x64 servers.We work on a wide range of problems: (a) auto data labeling, (b) developing CV/ML algorithms using deep learning technique, (c) inference engine for fast inference of deep learning algorithms, (d) cross-platform (CPU and OS) AI applications, (e) application license management (online and offline), (g) health monitoring of applications and dashboard analytics on the cloud.If this excites you and you are one who thinks critically to raise the bar continuously we welcome you to be part of this exciting journey.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'LVIS is a leader in cutting edge neural information analysis technology that decodes brain networks and provides visualizations assisting neurological disease diagnosis. LVIS owns patented technologies and our team includes leaders with strong expertise in neuroscience and engineering. LVIS has been selected to be a member of the Stanford StartX community and the NVIDIA inception program. We are an international team with our headquarter located in Palo Alto, California, USA and an office in Gangnam, Seoul, South Korea. We are looking for talented individuals to join us in transforming the neurology health care industry.ResponsibilitiesDeep learning model deployment for medical web applications.Machine learning system stability testing and optimization.Model compression with pruning, quantization and distillation.Collaborate with data scientists and software engineers to optimize deep learning model performance.RequirementsMinimum Required QualificationsMS or PHD in Computer Science, Statistics, Electrical Engineering, Applied Math, and other similar fields.Deep understanding of the machine learning algorithms and systems, especially convolutional neural networks.Proficient in python and python machine learning packages, such as numpy, scikit learn, pytorch, keras, etc.Preferred To HaveHands-on experience of model deployment in the cloud (AWS, Azure or GCP).Experience of model compression techniques.Experiences in medical image/signal processing and data analysis.Other InformationJob type: Full-time.U.S. citizens, green card holders, and those authorized to work in the U.S. for any employer will be considered.Willing to work onsite at our Palo Alto location.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Hours: Full-timeLocation: Molg HQ in Chantilly, VA (Northern Virginia)Salary: Competitive compensation, including salary, equity, and full healthcare benefitsOUR MISSIONTackle the fast growing e-waste problem by making electronics manufacturing circular.Molg builds robotics microfactories and software to autonomously assemble and disassemble complex electronic products like laptop PCs, servers, and battery packs. Working with some of the leading computer + server manufacturers as well as industrial companies like Stanley Black and Decker, we are building the circular manufacturing technology to recover existing in-market devices for reuse and recycling as well as helping develop the next generation of circular-focused devices at the design level.IN THIS ROLE YOU WILL:Work with a talented cross-functional team of software, mechanical, electrical, and robotics engineers to develop our core technologies in computer vision as it relates to our robotics and microfactories. As a Computer Vision Engineer, you will be responsible for:Continuous design, development, testing, and deployment of 2D and 3D vision capabilities incorporated into the Molg Microfactories.Testing and verifying accuracy and precision of off-the-shelf and novel in-house vision feedback systems as it relates to robotic motion planning and grasping.Collaborating with robotic, mechanical, and software engineers on design and packaging of vision systems inside Molg Microfactory designs. WHO YOU ARE:3+ years of industry experience in computer vision, machine vision, or image processing in manufacturing environmentsProficient in modern software development (e.g. python, ROS, github, docker, etc)Passionate about robotics, automation, and control systemsAbility to communicate effectively and efficiently both verbally and in writingWHO WE ARE:We spend our days building robotic systems, developing complex assembly intelligence software, and designing the next generation of circular products for our customers. Given the importance of working hands-on with physical systems, we are a 100% in-person team collaboratively working in our industrial space in Chantilly, VA, down the road from the largest data center market in the world. Our facility includes a variety of robots, CNC milling machines, 3D printers, and all the tools needed to build and test our products. It is important to us that anyone on our team that is interested in learning how to use our various pieces of equipment and machinery is taught and can gain the skills and appreciation for making physical things.While we are primarily funded by our work with Fortune 100 companies, we are also supported by amazing backers like Elemental Excelerator and Techstars.THINGS TO KNOW:We’re a small collaborative team with big ambitions, and there’s a good amount of context-switching. We expect people to be autonomous and drive their own work to completion.We are a profitable business that is primarily funded from customer revenue, which means we are scrappy and looking to build a great sustainable company for years to come.As a growing company and startup, priorities may shift as customer or business requirements change. We strive to empower individuals with context and decision-making power to meet this need.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Holy Grail developed a direct air carbon capture technology that uses electrons to capture CO2 from the atmosphere. We are looking for proactive candidates who are ready to take ownership and are passionate about creating a sustainable solution to removing excess CO2 from the atmosphere. The ultimate goal of Holy Grail is to contribute to the long-term sustainability of life on Earth.We are looking for a data machine learning engineer to join our team and help bring our modular CO2 scrubbers to market.This role will be located in Mountain View, CA.Requirements: Detail-oriented with a creative approach to science and engineering A high degree of autonomy and independence Intrinsic motivation with a fundamental love of science Ability to learn and adapt quickly Advanced skills with Tensorflow and/or Pytorch Experience with probabilistic models like Gaussian processes and BNNs Experience with active learning for Design of Experiments Experience with different active learning sampling methods Experience in building regression models in large combinatorial spacesResponsibilities: Design and build models for Design of Experiments Design and build multi-target regression models for research and engineering optimization Design and build hyperparameter tuning pipelines for machine learning and deep learning models Collaborate with mechanical engineers, chemical engineers, and design engineers to optimize manufacturing methodsNice to have: Advanced degree in data science or equivalent experience Data engineering experience Computational chemistry and atomistic simulations experience Bioinformatics experience Experience with TensorFlow probability and Pyro Experience with building active learning sampling methods from scratchWhat we offer:You will join a team that is passionate about having an impact on climate change. We care about the optimal way to solve a problem and nurture a culture of creativity and collaboration. We care about quick iterations, minimizing assumptions, and we use emojis to label our chemicals. We work on interesting technical problems and provide support and resources to tackle them.Impact: your contribution will directly impact our technical milestones and you will have full ownership of your projects. We don’t micromanageNo politics: we give you the resources to test all your wildest ideas in hours or days, not months. If there is a chance that something will advance our progress we will test it as soon as possibleOwnership: not only you will own your projects you will also own part of the companyAutonomy: we welcome your independent perspective and encourage you to set and manage your time to achieve our shared goalsFlexibility: we cultivate an informal environment that is more fun and less rigid compared to academia and larger companies\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"About UsConstructor.io powers product search and discovery for some of the largest retailers in the world. We serve billions of requests every week, and you’ve probably seen our results somewhere and used our product without knowing it. We differentiate ourselves by focusing on metrics over features, and reinventing search and discovery from the ground up as a machine learning challenge with the specific goal of improving metrics like revenue. We’re approximately doubling year over year despite the market slow down and have customers in every eCommerce vertical. We’re a passionate team of technologists who love solving problems and want to make our customers’ and coworkers’ lives better. We value empathy, openness, curiosity, continuous improvement, and are excited by metrics that matter. We believe that empowering everyone in a company to do what they think is best can lead to great things.Recall team are new in Constructor and we're plan to boost business KPIs, help clients to improve their catalogs with ML and make our DS part more transparent for our customers.Challenges you will tackleBuild and deploy robust ML systems for search.Collaborate with technical and non-technical business partners to develop analytical dashboards that describe the impact of ML algorithms to stakeholders.Improve business KPIs by using new techniques/models and validating hypotheses.Make whole system more transparent for our customer.About YouYou are excited about using ML to build a performant and practical search system for 100M+ requests per day.You excel at Python, at least one ML/DL framework (we're using torch), have proficiency with any variant of SQL, and feel comfortable with the big data stack like Spark, Presto/Athena & Hive.You have delivered production ML systems and conducted A/B tests to validate their value.You are an excellent communicator with the ability to translate intuition into data-driven hypotheses that result in engineering solutions that bring significant business valueYou love to work on performance optimization such as increasing result quality and improving code performanceRequirementsExcellent skills delivering and communicating business valueProficiency with Python, SQL, and the big data stack for end-to-end ML product developmentComprehensive knowledge of classical machine learningExperience with deep learningSkills designing, conducting, and analyzing A/B testsStrong knowledge of data structures, algorithms and their trade-offsA proven track record of software architecture and design skillsExperience with a public cloud like AWS, Azure, or GCPExperience with Rust (or C/C++) will be huge plusThe compensation range for this position is between a base range of 90-110K USD + stock options + stipends.BenefitsUnlimited vacation time: we strongly encourage all of our employees take at least 3 weeks per yearA competitive compensation package including stock optionsCompany sponsored US health coverage (100% paid for employee)Fully remote team - choose where you liveWork from home stipend! We want you to have the resources you need to set up your home officeApple laptops provided for new employeesTraining and development budget for every employee, refreshed each year Parental leave for qualified employeesWork with smart people who will help you grow and make a meaningful impactDiversity, Equity, and Inclusion at ConstructorAt Constructor.io we are committed to cultivating a work environment that is diverse, equitable, and inclusive. As an equal opportunity employer, we welcome individuals of all backgrounds and provide equal opportunities to all applicants regardless of their education, diversity of opinion, race, color, religion, gender, gender expression, sexual orientation, national origin, genetics, disability, age, veteran status or affiliation in any other protected group.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Botkeeper is an automated bookkeeping solution transforming the accounting industry. Named one of America’s fastest growing companies by both Inc. and the Financial Times in 2021, we’re building a team that isn’t afraid to push the boundaries of what's possible. Together, we work hard, collaborate constantly, lift one another up, and challenge each other without fear. Following our Series C funding led by Grand Oaks Capital, we’re now scaling to achieve the future of bookkeeping!Our Engineering Team:We are a group of T shaped engineers, who have an insatiable desire to learn new technologies, implement exciting scalable solutions, and teach each other as we collaborate on projects. Being a part of this team provides an opportunity to work across a variety of technical domains, while contributing insights from your own experiences and domain expertise.Position Overview:We're looking for a Machine Learning Engineer to join our Botkeeper team! This individual will collaborate closely with product, platform, and data engineering teams to create and improve machine learning models, build scalable implementations of these models for both training and consumption, and drive research for new solutions that will improve the product and internal efficiencies. You will be working across teams in order to take projects from ideation to fully integrated solutions and will have the opportunity to make a big impact in the world of automated bookkeeping!Responsibilities:* Train high performing machine learning models by applying feature engineering, model selection, sampling, and model evaluation strategies using Python frameworks such as TensorFlow, SciPy, Scikit-learn, NumPy, and Pandas* Develop and deploy scalable implementations of model training and model serving using technologies such as Linux, Docker, Kubernetes, and Redis* Monitor and analyze model performance and design strategies to improve performance and overcome errors* Work with product teams in order to understand user interactions and prototype solutions for improving customer's workflow and experiences* Work with data engineering teams to enrich the data that is available for training models, make recommendations for new data sources, and implement data governance standards* Influence the features and direction of our products with your own ideasQualifications:* Bachelor's degree or higher in a computer related degree program or equivalent work experience* Advanced knowledge of Python and frameworks such as Flask* Solid knowledge of machine learning and deep learning fundamentals with expertise in one of natural language processing or computer vision* Advanced knowledge of packages and frameworks such as TensorFlow, Numpy, Pandas, SciPy* Experience with Docker and Kubernetes* Experience with data ETL processes and both SQL and no SQL databases* Ability to take a project from scoping requirements through actual launch of the project* Experience in communicating with users, other technical teams, and management to collect requirements, identify tasks, provide estimates and meet production deadlines* Willingness to learn and experience new technologies* Curious about how things work, creative about how to approach problems, and eager to collaborate with othersAbout Botkeeper:Botkeeper provides bookkeeping to businesses using a powerful combination of skilled accountants and automated data entry through the use of machine learning and AI. Our clients receive 24/7 accounting and support as well as incredible insight into their financials with beautiful dashboards and unlimited reporting. The platform easily integrates with a client’s bank accounts, credit cards, HR system, and POS system, and makes appropriate entries and adjustments to their QuickBooks Online accounts, providing businesses with a 24/7 AI-driven Botkeeper. The company is headquartered in Boston, MA.Botkeeper Benefits:We offer unlimited PTO, competitive compensation and healthcare, remote work, and 12 weeks of parental leave. Additional benefits include our annual company retreat, incredible opportunities for career growth, continued professional education, and collaboration with our team of smart, supportive colleagues.Equal Employment Opportunity Statement:Botkeeper is proud to be an Equal Employment Opportunity employer and we encourage all to apply to join our team! We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, military or veteran status, disability, or any other applicable characteristics protected by law. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to accommodations@botkeeper.com.Powered by JazzHRkUD8QHXqwt\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Allozymes is a deep tech company based in Singapore. We are revolutionising the way industry uses enzymes for manufacturing chemicals and natural compounds. Our rapid discovery and evolution of custom-designed enzymes enables breakthrough developments for sustainable production of ingredients for pharmaceuticals, cosmetics, chemical, food and beverages.We’re hiring a highly capable Machine Learning Engineer into our Data team. This team is responsible for developing and implementing state-of-the-art approaches for evolving enzymes and microbes to enhance the production of chemicals and natural compounds. The engineer will integrate the development of our cloud-based artificial intelligence platform for enhancing Allozymes’ enzyme optimization capabilities. Working in a highly collaborative and dynamic environment, this role has the opportunity to interact with other scientists, automation and process engineers to achieve these goals. Responsibilities:Contribute to the design and improvement of Allozymes cloud-based AI platform.Scope project requirements, assess data quality, process data and perform feature engineering.Build, train and deploy ML/DL models, using state-of-the-art technologies and proprietary data to accurately perform predictions and generate new, high performing, enzymes.Perform model evaluation and statistical analysis to improve model quality.Enhance the performance and deployment environment of implemented solutions.Qualifications:MS or PhD in mathematics, statistics, computer science, engineering or a related quantitative field with a focus on AI and Machine Learning.2+ years of relevant industry experience.Expertise in building, training and deploying Machine and Deep Learning models.Proficiency in Python.Expertise in using ML/DS specific python libraries (Pandas, Numpy, Scipy, Scikit-learn, PyTorch, Keras).Experience with ML life-cycle management and code/data version control tools.Familiarity working with Cloud computing.Ability to work in a fast-paced, collaborative and cross-functional environment and communicate results effectively to management.Experience with supervised and unsupervised learning algorithms, clustering, feature selection methods, evaluation, dimensionality reduction, Bayesian inference, hyper-parameter tuning and model optimization is a plusExperience with Language models, Encoders, Transformers, Attention, Generative models and GANs is a plusExperience in biology, bioinformatics or computational biology.Experience using AWS/SageMaker is a plusExperience with containers and container orchestration tools is a plusExperience writing production-ready code (version-controlled, scalable, well-documented, testable, deployment-ready) is a plusNumber of Vacancies: 1\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Meta is embarking on the most transformative change to its business and technology in company history, and our Machine Learning Engineers are at the forefront of this evolution. By leading crucial projects and initiatives that have never been done before, you have an opportunity to help us advance the way people connect around the world. The ideal candidate will have industry experience working on a range of recommendation, classification, and optimization problems. You will bring the ability to own the whole ML life cycle, define projects and drive excellence across teams. You will work alongside the world’s leading engineers and researchers to solve some of the most exciting and massive social data and prediction problems that exist on the web.Software Engineer, Machine Learning Responsibilities:Play a critical role in setting the direction and goals for a sizable team, in terms of project impact, ML system design, and ML excellenceAdapt standard machine learning methods to best exploit modern parallel environments (e.g., distributed clusters, multicore SMP, and GPU)Re-evaluate the tradeoffs of already shipped features/ML systems, and you are able to drive large efforts across multiple teams to reduce technical debt, designing from first principles when appropriateLeading a team from a technical perspective to develop ML best practices and influence engineering cultureBe a go-to person to escalate the most complex online/production performance and evaluation issues, that require an in depth knowledge of how the machine learning system interacts with systems around itDevelop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based modelsSuggest, collect and synthesize requirements and create effective feature roadmapCode deliverables in tandem with the engineering teamMinimum Qualifications:6+ years of experience in software engineering, or a relevant field. 4+ years of experience if you have a PhD2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining, artificial intelligence, or related technical fieldExperience with developing machine learning models at scale from inception to business impactKnowledge developing and debugging in C/C++ and Java, or experience with scripting languages such as Python, Perl, PHP, and/or shell scriptsExperience demonstrating technical leadership working with teams, owning projects, defining and setting technical direction for projectsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Masters degree or PhD in Computer Science or a related technical fieldExposure to architectural patterns of large scale software applicationsMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company OverviewFounded in 2010, Lynx Analytics is a predictive analytics company run by world-class quantitative marketing scientists and industry-experienced data scientists. Our focus is to become a leading analytics solution provider in our chosen fields of expertise (telecom, retail, life sciences, and financial services) while advancing graph analytics technology.Lynx is headquartered in Singapore with operations in Hong Kong, Germany, USA, Hungary, South Africa, Indonesia, and several other Southeast Asian countries. We work with some of the world's largest companies and are constantly looking to expand our knowledge base and geographical footprint. Lynx Analytics' technology is deployed with various Clients across Asia and has significant growth potential.We have a diverse and inclusive global team comprising Professors, PhDs, MSc's, and MBAs from Ivy Leagues, INSEAD and NUS with a broad spectrum of experience in start-ups and blue-chip companies (Google, SAP, Vodafone, GE, Morgan Stanley, Barclays, HSBC to name but a few). It is the combination of our industry insight and experience, scalable proprietary technology, and highly qualified people that drives our compelling value proposition.Key ResponsibilitiesEstablish scalable, efficient, automated processes for data analyses, model development, validation and implementationWork closely with data scientists and analysts to create and deploy new featuresWrite efficient and well-organized software to ship products in an iterative, continual-release environmentMonitor and plan out core infrastructure enhancementsAbility to optimize model performance, push model into performance, track and test, refactor codeContribute to and promote good software engineering practices across the teamCommunicate clearly and effectively to technical and non-technical audiencesActively contribute to and re-use community best practicesRequirementsRelevant tertiary qualification2 to 4+ years of experience with at least 1 year of experience in Machine Learning EngineeringStrong knowledge of Python and SQL Good problem-solving skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for  Entry Level Machine Learning Engineer with a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer  Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech Industry Please Also Check The Below Linkshttps://www.synergisticit.com/candidate-outcomes/https://www.synergisticit.com/java-track/https://www.synergisticit.com/data-science-track/https://www.synergisticit.com/which-is-the-best-option-for-tech-job-seekers-staffing-companies-consulting-companies-bootcamps-or-synergisticit/https://www.synergisticit.com/contact-us/If the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software ProgrammersBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skills  For data Science/Machine learningRequired SkillsBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skills  Preferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Holy Grail developed a direct air carbon capture technology that uses electrons to capture CO2 from the atmosphere. We are looking for proactive candidates who are ready to take ownership and are passionate about creating a sustainable solution to removing excess CO2 from the atmosphere. The ultimate goal of Holy Grail is to contribute to the long-term sustainability of life on Earth.We are looking for a data machine learning engineer to join our team and help bring our modular CO2 scrubbers to market.This role will be located in Mountain View, CA.Requirements: Detail-oriented with a creative approach to science and engineering A high degree of autonomy and independence Intrinsic motivation with a fundamental love of science Ability to learn and adapt quickly Advanced skills with Tensorflow and/or Pytorch Experience with probabilistic models like Gaussian processes and BNNs Experience with active learning for Design of Experiments Experience with different active learning sampling methods Experience in building regression models in large combinatorial spacesResponsibilities: Design and build models for Design of Experiments Design and build multi-target regression models for research and engineering optimization Design and build hyperparameter tuning pipelines for machine learning and deep learning models Collaborate with mechanical engineers, chemical engineers, and design engineers to optimize manufacturing methodsNice to have: Advanced degree in data science or equivalent experience Data engineering experience Computational chemistry and atomistic simulations experience Bioinformatics experience Experience with TensorFlow probability and Pyro Experience with building active learning sampling methods from scratchWhat we offer:You will join a team that is passionate about having an impact on climate change. We care about the optimal way to solve a problem and nurture a culture of creativity and collaboration. We care about quick iterations, minimizing assumptions, and we use emojis to label our chemicals. We work on interesting technical problems and provide support and resources to tackle them.Impact: your contribution will directly impact our technical milestones and you will have full ownership of your projects. We don’t micromanageNo politics: we give you the resources to test all your wildest ideas in hours or days, not months. If there is a chance that something will advance our progress we will test it as soon as possibleOwnership: not only you will own your projects you will also own part of the companyAutonomy: we welcome your independent perspective and encourage you to set and manage your time to achieve our shared goalsFlexibility: we cultivate an informal environment that is more fun and less rigid compared to academia and larger companies\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Location: 100% REMOTEStart: ASAPDuration: 6 monthsInterviews: MS Teams videoPay Rate Range: $75/hourSummaryThe Division of Information Technology Services (ITS) is currently seeking a talented individual to fill the role of Machine Learning Engineer. We are looking for an expert in machine learning to help us extract value from our data. The person who fills this role will lead all the processes for new virtual assistants, from data collection, cleaning, and preprocessing, to training models and deploying them to production. This individual will be responsible for aligning the models with the university’s overall machine learning strategy and road map.The ideal candidate will be passionate about artificial intelligence and stay up-to-date with the latest developments in the field. This individual will also be passionate about delivering an exceptional customer experience.  We are currently in development of 2 bots hosted on the ServiceNow and the Microsoft Azure Bot Service platforms. This role will be responsible for updates and maintenance, and ongoing customer support as necessary. We are looking for a mentor to work with resources within and outside of existing Customer Experience (CX) team to leverage our data and provide an enhanced experience for our community. This role will need to collaborate and work with key groups and stakeholders across IT Services and the university. Representing ITS, the successful candidate will have strong collaboration, communication, and customer service skills to successfully partner with members across the community (at various levels).To ensure that essential services are provided to the university community, a flexible schedule is required. The employee may be required to work outside his/her regular working hours and on university holidays.Qualifications Proficiency with a deep learning framework such as TensorFlow or Keras Proficiency with languages such as JavaScript, HTML, Python, SQL, and C++. Expertise in visualizing and manipulating big datasets (pulling from AWS, CRMs, etc) Proficiency with OpenCV Familiarity with Linux Ability to select hardware to run an ML model with the required latency Familiarity with ServiceNow and/or Microsoft Azure Bot Services preferredExcellent interpersonal, communication and organizational skills are required. Excellent analytical and troubleshooting skills are necessary.Strong written communication skills are preferred, as is the ability to adapt to and follow an organization’s voice, tone, and style.Breakdown of time:Analysis- 50% of the timeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track their progressAnalyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probabilityVerifying data quality, and/or ensuring it via data cleaningSupervising the data acquisition process if more data is neededFinding available datasets online that could be used for trainingDesign – 25% of the timeExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldDefining validation strategiesDefining the preprocessing or feature engineering to be done on a given datasetDefining data augmentation pipelinesDeploy – 15% of the timeManaging available resources such as hardware, data, and personnel so that deadlines are metTraining models and tuning their hyperparametersAnalyzing the errors of the model and designing strategies to overcome themDeploying models to productionCollaboration – 10% of the timeCollaborating with customers, stakeholders, and service owners to build out solutionsPowered by JazzHRPFUMFt9Frk\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'When it comes to using cutting-edge machine learning to tackle complex problems, Lockheed Martin is driven by a singular mission focus and desire to continuously innovate. Today’s challenges to global security aren’t just changing – they’re accelerating faster than ever before. Through our dedication to our mission, our AI-enabled systems are changing the way militaries operate and protect their forces, the way first responders fight fires, and how researchers explore the far reaches of space and the ocean’s depths.The Lockheed Martin Artificial Intelligence Center (LAIC) team is seeking a high energy leader with hands-on experience in software engineering and AI/ML to lead and grow the AI Consulting portfolio for the business. In this role you will be part of the AI Foundations team consisting of colleagues possessing varying skill sets including AI/Machine Learning specialists, front-end and back-end developers, data engineers, product managers, and other data scientists. The selected candidate will focus on the AI Consulting team but will be included as part of a broader range of projects across the LAIC portfolio. The team is focused on exploiting small, innovative, and agile teams to rapidly iterate and mature solutions from prototypes to deployment for utilization across the Lockheed Martin enterprise.The LAIC AI Consulting Team’s mission includes serving as a center of excellence for AI at Lockheed Martin. The candidate will work to disseminate best practices of the AI Consulting Team to other AI and data science teams in the corporation. The candidate will be required to create knowledge materials to publish these best practices, as well as meet with other data science leaders in Lockheed Martin to teach and discuss these practices.The responsibilities of this position include collaboration with business stakeholders to identify business opportunities and requirements to develop associated statistical models that deliver useful, actionable recommendations, or which augment human capabilities in various work settings. The candidate is responsible for modeling complex business and engineering problems, discovering insights and deploying AI capabilities using machine learning and associated feature engineering techniques. Responsibilities also include tracking projects and driving work on them through to completion, as well as implementing best technical practices from the fields of machine learning and software engineering.The candidate will need a combination of business focus, creative thinking, strong analytical and problem solving skills, and programming knowledge to be able to quickly cycle hypotheses through the discovery phase of the project. Excellent communications skills to understand the needs of the business, and to communicate the value of the models built back to the business.Domestic travel may be required when travel resumes (approx. 10%).MUST BE A US CITIZEN.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Company DescriptionVericast is a premier marketing solutions company that accelerates profitable revenue growth for thousands of businesses businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily. We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients. For more information, visit http://www.vericast.com or follow Vericast on LinkedIn.Job DescriptionJOB SUMMARYA Software Engineer I is energized by the thought of developing new system stacks and tools for big data ingestion, processing, and analytics on a multi-petabyte infrastructure. This individual will work on a team of talented engineers responsible for reporting on the delivery of our campaigns and handling technical integrations and data ingestion. They will develop products that help validate our media buys, ingest data into our platform, and generate datasets and reporting for our teams to analyze and monitor delivery and performance of our campaigns.The Big Data Platform Team owns and operates the world-class big data processing infrastructure that over a dozen engineering teams use to power their 24/7 technical marketing products. We own and operate a large hadoop+spark processing cloud on which we store 6PB of data, and run 30 thousand jobs every day. We write a fabric of java microservices and bots to manage all those jobs, extend hadoop's functionality, and help us operate and optimize our investment. We write custom data streaming services that ingest and curate 100TB of data each day that drives the entire advertising data ecosystem. We also participate in all our users' groundbreaking workflow projects so that we can constantly stay abreast of our developer's tooling needs.What You're LikeThis position is perfect for a far-sighted engineer who always wants to be the first to apply cutting-edge technologies to solve complex business and engineering problems. You work throughout the software lifecycle including requirements analysis, development, testing and operations. If you are energized by the thought of developing new system stacks and tools for big data processing and analytics we want to talk to you. If you have worked on big data engineering, cloud migration, or infrastructure tooling projects, we want to talk to you. If you have ever worked on a service mesh or a collection of data workflows and thought 'I could make this better', we want to talk to you!Key Duties/ResponsibilitiesProficiency in Java/Scala/Python programming; experience with microservices; exposure to Spring BootCuriosity to learn and apply new technologiesExcellent problem-solving abilitiesExcellent verbal and written communication skillsExperience with agile development methodologiesProcess and analyze high volume data to mine valuable chunks of information using a combination of Scala, Python and SparkAnalyze input and output data to discover interesting signals, validate outputs, gain understanding of systemsBuild powerful systems from simple building blocks while managing the complexityContribute to our team's continuous efforts to improve quality and efficiency of development platforms, tools, and processesStrong in Java, Scala and/or Python programming language.Exposure to data process with Hadoop, Spark, Kafka and/or Spring Boot micro services QualificationsEDUCATIONBachelor's Degree in Computer Science or other technical discipline (e.g., Engineering, Mathematics, or Physics) (Required)In lieu of the above education requirements, a combination of experience and education will be considered.Two-year degree in Computer Science with relevant and high-performing work experience would be considered.Experience0 - 2 years Relevant Experience (Required)Knowledge/Skills/Abilities0-2 years Skills required: programming, design, testing, standard platform technologies (e.g. Microsoft, Java, Python, etc), SQL databases, independent thought, and methodical work habits.0-2 years Skills desired: big data techniques; high scalability computing techniques; ability to program in both web technologies (web-based UI; web services; etc.) and/or back-end (Java, C#, or C++) services.Learning team service architectureAdditional InformationSalary: $80,000 - $90,000Position is eligible for an annual bonus incentive programThe ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities.All team members are responsible for demonstrating the company's Core Values at all times and for using Performance Excellence principles to continuously improve effectiveness, efficiency, products, and services. This includes, but is not limited to, participating on improvement teams, recommending, and implementing improvement ideas, and participating in training and other activities to keep up to date on processes, information, etc.All team members are responsible for supporting and complying with internal and external audits, to include providing information, performing assigned tasks to ensure compliance, and preparing and maintaining evidence that key duties identified as internal controls have been performed.All team members are responsible for supporting and complying with safety and security policies to promote a healthy working environment.Vericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers!At Vericast, we don’t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community. As an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About HebbiaHebbia is reinventing the search engine to intelligently answer the world's most complex questions. Our AI understands and reasons over written knowledge to synthesize meaningful responses for users in seconds. We've raised significant funding from Peter Thiel, Index Ventures (via Mike Volpi), Jerry Yang (founder of Yahoo), Ram Sriram (one of the first investors in Google), and others, and have built the fastest-moving team in the world.Job DescriptionOur technology powers financial services firms who are running due diligence on billion-dollar deals and want to make their analysts faster and smarter.You will own major ML product features from design to launch. You'll have close feedback loops with users and with our Customer Success team. A major focus will be scaling indexing to terabytes of unstructured text and iterating on search until we have accurate sub-second performance.This role is based out of our New York City office in Soho.ResponsibilitiesOwn product features: Take a customer need and turn it into an operationally-excellent buildMeet with users: Serve as a deployed engineer to drive production contracts and upsellsIterate on publication-grade ML: Ideate on new ML approaches to drive step-change increases in search qualityWho You Are3+ years ML research or ML engineering at a venture-backed startup or top technology firmEmbraces rapid prototyping with an emphasis on user feedbackAutonomous and excited about taking ownership over major initiativesExtreme passion for learning, growth, and leadership\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The hiring company is one of the world’s leading mobile transportation platform. They are currently looking for experienced computer vision research engineers in their Mountain View office to develop algorithms and systems on augmented reality.Responsibilities:Research and develop algorithms and systems for augmented reality applications. Used to reimagine the way people interact with the surrounding world and improve their car driving and riding experience.Collaborate with other engineers and teams to deliver prototype and/or production solutions.Contribute to the company's intellectual property portfolio through patient filing.Track latest advancements and maintain a current understanding of related research areas.Qualifications: Ph.D. (preferred) or masters degree in Computer Science, Computer Engineering, Electrical Engineering or related programs.Expertise in one or more following areas: machine learning, computer vision, image processing, computer graphics. Hands-on experience and deep understanding in one or more of the following will be preferred:Machine learning, esp. deep learning, applied to visual recognition or understanding, e.g. object recognition and localization, semantic segmentation, scene understanding, etc.3D computer vision: structure from motion (SfM), stereo vision, visual SLAM, Visual (Inertial) OdometryLarge-scale content-based image or video retrieval.Single or multi-target visual tracking.Strong publication record and/or proven track record of delivering solid technologies or products in above areas is a large plus.Solid knowledge in fundamental algorithms and data structures.Programming proficiency in C++ and/or Python.One or more of the following skills will be a bonus:GPU programming: CUDA, OpenCL, OpenGL etc.Infrastructure of big data, high-performance computing and/or distributed system.Programming mobile or embedded devices, including code performance optimization.Development of web apps and/or micro-services.Passion for R&D and technical excellence, self-motivated, strong problem analysis and solving skills.Effective verbal and written communication and a spirit of collaboration in a rapidly growing team.Powered by JazzHRx67UPEoBc1\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Waabi, founded by AI pioneer and visionary Raquel Urtasun, is an AI company building the next generation of self-driving technology. With a world class team and an innovative approach that unleashes the power of AI to “drive” safely in the real world, Waabi is bringing the promise of self-driving closer to commercialization than ever before. Waabi is backed by best-in-class investors across the technology, logistics and the Canadian innovation ecosystem.With offices in Toronto and San Francisco, Waabi is growing quickly and looking for diverse, innovative and collaborative candidates who want to impact the world in a positive way. To learn more visit: www.waabi.aiYou will... Contribute and build the self-driving engineering foundations to develop the next generation autonomy software across several machine learning projects. Be part of a team of multidisciplinary Engineers and Researchers using an AI-first approach to enable safe self-driving at scale. Implement and improve machine learning training and inference pipelines. Make iterations on the models for improvements. Identify, propose and build infrastructure, data and computation pipelines, data storage strategies, common libraries and useful tools needed to optimize research and development of deep-learning models.Qualifications: MS/PhD or Bachelors degree with a minimum of 4 years of industry experience in Computer Science, Robotics and/or similar technical field(s) of study. Solid coding proficiency in Python or C++. Some experience in reading and developing production quality software, versus only creating prototypes/proof of concepts. Experience in software architecture, system performance, latency and data flow. Experience in Machine Learning. Understanding of parallel machine learning training and model deployment (e.g., TensorRT conversion). Ability to productionize machine learning models. Experience building software solutions on cloud infrastructure. Ability to rapidly prototype and test new algorithms. Solid problem solving skills using linear algebra, geometry, statistics & probability. Open-minded and collaborative team player with willingness to help others. Passionate about self-driving technologies, solving hard problems, and creating innovative solutions.Bonus/nice to have: Experience designing and implementing tools for automated model tuning and hyper-parameter optimization, as well as experiment analysis. Experience in Deep learning frameworks such as PyTorch and TensorFlow. Experience with automated testing. Experience working in an Agile/Scrum environment.The US yearly salary range for this role is: $122,000 - $190,000 USD in addition to competitive perks & benefits. Waabi (US) Inc.’s yearly salary ranges are determined based on several factors in accordance with the Company’s compensation practices. The salary base range is reflective of the minimum and maximum target for new hire salaries for the position across all US locations. Note: The Company provides additional compensation for employees in this role, including equity incentive awards and an annual performance bonus.Perks/Benefits: Competitive compensation and equity awards. Health and Wellness benefits encompassing Medical, Dental and Vision coverage (for full-time employees only). Unlimited Vacation. Flexible hours and Work from Home support. Daily drinks, snacks and catered meals (when in office). Regularly scheduled team building activities and social events both on-site, off-site & virtually. As we grow, this list continues to evolve!Waabi is an equal opportunity employer that celebrates diversity and is committed to creating a supportive, inclusive, and accessible environment for all employees. We seek applicants of all backgrounds and identities, across race, color, ethnicity, national origin or ancestry, age, citizenship, religion, sex, sexual orientation, gender identity or expression, military or veteran status, marital status, pregnancy or parental status, caregiver status, disability, or any other characteristic protected by law. We make workplace accommodations for qualified individuals with disabilities as required by applicable law. If reasonable accommodation is needed to participate in the job application or interview process please let our recruiting team know.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'ABOUT US:Braintrust is a user-owned talent network that connects you with great jobs with no fees or membership costs—so you keep 100% of what you earn.ABOUT THE HIRING PROCESS:When you join Braintrust, you will be invited to a screening process for Braintrust to learn more about your previous work experiences. Once completed, you will have access to the employer for this role and other top companies that seek high-quality talent. Apply to this job to kick off the process.JOB TYPE: Freelance, Contract Position (no agencies/C2C - see notes below)LOCATION: Remote - Work from anywhere (TimeZone: CST | Partial overlap)HOURLY RANGE: Our client is looking to pay $80 – $120/hrESTIMATED DURATION: 40h/week - Long termTHE OPPORTUNITYRequirementsDemonstrated experience in computer vision development and design - including clear evidence of exceptional skills in this areaSignificant core neural network experience / research orientated and familiar with the state of the art in neural network architectureAny experience in biometric authentication is a plus (but not required)Candidates will be asked to provide their accomplishments and experience in the above as a pre-requisite for interviewWhat you’ll be working onOur client is looking for a highly experienced Computer Vision engineer and Neural Network architect to join their team to help them continue to evolve the biometric capture systems that provides the foundation for biometric authentication within the network. Specifically, the candidate will be an important member in building computer vision software to match palm images on a massive scale for authentication in real-world environments.Confidence GapOur client knows the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates, so please don’t hesitate to apply — they’d love to hear from you.About Our ClientThey are building a company that reflects the world in which they want to live. One where they can enjoy the convenience of biometrics without compromising their privacy or personal freedom. To make this a reality, their technology allows businesses of all kinds to adopt biometric authentication quickly and easily. With them, people are clocking into work, paying for a coffee, and unlocking doors with a wave of their hand. Their team is remote first, by design. Their talented employees work from all over the world because they want to reflect the people who use it: global citizens who bring their diverse perspectives to solve unique problems.They are at an exciting juncture and looking for new voices and ideas to continue building their vision for the company. The client believes that the things that make them unique are their greatest strengths. They have an inclusive, global, remote-first workplace that comprises people from all different lifestyles, backgrounds, abilities, and nationalities.Please note: Our client is undergoing SOC2 compliance and performs background checks, and provides security training to team members.Apply Now!Braintrust Job ID: 6080C2C Candidates: This role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Meta is seeking Software Engineer, Machine Learning to join our Generative AI. The ideal candidate will have industry experience working on a range of classification and optimization problems, e.g. payment fraud, click-through rate prediction, click-fraud detection, search ranking, text/sentiment classification, collaborative filtering/recommendation, or spam detection. The position will involve taking these skills and applying them to some of the most exciting and massive social data and prediction problems that exist on the web.Generative AI represents a huge opportunity to unleash the creativity of the billions of people globally who use our technologies. For years, teams at Meta have been leading the industry in AI research. We are uniquely positioned to adopt an end-to-end approach to generative AI that few organizations can offer through building breakthrough product experiences using generative AI, generative AI research across all modalities, world-class applied AI/ML product engineering, building scalable, high-performance AI infrastructure and our deep experience building tools that enable social connection and expression.As a Software Engineer on the generative AI team at Meta, you can help bring the transformative potential of generative AI to people and businesses around the world as we build a new class of generative AI experiences.Software Engineer, Machine Learning - Generative AI Responsibilities:Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based modelsSuggest, collect and synthesize requirements and create effective feature roadmapCode deliverables in tandem with the engineering teamAdapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)Minimum Qualifications:2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining or artificial intelligenceProven experience to translate insights into business recommendationsExperience with Hadoop/HBase/Pig or MapReduce/Sawzall/BigtableKnowledge developing and debugging in C/C++ and JavaExperience with scripting languages such as Perl, Python, PHP, and shell scriptsCurrently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.Preferred Qualifications:Experience with filesystems, server architectures, and distributed systemsMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Who We AreMemryX, Inc. is an AI semiconductor startup company headquartered in Ann Arbor, Michigan, with branches in Taipei and Hsinchu, Taiwan. We develop highly scalable and innovative AI accelerator chips that offer high performance, low energy, and customer ease of implementation for embedded Edge AI vision-based applications and real-time data processing. MemryX has working HW & SW for customer sampling, with production designs in the pipeline, and a system architecture designed for a future of neuromorphic computing. MemryX is backed by excellent VC funding and is currently in a stage of rapid growth.While our tech is one of a kind we would not be able to make these advancements without our team. Our collaborative culture is one of the keys to our success.Who You AreYou are an open and honest communicator who values your team. You are innovative, enjoy bringing new ideas to the table, and are receptive to ideas and feedback from others. You are passionate about advancing the state of the world through new technology. You enjoy the ambiguity and pace of a startup environment. What you will be doing:Integrating the latest accelerator hardware and software with customer applications to validate the MemryX value proposition for each applicationOptimizing the performance of customer applications/end to end video pipelines for performance (fps) and latencyBenchmarking competitive solutions to identify advantages and disadvantages of the MemryX approachProviding feedback to the architecture and development teams based on customer and benchmarking trialsContributing to software engineering best practices for development, testing, documentation, and technical reviewsArchitecting, designing, and maintaining our neural software development kit to maintain compatibility with current and future neural compiler and hardware solutionsBuilding and maintaining customer-facing software toolsWhat we expect to see:BS in Computer Science with at least three years of direct experience in embedded computer visions systems (Camera system integration and optimization, OpenCV, Gstreamer, etc.)At least two years in a customer facing role requiring a customer service orientation. Knowledge of fundamental AI/neural-networks concepts and tools (Object Identification, Object Classification, Tensorflow, Pytorch, etc.)Strong programming proficiency (C/C++, Python, Linux) and excellent object-oriented design skillsWhat we would be happy to see:AI Accelerator ExperiencePrevious startup experienceReports to: Director of Customer & Applications EngineeringWork location: This role can be remote, hybrid or in person in the United StatesHours: Full timeEmployment Opportunity and Benefits of Employment: We are committed to creating and fostering a diverse and inclusive workplace environment for all of our employees. We are an equal opportunity employer.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"DetailsJob Description Stefanini Group is hiring!  Stefanini is looking for  Software Engineer (Machine Learning)  at Remote Location  For quick apply, please reach out Rajat Baloria  Phone: (248) 728-2620  Email: Rajatsingh.Baloria@stefanini.com Open to W2 candidates only! Position Description Position Description: Stefanini is looking for a Software Engineer focused on building and driving the strategy forward for our internal AI/ML platform. This role will work in a small, cross-functional teams. The position will collaborate directly and continuously with business partners, product managers and tech anchors. The team you will be working on supports ML Practitioners and Data Scientists in their Mach1ML (AI/ML platform similar to Uber's Michelangelo, Facebook's FBLearner, etc) on GCP journey or other ML Engineering / MLOps tasks, focusing on Mach1ML adoption and AI/ML democratization.Job RequirementsDetails Skills Required:  Work closely with Tech Anchor, Product Manager and Product Owner to deliver machine learning use cases using Agile Methodology. * Work with other Software and ML Engineers to tackle challenging AI problems. * Participate in Pair Programming for cross training/upskilling, problem solving, and speed to delivery. * Leverage latest ML and GCP technologies. * Work with Architects to make technical decision on tools, integration, and other issues. * Drive PoCs/Discoveries of new tools and technologies to support robust ML Platform * Collaborate with other software engineers to understand platform vision, break out tasks and help them solve complex issues. * Grow technical capabilities / expertise and provide guidance to other software engineers on the team.Skills Preferred Master's degree in Computer Science, Computer Engineering or a related field of study * Experience working with Google Cloud platform * Experience in delivering machine learning software products using iterative approach. * Experience in Software Craftsmanship such as Paired Programming, Test Driven Development, DevOps etc. * Experience in supporting continuous improvement by investigating development alternatives. * Experience using Machine Learning tools (pytorch, tensorflow, xgboost etc). * Experience applying Agile practices to solution delivery. * Experience in all phases of the development lifecycle. * Must be team-oriented and have excellent communication and presentation skills. * Must be a self-starter to understand existing bottlenecks and come up with innovative solutions. * Open to learning new technology. * Knowledge of coding and best practices. * Experience and good understanding of Machine Learning / Python / Java / Google Cloud / DevOps / CICD * Understanding or desire to learn end to end Machine Learning technology stack (Tools such as Kubeflow, Kubernetes, Seldon Core, GCP, Jupyter Notebook etc). * Strong communication and presentation skills, ability to share/teach others, work collaboratively with others. * Good understanding of cloud design considerations and limitations and impact of pricing. * Prior experience working with container technology, docker files, docker images, GitHub, CI/CD concepts.Experience Required 2+ years of experience with Machine Learning Technologies. * 2+ years of work experience as a software engineer with exceptional software engineering knowledge. * 1+ years of experience working with Google Cloud Platform or other cloud experience.Education RequiredBachelor's degree in Computer Science or a related field of study Listed Salary Range may vary based on experience, qualifications, and local market, Also some positions may Include bonuses and other Incentives About Stefanini GroupThe Stefanini Group is a global provider of offshore, onshore and near shore outsourcing, IT digital consulting, systems integration, application and strategic staffing services to Fortune 1000 enterprises around the world. Our presence is in countries like Americas, Europe, Africa and Asia, and more than 400 clients across a broad spectrum of markets, including financial services, manufacturing, telecommunications, chemical services, technology, public sector, and utilities. Stefanini is a CMM level 5, IT consulting, company with global presence. We are CMM Level 5 company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Modern Intelligence is seeking an ML Engineer to assist with the creation of classical and hierarchical neural networks for American defense, in areas including sensor fusion, decision making, autonomy, complex inference, electronic warfare, and more.Modern is using proprietary advances in information and complexity theory to build one AI for defense. Our hierarchical approach provides a dramatic scaling advantage over classical neural networks, naturally enabling very high accuracy on few-shot learning for novel problems, and in many cases, the ability to solve previously-unsolvable problems.We’re looking for an experienced and insightful ML practitioner who believes that the answer isn’t always just more data, and who has a deep appreciation of the benefits of sparsity, hierarchy, and the mixture-of-experts approach. With theoretical and practical assistance from your team, you’ll help architect solutions to some of the most fundamental problems in machine comprehension, and some of the biggest challenges to the defense industry. You’ll have substantial opportunity for project management and ownership. You’ll work with our contracts team to scope written proposals and project solutions. You’ll work with our R&D platform engineers to help them make their product useful for you and Modern’s scientists. If desired, you’ll have the opportunity to propose new theoretical innovations, and to design experiments to test and refine these innovations. As an early hire, you’ll have the opportunity and active encouragement to grow into leadership and supervisory roles as the company expands.QualificationsMS or equivalent experience in Computer Science, Data Science, Mathematics, Statistics, Physics, or related field. PhD or equivalent experience preferred. Candidates still in their graduate program will be consideredStrong proficiency in at least one popular ML framework, e.g. Tensorflow or Pytorch. The ideal candidate will have hand-rolled their own ML training environment, even if in a very limited capacityStrong proficiency in coding and data scienceEnd-to-end proficiency at the model engineering process -- from data acquisition, storage, processing, and interface design, to model architecting and training, to local or cloud model deploymentProficiency in Probability Theory and other mathematical areas relevant to MLA demonstrable track record of high-quality work in architecting and training neural networks. The ideal candidate will have a publication record demonstrating the ability to make novel contributionsSignificant experience with computer vision models, natural language models, multimodal data and/or sensor fusionExcellent communication skills, and the ability to work effectively in a teamIf you’re a first-rate engineer, and don’t want to waste your career on incremental advances; if you’re interested in working with an equally brilliant, dedicated, and close-knit team to develop groundbreaking approaches to ML; and if you want to see those approaches turn into real-world products that are orders of magnitude better than anything else on the market; then come work with us.This role requires US citizenship due to federal contracting guidelines. Cover letters are not necessary, but are welcome if they provide meaningful information about you as a candidate that is not conveyed otherwise.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"About the jobOur company JR Software Solutions, Inc, is a leading cloud consulting service provider that has been in the market for the last 17 years. We are seeking an experienced Azure Machine Learning Engineer to join our team. As an Azure Machine Learning Engineer, you will be responsible for designing, building, and deploying machine learning models using Azure Machine Learning Services. Experience in Hadoop ecosystem and real-time analytics tools including PySpark/Scala-Spark/Hive/Hadoop CLI/MapReduce/ Storm/Kafka/LambdaThe opportunityThis is a remote opportunity that can be performed within the Continental United States.Key Responsibilities:Develop, deploy, and maintain machine learning models using Azure Machine Learning ServicesCollaborate with data scientists, data engineers, and business stakeholders to understand business requirements and translate them into technical solutionsBuild data pipelines and integrate data from various sources into Azure Machine Learning ServicesOptimize machine learning models to improve their accuracy, speed, and scalabilityMonitor and troubleshoot deployed machine learning models to ensure they meet service-level objectivesStay up-to-date with the latest trends and technologies in machine learning, cloud computing, and data engineering Required Skills:Bachelor's or Master's degree in computer science, statistics, or a related fieldStrong experience with Azure Machine Learning Services, Azure Databricks, and Azure Synapse AnalyticsProficient in programming languages such as Python, R, and SQLExperience with machine learning frameworks such as sci-kit-learn, TensorFlow, and PyTorchExperience with data engineering technologies such as Apache Spark, Hadoop, and Azure Data FactoryStrong understanding of statistics and probability theoryExperience with data preprocessing, feature engineering, and model selectionStrong communication and collaboration skillsExpertise in Python/Spark and their related libraries and frameworksStrong programming and/or scripting experience with back-end languages such as Java, .NET, C# etcExperienced with Spring Framework and Spring BootExperience in other concepts real-time distributed model inferencing pipeline, Champion/Challenger framework, A/B Testing, Model performance Scorecard and assessment, Retraining framework, etc.Unix/Linux expertise; comfortable with Linux operating system and Shell ScriptingExperience in creating Kubernetes open-source container-orchestration system for automating application deployment, scaling, and management; (Experience in Azure is preferable)Experience in tweaking/using Github, deployment orchestration and/or Kubernetes for CI/CD pipelineCreating/modifying Dockers, microservices and deploying them via Kubernetes If you have a passion for machine learning and cloud computing and are excited about building innovative solutions using Azure Machine Learning Services, we encourage you to apply for this role. Join our team and help us shape the future of machine learning!What We OfferAt our company, we believe in valuing our employees and providing them with a comprehensive compensation and benefits package. You will be recognized and rewarded based on your performance and the value you bring to the business. The salary range for this job in the US is between $110,000 to $150,000. Additionally, we offer medical and dental coverage and paid time off to ensure your well-being and work-life balance.We are proud to be an equal opportunity and affirmative action employer, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, age, sex, sexual orientation, gender identity/expression, national origin, protected veteran status, disability status, or any other legally protected basis, in accordance with applicable law. We value diversity and strive to create a workplace where all individuals feel valued and respected.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title: Staff Software & Machine Learning EngineerLocation: Santa Clara CA 95051Pay range- $70/HR to $90/HR on W2Contract: 6+ Month with possibility of extension\\xa0Responsibilities:We are currently looking for contractors with solid Computer Engineering, Computer Science and ML backgrounds who would be interested in researching the applications of ML, statistical learning and optimization methodologies in the automated design exploration of modern hardware.Work with the machine learning branch of our CPU design team.Apply machine learning, deep learning, reinforcement learning to the automated design exploration in HW/CPU design process.Help explore, develop, implement, optimize and evaluate system of machine learning and statistical learning in automated design exploration in HW/CPU design process.Publish research results in top conferences.\\xa0Qualifications:Knowledge of deep reinforcement learning, optimization and search techniques.Knowledge of machine learning, statistical learning—e.g., deep neural networks, graph neural networks and sequence processing.Knowledge of CPU architecture and computer organization is a plus.Publication in relevant areas is a plus.Familiarity with ML implementation environments and platforms such as PyTorch and/or Tensorflow.Agility in learning and working with multiple tools, including research and commercial tools.Experience in developing software in Linux/Unix environments.Well organized, detail-oriented team player.Good verbal and written communication skills.Ph.D. or M.S. in Computer Engineering, Computer Science, Electrical Engineering or closely related majorsBest Regards, \\xa0\\xa0\\xa0www.enterprisesolutioninc.com SEEMA YADAVTechnical RecruiterEnterprise Solutions Inc.Work Cell: 469-898-4780E-Mail :\\xa0Seemak@enterprisesolutioninc.com \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Synergistic IT is a full-service staffing and placement firm servicing client in America for the past 12+ years. We are dedicated towards fulfilling the IT needs of our clients. From staffing to full implementation of projects we provide the highest quality IT Services. We don't just help you secure a Tech Job, but we build your solid career in technology.Job DescriptionTechnical Skills:Python, Model Training/Testing Primary ResponsibilitiesWorking on the awesome AI product for document information extraction.Build the next-generation information extraction product powered by state-of-the-art AI and Deep Learning techniques.Work with an international top-notch engineering team with full commitment on Machine Learning development. Required Candidate profileSkills RequiredPassionate about search amp; AI technologies. Open to collaborating with colleague's amp; external contributors.Good understanding about the mainstream deep learning models from multiple domains: computer vision, NLP, reinforcement learning, model optimization etc.Skilled in the following programming languages: Python 3.Good English skills especially for writing and reading documentationEducation RequirementBachelors, Masters in Computer Science/ Computer Engineering/ Information Systems/Information Technology/ Electrical Engineering/ Mechanical Engineering.Benefit's Of Working With Our ClientsE-Verified.Long Term PositionsOn Job Technical Support. Candidate who are missing the required skills, might be provided an option to enhance their skills, so that they can also apply for the role and can make a career in IT industry.If you do respond via e-mail, please include a daytime phone number so that we can reach you. In considering candidates, time is of the essence, so please respond ASAP. Thank you\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Position title: Machine Learning Engineer for Computer Vision ApplicationsDepartment: TechnologyFLSA Classification: Exempt Reports to: Engineering Development LeadSupervisory position: NoJob DescriptionSummary/objectiveThe Machine Learning (ML) Engineer is responsible for developing, implementing and refining products that improve their performance through the automation of predictive models. The ML Engineer has a sturdy foundation in mathematics, statistics, and programming, including modern (deep learning) and classical machine learning. They have a pragmatic view of ML system development, including model selection, training, testing, validation and deployment. The ML engineer applies their advanced knowledge to work independently on computer vision initiatives with limited supervision.Essential FunctionsReasonable accommodations may be made to enable individuals with disabilities to perform these essential functions.Design, prototype, and implement machine learning algorithms utilizing common ML frameworks. Demonstrate ability to develop custom extensions to available frameworks.Process, transform, visualize, and analyze data to guide the design and training processes of machine learning algorithms. Stay up to date with state-of-the-art methods for solving complex machine learning problems (e.g. computer vision, language modeling, multi-modal models)Collaborate with ML and Software engineers to produce software/data deliverables. This may include algorithm/software design documents, end-user guides, and status reports for customers.Contribute to solution development for project proposals.Generate content for status meetings with customers as a technical contributor. Responsibly and respectfully interact with customers and suppliers to ensure customer satisfaction and project alignment.Provide subject matter expertise on other projects pertaining to machine learning concept development and algorithm design.Perform other duties as required. Required Skills/AbilitiesPossess and maintain US Citizenship. Maintain Security Clearance.Experience with the Python programming language and ML frameworks like PyTorch, TensorFlow, and Scikit-Learn. Knowledge of other languages (C++, Java) and frameworks for scientific computing is ideal.Experience with computer vision and image analysis. Experience with natural language processing is a plus.Research experience is a plus.Strong problem-solving and organization skills.Curiosity, the willingness to be flexible, and the desire to learn new concepts and technologies on the job. Effectively manage ambiguous project requirements and mitigate their effect on software deliverables.Work independently given minimal guidance, including the ability to research methods that best suit project requirements.A deep understanding of machine learning system design concepts.Work effectively with senior engineers, and translate results from complex analytics into elegant data products. Work effectively and comfortably with multidisciplinary teams of engineers and support staff. Excellent communication skills. Education/Training/ExperienceM.S. in Computer Science, Computer Engineering, or a related field with up to 5 years of experience.Proven record of technical leadership in their job area. Physical demandsProlonged periods of sitting at a desk and working on a computer. Must be able to lift 15 pounds at times.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Share profile on this requirement This is TCS FT requirement APPLE CLIENT Salary $110k Location: Austin, TX day 1 onsite Role: Machine Learning EngineerJob DescriptionKey Qualifications - 5+ years of experience in one or more of the following areas: machine learning, Python, PyTorch, Tensorflow - Good experience with data science and machine learning modeling, from experimentation and prototyping to deployment into production pipelines - Good Hands with REST API and Natural Language Processing - Experience with machine learning libraries and packages such as PyTorch, Caffe2, TensorFlow, Keras - Experience with scientific computing and analysis packages such as NumPy, SciPy, Pandas, Scikit-learn The main responsibilities for this position include: - Define and build pipeline to ingest, process and tag search data - Define and build pipeline to capture implicit and explicit feedback to evaluate search quality\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'ABOUT US:Braintrust is a user-owned talent network that connects you with great jobs with no fees or membership costs—so you keep 100% of what you earn.ABOUT THE HIRING PROCESS:When you join Braintrust, you will be invited to a screening process for Braintrust to learn more about your previous work experiences. Once completed, you will have access to the employer for this role and other top companies that seek high-quality talent. Apply to this job to kick off the process.JOB TYPE: Freelance, Contract Position (no agencies/C2C - see notes below)LOCATION: Remote - Work from anywhere (TimeZone: CST | Partial overlap)HOURLY RANGE: Our client is looking to pay $80 – $120/hrESTIMATED DURATION: 40h/week - Long termTHE OPPORTUNITYRequirementsDemonstrated experience in computer vision development and design - including clear evidence of exceptional skills in this areaSignificant core neural network experience / research orientated and familiar with the state of the art in neural network architectureAny experience in biometric authentication is a plus (but not required)Candidates will be asked to provide their accomplishments and experience in the above as a pre-requisite for interviewWhat you’ll be working onOur client is looking for a highly experienced Computer Vision engineer and Neural Network architect to join their team to help them continue to evolve the biometric capture systems that provides the foundation for biometric authentication within the network. Specifically, the candidate will be an important member in building computer vision software to match palm images on a massive scale for authentication in real-world environments.Confidence GapOur client knows the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates, so please don’t hesitate to apply — they’d love to hear from you.About Our ClientThey are building a company that reflects the world in which they want to live. One where they can enjoy the convenience of biometrics without compromising their privacy or personal freedom. To make this a reality, their technology allows businesses of all kinds to adopt biometric authentication quickly and easily. With them, people are clocking into work, paying for a coffee, and unlocking doors with a wave of their hand. Their team is remote first, by design. Their talented employees work from all over the world because they want to reflect the people who use it: global citizens who bring their diverse perspectives to solve unique problems.They are at an exciting juncture and looking for new voices and ideas to continue building their vision for the company. The client believes that the things that make them unique are their greatest strengths. They have an inclusive, global, remote-first workplace that comprises people from all different lifestyles, backgrounds, abilities, and nationalities.Please note: Our client is undergoing SOC2 compliance and performs background checks, and provides security training to team members.Apply Now!Braintrust Job ID: 6080C2C Candidates: This role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'ML - Handson Tensorflow Dev -ML pipeline and process -Strong python coding skills -Experience in deploying models -API development -Flask or Django experience\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Functions: To research and develop scalable computer vision and machine learning solutions to a hard problem To investigate and solve exciting and difficult challenges of the real-world problems in image recognition/classification, object detection/recognition, 3D reconstruction and deep learning To design, implement, and deploy full-stack computer vision and machine learning solutionsDetailed Job Descriptions: Deep Learning Network Training and Deployment to wide range of CV application Image Enhancement Ghost removal / De-blurring / Contrast Enhancement Color Image Processing Denoising / Image Domain Transformation / Smoothing & Sharpening Segmentation Semantic Segmentation / Instance Segmentation Various Region Detection on Images Saliency / Anomaly Shape matching / Blob from multi-modal data / Model Fitting Classification Small Data driven / Big Data driven 3D / Depth image processing development Transformations / Denoising (Artifact, …) / Reconstruction / Ensemble Stereo Vision Camera Calibration / Depth EstimationEducation and ExperienceRequired: Master’s degree in Computer Science or Electrical Engineering plus 2 or more years of relevant experiencePreferred #1: Master's degree in Computer Science or Electrical Engineering plus 5 or more years of relevant experiencePreferred #2: Doctorate in Computer Science or Electrical Engineering plus 3 or more years of relevant experienceTechnical Requirements (At least, one of the below is required.)Experience to Research and Develop to Classical Computer Vision AlgorithmExperience to Research and Develop Machine LearningExperience to C++ implementation of Computer VisionSkills to programming language (At least, one of the below is required.)C++ / Python / CUDASalary rangefrom $112,066[채용 관련 개인정보 처리방침] 개인정보처리방침\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BioMap is a platform company that integrates AI technology with cutting-edge biotechnology. We are committed to achieving breakthroughs in target discovery and drug design, and bringing global first-in-class medicine for unmet medical needs in the areas of immune-oncology, autoimmune diseases, fibrosis, and aging-related diseases.Location: Menlo Park. This role is preferably based in The Bay Area, but we are open to discussing other locations in the United States.Keywords: drug/protein design, structural biology, computational biology, protein folding, protein design, protein-ligand interactionYou will:Utilize bioinformatics tools into drug/protein design workflow and develop computing protocols for drug/ protein design Transforming research work research, open-source models, and prototypes into production-level pipelineDesign and apply innovative computational/ statistical algorithms (including classic, statistical, ML, and AI techniques) to generate actionable biological insightWork closely with the department lead to design and optimize protein design-related algorithms Requirements:PhD degree with research experience in bioinformatics, protein folding, protein design, protein-ligand integration is highly preferred; Or MS degree in computational biology, structural biology, or related fields, plus 2+ years of industry experienceProficient in at least one programming language, including but not limited to Python, C/C++, Java, etc. Familiar with machine learning and deep learning frameworks (e.g. Pytorch, Tensorflow, etc.)Familiar with Alphatfold, ESMfold, RFdesign, and ProteinMPNNGreat communication skills, including code documentation, oral presentation, with excellent attention to details What we offer:The opportunity to work on high-impact tools and products that are immediately deployed to accelerate the discovery of new medicinesA strong team in AI, software, and biochemistryCompetitive salary and equity401(k) plan with generous employer matching for contributionsExcellent medical, dental, and vision coverageDaily lunch and a full snack stationCommuter benefitsBioMap is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Software Engineer - Machine Vision Application - (C#, C++,Python, OpenCV) (Onsite position in Auburn Hills, Michigan) Founded in 1994, Inovision offers automation and robotics products for automating manufacturing processes using AI, Industrial Internet of Things (IIoT) devices, and Big Data analysis. We are developing new applications to scan and analyze automobiles and other surface inspections during the automation process. Our automotive applications control factories for Tesla, Ford, Toyota, and Mercedes using IoT methods paired with AI algorithms. This position is for a strong image processing and AI software engineer. We are developing new products to scan and analyze automobiles and other surface inspection during the automation process. This job involves an understanding of cameras, lights, image processing and large scale software design. The candidate should have a solid electrical engineering or computer science background with strong image processing/AI skills. You must love to write code in C++, OpenCV, C# and Python. Highly motivated individuals who are good at working in a group or alone are desired. We use the latest technologies, OpenCV, Python, WPF, C#, C++. This is a great opportunity to stay up to date with the latest development tools. Job Description * Onsite position in Auburn Hills, MI. Some travel will be required to factories for debug. * Develop software in Microsoft C#/C++, OpenCV based on project requirements * Develop image processing algorithms in multi threaded windows environment Requirements * Solid engineering or computer science background * Motivated, intelligent, and hard-working * Excellent communication skills * Willingness to travel occasionally * Attention to detail * Legally authorized to work full-time in the United States and travel internationally as needed * Must be skilled in C#/C++ and OpenCV and multi threaded real time application development * Development may include some embedded system development, windows application development, multi-thread applications, and AI. To show your interest in this position, please explain why you would like to relocated to Michigan and which of the skills above you have expertise in to make you successful in this position! Health Benefits with Blue Cross Blue Shield PPO and matching IRA contributions are just some of our benefits! We offer great pay with 1.5x when working overtime! Other Information * Inovision is an equal opportunity employer. * Candidates must be able to perform the essential job functions with reasonable accommodation. * Employees must maintain a mobile phone and valid driver's license. * Candidates will be required to write a sample program during the interview process. * All candidate information will be kept confidential according to EEO guidelines. Company Description Growing leader in industrial vision and robotic integration for automotive and general industry.Growing leader in industrial vision and robotic integration for automotive and general industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Mujin's new US office is expanding rapidly, and to sustain that growth we're building a whole new branch of our world-class computer vision team.As a Computer Vision Engineer, you will be a part of the Mujin R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition. You will work directly with and expand on the world’s first 3D vision system for factory automation and logistics solutions.You will work directly with global leaders in applied computer vision, solving the kind of problems that haven't even been asked on Stack Overflow yet -- let alone answered.ResponsibilitiesSolve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenariosAnalyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from both academic and industrial research, and implement and enhance them in a production environmentDesign, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications in Python and C/C++Perform detailed tests, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithmsMinimum RequirementsGraduating/graduated from Computer Science or relevant faculty with a BS, MSc or Ph.DBS or MS with computer vision experience, or Ph.D. in Computer Vision related topicsAbility to develop applications and tools in Python and/or C++Technical communication skills in English (reading and writing)Preferred Experience3D pose estimation of textured and texture-less objects in cluttered scenesExtensive Python and C++ development experienceBroad experience with computer vision librariesMathematical backgroundPrevious contributions to open source projectsIt would be amazing if you have experience in: object tracking, SLAM, computer graphics, augmented reality, machine learning, or robotics projectsAbout The RoleYou'll work directly with researchers from the world’s top-tier universities and labs in robotics, computer vision, and image and signal processing. The team includes Ph. D. and MSc grads from Carnegie Mellon, Stanford, and more. Mujin has the most active real-world deployments of industrial computer vision systems. That means you won't be working in a vacuum--you'll have access to the largest set of customer feedback data in this industry globallyOur computer vision algorithms are robust enough to run on 24/7 systems, handling thousands of items per customer, for diverse customers and applications. The challenges of enlarging its capabilities toward more autonomy, scalability, and diversity of applications mean you will never stop learning at MujinWe're a well-established startup entering a global scale-up phase. That means we have enough structure so you can focus on computer vision, but not so much structure that you can't spread your wings. Come grow with us!If you would like to apply real-time computer vision algorithms to robotics and join the industrial automation revolution, this role is for you!Check out our blog for more information about Mujin's work culture! You can meet our dual-Ph. D. Computer Vision team manager, Jeronimo, here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About AppliedAutonomy is one of the leading technological advances of this century that will come to impact our lives. The work you'll do at Applied will meaningfully accelerate the efforts of the top autonomy teams in the world. At Applied, you will have a unique perspective on the development of cutting-edge technology while working with major players across the industry and the globe.Applied Intuition provides software solutions to safely develop, test, and deploy autonomous vehicles at scale. The company's suite of simulation, validation, and drive log management software enables development teams to create thousands of scenarios in minutes, run simulations at scale, and verify and validate algorithms for production deployment. Headquartered in Silicon Valley with offices in Los Angeles, Detroit, Washington, D.C., Munich, Stockholm, Seoul, and Tokyo, Applied consists of software, robotics, and automotive experts with experiences from top global companies. Leading autonomy programs and 17 of the top 20 global OEMs use Applied's solutions to bring autonomy to market faster.About The RoleWe are looking for bright engineers interested in designing elegant solutions to difficult problems in the autonomy space. Our software engineers work across our suite of products, tackling a variety of full-stack, infrastructure, robotics, and graphics challenges. At Applied, we encourage engineers to take ownership over technical and product decisions, closely interact with users to collect feedback, and contribute to a thoughtful, dynamic team culture.At Applied you will:Work across our entire stack to develop new products, features, and tools for our customers' autonomy development workflowsHave an unparalleled opportunity to work with domain experts across a variety of fields: infrastructure, robotics, and graphics engineers, as well as startup veteransCarve out your own area of expertise and influence product decisionsCollaborate with other members in the autonomy ecosystem and learn about different approaches to solving core issues in autonomyWe're looking for someone who:Is a self-starter and can quickly become comfortable with new technical toolsDesigns efficient and effective solutions to a wide range of engineering challengesTakes initiative in a fast-paced environmentNice to have:Working knowledge of frontend, API layer, database ORM, containerization, or cluster orchestration frameworks (such as React, GraphQL, SQLAlchemy, Docker, or Kubernetes)Experience working with simulation tools, modeling physical problems, or using robotics middleware (such as ROS)Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"WHO ARE WE?Our team is the first in the world to use autonomous vehicles on public roads using end-to-end deep learning, computer vision and reinforcement learning. Leveraging our multi-national world-class research team we're focusing on using less data to learn more intelligent algorithms to bring autonomy for everyone, everywhere. We aim to be the future of self-driving cars, not vehicles that are told how to drive through hand-coded rules and maps, but ones which learn from experience and data.WHERE YOU'LL HAVE AN IMPACTWe're looking for bold, talented and creative people to join our journey in developing next-generation autonomous vehicles. We're a growing start-up, building our first cohort of engineers and you can be at the heart of this!We are looking for ML Engineers to help productionize an end-to-end self driving neural network for autonomous driving. You'll be working closely with Platform and Research teams to integrate, test and scale ML features for production. Productionizing and scaling our ML models by working across Data, Validation, Platform and Research is a core component of this role and why we need you!What You'll Bring To WayveExperience in shipping ML features and in applied researchPassion to take research ideas to productionGood grasp of machine learning literatureExperience in working in platform teams and working with research teamsGood insight into the training, validation, testing and metrics for deep learning features/modelsAbility to write high quality, well-structured and tested Python codeSolid experience working with concurrent, parallel and distributed computingComfortable working with and visualising huge data setsKnowledge of computing fundamentals - what makes code fast, secure and reliableBS or MS in Machine Learning, Computer Science, Engineering, or a related technical discipline or equivalent experienceWhat We Offer YouAttractive compensation with salary and equityImmersion in a team of world-class researchers, engineers and entrepreneursA unique position to shape the future of autonomous driving and to tackle the biggest challenge of our timeBespoke learning and development opportunitiesRelocation support with visa sponsorshipFlexible working hours - we trust you to do your job well, at times that suit you and your teamPrivate on-site chef, in-house bar, lots of socials, and more!Wayve is built by people from all walks of life. We believe that it is our differences that make us stronger, and our unique perspectives and backgrounds that allow us to build something different. We are proud to be an equal opportunities workplace, where we don't just embrace diversity but nurture it - so that we all thrive and grow.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityResponsibilities:As the Geometric Computer Vision Engineer you will need to develop computer vision algorithms for object detection, tracking, and classifications that are robust to lighting and weather changes. This work requires that you collaborate with state estimation engineers and assist in developing powerful feature detectors/ descriptors and large-scale 3D maps. Furthermore, it is expected that you stay organized and communicative with others to ensure that goals and objectives are being met on time. To guarantee the consistency of projects, you will participate in end-to-end development and training in Cloud to optimize development on embedded platforms.Required Qualifications:3-5+ years' significant industry experience and/or publications at venues such as ICRA, RSS, IROS, or CVPR in one or more areas- Image Processing Geometric Computer Vision Deep Learning (ideally CNNs) Classical machine learning such as SVM, decision trees, boosting, graphical models, sequential prediction, or sampling methodsStrong C++ programming and software design skillsFamiliarity with a deep learning framework such as PyTorch, TensorFlow, Caffe, or TheanoBS, MS, or PhD in Robotics, Machine Learning, Computer Science, Electrical Engineering, a related field, or equivalent experienceDesired Qualifications: Experience deploying CV/ML in a robot or real-time applicationUnderstanding of optimization of DL models and deployment on embedded platforms such as the Nvidia JetsonExperience in designing large-scale machine learning pipelinesCompensation:90,000-220,000Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are searching for an engineer with medical image analysis experience as well as experience in ML (Machine Learning), DL (Deep Learning) and Computer Vision to join a fast-growing AI company that is addressing real-world challenges in the Health Care industry.Our client has beautiful offices in downtown Ann Arbor. Employees are well compensated, promoted from within and taught new programming languages, techniques and disciplines as part of their jobs. The culture is relaxed. The PTO is generous.The ideal candidate has worked on a commercial product and has had their work released to customers.LOCATIONAnn Arbor MichiganSince this role deals with Personal Health Information, candidates are required to perform the majority of their work onsite.At this time, our client is not able to accommodate any type of work visa other than TN Visas.Compensation$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.EDUCATIONComputer Science or engineering degreeRequired Skills For Machine Learning ScientistMinimum of 3 years' commercial experience using machine learningProficiency with Python development.Solid experience with Image Analysis (preferably x-ray images)Experience with data noise removal, data augmentation, dataset truthing and constructionExpertise in visualizing and manipulating large datasetsProficiency with a deep learning library (e.g., PyTorch, TensorFlow, or Keras) and deployment of models across languages a plusResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themTAGSMachine Learning | ML | Deep Learning | DL | Computer Vision | Image Analysis | Java | Python | PyTorch | TensorFlow | Keras | 3909-WPlease submit resume and cover letter to recruit@stoutsystems.com with the job title/number in the email.We have a bunch of technology jobs available! View more jobs at https://www.stoutsystems.com/jobsWe host free career webinars every week at https://www.stoutsystems.com/eventsRequirementsEDUCATIONComputer Science or engineering degreeResponsibilities In This Role May IncludeUnderstanding business objectives and developing models that help to achieve them, along with metrics to track progressAnalyzing deep learning algorithms that could be used to solve a problem and ranking them by their success probabilityExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real worldVerifying data quality and/or ensuring it via data cleaningDefining validation strategiesTraining models and tuning hyperparametersAnalyzing errors of the model and designing strategies to overcome themBenefitsCOMPENSATION$90K to $130K (potentially higher for an excellent-fit candidate). Excellent, comprehensive benefits.Some relocation assistance available for a highly qualified candidate.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'LVIS is a leader in cutting edge neural information analysis technology that decodes brain networks and provides visualizations assisting neurological disease diagnosis. LVIS owns patented technologies and our team includes leaders with strong expertise in neuroscience and engineering. LVIS has been selected to be a member of the Stanford StartX community and the NVIDIA inception program. We are an international team with our headquarter located in Palo Alto, California, USA and an office in Gangnam, Seoul, South Korea. We are looking for talented individuals to join us in transforming the neurology health care industry.ResponsibilitiesDeep learning model deployment for medical web applications.Machine learning system stability testing and optimization.Model compression with pruning, quantization and distillation.Collaborate with data scientists and software engineers to optimize deep learning model performance.RequirementsMinimum Required QualificationsMS or PHD in Computer Science, Statistics, Electrical Engineering, Applied Math, and other similar fields.Deep understanding of the machine learning algorithms and systems, especially convolutional neural networks.Proficient in python and python machine learning packages, such as numpy, scikit learn, pytorch, keras, etc.Preferred To HaveHands-on experience of model deployment in the cloud (AWS, Azure or GCP).Experience of model compression techniques.Experiences in medical image/signal processing and data analysis.Other InformationJob type: Full-time.U.S. citizens, green card holders, and those authorized to work in the U.S. for any employer will be considered.Willing to work onsite at our Palo Alto location.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionJob Role : Software Engineer (Python &plus; Machine learning)Job Location: Mountain View CAFull Time Only Job DescriptionStrong experience with Python.Strong debugging skills working in diversified environments.Knowledge on Tensorflow and its various sub components.Experience with GitHub and Stackoverflow.Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Hours: Full-timeLocation: Molg HQ in Chantilly, VA (Northern Virginia)Salary: Competitive compensation, including salary, equity, and full healthcare benefitsOUR MISSIONTackle the fast growing e-waste problem by making electronics manufacturing circular.Molg builds robotics microfactories and software to autonomously assemble and disassemble complex electronic products like laptop PCs, servers, and battery packs. Working with some of the leading computer + server manufacturers as well as industrial companies like Stanley Black and Decker, we are building the circular manufacturing technology to recover existing in-market devices for reuse and recycling as well as helping develop the next generation of circular-focused devices at the design level.IN THIS ROLE YOU WILL:Work with a talented cross-functional team of software, mechanical, electrical, and robotics engineers to develop our core technologies in computer vision as it relates to our robotics and microfactories. As a Computer Vision Engineer, you will be responsible for:Continuous design, development, testing, and deployment of 2D and 3D vision capabilities incorporated into the Molg Microfactories.Testing and verifying accuracy and precision of off-the-shelf and novel in-house vision feedback systems as it relates to robotic motion planning and grasping.Collaborating with robotic, mechanical, and software engineers on design and packaging of vision systems inside Molg Microfactory designs. WHO YOU ARE:3+ years of industry experience in computer vision, machine vision, or image processing in manufacturing environmentsProficient in modern software development (e.g. python, ROS, github, docker, etc)Passionate about robotics, automation, and control systemsAbility to communicate effectively and efficiently both verbally and in writingWHO WE ARE:We spend our days building robotic systems, developing complex assembly intelligence software, and designing the next generation of circular products for our customers. Given the importance of working hands-on with physical systems, we are a 100% in-person team collaboratively working in our industrial space in Chantilly, VA, down the road from the largest data center market in the world. Our facility includes a variety of robots, CNC milling machines, 3D printers, and all the tools needed to build and test our products. It is important to us that anyone on our team that is interested in learning how to use our various pieces of equipment and machinery is taught and can gain the skills and appreciation for making physical things.While we are primarily funded by our work with Fortune 100 companies, we are also supported by amazing backers like Elemental Excelerator and Techstars.THINGS TO KNOW:We’re a small collaborative team with big ambitions, and there’s a good amount of context-switching. We expect people to be autonomous and drive their own work to completion.We are a profitable business that is primarily funded from customer revenue, which means we are scrappy and looking to build a great sustainable company for years to come.As a growing company and startup, priorities may shift as customer or business requirements change. We strive to empower individuals with context and decision-making power to meet this need.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Holy Grail developed a direct air carbon capture technology that uses electrons to capture CO2 from the atmosphere. We are looking for proactive candidates who are ready to take ownership and are passionate about creating a sustainable solution to removing excess CO2 from the atmosphere. The ultimate goal of Holy Grail is to contribute to the long-term sustainability of life on Earth.We are looking for a data machine learning engineer to join our team and help bring our modular CO2 scrubbers to market.This role will be located in Mountain View, CA.Requirements: Detail-oriented with a creative approach to science and engineering A high degree of autonomy and independence Intrinsic motivation with a fundamental love of science Ability to learn and adapt quickly Advanced skills with Tensorflow and/or Pytorch Experience with probabilistic models like Gaussian processes and BNNs Experience with active learning for Design of Experiments Experience with different active learning sampling methods Experience in building regression models in large combinatorial spacesResponsibilities: Design and build models for Design of Experiments Design and build multi-target regression models for research and engineering optimization Design and build hyperparameter tuning pipelines for machine learning and deep learning models Collaborate with mechanical engineers, chemical engineers, and design engineers to optimize manufacturing methodsNice to have: Advanced degree in data science or equivalent experience Data engineering experience Computational chemistry and atomistic simulations experience Bioinformatics experience Experience with TensorFlow probability and Pyro Experience with building active learning sampling methods from scratchWhat we offer:You will join a team that is passionate about having an impact on climate change. We care about the optimal way to solve a problem and nurture a culture of creativity and collaboration. We care about quick iterations, minimizing assumptions, and we use emojis to label our chemicals. We work on interesting technical problems and provide support and resources to tackle them.Impact: your contribution will directly impact our technical milestones and you will have full ownership of your projects. We don’t micromanageNo politics: we give you the resources to test all your wildest ideas in hours or days, not months. If there is a chance that something will advance our progress we will test it as soon as possibleOwnership: not only you will own your projects you will also own part of the companyAutonomy: we welcome your independent perspective and encourage you to set and manage your time to achieve our shared goalsFlexibility: we cultivate an informal environment that is more fun and less rigid compared to academia and larger companies\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Meta is seeking Software Engineer, Machine Learning to join our Generative AI. The ideal candidate will have industry experience working on a range of classification and optimization problems, e.g. payment fraud, click-through rate prediction, click-fraud detection, search ranking, text/sentiment classification, collaborative filtering/recommendation, or spam detection. The position will involve taking these skills and applying them to some of the most exciting and massive social data and prediction problems that exist on the web.Generative AI represents a huge opportunity to unleash the creativity of the billions of people globally who use our technologies. For years, teams at Meta have been leading the industry in AI research. We are uniquely positioned to adopt an end-to-end approach to generative AI that few organizations can offer through building breakthrough product experiences using generative AI, generative AI research across all modalities, world-class applied AI/ML product engineering, building scalable, high-performance AI infrastructure and our deep experience building tools that enable social connection and expression.As a Software Engineer on the generative AI team at Meta, you can help bring the transformative potential of generative AI to people and businesses around the world as we build a new class of generative AI experiences.Software Engineer, Machine Learning - Generative AI Responsibilities:Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based modelsSuggest, collect and synthesize requirements and create effective feature roadmapCode deliverables in tandem with the engineering teamAdapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)Minimum Qualifications:2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining or artificial intelligenceProven experience to translate insights into business recommendationsExperience with Hadoop/HBase/Pig or MapReduce/Sawzall/BigtableKnowledge developing and debugging in C/C++ and JavaExperience with scripting languages such as Perl, Python, PHP, and shell scriptsCurrently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.Preferred Qualifications:Experience with filesystems, server architectures, and distributed systemsMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. You may view our Equal Employment Opportunity notice here. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. We may use your information to maintain the safety and security of Meta, its employees, and others as required or permitted by law. You may view Meta's Pay Transparency Policy, Equal Employment Opportunity is the Law notice, and Notice to Applicants for Employment and Employees by clicking on their corresponding links. Additionally, Meta participates in the E-Verify program in certain locations, as required by law\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'about the senior machine learning engineer role:soona is looking for a senior. machine learning engineer who will assume the primary responsibility of embedding our various machine learning models related to decision science, computer vision, and logistics optimization into robust production systems accessed by our internal stakeholders and external customers alike. you will work closely with our data scientists and engineers to build and maintain these products and services. to be successful in this role, you will understand the general methods of training machine learning models, how to serialize and deploy those models, and how to leverage the necessary architecture (e.g. Kubernetes and GPUs) to make model inference performant for the consumers’ needs.this is a full time position that will report directly to the senior director of data science.about soona:soona makes it possible for brands to create professional photo and video starting at $39. our studios give customers a playground for creating their content and our online platform makes it possible for any product company in the world to experience a remote shoot. we are creating a fast casual content revolution!soona is currently supporting a US remote work environment for this role with opportunity for a flex hybrid work environment within our operating cities--Denver and Minneapolis, if that’s your thing.about tech at soona:at soona, we’re focused on building a world-class engineering and data organization. we’re developing a highly-scalable platform for real-time customer engagement with our studio creatives and technology that optimizes the content they create. our typical engineering and data projects blend SaaS with e-commerce, providing opportunities to work on everything from app engineering and cloud/server architecture to computer vision and logistics/routing optimization. our tech stack consists primarily of ruby on rails, javascript vue, and python. we pride ourselves on our culture of innovation, community engagement, technical mentorship, and caring for the individual.our hiring philosophy:at soona, we look for representation across all intersectionalities of identities, specifically within underrepresented groups. it is these differences that push us towards innovation, curiosity, and success in our business. we believe in providing equal employment opportunities without regard to race, color, religion, age, sex, national origin, disability status, protected veteran status, genetics, sexual orientation, gender identity or expression, or any other characteristic protected by laws or regulations in the locations we operate. this means that timelines of processes may be impacted, depending on our applicant pools.Requirementsan ideal candidate can:deploy machine learning models into production services and environmentsbuild architecture required to efficiently operate our data science services (including computer vision, analytics, and optimization systems)create and maintain telemetry/observability systems to monitor app performancethink for themselves and discover new and insightful ways to solve difficult problemsdeliver quality code in an agile framework that ships to a production environmentcommunicate with data and engineering teams as well as business stakeholdershas experience in:effectively communicating and coding in a remote work environmentpython – the core language of the data organizationdata science, data engineering, or backend engineering, specifically in building data science products and services in a production environmentaws or equivalent cloud environmentleveraging GPUs/CUDA vis-à-vis pytorch (or similar)kubernetes, docker, flask/fastAPI (or similar)infrastructure-as-code tooling like terraform (preferred)designing and building machine learning models (preferred)sql, dbt – our data layer platform (preferred)looker, segment, airbyte (preferred)working in a startup environment (preferred)Benefitswe can offer:starting salary: $170,000 - $200,000stock options in a booming startupbenefits & perks + unlimited pto + intentional culturereally badass headshots\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are seeking a highly analytical, self-motivated, and detail-oriented individual to join our team as a Data Analyst.As a Data Analyst, you have a knack for problem solving, are passionate about leveraging data and insights to drive key business outcomes, and are skilled in cutting through the noise to deliver value. We’re looking for somebody who is highly curious and skeptical, and as a result doesn’t accept things as they are. You play a key role on the Product & Operations team, ensuring our clients and operations team are equipped with high quality campaign data reports and workflows that meet their needs.You possess strong attention to detail and will stop at nothing to leave no stone unturned; you have an eye for process and improvement while always seeking efficiency; you have excellent time management skills and like to take immediate action when tasks come through and above all - your motivation comes from within: you are an independent self-starter that feels accomplished by helping and doing an awesome job!This is an internal role that is responsible for the delivery and optimization of business critical reporting deliverables owed to our clients and internal team. The Data Analyst will have the opportunity to learn from and grow with a dynamic, hard-working, and tight-knit team.RESPONSIBILITIES:Maintain reporting systems, including databases, tools, and connectionsCreate custom metrics in reporting dashboards for clients and internal operations stakeholdersSetup new data feeds in reporting tools when new products are offeredAutomate current manual data upload processesPerform quality assurance on data feeds, metrics, etcTroubleshoot and diagnose reporting issuesRethink or make recommendations on improvements to current processes, tools, and platformsConsult on areas of uncertainty to promote optimal use of dataRequirementsBASIC QUALIFICATIONS:4-6 Years experience in advertising, management information systems, finance, econometrics, statistics, or similarExperience creating end to end reporting workflows with both internal and external usersLand data products with internal and external stakeholders including preparing how to operationalize the data products, measure the impact of the data products and enable usersProficiency in SQLExperience with data visualization tools such as Tableau, Looker, Power BI, etcKnowledge of suitable data analytic processesCapacity to train staff in foundational data entry techniquesAbility to create, update, and share databasesStrong troubleshooting abilitiesAttentive and considerate team playerAnalytical skills that allow for the development of data-driven reportsTendency to pay close attention to small details that could impact resultsBachelor's degree or comparable experienceAbility to work within a highly collaborative, dynamic environmentAbility to legally work in the United States PREFERRED QUALIFICATIONS:Experience with R, and Python a plusStrong interest in the Digital Media/Advertising spaceExperience and knowledge of Amazon Marketing CloudStrong organizational, interpersonal, and communication (written and verbal) skillsAdept at solving problems that span business and technologyThe ability to influence process improvements that scale broadly, while inventing and simplifying within existing processesUnderstanding of digital media ad serving, technology, and associated terminologyBenefitsHealth Insurance + 401kUnlimited PTOMonthly 3-day weekendAlways RemoteWork From Home StipendTeam and Individual Performance BonusesHeadspace + MasterClass SubscriptionsAbout Revive100% RemoteWe always have been remote and always will be remote. We believe you should have the opportunity to spend more time with your kids, work at your favorite coffee shop (on us, of course), and play your favorite playlists however loud you need to get your work done. We’re all built differently and have different needs in different places. We celebrate this diversity at Revive and do everything we can to empower our teammates.A Rocket ShipWe are built on unfair advantages. Through our deep relationships, platform development, and top-notch talent and culture, the only thing slowing us down is preconceived notions. We know there are better ways of doing business than conventional methods and our rapid growth is backing it up.High Empathy, No-Ego Over-AchieversThe cat's out of the bag: Our secret sauce is our people. Our people facilitate every client interaction with empathy, make impact-driving decisions for our business, and come ready to support one another every day. If you have heart, hunger, and humility, you may be the best person to fill the next seat on our rocket ship.The Elevator PitchRevive Media unlocks growth by delivering simplicity, transparency, and quality interactions to digital advertising. We specialize in OTT and e-commerce advertising across Amazon Fire TV, Roku TV, IMDbTV, Twitch, and the open web.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Why Work Here?“Opportunity for Growth - Team Atmosphere - Great Culture”Get to Know Us:Our success is powered by team members who embrace the challenges of meeting our goals and exceeding the standards set by the industry. In our pursuit of a better future, we refuse to settle.Culture:Encouraged to share new ideas, collaborate with other team members as well as customers and partners, we are not afraid to take risks and fail in our push to continuously learn new and develop new skills.Position Purpose & FocusThe successful candidate will have an understanding and demonstrated experience in data collection and analysis. In this role, you will be responsible for collecting, reviewing, and analyzing data from delivered products. You will look for trends and identify unexpected behavior from customer’s assets in the field. You will also assist with compiling information for publications and presentation.Essential Duties & ResponsibilitiesThe Reporting Data Analyst role will be responsible for collecting backend data, data preparation and delivering reporting and business intelligence, and be able to present the data through Tableau or similar tool (ad-hoc, Visme etc). Our main objective will be creating analytics for delivered units, identifying issues from customer assets in the field and assess device health diagnostics. Analyze asset history to proactively identify issues and trends. Creating and maintaining performant queries to expedite data collection/analysis times. Analyzing and manipulating data as required for Tableau analysis/presentation. Isolating and resolving data source issues with limited supervision and oversight. Scoping out business requirements and creating reports from multiple sources. Timely and accurately preparation of weekly performance reports for each customer. Collaborating with other team members to assist in data related tasks. Performs additional duties as assigned.Education and ExperienceBachelor’s degree or equivalent from a technical school preferred (i.e., computes science, Data science, Applied mathematics, or statistics2+ years of relative working experience in data and analysis. Proficient with Excel, SQL and Tableau. Knowledge of a programming language for statistical computing (Python, R, SQL). Comfortable working in a fast-paced environment and handling multi-tasks. Demonstrated experience with data visualization software (e.g., Tableau, Visme, ad-hoc) Demonstrated data analysis skills & experience. Demonstrated data collection skills & experience (e.g., creating surveys) Demonstrated problem-solving and critical thinking experience. Solid oral and written communication skills, including presentation skills. Solid interpersonal skills and ability to work in a cross-functional team environment. Solid understanding of statistical techniques and analysis.Benefits and PerksTime-Off Benefits (Paid Vacation, Sick Leave, Holidays, Bereavement)401k MatchingFull Medical (Dental, Vision, Short-Term Disability, Accident, Life insurance)Educational ReimbursementContinuing Education/Training ProgramsEmployee Assistance Plan (EAP)Pre-tax deduction of insurance premiumsDirect depositCredit unionWellness ProgramEqual Opportunity EmployerWe are an equal opportunity employer and value diversity. We make hiring and other employment related decisions based on qualifications, merit, and business need and without regard to race, color, age (except as required to comply with applicable laws), religion, creed, sex, gender (including pregnancy, childbirth, breastfeeding or related medical conditions), sexual orientation, gender identity or expression, marital or domestic partner status, ancestry, national origin, medical condition, genetic information, military or veteran status, mental or physical disability, or any other status or characteristic protected by applicable laws and regulations. We will not tolerate discrimination or harassment based on any of these characteristics.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Key Responsibilities: Analyze data sets to determine data gaps Support the team with data analysis, such as data discovery and data usage viability Partner with team on testing with data verification, completeness, and data quality checks. Participate in data driven initiatives, such as data linage, data quality checks, data migrationQualificationsSkills Required: Bachelor's Degree in Computer Science or similar Strong communication skills, both verbal and written Have strong reasoning skills, logical deduction and apply to data analysis Present and be able to tell a story with the data analysis/reporting ?Experience working in SQL and relational databases Self-motivated individual and creative thinker who will take ownership of tasks assigned Ability to problem solve and have creative solutions in challenging environments Able to thrive in a fast-paced, high energy, demanding and team-orientated environment Good customer service skills. Ability to deal with difficult situations gracefully. Microsoft Office Suite: Word, Excel, and PowerPointSkills Desired: Knowledge of trades data, positions data, reference data. Experience with trade lifecycles and asset classes, Equity, Fixed Income, Options, Futures Understanding of Risk or Compliance Systems, such as Actimize, MANTAS, or SungardRate Range: $45-$50/hrPowered by JazzHRvpkaehKEHR\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Contract Remote Role: Data AnalystDuration: 6 months contract with possible extensionLocation: Newark/Remote (primarily remote with ability to occasionally go on-site when needed).Job DescriptionThis position will support the clients Clean Energy Jobs Program, which includes following:The use of data and interpreting to develop executive reports and power points.Gather the information and statistics, analyze trends, and then use charts and graphs to present the results.Documentation of various processes by collaborating with client QA/QC team.Develop actionable roadmaps for improving workflows and processes and establish and organize KPIs in line with global directives.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Continuum Clinical (CC), a part of BC Worldwide, is a global clinical trial enrollment company. With over twenty-five years of experience, Continuum Clinical specializes in providing sponsors and CROs with patient recruitment and retention planning, study and site support, patient recruitment campaigns, patient advocacy and diversity & inclusion services, retention solutions, and reporting and analytics. We exist to give incredible people the opportunity to make a difference.  Values CollaborativeGenuineKind & CompassionatePride of Ownership & Accountability Job SummaryAs a Data Analyst, you will be responsible for reporting and analyzing a variety of healthcare related digital campaigns and outreach programs at the agency. This includes the design and development of program dashboards and reports, creating new reporting templates, and collaborating with other members of the Data and Analytics team to create analyses, optimizations, and recommendations across the full spectrum of digital media and other processes. You should have a strong attention to detail, familiarity with common digital reporting applications, and a solid working knowledge of analytic tools and processes. This position works closely with members of the Integrated Media, Global Site Solutions, and Account teams, and reports directly to the Director of Data and Analytics. Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Other duties may be assigned. Demonstrate the mission, vision, values, and culture principles of BC WorldwideCreate and manage dashboards and other data visualizations in Einstein Analytics, Tableau, and Google AnalyticsServe as Subject Matter Expert for Google Analytics/Google Tag Manager setup and reportingManage and update weekly reports on Continuum program performanceAssist in the setup of new programs, including gathering requirements and customizing reportsMonitor campaign performance, analyze results, and provide fact-based recommendations for clients and internal team members on a weekly/monthly/quarterly basisIdentify and define new process improvement opportunitiesAs needed, create new ad hoc analyses based on business needsComply with all corporate and departmental standard operating procedures as well as FDA and other governmental regulations (e.g., IRB, EC).Ensure all activities and operations are performed in compliance with regulatory and federal regulations.Responsible for maintaining up to date weekly time tracking, per the Agency’s time tracking policy.Continuum Clinical QualitiesTo be successful, every BC Worldwide employee should possess the following qualities:Attitude & Commitment – you are a passionate, resourceful, and productive achiever that is a pleasure to be aroundPriority Setting – you define clear action steps and manage expectations of othersCreative Thinking & Problem Solving – you recognize therelevancy of your ideas to the big picture, demonstrate original thinking and make an impact on your teamDependability – you are self-motivated to deliver the highest quality work, on time and budgetLeadership Ability – you take initiative, motivate others, and assume accountability for your actionsCommunication – you use organized, constructive communication to facilitate great work Education, Experience, and CertificationsBachelor’s degree (master’s preferred), or equivalent work experience3-6 years in an analytical role for a digital/online/interactive firmKnowledge and experience in digital advertising analyticsSolid understanding of web analytics/tracking tag implementationSolid working knowledge of one or more analytic tools or programs (Python, SQL, R, etc.)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'We have an excellent contract opportunity for a Junior Data Analyst in New York City! If you want to have a big client\\'s name on your resume, this is your opportunity! The AMI Meter Installation Issues Group (MIIG) of our Client is looking for a temporary resource to support the team in reviewing a large data set of meter installation issues and being able to channel the work in and out of our client\\'s database. Excel is the primary application used by various work groups for tracking the progress of the installation.  Basic training in the use of Excel will not be provided as the applicant is expected to be proficient. Other responsibilities are:The Consultant must be proficient in analyzing and reviewing large data sets in Excel and demonstrate proficiency in using formulas (such as and not limited to Vlookup, Pivot Tables, Graphs, and Charts) to efficiently manipulate the data so that it can be imported into the database Will review and process large sets of data in the various Client databases and must be proficient in using Excel, PowerPoint, Access database, SQL, and TableauWill work independently as well as on a team - Must be self-motivatedThe Consultant will learn the functions of AMI and the Legacy applications used by the team with proper training and be able to communicate with end-user customers to resolve issues, and gaps, and collect dataWill be interacting with other vendors on the MIIG team and will be managing the database that is used to issue escalation work for the team to review and be able to receive the data in return and update the databaseThe Consultant must be flexible and able to work onsite for the first few weeks for onboarding and training. After the onboarding, we can consider transiting to a hybrid work schedule (3 days in the office and 2 days remote)The Consultant will be responsible for managing the database for tracking legacy meters to upgrade and the tracking of work for the different work streamsThe Consultant will be also responsible for managing the work of other MIIG analysts by issuing work from the database and importing reviews completed by the MIIG analyst into the databaseDevelop and deliver PowerPoint presentations to communicate status, work scope, and workflow This is an hourly position with opportunity for overtime.All Candidates Must be Authorized to Legally Work in the US Without Sponsorship**Mandatory Qualifications: (Please read carefully. They MUST be shown on your resume)Must be proficient in Access database, PowerPoint, SQL, and Tableau, Must be proficient in Excel working with Vlookup, Pivot Tables, Graphs, and ChartsMust have strong communication skills with all stakeholders (verbal and written)Must have the ability to draft documentsMust have the ability to clearly communicate technical issues and potential resolution pathsBachelor\\'s degree and 2 years of relevant work experience OR, Associates Degree and 5 years of relevant work experienceProduce high-quality work and check work frequentlyAgile, self-motivatedMust be able to work in a team and as an individual contributorExperience developing and delivering PowerPoint presentations to communicate status, work scope, and workflowPreferably with Legacy Experience $500 Referral Fee Program Earn extra cash while helping your friends!VTS3 will pay you up to $500.00 for each person you refer to us and we place into a contract or full-time position. If you know someone who\\'s a good candidate for any of our openings, use the \"Refer a friend\" button on this page and earn extra cash.The rules are simple:The referral must be made by using the \"Refer a friend\" button on this pageThe person you refer must be placed within 90 days of being referredThe person you refer must complete 480 billable hoursCannot be someone we already have on our team or are currently working withPowered by JazzHRHi7bfAh9Zp\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Hubble Contacts (Hubble) pioneered private label daily contact lenses sold directly to consumers through a subscription-based e-commerce business model. The company was founded in 2016 with the mission of delivering high quality lenses at an affordable price point in a manner that had never been offered before.Historically, four manufacturers controlled about 95% of the contact lens category in the United States and Canada and set prices much higher than a fair and open market would tolerate. Enter Hubble: a company offering a more affordable and consumer friendly option than any product currently on the market. Hubble recently launched ContactsCart, offering its customers alternative manufacturer brands including Bausch & Lomb, CooperVision, and Johnson & Johnson at a meaningful discount. The company is also exploring strategic opportunities for new product launches including toric lenses, eyeglasses, as well as entering new distribution and retail channels.Due to the rising prevalence of eyesight disorders coupled with an increase in consumer spending, Hubble is uniquely positioned to capitalize nationally and internationally on the growth of a global contact lens market predicted to reach $17.7 billion by 2025.Position Summary:The Data Analyst is responsible for analyzing and evaluating the quality and consistency of the organization’s data. You will serve as a primary subject matter expert for technical project management and data integrations across various platforms to ensure operational excellence. This role will work cross-functionally with department stakeholders to find opportunities to streamline and improve processes, ideally automating efforts. This position requires in-depth experience, knowledge, and skills in data analytics, visualization, and technical architecture.RequirementsProactively design and build dashboards in Tableau while presenting findings and interesting trends to stakeholders.Automate reporting procedures as necessary by establishing secure and robust data links between various sources and documents.Maintain all data logs regarding revisions made to the data and version changes.Collaborate with internal partners to understand business strategy, questions, and goals while supporting all data needs.Acquire and compile structured and unstructured data and verify their quality and accuracy while providing daily spot checks to ensure the validity of the organization's data.Bring structure to business requests and ad-hoc reports for various projects, translate requirements into an analytical approach, and lead projects through to completion.Assist in developing technical solutions to survey-related projects in partnership with internal teams and internal/external engineers.Complete assessments of business processes and document each of the following areas: problem statements, process flows, gap analysis, and solution recommendations.Deconstruct technical concepts and metrics for business partners.Develop repeatable and scalable plans and processes to speed time to market and improve operational efficiency.Exercise independent judgment and discretion in matters of significance.Other Qualifications & Characteristics: Obsession with knowing the data and with understanding the business context. Willingness to do the groundwork of learning and exploring the weaknesses and strengths of various data tables and their relations to each other. Capable of writing complex SQL queries in an elegant and structured way to retrieve information that can be translated into easily interpretable and actionable reports; Capable of understanding existing query structures and can critique constructively.Advanced Excel user with experience in automating reports using Power Query; some knowledge of the DAX languageExperienced Google Sheet userExperience with building dashboards in TableauExperience with Google Analytics and various social media platformsProven ability to work both independently and collaboratively with different levels of employeesSelf-starter and self-learner. Bachelor’s Degree; STEM majors are preferred.BenefitsAt Hubble, we invest in our employees' well-being and empower them with benefits to ensure they can continue to be both happy and productive!Receive Insurance Covering, Medical, Dental & Vision. In addition, options for Flexible Spending, Health Saving Accounts, and Membership Options To One Medical, Teladoc, HealthAdvocate, and Talkspaces are also available!401k OptionCommuter BenefitsFitness Membership To ClassPassVoluntary Long-Term & Short-Term Disability InsuranceVoluntary Supplemental Life InsuranceHybrid Working EnvironmentUnlimited PTO - Geared Towards Work/Life BalanceAnnual Professional Development StipendQuarterly Team Meet Ups & Team Philantrhopic Events #HubbleCaresSalary: $70k to $95k - with bonus targets\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Mb Staffing Services is seeking a qualified Data Analyst to assist our DC Based client with data surrounding the Opioid crisis in our region. This is an interesting role and would require the experienced Data Analyst to Respond to inbound calls in a timely and professional manner and follow identified procedures to respond, document, log, and notify the appropriate persons Ensure that reporting remains current Timely and accurate submission of all reports with an error rate no greater than 5%. Perform descriptive analyses of public health data using statistical software (SAS preferred) and produce daily reports and other analytical reports as needed Ensuring data quality and integrity, perform tasks such as electronic file transfers; listing and tabulation of data for preparation of statistical reports; and electronic file linkages Develop analytic datasets (to include, for example, data extraction, data cleaning, matching/merging, and variable coding) and document processes in codebooks, protocols, and associated guidance documents Design databases and tracking systems and monitor data collection activities for multiple surveillance programs Utilize business analytics tools, such as Tableau, to perform data analysis. Support design and recommend content, format, dissemination methods, etc. Maintain and automate reporting applications and visualizations Monitor quality assurance and quality improvement of applicable surveillance and other data systems and processes Develop strategies for improving data processing efficiency, as well as data completeness and quality. Work hours are Monday through Friday 8:30 a.m. to 5:00 p.m. This position is Hybrid Company Description In an era of constant workforce changes, Mb Staffing Services offers something you can count on: The perfect fit! We continue this with a seamless transition. We listen intently. We think strategically. And we act methodically. We respond with speed and an eye to the future! We are a precision placement, results-oriented firm serving a full spectrum of industries and staffing needs.In an era of constant workforce changes, Mb Staffing Services offers something you can count on: The perfect fit! We continue this with a seamless transition. We listen intently. We think strategically. And we act methodically. We respond with speed and an eye to the future! We are a precision placement, results-oriented firm serving a full spectrum of industries and staffing needs.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'JDC -61 Data Analyst, Tallahassee, FLAbout Syra HealthSyra Health Corp. is a pioneering healthcare technology consulting company that develops outcomes-driven solutions having a direct and quantitative benefits to the healthcare industry. We work with payers, health services companies, and life sciences companies to build solutions that create measurable business value and have a positive impact on the lives of their customers. And we are dedicated to cultivating an inclusive culture of respect, honesty, and integrity by embracing the unknown, recognize the value of diversity, and harness the power of enthusiasm.Job SummarySyra Health, a healthcare organization, is seeking a highly skilled Data Analyst to join our team. The ideal candidate will be responsible for analysing and interpreting complex healthcare data sets, including experience in Medicaid data management. The candidate should have advanced knowledge of SQL, and experience working with large data sets. The candidate will be expected to provide actionable insights to inform decision-making and improve patient outcomes.ResponsibilitiesAnalyse and interpret large and complex healthcare data sets, including experience in Medicaid data management.Develop and maintain databases, data systems, and data analytics tools to support data-driven decision-making.Extract qualitative and quantitative relationships (i.e., patterns, trends) from large amounts of publicly available data using SAS, SQL, R, Python, or other statistical toolsIdentify and interpret trends or patterns in data sets.Prepare reports and visualizations that effectively communicate insights and recommendations to management and stakeholders.Collaborate with other teams, including clinical and operational teams, to develop data-driven solutions that improve patient outcomes and reduce costs.Design and implement experiments to test hypotheses and validate assumptions.Ensure data accuracy and completeness by conducting regular data audits.Stay up to date with industry trends, best practices, and regulations related to healthcare data management.RequirementsMinimum of 3 years of experience in data analysis, preferably in healthcare.Experience creating datasets for CMS programs such as MSSP, DCE, or ACO Advanced knowledge of SQL and experience with relational databases.Experience working with Medicaid data and other healthcare data sets.Strong analytical and problem-solving skills.Ability to work independently and in a team environment.Excellent communication and presentation skills.Strong attention to detail and accuracy.Strong hands-on with data visualization tools, such as Tableau or Power BI, is a plus.Careers At Syra HealthOur objective is to make the world a better place by thinking big and seizing opportunities for ourselves, our clients, and our consumers. We are driven by a passion for health and encourage you to be unique, inquisitive, and bold. And by working together, we can increase your contribution on both your career and the world of healthcare.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Summary / Position Purpose: The primary responsibility of this role is to create consolidated reports, dashboards, and data analysis for the internal customers of ACG. This role will be responsible for the day-to-day support, maintenance, and improvement of our CRM and supporting platforms, as well as excel-heavy data-related projects. Their work will involve collecting and cleaning data from multiple sources, running ad hoc reports, building automated dashboards, investigating, and fixing any potential errors/bugs, and working with the Database Administrator to ensure that the information in our database is error-free for accurate reporting. Essential Duties, Functions and/or Responsibilities: Create, validate, and send daily weekly, and monthly management reports.Assistance with requests for non-standard reports and analysisSupport management reporting by maintaining hierarchical information.Perform business-to-system analysis and troubleshooting analysis of complex management reports and business problems.In the report, development lifecycle support impacts analysis and project requirements definitionTransform client needs into functional requirements.With guidance, collect, analyze, and document business requirements for project proposals including but not limited to process and data flow, user interface, and reporting requirements.Together with managers and/or senior analysts, participate in cross-functional meetings to understand customer needs and identify problems and solutions.Appropriate solutions, develop specifications, analyze, and document business processes, validate testing processes, and train the user community.Gather, clean, and transform large data sets to be used in reports and visualization.Design, develop and implement innovative/effective/strategic fully automated business solutions.Works closely with IT and business to incorporate daily automated data refreshing.Develops and provides a standard set of user-friendly reporting tools to internal business customers.Provides maintenance on deployed tools and dashboards.Assist sales & marketing teams with CRM reports and data management, building and maintaining outreach lists for up to several dozen sales and inside sales colleagues.Other duties as assigned.  Education and/or Work Experience Requirements: EDUCATION: Bachelors/4 Yr. DegreeYEARS OF RELEVANT WORK EXPERIENCE: 1+ yearsSalesforce.com (or equivalent CRM) power-user/admin experienceExpert knowledge of Microsoft Office (especially Excel)Demonstrable excel & CRM familiarity with pivot tables and other similar visual reporting tools to display/reconcile large amounts of data.Strong ability to meet deadlines and manage and prioritize simultaneous requests.Creative and analytical thinker with strong problem-solving skillsMust demonstrate ability to communicate effectively verbally and in writing with all levels of the organization.Ability to critically evaluate and prioritize information gathered from multiple sources and reconcile conflicts.Ability to assess the impact of new requirements on Salesforce and other integrated systems.Ability to safely and successfully perform the essential job functions consistent with ADA and all other applicable federal, state, and local standards, including meeting qualitative and/or quantitative productivity standards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'NovoEd builds the next generation of learning technology to offer engaging learning experiences at scale through social collaborative and experiential learning. Our platform is used by enterprise companies including those in the Fortune 500, top universities, training firms, and foundations, around the world to provide experiential and collaborative learning to adult learners. These online learning experiences replicate in-person learning experiences such as workshops that have traditionally been hard to bring online. Social collaboration and peer learning are not only built into our product, but also the DNA of our company. We have a collaborative team with a passion for learning and an amazing culture.The Data Analyst will report to the VP of Product and be a key partner of the R&D, Revenue Operations and Customer Experience teams. The role is expected to provide deep analysis of data and then determine the best way visualize it for customers, business partners and management. This will require solving business problems by customizing the Salesforce and Churn Zero platforms as well as setting up data pipelines using open-source relational database management systems with wysiwyg type tools. The Data Analyst will create metrics and charts using embedded analytics tools, resolve data issues with the quality assurance team, and liaise with the design team on aesthetics and the user experience aspects of dashboards. The Data Analyst will be the owner of the embedded analytics tool, and be responsible for managing the data vendors, including the reporting and resolution of issues.Responsibilities:Manage dashboards, reports and insights for customers as well as the product, sales, marketing, and customer experience teams. Gather requirements, configure changes, design best practice solutions, data governance and reporting for the Salesforce and Churn Zero platforms. Deliver data sources relevant to customer engagement and the use of the NovoEd product into the SaaS product data store; Use APIs or MySQL to bring data in from relevant sources. Design data sets that are performant, can sync data with a lag of at most 30 minutes using a tool like AWS ETL/AWS GLUE. Create metrics and charts using a tool like Tableau, Google and Excel Charts. Generate, evaluate, and improve in-product, problem focused dashboards. Work with Product, Design, Engineering, and Quality Assurance teams to ship dashboards to production systems. Partner with the Product, Revenue Operations, and Customer Success and Support teams to answer specific data questions that are not yet built into the SaaS product. Qualifications:5+ years of experience with MySQL writing complex queries. 3+ years of experience creating and modeling performant data sets as well as deep data analysis. 5+ years of experience building charts and dashboards in tools like Salesforce, Churn Zero and Tableau. Ability to work independently, prioritize workload, and manage cross-functional projects. Advanced technical, analysis and modeling skills in data analytics tools, python and Excel (pivot, VLOOKUP, etc.). Experience using data analytics to support assumptions and develop business cases. Strong communication skills (verbal and written) and interpersonal skills with the ability to translate complex analysis into actionable recommendations. Compelling storytelling and presentation skills. Client centricity, empathy and deep curiosity to find deeper answers to data questions. What will set you apart:Experience working with a wide variety of business data sources. Experience with predictive analytics and data visualizations. Salesforce Administrator experienceNovoEd provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Salary range: The base pay for this role is up to $110k base + bonus. The actual base pay is dependent upon many factors, such as training, skills, work experience, business needs, and location. The base pay range is subject to change and may be modified in the future.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data Analyst Job Description : * Supports and contributes to business analytics projects and processes to provide data-driven insights related to business performance used to advise and develop strategies for operational improvements and future business initiatives. * Uses statistical methods, modeling, analytical methodologies, and data analysis to develop and deploy tools including dashboards, infographics, reports, and models to inform and support decision-making. * Processes, and analyzes internal and external data using KPIs, business results, industry sources, competitor intelligence, and customer information. * Develops a good understanding of the business's model, objectives, issues, and challenges by interacting and collaborating with users and stakeholders. * Typically reports to a supervisor or manager and make sure work is closely managed. * Works on projects/matters of limited complexity in a support role. Qualifications: * Desired a Master's or Bachelor's degree in computer science, information technology, statistics or a quantitative field. * Desired 0-2 years of related experience. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Company Description ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTitle: Data AnalystJob Type: Onsite, Full-time, Hybrid ModelLocation: Irving, TXJob DescriptionFamiliar with Banking Products.Good communications to interact with business clients.Familiar with finance data models data acquisitions.Good in excel Working on collecting and understanding the requirements.Should be well versed on Data Investigation, Data Analysis.Ability to explain functional technical details.Should have good SQL writing capabilities Validate UAT results and identify issue.Should be Independent and resourceful dealing with risks issues and resolving them in a timely manner.About CapgeminiCapgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.Get The Future You Want |\\u202fwww.capgemini.comDisclaimerCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-lawApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Skill/RequirementJob DescriptionNew graduate or individual with 1-2 years of experience with Geographic Information Systems (GIS) tools such as QGIS; basic familiarity with land cover classification methodologies. Knowledge of one or more scripting languages such as Python to automate GIS processing, data analysis and image processing is a plus.ResponsibilitiesJOB Description:Execute manual analytics steps and assist Data Scientists with data and result analysis & quality control for the LandVisor Brazil product. Assess patterns in data acquisition and model output for larger scale workflow improvementsProject scope:-Data analysis support and quality control for consumer-facing product and research projects, particularly QA and editing of data inputs and quality assurance of model outputs. Automation of data acquisition and result delivery.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Minimum Position Qualifications: * 6 - 8 years' experience with IT initiatives * 4 - 5 years as a data analyst for data related projects; data warehouses, data marts, BI reporting, analytics; experience with migrations from on-prem to cloud a big plus * Thorough knowledge and understanding of systems, procedures, and technology/project life cycles. * Excellent communication and presentation skills to effectively communicate information to customers and to all levels within the organization * A working knowledge of IT Service Management practices. * Hands-on technical knowledge including SQL, or ETL platforms * Hands-on exposure to modern cloud solutions (Azure, Snowflake, ...) Company Description Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That's why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure - even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants' experience so far!Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That’s why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure – even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants’ experience so far! https://fusionalliance.com/careers/spotlight/\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are a Direct Mail and Email Marketing company. We acquire database lists and put them in a format for printing and mailing or emailing. We use Altryx and Excel. Company Description TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The data analyst/report technical writer performs highly advanced work related to special education and special populations data collection and reporting activities and projects.Essential FunctionsDevelops and writes data documentation, analytical requirements, business rules, workflows, and data calendar/timelines for existing and new data projects using simple, clear, unambiguous, and concise languageOversees the planning, design, scope, structure, creation, analysis, and maintenance of SAS programs, datasets, data reporting systems, and reportsDevelops and manages extensive quality assurance and quality control checks of SAS programs and workflows to improve existing programs and processes including comprehensive documentationPlans, studies, researches, and evaluates current information and data systems and recommends changes as neededMinimum RequirementsII. CANDIDATE SKILLS AND QUALIFICATIONSCandidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity. Years Required/Preferred Experience 4 Required Experience with SAS programming or similar statistical programming language 3 Required Education: Graduation from an accredited four-year college or university 3 Required Experience working with administrative data 3 Required Experience developing technical documentation 3 Required Experience with MS Office suite, especially Word and Excel 2 Preferred Experience working with education data\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"ARE YOU HAPPY? ARE YOU VALUED? ARE YOU IN CHARGE OF YOUR FUTURE?Our Mission is to provide products and services, in an honorable way, that exceed the expectations of each one of our clients. We are not like other HVAC companies, Conditioned Air, “The Comfort People since 1962” Success Depends on Employees Like You, who pride themselves in teamwork, professionalism, knowledge, ability, loyalty, and exceeding customer expectations.We Want Our Employees to Thrive and Grow, in a place where a job is more than a job, It Is a Career! Learn while on the job, always preparing to achieve the next step of personal and professional success. We continually invest in you! Named 2019's “Top 500 Companies on the Gulf Coast” by Business Observer and recognized in Gulfshore Magazine’s “Best in Business” several years in a row. Now is the time to Join Our Growing Team! We are now seeking a Data Analyst to work in either our Fort Myers or Naples location.The position works on multiple projects as a subject matter expert in a fast-paced environment for the support of executive management and other internal clients.PLEASE BE AWARE THAT THIS IS AN ON-SITE POSITION IN SWFL, THERE IS NO OPTION FOR REMOTE WORK. IF YOU LIVE IN SWFL OR ARE PLANNING TO RELOCATE, PLEASE APPLY AND YOU WILL BE CONTACTED.Essential Duties and Responsibilities:Creates, analyzes, and utilizes financial data to create reporting related to revenue, sales, and operating metrics/KPINormalizes financial and operational data to maintain appropriate and accurate financial databasesEnhances and refines databases to improve reporting and analysis capabilitiesTracks, reconciles and analyzes variancesCompletes weekly, monthly, quarterly, annual, and ad-hoc management reports and analysisIs the go-to expert regarding system data and report buildingCreate proactive analyses comparing company results to industry data to evaluate program performance.Participates in project teams, analyzing various new programs, projects, or venturesPrepares reports, presentations, and other documents and presents these materials in meetingsIdentify problematic areas and research to determine the best course of action to correct the dataIdentify and research anomalies and outliers in dataPerforms other related duties as assigned or requestedEducation and Experience:BachelorsRequired- 3+ years of experience working in a Data Analyst or Business Analyst RoleAttention to detailCoding skills (SQL)BI tools (Tableau or PowerBI)MS Office (Excel)Critical thinkingAbility to work with technical and non-technical stakeholdersDesire to learn / Intellectual curiosityWANT COMPETITIVE PAY AND GREAT BENEFITS? Look no more, we offer 8 Paid Holidays, Company Paid Basic Life and Long-Term Disability, PTO, Medical, Dental, Vision, supplemental insurance benefits for Accident, Critical Illness, 401(K) Retirement plan, a bonus plan, and above all, a great atmosphere with on-going training and teamwork. For additional information or assistance please visit www.conditionedair.com.Conditioned Air provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.In compliance with the Drug-Free Workplace Act of 1988, Conditioned Air has a longstanding commitment to providing a safe, quality-oriented, and productive work environment. Alcohol and drug abuse pose a threat to the health and safety of Conditioned Air employees and the security of the company’s equipment and facilities. For these reasons, Conditioned Air is committed to the elimination of drug and alcohol use and abuse in the workplace\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Position: Data AnalystLocation: West Chester, PADuration: 12 monthsThe ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users. As part of the Cyber Recovery program it is vital to measure and document multiple recovery scenarios. This position will assist in gathering, evaluating and transforming recovery time information into a formula which can be re-used across multiple scenarios.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with dataCompile and analyze data related to business' issuesDevelop clear visualizations to convey complicated data in a straightforward fashionQualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience1 - 2 years' Data Analysis experienceProficient in SQL\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The Black Tux is reinventing formal wear so people can show up at their best on the days that matter most. We design and manufacture modern rental suits and tuxedos that actually fit—made of 100% wool, ordered online, and delivered for free.As a member of the Data & Analytics team, you will become the company expert on data. Our data is key to the company’s ability to live up to our mission to provide our customers with concierge level service and you will be an integral part of ensuring we succeed. You will work on a variety of projects from utilizing Zendesk data to help the CX team track and plan staffing, to analyzing trends to help showrooms expand and convert customers, and working with our stakeholders and defining key metrics and visibility for performance management. You will work to mainly support stakeholders in the Customer Experience and Showroom teams to help them make smarter, data driven decisions and inform company-wide strategy as we continue to grow.What You'll DoBuild analytics solutions to monitor the health of our business and solve a wide range of business problems to inform data-driven strategic and operational decisionsWork closely with stakeholders to understand business requirements and translate them into technical solutionsCommunicate directly with stakeholders to understand the business, project requirements, and to better ideate analytical solutionsDefine KPIs, develop and own business intelligence dashboards, and provide ongoing tracking and insights to partnersCollaborate with data engineering to ensure that we have accurate sources of truth data to serve needs across our organizationEngage stakeholders to identify obstacles and implement data analytics and tools to help improve their day-to-day business decisions and operationsWho You AreA problem solver that is excited to take on new challenges and, given context, being self-directed and enthusiastic about owning your work autonomouslyYou use SQL every day to help companies understand their operations and make data-driven decisions, preferably with experience working with warehouse, inventory, and/or customer care dataAn empathetic analyst that thrives as a true partner to business stakeholders and understanding their needs, building strong relationships to achieve the shared goal of using analytics and insights to drive the business forwardA storyteller that can use data visualization to communicate insights effectively to a variety of stakeholdersYou show modesty, kindness and support to your team and the people you work withThe Data Analyst role is remote.The base salary for this position will be $95,000 - $105,000, but the actual compensation may vary based on the candidate’s skills, qualifications, and location. The Black Tux defines compensation plans using market data aligned with comparable companies at a similar stage and size as ours.This position also qualifies incentive based compensation which may include a performance based bonus and/or incentive stock options. The Black Tux also offers unlimited PTO on top of generous company holidays, including a winter break at the end of each year.Our people are the most important asset to us. Our benefits, perks, pay and culture reflect this in every decision we make. If you want to learn more about us, check out our Culture Book.We're an equal opportunity employer to all. We interview and hire applicants of all backgrounds, orientations, expressions, and identities.Notice to California Job Applicants disclosed here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'At Better Life Partners, We provide what it takes to heal from addiction. Wherever. Whenever.We focus on bringing high quality, accessible and effective tech-enabled care to those with Addiction Disorders, especially those in communities for whom traditional care has been found lacking. We provide evidence-based, scalable, holistic healthcare while working alongside community-based organizations to ensure that our care is accessible, non-punitive and responsive to our communities. We build trusted relationships and healing spaces to nourish Belonging, Love, and Purpose.If you’re passionate about healthcare innovation, low-barrier care, and harm reduction, Better Life Partners is the team for you! Our Headquarters office is seeking a Data Analyst.The ideal candidate will have a deep knowledge of SQL and Python and will be self-motivated with a strong bias for action.Responsibilities include, but are not limited to:Expand and maintain optimal data pipeline architecture.Provide information to teammates that helps increase and optimize member experiences, revenue generation, and other business outcomes.(ad hoc queries, explanations of reports, technical guidance, etc.);Build Tableau dashboards for business usersImplement, integrate and document a variety of software platforms through the REST API frameworkMaintain and upgrade the division’s data warehouse (ETLs, design, dependencies, entity and referential integrity)Qualifications:Bachelor’s Degree in computer science, statistics, mathematics, or related field or equivalent experience. Willingness and eagerness to learn and be flexible.Experience using statistical computer languages (R, Python, SQL) to manipulate and draw insights from data.Extra Points:Knowledge of statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.).Knowledge of some statistical and machine learning techniques (for example, GLM/Regression, Random Forest, clustering, neural networks, k-Nearest Neighbors, Naive Bayes, SVM, etc.) and willingness to learn additional techniques.Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).Experience with TableauProven experience with Time Series Clustering.This is a full-time, exempt position. The starting salary range for this position is $70-90k annually.This position is fully remote (work from home).Work from home requirements:Must have internet service with minimum upload/download ability.Company will provide equipment (laptop, monitor, keyboard, mouse and headset) plus a remote work stipend. Must have a quiet space to speak to members with minimal background noise.Must understand the importance of protected health information and ensure any data/information is not visible to others.Better Life Partners facilitates the treatment of behavioral health conditions including addiction medicine. We offer a full slate of benefits including competitive compensation, medical, dental and vision coverages, four weeks of paid vacation, sick time, wellness days, thirteen paid holidays, a 401(k) plan with company match, parental leave program, learning & development stipend, employee referral bonus, company-issued technology, remote work stipend, paid volunteer time off, stock options for eligible employees, and more!At Better Life Partners, we believe our work directly correlates to the diverse perspectives of our employees. Better Life Partners celebrates inclusion and is a committed Equal Opportunity Employer to all qualified applicants, ensuring individuals will not be discriminated against on the basis of race, color, religion, sex, gender identity, sexual orientation, age, national origin, physical or mental disability, marital or parental status, military or veteran status, or any other protected classification. Persons of color, women, LGBTQ candidates, veterans and individuals with disabilities are encouraged to apply. Better Life Partners is a recovery-friendly workplace.COVID-19 Vaccine RequirementBetter Life Partners has instituted a COVID-19 vaccine mandate for all employees, including remote staff, to remain in full compliance with regulatory bodies. Individuals selected for employment must be able to show proof of vaccination status prior to start date.If you are unable to be vaccinated for medical reasons or religious beliefs, Better Life Partners will consider requests for reasonable accommodation consistent with its policy and if able to do so without undue hardship to the company pursuant to applicable law. Such accommodations must be approved prior to start date. Powered by JazzHRJlsmK7QPZV\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Summary / Position Purpose: The primary responsibility of this role is to create consolidated reports, dashboards, and data analysis for the internal customers of ACG. This role will be responsible for the day-to-day support, maintenance, and improvement of our CRM and supporting platforms, as well as excel-heavy data-related projects. Their work will involve collecting and cleaning data from multiple sources, running ad hoc reports, building automated dashboards, investigating, and fixing any potential errors/bugs, and working with the Database Administrator to ensure that the information in our database is error-free for accurate reporting. Essential Duties, Functions and/or Responsibilities: Create, validate, and send daily weekly, and monthly management reports.Assistance with requests for non-standard reports and analysisSupport management reporting by maintaining hierarchical information.Perform business-to-system analysis and troubleshooting analysis of complex management reports and business problems.In the report, development lifecycle support impacts analysis and project requirements definitionTransform client needs into functional requirements.With guidance, collect, analyze, and document business requirements for project proposals including but not limited to process and data flow, user interface, and reporting requirements.Together with managers and/or senior analysts, participate in cross-functional meetings to understand customer needs and identify problems and solutions.Appropriate solutions, develop specifications, analyze, and document business processes, validate testing processes, and train the user community.Gather, clean, and transform large data sets to be used in reports and visualization.Design, develop and implement innovative/effective/strategic fully automated business solutions.Works closely with IT and business to incorporate daily automated data refreshing.Develops and provides a standard set of user-friendly reporting tools to internal business customers.Provides maintenance on deployed tools and dashboards.Assist sales & marketing teams with CRM reports and data management, building and maintaining outreach lists for up to several dozen sales and inside sales colleagues.Other duties as assigned.  Education and/or Work Experience Requirements: EDUCATION: Bachelors/4 Yr. DegreeYEARS OF RELEVANT WORK EXPERIENCE: 1+ yearsSalesforce.com (or equivalent CRM) power-user/admin experienceExpert knowledge of Microsoft Office (especially Excel)Demonstrable excel & CRM familiarity with pivot tables and other similar visual reporting tools to display/reconcile large amounts of data.Strong ability to meet deadlines and manage and prioritize simultaneous requests.Creative and analytical thinker with strong problem-solving skillsMust demonstrate ability to communicate effectively verbally and in writing with all levels of the organization.Ability to critically evaluate and prioritize information gathered from multiple sources and reconcile conflicts.Ability to assess the impact of new requirements on Salesforce and other integrated systems.Ability to safely and successfully perform the essential job functions consistent with ADA and all other applicable federal, state, and local standards, including meeting qualitative and/or quantitative productivity standards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'JDC -61 Data Analyst, Tallahassee, FLAbout Syra HealthSyra Health Corp. is a pioneering healthcare technology consulting company that develops outcomes-driven solutions having a direct and quantitative benefits to the healthcare industry. We work with payers, health services companies, and life sciences companies to build solutions that create measurable business value and have a positive impact on the lives of their customers. And we are dedicated to cultivating an inclusive culture of respect, honesty, and integrity by embracing the unknown, recognize the value of diversity, and harness the power of enthusiasm.Job SummarySyra Health, a healthcare organization, is seeking a highly skilled Data Analyst to join our team. The ideal candidate will be responsible for analysing and interpreting complex healthcare data sets, including experience in Medicaid data management. The candidate should have advanced knowledge of SQL, and experience working with large data sets. The candidate will be expected to provide actionable insights to inform decision-making and improve patient outcomes.ResponsibilitiesAnalyse and interpret large and complex healthcare data sets, including experience in Medicaid data management.Develop and maintain databases, data systems, and data analytics tools to support data-driven decision-making.Extract qualitative and quantitative relationships (i.e., patterns, trends) from large amounts of publicly available data using SAS, SQL, R, Python, or other statistical toolsIdentify and interpret trends or patterns in data sets.Prepare reports and visualizations that effectively communicate insights and recommendations to management and stakeholders.Collaborate with other teams, including clinical and operational teams, to develop data-driven solutions that improve patient outcomes and reduce costs.Design and implement experiments to test hypotheses and validate assumptions.Ensure data accuracy and completeness by conducting regular data audits.Stay up to date with industry trends, best practices, and regulations related to healthcare data management.RequirementsMinimum of 3 years of experience in data analysis, preferably in healthcare.Experience creating datasets for CMS programs such as MSSP, DCE, or ACO Advanced knowledge of SQL and experience with relational databases.Experience working with Medicaid data and other healthcare data sets.Strong analytical and problem-solving skills.Ability to work independently and in a team environment.Excellent communication and presentation skills.Strong attention to detail and accuracy.Strong hands-on with data visualization tools, such as Tableau or Power BI, is a plus.Careers At Syra HealthOur objective is to make the world a better place by thinking big and seizing opportunities for ourselves, our clients, and our consumers. We are driven by a passion for health and encourage you to be unique, inquisitive, and bold. And by working together, we can increase your contribution on both your career and the world of healthcare.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are a Direct Mail and Email Marketing company. We acquire database lists and put them in a format for printing and mailing or emailing. We use Altryx and Excel. Company Description TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Key Responsibilities: Analyze data sets to determine data gaps Support the team with data analysis, such as data discovery and data usage viability Partner with team on testing with data verification, completeness, and data quality checks. Participate in data driven initiatives, such as data linage, data quality checks, data migrationQualificationsSkills Required: Bachelor's Degree in Computer Science or similar Strong communication skills, both verbal and written Have strong reasoning skills, logical deduction and apply to data analysis Present and be able to tell a story with the data analysis/reporting ?Experience working in SQL and relational databases Self-motivated individual and creative thinker who will take ownership of tasks assigned Ability to problem solve and have creative solutions in challenging environments Able to thrive in a fast-paced, high energy, demanding and team-orientated environment Good customer service skills. Ability to deal with difficult situations gracefully. Microsoft Office Suite: Word, Excel, and PowerPointSkills Desired: Knowledge of trades data, positions data, reference data. Experience with trade lifecycles and asset classes, Equity, Fixed Income, Options, Futures Understanding of Risk or Compliance Systems, such as Actimize, MANTAS, or SungardRate Range: $45-$50/hrPowered by JazzHRvpkaehKEHR\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"ARE YOU HAPPY? ARE YOU VALUED? ARE YOU IN CHARGE OF YOUR FUTURE?Our Mission is to provide products and services, in an honorable way, that exceed the expectations of each one of our clients. We are not like other HVAC companies, Conditioned Air, “The Comfort People since 1962” Success Depends on Employees Like You, who pride themselves in teamwork, professionalism, knowledge, ability, loyalty, and exceeding customer expectations.We Want Our Employees to Thrive and Grow, in a place where a job is more than a job, It Is a Career! Learn while on the job, always preparing to achieve the next step of personal and professional success. We continually invest in you! Named 2019's “Top 500 Companies on the Gulf Coast” by Business Observer and recognized in Gulfshore Magazine’s “Best in Business” several years in a row. Now is the time to Join Our Growing Team! We are now seeking a Data Analyst to work in either our Fort Myers or Naples location.The position works on multiple projects as a subject matter expert in a fast-paced environment for the support of executive management and other internal clients.PLEASE BE AWARE THAT THIS IS AN ON-SITE POSITION IN SWFL, THERE IS NO OPTION FOR REMOTE WORK. IF YOU LIVE IN SWFL OR ARE PLANNING TO RELOCATE, PLEASE APPLY AND YOU WILL BE CONTACTED.Essential Duties and Responsibilities:Creates, analyzes, and utilizes financial data to create reporting related to revenue, sales, and operating metrics/KPINormalizes financial and operational data to maintain appropriate and accurate financial databasesEnhances and refines databases to improve reporting and analysis capabilitiesTracks, reconciles and analyzes variancesCompletes weekly, monthly, quarterly, annual, and ad-hoc management reports and analysisIs the go-to expert regarding system data and report buildingCreate proactive analyses comparing company results to industry data to evaluate program performance.Participates in project teams, analyzing various new programs, projects, or venturesPrepares reports, presentations, and other documents and presents these materials in meetingsIdentify problematic areas and research to determine the best course of action to correct the dataIdentify and research anomalies and outliers in dataPerforms other related duties as assigned or requestedEducation and Experience:BachelorsRequired- 3+ years of experience working in a Data Analyst or Business Analyst RoleAttention to detailCoding skills (SQL)BI tools (Tableau or PowerBI)MS Office (Excel)Critical thinkingAbility to work with technical and non-technical stakeholdersDesire to learn / Intellectual curiosityWANT COMPETITIVE PAY AND GREAT BENEFITS? Look no more, we offer 8 Paid Holidays, Company Paid Basic Life and Long-Term Disability, PTO, Medical, Dental, Vision, supplemental insurance benefits for Accident, Critical Illness, 401(K) Retirement plan, a bonus plan, and above all, a great atmosphere with on-going training and teamwork. For additional information or assistance please visit www.conditionedair.com.Conditioned Air provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.In compliance with the Drug-Free Workplace Act of 1988, Conditioned Air has a longstanding commitment to providing a safe, quality-oriented, and productive work environment. Alcohol and drug abuse pose a threat to the health and safety of Conditioned Air employees and the security of the company’s equipment and facilities. For these reasons, Conditioned Air is committed to the elimination of drug and alcohol use and abuse in the workplace\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Position: Data AnalystLocation: West Chester, PADuration: 12 monthsThe ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users. As part of the Cyber Recovery program it is vital to measure and document multiple recovery scenarios. This position will assist in gathering, evaluating and transforming recovery time information into a formula which can be re-used across multiple scenarios.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with dataCompile and analyze data related to business' issuesDevelop clear visualizations to convey complicated data in a straightforward fashionQualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience1 - 2 years' Data Analysis experienceProficient in SQL\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The Black Tux is reinventing formal wear so people can show up at their best on the days that matter most. We design and manufacture modern rental suits and tuxedos that actually fit—made of 100% wool, ordered online, and delivered for free.As a member of the Data & Analytics team, you will become the company expert on data. Our data is key to the company’s ability to live up to our mission to provide our customers with concierge level service and you will be an integral part of ensuring we succeed. You will work on a variety of projects from utilizing Zendesk data to help the CX team track and plan staffing, to analyzing trends to help showrooms expand and convert customers, and working with our stakeholders and defining key metrics and visibility for performance management. You will work to mainly support stakeholders in the Customer Experience and Showroom teams to help them make smarter, data driven decisions and inform company-wide strategy as we continue to grow.What You'll DoBuild analytics solutions to monitor the health of our business and solve a wide range of business problems to inform data-driven strategic and operational decisionsWork closely with stakeholders to understand business requirements and translate them into technical solutionsCommunicate directly with stakeholders to understand the business, project requirements, and to better ideate analytical solutionsDefine KPIs, develop and own business intelligence dashboards, and provide ongoing tracking and insights to partnersCollaborate with data engineering to ensure that we have accurate sources of truth data to serve needs across our organizationEngage stakeholders to identify obstacles and implement data analytics and tools to help improve their day-to-day business decisions and operationsWho You AreA problem solver that is excited to take on new challenges and, given context, being self-directed and enthusiastic about owning your work autonomouslyYou use SQL every day to help companies understand their operations and make data-driven decisions, preferably with experience working with warehouse, inventory, and/or customer care dataAn empathetic analyst that thrives as a true partner to business stakeholders and understanding their needs, building strong relationships to achieve the shared goal of using analytics and insights to drive the business forwardA storyteller that can use data visualization to communicate insights effectively to a variety of stakeholdersYou show modesty, kindness and support to your team and the people you work withThe Data Analyst role is remote.The base salary for this position will be $95,000 - $105,000, but the actual compensation may vary based on the candidate’s skills, qualifications, and location. The Black Tux defines compensation plans using market data aligned with comparable companies at a similar stage and size as ours.This position also qualifies incentive based compensation which may include a performance based bonus and/or incentive stock options. The Black Tux also offers unlimited PTO on top of generous company holidays, including a winter break at the end of each year.Our people are the most important asset to us. Our benefits, perks, pay and culture reflect this in every decision we make. If you want to learn more about us, check out our Culture Book.We're an equal opportunity employer to all. We interview and hire applicants of all backgrounds, orientations, expressions, and identities.Notice to California Job Applicants disclosed here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionHertz and the Advanced Analytics and Tool Development team is seeking talented individuals with passion for real-world problem solving. The analyst will partner with various functions within the company (Revenue Management, Fleet, Operations) and develop advanced tools and resources to support overall location-level planning and operational decisions. The analyst will be working with large sets of structured and unstructured data to perform analysis, develop tools, and provide actionable insights.What You’ll Be Doing Develop tools for the field for car assignment to optimize upgrade/upsell/booking success.  Develop tools to provide visibility to many of the operational processes.  Conduct analyses to inform stakeholders and help make the most optimal decisions regarding various strategic initiatives.  Code and automate performance reports.  Configure shared PC resources to automate scripts and collect data. What We Expect A Bachelor’s degree; preferably in Data Science, Computer Science, Statistics, Engineering, or another quantitative field.  A demonstrated ability to query and extract findings from large data sets in relational databases such as SQL Server, Teradata, Oracle, etc.  A wide range of data-related technical skills regarding databases, scripts, and web APIs.  Experience with programming/scripting languages like R or Python  Experience with advanced data visualization platforms such as Tableau.  Quick on feet; willingness to discover alternative solutions to technical problems.  A desire to solve complex problems with creative and concise solutions.  Excellent written and oral presentation skills – ability to communicate findings with non-technical stakeholders in concise and simple terms.  An individual who thrives in a collaborative environment. Nice To Haves More than 1 year of work experience in a data driven industry including Rent-A-Car, travel, or service industry  A Master’s degree in a quantitative field  Experience with statistical modeling  Experience with web development languages such as Ruby, PHP, or JavaScript. r work every day represent a significant part of our culture – and our success and reputation as a company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionRole: Data AnalystSalary: $110,000 - $140,000 (plus benefits)Location: Austin, Texas (Hybrid Model)Sponsorship: Not availableI am currently on the lookout for a Data Analysis to join one of the largest U.S. banks based in Austin Texas. Within this position you will be working functionally across the business with Engineering, Finance, Customer success and product to collect, analyze and interpret data related to the bank's commercial lending and business operations.Working on a Hybrid model, if you have a strong curiosity of data and enjoy problem-solving a wide range of topics, who thrives on a fast-paced environment then this would be the perfect role for you!ResponsibilitiesCollect and analyze data related to commercial lending portfolios, including loan performance, risk assessments, and compliance with regulations.Develop and maintain reporting and analytics tools to provide insights into commercial lending and business operations.Work with stakeholders to identify key performance indicators and develop dashboards and reports to monitor them.Generate insights to uncover usage trends to inform product development, drive user adoption and savings (time and/or cost)About YouExperience with data visualization tools such as Tableau or PowerBI.Commercial knowledge working with SQL and programming languages such as Python or R.Strong analytical and problem-solving skills with attention to detail.Knowledge of commercial lending and banking operations is a plus.Our client is an equal opportunity employer committed to creating a diverse and inclusive workplace. They offer a competitive salary, comprehensive benefits package, and opportunities for career growth and development.If you are a data analyst who is passionate about using data to drive business decisions and interested in joining a dynamic team at one of the largest commercial banks in the US, please click to apply!For more information about ITECCO and the opportunities we have to offer follow us on Twitter @ITECCOrecITECCO Ltd is acting as an Employment Agency in relation to this vacancy.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Extend OverviewExtend is a rapidly growing fintech startup in the B2B payments space with a focus on serving banks and their customers. We have built the first virtual card platform of its kind, directly integrated with processors, networks, and the technology that supports banking across the industry. We offer several virtual card products including an app-as-a-service that banks can offer business customers with their existing credit cards, a suite of virtual card APIs for those looking to build custom payment solutions, and we also offer secure connectivity to key banking and payment services that enable 3rd-parties to integrate and embed payments into their software.Founded in 2017 by 3 industry experts with experience at Fortune 500 companies, including American Express and Capital One, Extend is headquartered in Manhattan and has recently raised $40m in venture capital from top fintech investors. Extend was recently voted one of America's best startup employers by Forbes and best payments service platform by Tearsheet.With extreme monthly growth and 85+ mission-driven employees, now is prime time to join our team!For more information visitAbout The RoleWe are looking to add a Business Intelligence Analyst to our growing Business Intelligence team; as part of this team, you will be responsible for data reporting, developing analytics and measurement tools, and driving initiatives that help optimize revenue across multiple business segments. You will own much of the Tableau dashboarding and ad hoc data requests. You will also ensure our data remains clean and accurate. You’ll work with the Business Insights team to gather requirements from departments across the company, design new dashboards, and incorporate feedback. This is a hybrid role, based out of our New York City office, with three days on-site.At Extend, you’ll:Create and maintain data tables and Tableau dashboards that allow key stakeholders to view data in a quick and concise manner, effectively communicating insights through visualizations.Manage and resolve ad hoc Business Intelligence requests, developing new tools to automate repetitive tasks.Design metrics, derive data-driven insights, and communicate findings in a concise manner to key stakeholders to help improve business performance.Maintain the integrity of company data and put checks in place to ensure accuracy. Identify and fix data quality issues before reports are generated.Partner with stakeholders across the long/short business to identify data needs and build reporting to inform business decisions.Design data models, ensure data quality, and automate processes where possible.THE CANDIDATE4+ years of previous experience within data analytics or business intelligenceExcellent data visualization skills (Tableau, PowerBI, or software libraries in R or Python)Mastery of SQL and database conceptsThe ability to synthesize information quickly to provide an independent and objective viewpoint, propose appropriate solutions, and drive meaningful changeThe ability to multitask and prioritize assignments while producing high quality work in a demanding, fast-paced environmentStrong written and verbal communication skills to interpret the data and dashboards for those less technically inclinedStrong attention to detail Data curiosity – When you look at data or a visualization, do you ask yourself if the values make sense, or what could be causing something to stand out?The ability to work independently as well as collaborate with a small team and internal clientsWhat We OfferCompetitive compensation packageEquity for all–our success is your successUnlimited vacation–and we want you to use it401K matchingFlexible work optionsComprehensive health coverage for you and your familyMaternity and paternity leave benefitsReimbursement for gym membershipsReferral bonus program–bring your friends!Work with and learn from functional experts across disciplinesThe salary range for this role is $100,000-$140,000. Your final base salary will be determined based on various factors which may include, but are not limited to location, work experience, skills, knowledge, education and/or certifications. You may be eligible to participate in Extend’s annual bonus plan, based on individual and organizational performance.To all recruitment agencies, Extend does not accept agency resumes. Please do not forward resumes to our jobs alias, Extend employees or any other company location. Extend is not responsible for any fees related to unsolicited resumesExtend is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, citizenship or immigration status, or any other status protected by law.Powered by JazzHRIJ33N9DZnA\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " '12860BRNew JerseyJob DescriptionData Analyst:Location : Onshore. Working with clients and preparing the Prologue Financials database for implementation.  Importing and converting client conversion data into Prologue-friendly format, retaining all meaningful data points. Working with client on how to handle any discrepancies or exceptions.  Posting general ledger journal entries as required to adjust data loaded.  Crafting client financial and validation reports through the Prologue report writer and working with the client to resolve any findings.  Partnering with the Business Consultants, Project Managers and Project Team to craft a solution to fulfill and prioritize the client’s business requirements.  Identifying and implementing solutions to automate, or otherwise build efficiencies for, the various steps required for building out client databases – encouraging an environment of continual improvement. QualificationsGraduateRange of Year Experience-Min Year5Range of Year Experience-Max Year8\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"SummaryS&S Activewear has an opportunity for a new HRIS & Data Specialist to join our team. In this role, you will be responsible for day-to-day support, maintenance, and data integrity within our Human Resource Information System (HRIS), including but not limited to data management, reporting, compliance, analysis, training, and process improvement, acting as Super User. This role will also partner with the HRIS Manager on improvements to achieve short-term and long-term objectives working with business related departments including but not limited to finance, information technology and other partners as identified. Schedule Monday-Friday 8AM-5PM, Exempt Base location for this role is flexible - working remotely or from one of our Warehouse locations.Duties and ResponsibilitiesMaintain optimal functions to HR systems which may include installation, customization, development, maintenance and upgrade to applications, systems, modules, and software.Provide technical support, troubleshooting to HRIS users.Collaborate with HRIS Manager and business partners to identify system improvements enhancements while recommending and implementing viable solutions.Manage permissions, access, personalization and similar system operations and settings for HRIS users.Compile and assist with the acquisition of data reports and summaries for leadership and team members.Conduct regular assessments including quality assurance testing, system audits, data cleanup and corrections.Develop a variety of user procedures, guides, manuals, and instructional tools.Assist/train end users with inputting, updating, analyzing, and maintaining accurate data for new hires, transfers, terminations, pay location changes, salary changes, address changes, etc. to meet entity needs.Maintain high standards of confidentiality and in compliance with data privacy guidelines.Perform additional duties as assigned.Required Education, Skills, Abilities and ExperienceDegree or diploma in systems or HR related field.Experience in HRIS setup/design, support, data management and reporting.Experience in ADP Workforce Now strongly preferred.Advanced knowledge of Microsoft Excel required.Possess knowledge of human resources practices.Data analysis and Implementation of technical effective solutions; creative problem solver.Project management experience and innovative thinking skills.Process orientated and action-orientation with excellent follow-through skills.Ability to prioritize workload and provide timely follow-up and resolution to meet tight deadlines.Excellent customer service skills, with excellent verbal and written communication skills.Demonstrated high level of accountability, integrity, discretion and confidentiality.Proven ability to collaborate and work in a cross-functional team environment.Able to develop various types of end-user written training materials/manuals/guides.Strong interpersonal and customer relations skills.Working EnvironmentThis job operates in a professional office environment. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines. Reasonable accommodations may be made to enable people with disabilities to perform the essential functions. Physical DemandsThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. While performing the duties of this job, the employee is regularly required to talk or hear. S&S conducts its business without regard to sex, race, creed, color, religion, marital status, national origin, citizenship status, age, pregnancy, sexual orientation, gender identity or expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. S&S's policy is to recruit, hire, train, promote, assign, transfer and terminate employees based on their own ability, achievement, experience and conduct and other legitimate business reasons. S&S participates in E-Verify and will provide the federal government with your Form I-9 information to confirm you are authorized to work in the U.S. This job offer is contingent upon the completion of a satisfactory background check.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Genesis10 is seeking a JR SQL Data Analyst for a contract to hire with our client in Plano, TX. \\xa0100% Remote.Job Description:Job responsibilities focus on analyzing, querying, and performing quality assurance on data maintained in a complex relational database environment.Responsibilities:Designs and analyzes data utilizing advanced technical experience with SQL Server technologiesAnalyzes Title Insurance rates and related data maintained in complex relational databasesProduces ad hoc reports and queriesDevelops and maintains familiarity with internal, proprietary SQL Server database structuresWorks collaboratively with database developers and business analysts to identify and resolve data issuesDevelops and maintains familiarity with relevant data reporting and State requirementsAssists in updating in-house proprietary software to reflect required changes to data processing and reporting specificationsParticipates in the development and maintenance of data warehousePerforms testing and validation against software application for quality assurance.Regular consistent attendance is required, that could include attendance at after hour Company events.Ability to accept supervision.Ability to foster, develop and maintain professional and collaborative working relationships. Must be able to get along with others, i.e., peers, supervisors, outside customers, and vendors.Ability to interact effectively and professionally with all levels of management, employees and customers by email, phone and in person.Must be personable, positive, and a professional representative of the Company.Perform other duties as assigned by supervisor.Qualifications:Minimum BS or BA, in computer science or related field; preferred2 - 5 years of experience querying relational databases using SQLStrong PC skills required, including proficiency with Microsoft Windows, Excel, and WordExcellent analytic, interpersonal, and communication skills, especially written communication skillsT-SQL stored procedure development, preferred.Microsoft SQL Server Reporting Services design and development, or similar report design and development experience (e.g. Microsoft Access or Crystal Reports)Querying and/or developing Microsoft Analysis Services (or similar) OLAP databasesExcellent verbal and written communication skills.Excellent interpersonal and customer service skills.Ability to prioritize and handle multiple projects.Strong attention to detail and organizational skills.Proficient in Microsoft Office Suite and Outlook.Compensation:Hourly W2 pay rate $30.00 - $33.00We have access to additional contract, contract-to-hire, and direct hire positions with various rate ranges.\\xa0If you have the described qualifications and are interested in this exciting opportunity, apply today!Ranked a Top Staffing Firm in the U.S. by Staffing Industry Analysts for six consecutive years, Genesis10 puts thousands of consultants and employees to work across the United States every year in contract, contract-for-hire, and permanent placement roles. With more than 300 active clients, Genesis10 provides access to many of the Fortune 100 firms and a variety of mid-market organizations across the full spectrum of industry verticals.For contract roles, Genesis10 offers the benefits listed below. If this is a perm-placement opportunity, our recruiter can talk you through the unique benefits offered for that particular client.Benefits of Working with Genesis10:Access to hundreds of clients, most who have been working with Genesis10 for 5-20+ years.The opportunity to have a career-home in Genesis10; many of our consultants have been working exclusively with Genesis10 for years.Access to an experienced, caring recruiting team (more than 7 years of experience, on average.)Behavioral Health PlatformMedical, Dental, VisionHealth Savings AccountVoluntary Hospital Indemnity (Critical Illness & Accident)Voluntary Term Life Insurance401KSick Pay (for applicable states/municipalities)Commuter Benefits (Dallas, NYC, SF)Remote opportunities availableFor multiple years running, Genesis10 has been recognized as a Top Staffing Firm in the U.S., as a Best Company for Work-Life Balance, as a Best Company for Career Growth, for Diversity, and for Leadership, amongst others. To learn more and to view all our available career opportunities, please visit us at our website.Genesis10 is an Equal Opportunity Employer. Candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Continuum Clinical (CC), a part of BC Worldwide, is a global clinical trial enrollment company. With over twenty-five years of experience, Continuum Clinical specializes in providing sponsors and CROs with patient recruitment and retention planning, study and site support, patient recruitment campaigns, patient advocacy and diversity & inclusion services, retention solutions, and reporting and analytics. We exist to give incredible people the opportunity to make a difference.  Values CollaborativeGenuineKind & CompassionatePride of Ownership & Accountability Job SummaryAs a Data Analyst, you will be responsible for reporting and analyzing a variety of healthcare related digital campaigns and outreach programs at the agency. This includes the design and development of program dashboards and reports, creating new reporting templates, and collaborating with other members of the Data and Analytics team to create analyses, optimizations, and recommendations across the full spectrum of digital media and other processes. You should have a strong attention to detail, familiarity with common digital reporting applications, and a solid working knowledge of analytic tools and processes. This position works closely with members of the Integrated Media, Global Site Solutions, and Account teams, and reports directly to the Director of Data and Analytics. Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Other duties may be assigned. Demonstrate the mission, vision, values, and culture principles of BC WorldwideCreate and manage dashboards and other data visualizations in Einstein Analytics, Tableau, and Google AnalyticsServe as Subject Matter Expert for Google Analytics/Google Tag Manager setup and reportingManage and update weekly reports on Continuum program performanceAssist in the setup of new programs, including gathering requirements and customizing reportsMonitor campaign performance, analyze results, and provide fact-based recommendations for clients and internal team members on a weekly/monthly/quarterly basisIdentify and define new process improvement opportunitiesAs needed, create new ad hoc analyses based on business needsComply with all corporate and departmental standard operating procedures as well as FDA and other governmental regulations (e.g., IRB, EC).Ensure all activities and operations are performed in compliance with regulatory and federal regulations.Responsible for maintaining up to date weekly time tracking, per the Agency’s time tracking policy.Continuum Clinical QualitiesTo be successful, every BC Worldwide employee should possess the following qualities:Attitude & Commitment – you are a passionate, resourceful, and productive achiever that is a pleasure to be aroundPriority Setting – you define clear action steps and manage expectations of othersCreative Thinking & Problem Solving – you recognize therelevancy of your ideas to the big picture, demonstrate original thinking and make an impact on your teamDependability – you are self-motivated to deliver the highest quality work, on time and budgetLeadership Ability – you take initiative, motivate others, and assume accountability for your actionsCommunication – you use organized, constructive communication to facilitate great work Education, Experience, and CertificationsBachelor’s degree (master’s preferred), or equivalent work experience3-6 years in an analytical role for a digital/online/interactive firmKnowledge and experience in digital advertising analyticsSolid understanding of web analytics/tracking tag implementationSolid working knowledge of one or more analytic tools or programs (Python, SQL, R, etc.)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Summary / Position Purpose: The primary responsibility of this role is to create consolidated reports, dashboards, and data analysis for the internal customers of ACG. This role will be responsible for the day-to-day support, maintenance, and improvement of our CRM and supporting platforms, as well as excel-heavy data-related projects. Their work will involve collecting and cleaning data from multiple sources, running ad hoc reports, building automated dashboards, investigating, and fixing any potential errors/bugs, and working with the Database Administrator to ensure that the information in our database is error-free for accurate reporting. Essential Duties, Functions and/or Responsibilities: Create, validate, and send daily weekly, and monthly management reports.Assistance with requests for non-standard reports and analysisSupport management reporting by maintaining hierarchical information.Perform business-to-system analysis and troubleshooting analysis of complex management reports and business problems.In the report, development lifecycle support impacts analysis and project requirements definitionTransform client needs into functional requirements.With guidance, collect, analyze, and document business requirements for project proposals including but not limited to process and data flow, user interface, and reporting requirements.Together with managers and/or senior analysts, participate in cross-functional meetings to understand customer needs and identify problems and solutions.Appropriate solutions, develop specifications, analyze, and document business processes, validate testing processes, and train the user community.Gather, clean, and transform large data sets to be used in reports and visualization.Design, develop and implement innovative/effective/strategic fully automated business solutions.Works closely with IT and business to incorporate daily automated data refreshing.Develops and provides a standard set of user-friendly reporting tools to internal business customers.Provides maintenance on deployed tools and dashboards.Assist sales & marketing teams with CRM reports and data management, building and maintaining outreach lists for up to several dozen sales and inside sales colleagues.Other duties as assigned.  Education and/or Work Experience Requirements: EDUCATION: Bachelors/4 Yr. DegreeYEARS OF RELEVANT WORK EXPERIENCE: 1+ yearsSalesforce.com (or equivalent CRM) power-user/admin experienceExpert knowledge of Microsoft Office (especially Excel)Demonstrable excel & CRM familiarity with pivot tables and other similar visual reporting tools to display/reconcile large amounts of data.Strong ability to meet deadlines and manage and prioritize simultaneous requests.Creative and analytical thinker with strong problem-solving skillsMust demonstrate ability to communicate effectively verbally and in writing with all levels of the organization.Ability to critically evaluate and prioritize information gathered from multiple sources and reconcile conflicts.Ability to assess the impact of new requirements on Salesforce and other integrated systems.Ability to safely and successfully perform the essential job functions consistent with ADA and all other applicable federal, state, and local standards, including meeting qualitative and/or quantitative productivity standards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Hubble Contacts (Hubble) pioneered private label daily contact lenses sold directly to consumers through a subscription-based e-commerce business model. The company was founded in 2016 with the mission of delivering high quality lenses at an affordable price point in a manner that had never been offered before.Historically, four manufacturers controlled about 95% of the contact lens category in the United States and Canada and set prices much higher than a fair and open market would tolerate. Enter Hubble: a company offering a more affordable and consumer friendly option than any product currently on the market. Hubble recently launched ContactsCart, offering its customers alternative manufacturer brands including Bausch & Lomb, CooperVision, and Johnson & Johnson at a meaningful discount. The company is also exploring strategic opportunities for new product launches including toric lenses, eyeglasses, as well as entering new distribution and retail channels.Due to the rising prevalence of eyesight disorders coupled with an increase in consumer spending, Hubble is uniquely positioned to capitalize nationally and internationally on the growth of a global contact lens market predicted to reach $17.7 billion by 2025.Position Summary:The Data Analyst is responsible for analyzing and evaluating the quality and consistency of the organization’s data. You will serve as a primary subject matter expert for technical project management and data integrations across various platforms to ensure operational excellence. This role will work cross-functionally with department stakeholders to find opportunities to streamline and improve processes, ideally automating efforts. This position requires in-depth experience, knowledge, and skills in data analytics, visualization, and technical architecture.RequirementsProactively design and build dashboards in Tableau while presenting findings and interesting trends to stakeholders.Automate reporting procedures as necessary by establishing secure and robust data links between various sources and documents.Maintain all data logs regarding revisions made to the data and version changes.Collaborate with internal partners to understand business strategy, questions, and goals while supporting all data needs.Acquire and compile structured and unstructured data and verify their quality and accuracy while providing daily spot checks to ensure the validity of the organization's data.Bring structure to business requests and ad-hoc reports for various projects, translate requirements into an analytical approach, and lead projects through to completion.Assist in developing technical solutions to survey-related projects in partnership with internal teams and internal/external engineers.Complete assessments of business processes and document each of the following areas: problem statements, process flows, gap analysis, and solution recommendations.Deconstruct technical concepts and metrics for business partners.Develop repeatable and scalable plans and processes to speed time to market and improve operational efficiency.Exercise independent judgment and discretion in matters of significance.Other Qualifications & Characteristics: Obsession with knowing the data and with understanding the business context. Willingness to do the groundwork of learning and exploring the weaknesses and strengths of various data tables and their relations to each other. Capable of writing complex SQL queries in an elegant and structured way to retrieve information that can be translated into easily interpretable and actionable reports; Capable of understanding existing query structures and can critique constructively.Advanced Excel user with experience in automating reports using Power Query; some knowledge of the DAX languageExperienced Google Sheet userExperience with building dashboards in TableauExperience with Google Analytics and various social media platformsProven ability to work both independently and collaboratively with different levels of employeesSelf-starter and self-learner. Bachelor’s Degree; STEM majors are preferred.BenefitsAt Hubble, we invest in our employees' well-being and empower them with benefits to ensure they can continue to be both happy and productive!Receive Insurance Covering, Medical, Dental & Vision. In addition, options for Flexible Spending, Health Saving Accounts, and Membership Options To One Medical, Teladoc, HealthAdvocate, and Talkspaces are also available!401k OptionCommuter BenefitsFitness Membership To ClassPassVoluntary Long-Term & Short-Term Disability InsuranceVoluntary Supplemental Life InsuranceHybrid Working EnvironmentUnlimited PTO - Geared Towards Work/Life BalanceAnnual Professional Development StipendQuarterly Team Meet Ups & Team Philantrhopic Events #HubbleCaresSalary: $70k to $95k - with bonus targets\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Mb Staffing Services is seeking a qualified Data Analyst to assist our DC Based client with data surrounding the Opioid crisis in our region. This is an interesting role and would require the experienced Data Analyst to Respond to inbound calls in a timely and professional manner and follow identified procedures to respond, document, log, and notify the appropriate persons Ensure that reporting remains current Timely and accurate submission of all reports with an error rate no greater than 5%. Perform descriptive analyses of public health data using statistical software (SAS preferred) and produce daily reports and other analytical reports as needed Ensuring data quality and integrity, perform tasks such as electronic file transfers; listing and tabulation of data for preparation of statistical reports; and electronic file linkages Develop analytic datasets (to include, for example, data extraction, data cleaning, matching/merging, and variable coding) and document processes in codebooks, protocols, and associated guidance documents Design databases and tracking systems and monitor data collection activities for multiple surveillance programs Utilize business analytics tools, such as Tableau, to perform data analysis. Support design and recommend content, format, dissemination methods, etc. Maintain and automate reporting applications and visualizations Monitor quality assurance and quality improvement of applicable surveillance and other data systems and processes Develop strategies for improving data processing efficiency, as well as data completeness and quality. Work hours are Monday through Friday 8:30 a.m. to 5:00 p.m. This position is Hybrid Company Description In an era of constant workforce changes, Mb Staffing Services offers something you can count on: The perfect fit! We continue this with a seamless transition. We listen intently. We think strategically. And we act methodically. We respond with speed and an eye to the future! We are a precision placement, results-oriented firm serving a full spectrum of industries and staffing needs.In an era of constant workforce changes, Mb Staffing Services offers something you can count on: The perfect fit! We continue this with a seamless transition. We listen intently. We think strategically. And we act methodically. We respond with speed and an eye to the future! We are a precision placement, results-oriented firm serving a full spectrum of industries and staffing needs.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'JDC -61 Data Analyst, Tallahassee, FLAbout Syra HealthSyra Health Corp. is a pioneering healthcare technology consulting company that develops outcomes-driven solutions having a direct and quantitative benefits to the healthcare industry. We work with payers, health services companies, and life sciences companies to build solutions that create measurable business value and have a positive impact on the lives of their customers. And we are dedicated to cultivating an inclusive culture of respect, honesty, and integrity by embracing the unknown, recognize the value of diversity, and harness the power of enthusiasm.Job SummarySyra Health, a healthcare organization, is seeking a highly skilled Data Analyst to join our team. The ideal candidate will be responsible for analysing and interpreting complex healthcare data sets, including experience in Medicaid data management. The candidate should have advanced knowledge of SQL, and experience working with large data sets. The candidate will be expected to provide actionable insights to inform decision-making and improve patient outcomes.ResponsibilitiesAnalyse and interpret large and complex healthcare data sets, including experience in Medicaid data management.Develop and maintain databases, data systems, and data analytics tools to support data-driven decision-making.Extract qualitative and quantitative relationships (i.e., patterns, trends) from large amounts of publicly available data using SAS, SQL, R, Python, or other statistical toolsIdentify and interpret trends or patterns in data sets.Prepare reports and visualizations that effectively communicate insights and recommendations to management and stakeholders.Collaborate with other teams, including clinical and operational teams, to develop data-driven solutions that improve patient outcomes and reduce costs.Design and implement experiments to test hypotheses and validate assumptions.Ensure data accuracy and completeness by conducting regular data audits.Stay up to date with industry trends, best practices, and regulations related to healthcare data management.RequirementsMinimum of 3 years of experience in data analysis, preferably in healthcare.Experience creating datasets for CMS programs such as MSSP, DCE, or ACO Advanced knowledge of SQL and experience with relational databases.Experience working with Medicaid data and other healthcare data sets.Strong analytical and problem-solving skills.Ability to work independently and in a team environment.Excellent communication and presentation skills.Strong attention to detail and accuracy.Strong hands-on with data visualization tools, such as Tableau or Power BI, is a plus.Careers At Syra HealthOur objective is to make the world a better place by thinking big and seizing opportunities for ourselves, our clients, and our consumers. We are driven by a passion for health and encourage you to be unique, inquisitive, and bold. And by working together, we can increase your contribution on both your career and the world of healthcare.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'NovoEd builds the next generation of learning technology to offer engaging learning experiences at scale through social collaborative and experiential learning. Our platform is used by enterprise companies including those in the Fortune 500, top universities, training firms, and foundations, around the world to provide experiential and collaborative learning to adult learners. These online learning experiences replicate in-person learning experiences such as workshops that have traditionally been hard to bring online. Social collaboration and peer learning are not only built into our product, but also the DNA of our company. We have a collaborative team with a passion for learning and an amazing culture.The Data Analyst will report to the VP of Product and be a key partner of the R&D, Revenue Operations and Customer Experience teams. The role is expected to provide deep analysis of data and then determine the best way visualize it for customers, business partners and management. This will require solving business problems by customizing the Salesforce and Churn Zero platforms as well as setting up data pipelines using open-source relational database management systems with wysiwyg type tools. The Data Analyst will create metrics and charts using embedded analytics tools, resolve data issues with the quality assurance team, and liaise with the design team on aesthetics and the user experience aspects of dashboards. The Data Analyst will be the owner of the embedded analytics tool, and be responsible for managing the data vendors, including the reporting and resolution of issues.Responsibilities:Manage dashboards, reports and insights for customers as well as the product, sales, marketing, and customer experience teams. Gather requirements, configure changes, design best practice solutions, data governance and reporting for the Salesforce and Churn Zero platforms. Deliver data sources relevant to customer engagement and the use of the NovoEd product into the SaaS product data store; Use APIs or MySQL to bring data in from relevant sources. Design data sets that are performant, can sync data with a lag of at most 30 minutes using a tool like AWS ETL/AWS GLUE. Create metrics and charts using a tool like Tableau, Google and Excel Charts. Generate, evaluate, and improve in-product, problem focused dashboards. Work with Product, Design, Engineering, and Quality Assurance teams to ship dashboards to production systems. Partner with the Product, Revenue Operations, and Customer Success and Support teams to answer specific data questions that are not yet built into the SaaS product. Qualifications:5+ years of experience with MySQL writing complex queries. 3+ years of experience creating and modeling performant data sets as well as deep data analysis. 5+ years of experience building charts and dashboards in tools like Salesforce, Churn Zero and Tableau. Ability to work independently, prioritize workload, and manage cross-functional projects. Advanced technical, analysis and modeling skills in data analytics tools, python and Excel (pivot, VLOOKUP, etc.). Experience using data analytics to support assumptions and develop business cases. Strong communication skills (verbal and written) and interpersonal skills with the ability to translate complex analysis into actionable recommendations. Compelling storytelling and presentation skills. Client centricity, empathy and deep curiosity to find deeper answers to data questions. What will set you apart:Experience working with a wide variety of business data sources. Experience with predictive analytics and data visualizations. Salesforce Administrator experienceNovoEd provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Salary range: The base pay for this role is up to $110k base + bonus. The actual base pay is dependent upon many factors, such as training, skills, work experience, business needs, and location. The base pay range is subject to change and may be modified in the future.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data Analyst Job Description : * Supports and contributes to business analytics projects and processes to provide data-driven insights related to business performance used to advise and develop strategies for operational improvements and future business initiatives. * Uses statistical methods, modeling, analytical methodologies, and data analysis to develop and deploy tools including dashboards, infographics, reports, and models to inform and support decision-making. * Processes, and analyzes internal and external data using KPIs, business results, industry sources, competitor intelligence, and customer information. * Develops a good understanding of the business's model, objectives, issues, and challenges by interacting and collaborating with users and stakeholders. * Typically reports to a supervisor or manager and make sure work is closely managed. * Works on projects/matters of limited complexity in a support role. Qualifications: * Desired a Master's or Bachelor's degree in computer science, information technology, statistics or a quantitative field. * Desired 0-2 years of related experience. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Company Description ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Contract Remote Role: Data AnalystDuration: 6 months contract with possible extensionLocation: Newark/Remote (primarily remote with ability to occasionally go on-site when needed).Job DescriptionThis position will support the clients Clean Energy Jobs Program, which includes following:The use of data and interpreting to develop executive reports and power points.Gather the information and statistics, analyze trends, and then use charts and graphs to present the results.Documentation of various processes by collaborating with client QA/QC team.Develop actionable roadmaps for improving workflows and processes and establish and organize KPIs in line with global directives.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are a Direct Mail and Email Marketing company. We acquire database lists and put them in a format for printing and mailing or emailing. We use Altryx and Excel. Company Description TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Key Responsibilities: Analyze data sets to determine data gaps Support the team with data analysis, such as data discovery and data usage viability Partner with team on testing with data verification, completeness, and data quality checks. Participate in data driven initiatives, such as data linage, data quality checks, data migrationQualificationsSkills Required: Bachelor's Degree in Computer Science or similar Strong communication skills, both verbal and written Have strong reasoning skills, logical deduction and apply to data analysis Present and be able to tell a story with the data analysis/reporting ?Experience working in SQL and relational databases Self-motivated individual and creative thinker who will take ownership of tasks assigned Ability to problem solve and have creative solutions in challenging environments Able to thrive in a fast-paced, high energy, demanding and team-orientated environment Good customer service skills. Ability to deal with difficult situations gracefully. Microsoft Office Suite: Word, Excel, and PowerPointSkills Desired: Knowledge of trades data, positions data, reference data. Experience with trade lifecycles and asset classes, Equity, Fixed Income, Options, Futures Understanding of Risk or Compliance Systems, such as Actimize, MANTAS, or SungardRate Range: $45-$50/hrPowered by JazzHRvpkaehKEHR\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"ARE YOU HAPPY? ARE YOU VALUED? ARE YOU IN CHARGE OF YOUR FUTURE?Our Mission is to provide products and services, in an honorable way, that exceed the expectations of each one of our clients. We are not like other HVAC companies, Conditioned Air, “The Comfort People since 1962” Success Depends on Employees Like You, who pride themselves in teamwork, professionalism, knowledge, ability, loyalty, and exceeding customer expectations.We Want Our Employees to Thrive and Grow, in a place where a job is more than a job, It Is a Career! Learn while on the job, always preparing to achieve the next step of personal and professional success. We continually invest in you! Named 2019's “Top 500 Companies on the Gulf Coast” by Business Observer and recognized in Gulfshore Magazine’s “Best in Business” several years in a row. Now is the time to Join Our Growing Team! We are now seeking a Data Analyst to work in either our Fort Myers or Naples location.The position works on multiple projects as a subject matter expert in a fast-paced environment for the support of executive management and other internal clients.PLEASE BE AWARE THAT THIS IS AN ON-SITE POSITION IN SWFL, THERE IS NO OPTION FOR REMOTE WORK. IF YOU LIVE IN SWFL OR ARE PLANNING TO RELOCATE, PLEASE APPLY AND YOU WILL BE CONTACTED.Essential Duties and Responsibilities:Creates, analyzes, and utilizes financial data to create reporting related to revenue, sales, and operating metrics/KPINormalizes financial and operational data to maintain appropriate and accurate financial databasesEnhances and refines databases to improve reporting and analysis capabilitiesTracks, reconciles and analyzes variancesCompletes weekly, monthly, quarterly, annual, and ad-hoc management reports and analysisIs the go-to expert regarding system data and report buildingCreate proactive analyses comparing company results to industry data to evaluate program performance.Participates in project teams, analyzing various new programs, projects, or venturesPrepares reports, presentations, and other documents and presents these materials in meetingsIdentify problematic areas and research to determine the best course of action to correct the dataIdentify and research anomalies and outliers in dataPerforms other related duties as assigned or requestedEducation and Experience:BachelorsRequired- 3+ years of experience working in a Data Analyst or Business Analyst RoleAttention to detailCoding skills (SQL)BI tools (Tableau or PowerBI)MS Office (Excel)Critical thinkingAbility to work with technical and non-technical stakeholdersDesire to learn / Intellectual curiosityWANT COMPETITIVE PAY AND GREAT BENEFITS? Look no more, we offer 8 Paid Holidays, Company Paid Basic Life and Long-Term Disability, PTO, Medical, Dental, Vision, supplemental insurance benefits for Accident, Critical Illness, 401(K) Retirement plan, a bonus plan, and above all, a great atmosphere with on-going training and teamwork. For additional information or assistance please visit www.conditionedair.com.Conditioned Air provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.In compliance with the Drug-Free Workplace Act of 1988, Conditioned Air has a longstanding commitment to providing a safe, quality-oriented, and productive work environment. Alcohol and drug abuse pose a threat to the health and safety of Conditioned Air employees and the security of the company’s equipment and facilities. For these reasons, Conditioned Air is committed to the elimination of drug and alcohol use and abuse in the workplace\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Position: Data AnalystLocation: West Chester, PADuration: 12 monthsThe ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users. As part of the Cyber Recovery program it is vital to measure and document multiple recovery scenarios. This position will assist in gathering, evaluating and transforming recovery time information into a formula which can be re-used across multiple scenarios.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with dataCompile and analyze data related to business' issuesDevelop clear visualizations to convey complicated data in a straightforward fashionQualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience1 - 2 years' Data Analysis experienceProficient in SQL\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The Black Tux is reinventing formal wear so people can show up at their best on the days that matter most. We design and manufacture modern rental suits and tuxedos that actually fit—made of 100% wool, ordered online, and delivered for free.As a member of the Data & Analytics team, you will become the company expert on data. Our data is key to the company’s ability to live up to our mission to provide our customers with concierge level service and you will be an integral part of ensuring we succeed. You will work on a variety of projects from utilizing Zendesk data to help the CX team track and plan staffing, to analyzing trends to help showrooms expand and convert customers, and working with our stakeholders and defining key metrics and visibility for performance management. You will work to mainly support stakeholders in the Customer Experience and Showroom teams to help them make smarter, data driven decisions and inform company-wide strategy as we continue to grow.What You'll DoBuild analytics solutions to monitor the health of our business and solve a wide range of business problems to inform data-driven strategic and operational decisionsWork closely with stakeholders to understand business requirements and translate them into technical solutionsCommunicate directly with stakeholders to understand the business, project requirements, and to better ideate analytical solutionsDefine KPIs, develop and own business intelligence dashboards, and provide ongoing tracking and insights to partnersCollaborate with data engineering to ensure that we have accurate sources of truth data to serve needs across our organizationEngage stakeholders to identify obstacles and implement data analytics and tools to help improve their day-to-day business decisions and operationsWho You AreA problem solver that is excited to take on new challenges and, given context, being self-directed and enthusiastic about owning your work autonomouslyYou use SQL every day to help companies understand their operations and make data-driven decisions, preferably with experience working with warehouse, inventory, and/or customer care dataAn empathetic analyst that thrives as a true partner to business stakeholders and understanding their needs, building strong relationships to achieve the shared goal of using analytics and insights to drive the business forwardA storyteller that can use data visualization to communicate insights effectively to a variety of stakeholdersYou show modesty, kindness and support to your team and the people you work withThe Data Analyst role is remote.The base salary for this position will be $95,000 - $105,000, but the actual compensation may vary based on the candidate’s skills, qualifications, and location. The Black Tux defines compensation plans using market data aligned with comparable companies at a similar stage and size as ours.This position also qualifies incentive based compensation which may include a performance based bonus and/or incentive stock options. The Black Tux also offers unlimited PTO on top of generous company holidays, including a winter break at the end of each year.Our people are the most important asset to us. Our benefits, perks, pay and culture reflect this in every decision we make. If you want to learn more about us, check out our Culture Book.We're an equal opportunity employer to all. We interview and hire applicants of all backgrounds, orientations, expressions, and identities.Notice to California Job Applicants disclosed here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionHertz and the Advanced Analytics and Tool Development team is seeking talented individuals with passion for real-world problem solving. The analyst will partner with various functions within the company (Revenue Management, Fleet, Operations) and develop advanced tools and resources to support overall location-level planning and operational decisions. The analyst will be working with large sets of structured and unstructured data to perform analysis, develop tools, and provide actionable insights.What You’ll Be Doing Develop tools for the field for car assignment to optimize upgrade/upsell/booking success.  Develop tools to provide visibility to many of the operational processes.  Conduct analyses to inform stakeholders and help make the most optimal decisions regarding various strategic initiatives.  Code and automate performance reports.  Configure shared PC resources to automate scripts and collect data. What We Expect A Bachelor’s degree; preferably in Data Science, Computer Science, Statistics, Engineering, or another quantitative field.  A demonstrated ability to query and extract findings from large data sets in relational databases such as SQL Server, Teradata, Oracle, etc.  A wide range of data-related technical skills regarding databases, scripts, and web APIs.  Experience with programming/scripting languages like R or Python  Experience with advanced data visualization platforms such as Tableau.  Quick on feet; willingness to discover alternative solutions to technical problems.  A desire to solve complex problems with creative and concise solutions.  Excellent written and oral presentation skills – ability to communicate findings with non-technical stakeholders in concise and simple terms.  An individual who thrives in a collaborative environment. Nice To Haves More than 1 year of work experience in a data driven industry including Rent-A-Car, travel, or service industry  A Master’s degree in a quantitative field  Experience with statistical modeling  Experience with web development languages such as Ruby, PHP, or JavaScript. r work every day represent a significant part of our culture – and our success and reputation as a company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionRole: Data AnalystSalary: $110,000 - $140,000 (plus benefits)Location: Austin, Texas (Hybrid Model)Sponsorship: Not availableI am currently on the lookout for a Data Analysis to join one of the largest U.S. banks based in Austin Texas. Within this position you will be working functionally across the business with Engineering, Finance, Customer success and product to collect, analyze and interpret data related to the bank's commercial lending and business operations.Working on a Hybrid model, if you have a strong curiosity of data and enjoy problem-solving a wide range of topics, who thrives on a fast-paced environment then this would be the perfect role for you!ResponsibilitiesCollect and analyze data related to commercial lending portfolios, including loan performance, risk assessments, and compliance with regulations.Develop and maintain reporting and analytics tools to provide insights into commercial lending and business operations.Work with stakeholders to identify key performance indicators and develop dashboards and reports to monitor them.Generate insights to uncover usage trends to inform product development, drive user adoption and savings (time and/or cost)About YouExperience with data visualization tools such as Tableau or PowerBI.Commercial knowledge working with SQL and programming languages such as Python or R.Strong analytical and problem-solving skills with attention to detail.Knowledge of commercial lending and banking operations is a plus.Our client is an equal opportunity employer committed to creating a diverse and inclusive workplace. They offer a competitive salary, comprehensive benefits package, and opportunities for career growth and development.If you are a data analyst who is passionate about using data to drive business decisions and interested in joining a dynamic team at one of the largest commercial banks in the US, please click to apply!For more information about ITECCO and the opportunities we have to offer follow us on Twitter @ITECCOrecITECCO Ltd is acting as an Employment Agency in relation to this vacancy.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Extend OverviewExtend is a rapidly growing fintech startup in the B2B payments space with a focus on serving banks and their customers. We have built the first virtual card platform of its kind, directly integrated with processors, networks, and the technology that supports banking across the industry. We offer several virtual card products including an app-as-a-service that banks can offer business customers with their existing credit cards, a suite of virtual card APIs for those looking to build custom payment solutions, and we also offer secure connectivity to key banking and payment services that enable 3rd-parties to integrate and embed payments into their software.Founded in 2017 by 3 industry experts with experience at Fortune 500 companies, including American Express and Capital One, Extend is headquartered in Manhattan and has recently raised $40m in venture capital from top fintech investors. Extend was recently voted one of America's best startup employers by Forbes and best payments service platform by Tearsheet.With extreme monthly growth and 85+ mission-driven employees, now is prime time to join our team!For more information visitAbout The RoleWe are looking to add a Business Intelligence Analyst to our growing Business Intelligence team; as part of this team, you will be responsible for data reporting, developing analytics and measurement tools, and driving initiatives that help optimize revenue across multiple business segments. You will own much of the Tableau dashboarding and ad hoc data requests. You will also ensure our data remains clean and accurate. You’ll work with the Business Insights team to gather requirements from departments across the company, design new dashboards, and incorporate feedback. This is a hybrid role, based out of our New York City office, with three days on-site.At Extend, you’ll:Create and maintain data tables and Tableau dashboards that allow key stakeholders to view data in a quick and concise manner, effectively communicating insights through visualizations.Manage and resolve ad hoc Business Intelligence requests, developing new tools to automate repetitive tasks.Design metrics, derive data-driven insights, and communicate findings in a concise manner to key stakeholders to help improve business performance.Maintain the integrity of company data and put checks in place to ensure accuracy. Identify and fix data quality issues before reports are generated.Partner with stakeholders across the long/short business to identify data needs and build reporting to inform business decisions.Design data models, ensure data quality, and automate processes where possible.THE CANDIDATE4+ years of previous experience within data analytics or business intelligenceExcellent data visualization skills (Tableau, PowerBI, or software libraries in R or Python)Mastery of SQL and database conceptsThe ability to synthesize information quickly to provide an independent and objective viewpoint, propose appropriate solutions, and drive meaningful changeThe ability to multitask and prioritize assignments while producing high quality work in a demanding, fast-paced environmentStrong written and verbal communication skills to interpret the data and dashboards for those less technically inclinedStrong attention to detail Data curiosity – When you look at data or a visualization, do you ask yourself if the values make sense, or what could be causing something to stand out?The ability to work independently as well as collaborate with a small team and internal clientsWhat We OfferCompetitive compensation packageEquity for all–our success is your successUnlimited vacation–and we want you to use it401K matchingFlexible work optionsComprehensive health coverage for you and your familyMaternity and paternity leave benefitsReimbursement for gym membershipsReferral bonus program–bring your friends!Work with and learn from functional experts across disciplinesThe salary range for this role is $100,000-$140,000. Your final base salary will be determined based on various factors which may include, but are not limited to location, work experience, skills, knowledge, education and/or certifications. You may be eligible to participate in Extend’s annual bonus plan, based on individual and organizational performance.To all recruitment agencies, Extend does not accept agency resumes. Please do not forward resumes to our jobs alias, Extend employees or any other company location. Extend is not responsible for any fees related to unsolicited resumesExtend is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, citizenship or immigration status, or any other status protected by law.Powered by JazzHRIJ33N9DZnA\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " '12860BRNew JerseyJob DescriptionData Analyst:Location : Onshore. Working with clients and preparing the Prologue Financials database for implementation.  Importing and converting client conversion data into Prologue-friendly format, retaining all meaningful data points. Working with client on how to handle any discrepancies or exceptions.  Posting general ledger journal entries as required to adjust data loaded.  Crafting client financial and validation reports through the Prologue report writer and working with the client to resolve any findings.  Partnering with the Business Consultants, Project Managers and Project Team to craft a solution to fulfill and prioritize the client’s business requirements.  Identifying and implementing solutions to automate, or otherwise build efficiencies for, the various steps required for building out client databases – encouraging an environment of continual improvement. QualificationsGraduateRange of Year Experience-Min Year5Range of Year Experience-Max Year8\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"SummaryS&S Activewear has an opportunity for a new HRIS & Data Specialist to join our team. In this role, you will be responsible for day-to-day support, maintenance, and data integrity within our Human Resource Information System (HRIS), including but not limited to data management, reporting, compliance, analysis, training, and process improvement, acting as Super User. This role will also partner with the HRIS Manager on improvements to achieve short-term and long-term objectives working with business related departments including but not limited to finance, information technology and other partners as identified. Schedule Monday-Friday 8AM-5PM, Exempt Base location for this role is flexible - working remotely or from one of our Warehouse locations.Duties and ResponsibilitiesMaintain optimal functions to HR systems which may include installation, customization, development, maintenance and upgrade to applications, systems, modules, and software.Provide technical support, troubleshooting to HRIS users.Collaborate with HRIS Manager and business partners to identify system improvements enhancements while recommending and implementing viable solutions.Manage permissions, access, personalization and similar system operations and settings for HRIS users.Compile and assist with the acquisition of data reports and summaries for leadership and team members.Conduct regular assessments including quality assurance testing, system audits, data cleanup and corrections.Develop a variety of user procedures, guides, manuals, and instructional tools.Assist/train end users with inputting, updating, analyzing, and maintaining accurate data for new hires, transfers, terminations, pay location changes, salary changes, address changes, etc. to meet entity needs.Maintain high standards of confidentiality and in compliance with data privacy guidelines.Perform additional duties as assigned.Required Education, Skills, Abilities and ExperienceDegree or diploma in systems or HR related field.Experience in HRIS setup/design, support, data management and reporting.Experience in ADP Workforce Now strongly preferred.Advanced knowledge of Microsoft Excel required.Possess knowledge of human resources practices.Data analysis and Implementation of technical effective solutions; creative problem solver.Project management experience and innovative thinking skills.Process orientated and action-orientation with excellent follow-through skills.Ability to prioritize workload and provide timely follow-up and resolution to meet tight deadlines.Excellent customer service skills, with excellent verbal and written communication skills.Demonstrated high level of accountability, integrity, discretion and confidentiality.Proven ability to collaborate and work in a cross-functional team environment.Able to develop various types of end-user written training materials/manuals/guides.Strong interpersonal and customer relations skills.Working EnvironmentThis job operates in a professional office environment. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines. Reasonable accommodations may be made to enable people with disabilities to perform the essential functions. Physical DemandsThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. While performing the duties of this job, the employee is regularly required to talk or hear. S&S conducts its business without regard to sex, race, creed, color, religion, marital status, national origin, citizenship status, age, pregnancy, sexual orientation, gender identity or expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. S&S's policy is to recruit, hire, train, promote, assign, transfer and terminate employees based on their own ability, achievement, experience and conduct and other legitimate business reasons. S&S participates in E-Verify and will provide the federal government with your Form I-9 information to confirm you are authorized to work in the U.S. This job offer is contingent upon the completion of a satisfactory background check.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Genesis10 is seeking a JR SQL Data Analyst for a contract to hire with our client in Plano, TX. \\xa0100% Remote.Job Description:Job responsibilities focus on analyzing, querying, and performing quality assurance on data maintained in a complex relational database environment.Responsibilities:Designs and analyzes data utilizing advanced technical experience with SQL Server technologiesAnalyzes Title Insurance rates and related data maintained in complex relational databasesProduces ad hoc reports and queriesDevelops and maintains familiarity with internal, proprietary SQL Server database structuresWorks collaboratively with database developers and business analysts to identify and resolve data issuesDevelops and maintains familiarity with relevant data reporting and State requirementsAssists in updating in-house proprietary software to reflect required changes to data processing and reporting specificationsParticipates in the development and maintenance of data warehousePerforms testing and validation against software application for quality assurance.Regular consistent attendance is required, that could include attendance at after hour Company events.Ability to accept supervision.Ability to foster, develop and maintain professional and collaborative working relationships. Must be able to get along with others, i.e., peers, supervisors, outside customers, and vendors.Ability to interact effectively and professionally with all levels of management, employees and customers by email, phone and in person.Must be personable, positive, and a professional representative of the Company.Perform other duties as assigned by supervisor.Qualifications:Minimum BS or BA, in computer science or related field; preferred2 - 5 years of experience querying relational databases using SQLStrong PC skills required, including proficiency with Microsoft Windows, Excel, and WordExcellent analytic, interpersonal, and communication skills, especially written communication skillsT-SQL stored procedure development, preferred.Microsoft SQL Server Reporting Services design and development, or similar report design and development experience (e.g. Microsoft Access or Crystal Reports)Querying and/or developing Microsoft Analysis Services (or similar) OLAP databasesExcellent verbal and written communication skills.Excellent interpersonal and customer service skills.Ability to prioritize and handle multiple projects.Strong attention to detail and organizational skills.Proficient in Microsoft Office Suite and Outlook.Compensation:Hourly W2 pay rate $30.00 - $33.00We have access to additional contract, contract-to-hire, and direct hire positions with various rate ranges.\\xa0If you have the described qualifications and are interested in this exciting opportunity, apply today!Ranked a Top Staffing Firm in the U.S. by Staffing Industry Analysts for six consecutive years, Genesis10 puts thousands of consultants and employees to work across the United States every year in contract, contract-for-hire, and permanent placement roles. With more than 300 active clients, Genesis10 provides access to many of the Fortune 100 firms and a variety of mid-market organizations across the full spectrum of industry verticals.For contract roles, Genesis10 offers the benefits listed below. If this is a perm-placement opportunity, our recruiter can talk you through the unique benefits offered for that particular client.Benefits of Working with Genesis10:Access to hundreds of clients, most who have been working with Genesis10 for 5-20+ years.The opportunity to have a career-home in Genesis10; many of our consultants have been working exclusively with Genesis10 for years.Access to an experienced, caring recruiting team (more than 7 years of experience, on average.)Behavioral Health PlatformMedical, Dental, VisionHealth Savings AccountVoluntary Hospital Indemnity (Critical Illness & Accident)Voluntary Term Life Insurance401KSick Pay (for applicable states/municipalities)Commuter Benefits (Dallas, NYC, SF)Remote opportunities availableFor multiple years running, Genesis10 has been recognized as a Top Staffing Firm in the U.S., as a Best Company for Work-Life Balance, as a Best Company for Career Growth, for Diversity, and for Leadership, amongst others. To learn more and to view all our available career opportunities, please visit us at our website.Genesis10 is an Equal Opportunity Employer. Candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'We have an excellent contract opportunity for a Junior Data Analyst in New York City! If you want to have a big client\\'s name on your resume, this is your opportunity! The AMI Meter Installation Issues Group (MIIG) of our Client is looking for a temporary resource to support the team in reviewing a large data set of meter installation issues and being able to channel the work in and out of our client\\'s database. Excel is the primary application used by various work groups for tracking the progress of the installation.  Basic training in the use of Excel will not be provided as the applicant is expected to be proficient. Other responsibilities are:The Consultant must be proficient in analyzing and reviewing large data sets in Excel and demonstrate proficiency in using formulas (such as and not limited to Vlookup, Pivot Tables, Graphs, and Charts) to efficiently manipulate the data so that it can be imported into the database Will review and process large sets of data in the various Client databases and must be proficient in using Excel, PowerPoint, Access database, SQL, and TableauWill work independently as well as on a team - Must be self-motivatedThe Consultant will learn the functions of AMI and the Legacy applications used by the team with proper training and be able to communicate with end-user customers to resolve issues, and gaps, and collect dataWill be interacting with other vendors on the MIIG team and will be managing the database that is used to issue escalation work for the team to review and be able to receive the data in return and update the databaseThe Consultant must be flexible and able to work onsite for the first few weeks for onboarding and training. After the onboarding, we can consider transiting to a hybrid work schedule (3 days in the office and 2 days remote)The Consultant will be responsible for managing the database for tracking legacy meters to upgrade and the tracking of work for the different work streamsThe Consultant will be also responsible for managing the work of other MIIG analysts by issuing work from the database and importing reviews completed by the MIIG analyst into the databaseDevelop and deliver PowerPoint presentations to communicate status, work scope, and workflow This is an hourly position with opportunity for overtime.All Candidates Must be Authorized to Legally Work in the US Without Sponsorship**Mandatory Qualifications: (Please read carefully. They MUST be shown on your resume)Must be proficient in Access database, PowerPoint, SQL, and Tableau, Must be proficient in Excel working with Vlookup, Pivot Tables, Graphs, and ChartsMust have strong communication skills with all stakeholders (verbal and written)Must have the ability to draft documentsMust have the ability to clearly communicate technical issues and potential resolution pathsBachelor\\'s degree and 2 years of relevant work experience OR, Associates Degree and 5 years of relevant work experienceProduce high-quality work and check work frequentlyAgile, self-motivatedMust be able to work in a team and as an individual contributorExperience developing and delivering PowerPoint presentations to communicate status, work scope, and workflowPreferably with Legacy Experience $500 Referral Fee Program Earn extra cash while helping your friends!VTS3 will pay you up to $500.00 for each person you refer to us and we place into a contract or full-time position. If you know someone who\\'s a good candidate for any of our openings, use the \"Refer a friend\" button on this page and earn extra cash.The rules are simple:The referral must be made by using the \"Refer a friend\" button on this pageThe person you refer must be placed within 90 days of being referredThe person you refer must complete 480 billable hoursCannot be someone we already have on our team or are currently working withPowered by JazzHRHi7bfAh9Zp\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'We have an excellent contract opportunity for a Junior Data Analyst in New York City! If you want to have a big client\\'s name on your resume, this is your opportunity! The AMI Meter Installation Issues Group (MIIG) of our Client is looking for a temporary resource to support the team in reviewing a large data set of meter installation issues and being able to channel the work in and out of our client\\'s database. Excel is the primary application used by various work groups for tracking the progress of the installation.  Basic training in the use of Excel will not be provided as the applicant is expected to be proficient. Other responsibilities are:The Consultant must be proficient in analyzing and reviewing large data sets in Excel and demonstrate proficiency in using formulas (such as and not limited to Vlookup, Pivot Tables, Graphs, and Charts) to efficiently manipulate the data so that it can be imported into the database Will review and process large sets of data in the various Client databases and must be proficient in using Excel, PowerPoint, Access database, SQL, and TableauWill work independently as well as on a team - Must be self-motivatedThe Consultant will learn the functions of AMI and the Legacy applications used by the team with proper training and be able to communicate with end-user customers to resolve issues, and gaps, and collect dataWill be interacting with other vendors on the MIIG team and will be managing the database that is used to issue escalation work for the team to review and be able to receive the data in return and update the databaseThe Consultant must be flexible and able to work onsite for the first few weeks for onboarding and training. After the onboarding, we can consider transiting to a hybrid work schedule (3 days in the office and 2 days remote)The Consultant will be responsible for managing the database for tracking legacy meters to upgrade and the tracking of work for the different work streamsThe Consultant will be also responsible for managing the work of other MIIG analysts by issuing work from the database and importing reviews completed by the MIIG analyst into the databaseDevelop and deliver PowerPoint presentations to communicate status, work scope, and workflow This is an hourly position with opportunity for overtime.All Candidates Must be Authorized to Legally Work in the US Without Sponsorship**Mandatory Qualifications: (Please read carefully. They MUST be shown on your resume)Must be proficient in Access database, PowerPoint, SQL, and Tableau, Must be proficient in Excel working with Vlookup, Pivot Tables, Graphs, and ChartsMust have strong communication skills with all stakeholders (verbal and written)Must have the ability to draft documentsMust have the ability to clearly communicate technical issues and potential resolution pathsBachelor\\'s degree and 2 years of relevant work experience OR, Associates Degree and 5 years of relevant work experienceProduce high-quality work and check work frequentlyAgile, self-motivatedMust be able to work in a team and as an individual contributorExperience developing and delivering PowerPoint presentations to communicate status, work scope, and workflowPreferably with Legacy Experience $500 Referral Fee Program Earn extra cash while helping your friends!VTS3 will pay you up to $500.00 for each person you refer to us and we place into a contract or full-time position. If you know someone who\\'s a good candidate for any of our openings, use the \"Refer a friend\" button on this page and earn extra cash.The rules are simple:The referral must be made by using the \"Refer a friend\" button on this pageThe person you refer must be placed within 90 days of being referredThe person you refer must complete 480 billable hoursCannot be someone we already have on our team or are currently working withPowered by JazzHRHi7bfAh9Zp\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Hubble Contacts (Hubble) pioneered private label daily contact lenses sold directly to consumers through a subscription-based e-commerce business model. The company was founded in 2016 with the mission of delivering high quality lenses at an affordable price point in a manner that had never been offered before.Historically, four manufacturers controlled about 95% of the contact lens category in the United States and Canada and set prices much higher than a fair and open market would tolerate. Enter Hubble: a company offering a more affordable and consumer friendly option than any product currently on the market. Hubble recently launched ContactsCart, offering its customers alternative manufacturer brands including Bausch & Lomb, CooperVision, and Johnson & Johnson at a meaningful discount. The company is also exploring strategic opportunities for new product launches including toric lenses, eyeglasses, as well as entering new distribution and retail channels.Due to the rising prevalence of eyesight disorders coupled with an increase in consumer spending, Hubble is uniquely positioned to capitalize nationally and internationally on the growth of a global contact lens market predicted to reach $17.7 billion by 2025.Position Summary:The Data Analyst is responsible for analyzing and evaluating the quality and consistency of the organization’s data. You will serve as a primary subject matter expert for technical project management and data integrations across various platforms to ensure operational excellence. This role will work cross-functionally with department stakeholders to find opportunities to streamline and improve processes, ideally automating efforts. This position requires in-depth experience, knowledge, and skills in data analytics, visualization, and technical architecture.RequirementsProactively design and build dashboards in Tableau while presenting findings and interesting trends to stakeholders.Automate reporting procedures as necessary by establishing secure and robust data links between various sources and documents.Maintain all data logs regarding revisions made to the data and version changes.Collaborate with internal partners to understand business strategy, questions, and goals while supporting all data needs.Acquire and compile structured and unstructured data and verify their quality and accuracy while providing daily spot checks to ensure the validity of the organization's data.Bring structure to business requests and ad-hoc reports for various projects, translate requirements into an analytical approach, and lead projects through to completion.Assist in developing technical solutions to survey-related projects in partnership with internal teams and internal/external engineers.Complete assessments of business processes and document each of the following areas: problem statements, process flows, gap analysis, and solution recommendations.Deconstruct technical concepts and metrics for business partners.Develop repeatable and scalable plans and processes to speed time to market and improve operational efficiency.Exercise independent judgment and discretion in matters of significance.Other Qualifications & Characteristics: Obsession with knowing the data and with understanding the business context. Willingness to do the groundwork of learning and exploring the weaknesses and strengths of various data tables and their relations to each other. Capable of writing complex SQL queries in an elegant and structured way to retrieve information that can be translated into easily interpretable and actionable reports; Capable of understanding existing query structures and can critique constructively.Advanced Excel user with experience in automating reports using Power Query; some knowledge of the DAX languageExperienced Google Sheet userExperience with building dashboards in TableauExperience with Google Analytics and various social media platformsProven ability to work both independently and collaboratively with different levels of employeesSelf-starter and self-learner. Bachelor’s Degree; STEM majors are preferred.BenefitsAt Hubble, we invest in our employees' well-being and empower them with benefits to ensure they can continue to be both happy and productive!Receive Insurance Covering, Medical, Dental & Vision. In addition, options for Flexible Spending, Health Saving Accounts, and Membership Options To One Medical, Teladoc, HealthAdvocate, and Talkspaces are also available!401k OptionCommuter BenefitsFitness Membership To ClassPassVoluntary Long-Term & Short-Term Disability InsuranceVoluntary Supplemental Life InsuranceHybrid Working EnvironmentUnlimited PTO - Geared Towards Work/Life BalanceAnnual Professional Development StipendQuarterly Team Meet Ups & Team Philantrhopic Events #HubbleCaresSalary: $70k to $95k - with bonus targets\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Mb Staffing Services is seeking a qualified Data Analyst to assist our DC Based client with data surrounding the Opioid crisis in our region. This is an interesting role and would require the experienced Data Analyst to Respond to inbound calls in a timely and professional manner and follow identified procedures to respond, document, log, and notify the appropriate persons Ensure that reporting remains current Timely and accurate submission of all reports with an error rate no greater than 5%. Perform descriptive analyses of public health data using statistical software (SAS preferred) and produce daily reports and other analytical reports as needed Ensuring data quality and integrity, perform tasks such as electronic file transfers; listing and tabulation of data for preparation of statistical reports; and electronic file linkages Develop analytic datasets (to include, for example, data extraction, data cleaning, matching/merging, and variable coding) and document processes in codebooks, protocols, and associated guidance documents Design databases and tracking systems and monitor data collection activities for multiple surveillance programs Utilize business analytics tools, such as Tableau, to perform data analysis. Support design and recommend content, format, dissemination methods, etc. Maintain and automate reporting applications and visualizations Monitor quality assurance and quality improvement of applicable surveillance and other data systems and processes Develop strategies for improving data processing efficiency, as well as data completeness and quality. Work hours are Monday through Friday 8:30 a.m. to 5:00 p.m. This position is Hybrid Company Description In an era of constant workforce changes, Mb Staffing Services offers something you can count on: The perfect fit! We continue this with a seamless transition. We listen intently. We think strategically. And we act methodically. We respond with speed and an eye to the future! We are a precision placement, results-oriented firm serving a full spectrum of industries and staffing needs.In an era of constant workforce changes, Mb Staffing Services offers something you can count on: The perfect fit! We continue this with a seamless transition. We listen intently. We think strategically. And we act methodically. We respond with speed and an eye to the future! We are a precision placement, results-oriented firm serving a full spectrum of industries and staffing needs.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'JDC -61 Data Analyst, Tallahassee, FLAbout Syra HealthSyra Health Corp. is a pioneering healthcare technology consulting company that develops outcomes-driven solutions having a direct and quantitative benefits to the healthcare industry. We work with payers, health services companies, and life sciences companies to build solutions that create measurable business value and have a positive impact on the lives of their customers. And we are dedicated to cultivating an inclusive culture of respect, honesty, and integrity by embracing the unknown, recognize the value of diversity, and harness the power of enthusiasm.Job SummarySyra Health, a healthcare organization, is seeking a highly skilled Data Analyst to join our team. The ideal candidate will be responsible for analysing and interpreting complex healthcare data sets, including experience in Medicaid data management. The candidate should have advanced knowledge of SQL, and experience working with large data sets. The candidate will be expected to provide actionable insights to inform decision-making and improve patient outcomes.ResponsibilitiesAnalyse and interpret large and complex healthcare data sets, including experience in Medicaid data management.Develop and maintain databases, data systems, and data analytics tools to support data-driven decision-making.Extract qualitative and quantitative relationships (i.e., patterns, trends) from large amounts of publicly available data using SAS, SQL, R, Python, or other statistical toolsIdentify and interpret trends or patterns in data sets.Prepare reports and visualizations that effectively communicate insights and recommendations to management and stakeholders.Collaborate with other teams, including clinical and operational teams, to develop data-driven solutions that improve patient outcomes and reduce costs.Design and implement experiments to test hypotheses and validate assumptions.Ensure data accuracy and completeness by conducting regular data audits.Stay up to date with industry trends, best practices, and regulations related to healthcare data management.RequirementsMinimum of 3 years of experience in data analysis, preferably in healthcare.Experience creating datasets for CMS programs such as MSSP, DCE, or ACO Advanced knowledge of SQL and experience with relational databases.Experience working with Medicaid data and other healthcare data sets.Strong analytical and problem-solving skills.Ability to work independently and in a team environment.Excellent communication and presentation skills.Strong attention to detail and accuracy.Strong hands-on with data visualization tools, such as Tableau or Power BI, is a plus.Careers At Syra HealthOur objective is to make the world a better place by thinking big and seizing opportunities for ourselves, our clients, and our consumers. We are driven by a passion for health and encourage you to be unique, inquisitive, and bold. And by working together, we can increase your contribution on both your career and the world of healthcare.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Summary / Position Purpose: The primary responsibility of this role is to create consolidated reports, dashboards, and data analysis for the internal customers of ACG. This role will be responsible for the day-to-day support, maintenance, and improvement of our CRM and supporting platforms, as well as excel-heavy data-related projects. Their work will involve collecting and cleaning data from multiple sources, running ad hoc reports, building automated dashboards, investigating, and fixing any potential errors/bugs, and working with the Database Administrator to ensure that the information in our database is error-free for accurate reporting. Essential Duties, Functions and/or Responsibilities: Create, validate, and send daily weekly, and monthly management reports.Assistance with requests for non-standard reports and analysisSupport management reporting by maintaining hierarchical information.Perform business-to-system analysis and troubleshooting analysis of complex management reports and business problems.In the report, development lifecycle support impacts analysis and project requirements definitionTransform client needs into functional requirements.With guidance, collect, analyze, and document business requirements for project proposals including but not limited to process and data flow, user interface, and reporting requirements.Together with managers and/or senior analysts, participate in cross-functional meetings to understand customer needs and identify problems and solutions.Appropriate solutions, develop specifications, analyze, and document business processes, validate testing processes, and train the user community.Gather, clean, and transform large data sets to be used in reports and visualization.Design, develop and implement innovative/effective/strategic fully automated business solutions.Works closely with IT and business to incorporate daily automated data refreshing.Develops and provides a standard set of user-friendly reporting tools to internal business customers.Provides maintenance on deployed tools and dashboards.Assist sales & marketing teams with CRM reports and data management, building and maintaining outreach lists for up to several dozen sales and inside sales colleagues.Other duties as assigned.  Education and/or Work Experience Requirements: EDUCATION: Bachelors/4 Yr. DegreeYEARS OF RELEVANT WORK EXPERIENCE: 1+ yearsSalesforce.com (or equivalent CRM) power-user/admin experienceExpert knowledge of Microsoft Office (especially Excel)Demonstrable excel & CRM familiarity with pivot tables and other similar visual reporting tools to display/reconcile large amounts of data.Strong ability to meet deadlines and manage and prioritize simultaneous requests.Creative and analytical thinker with strong problem-solving skillsMust demonstrate ability to communicate effectively verbally and in writing with all levels of the organization.Ability to critically evaluate and prioritize information gathered from multiple sources and reconcile conflicts.Ability to assess the impact of new requirements on Salesforce and other integrated systems.Ability to safely and successfully perform the essential job functions consistent with ADA and all other applicable federal, state, and local standards, including meeting qualitative and/or quantitative productivity standards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'NovoEd builds the next generation of learning technology to offer engaging learning experiences at scale through social collaborative and experiential learning. Our platform is used by enterprise companies including those in the Fortune 500, top universities, training firms, and foundations, around the world to provide experiential and collaborative learning to adult learners. These online learning experiences replicate in-person learning experiences such as workshops that have traditionally been hard to bring online. Social collaboration and peer learning are not only built into our product, but also the DNA of our company. We have a collaborative team with a passion for learning and an amazing culture.The Data Analyst will report to the VP of Product and be a key partner of the R&D, Revenue Operations and Customer Experience teams. The role is expected to provide deep analysis of data and then determine the best way visualize it for customers, business partners and management. This will require solving business problems by customizing the Salesforce and Churn Zero platforms as well as setting up data pipelines using open-source relational database management systems with wysiwyg type tools. The Data Analyst will create metrics and charts using embedded analytics tools, resolve data issues with the quality assurance team, and liaise with the design team on aesthetics and the user experience aspects of dashboards. The Data Analyst will be the owner of the embedded analytics tool, and be responsible for managing the data vendors, including the reporting and resolution of issues.Responsibilities:Manage dashboards, reports and insights for customers as well as the product, sales, marketing, and customer experience teams. Gather requirements, configure changes, design best practice solutions, data governance and reporting for the Salesforce and Churn Zero platforms. Deliver data sources relevant to customer engagement and the use of the NovoEd product into the SaaS product data store; Use APIs or MySQL to bring data in from relevant sources. Design data sets that are performant, can sync data with a lag of at most 30 minutes using a tool like AWS ETL/AWS GLUE. Create metrics and charts using a tool like Tableau, Google and Excel Charts. Generate, evaluate, and improve in-product, problem focused dashboards. Work with Product, Design, Engineering, and Quality Assurance teams to ship dashboards to production systems. Partner with the Product, Revenue Operations, and Customer Success and Support teams to answer specific data questions that are not yet built into the SaaS product. Qualifications:5+ years of experience with MySQL writing complex queries. 3+ years of experience creating and modeling performant data sets as well as deep data analysis. 5+ years of experience building charts and dashboards in tools like Salesforce, Churn Zero and Tableau. Ability to work independently, prioritize workload, and manage cross-functional projects. Advanced technical, analysis and modeling skills in data analytics tools, python and Excel (pivot, VLOOKUP, etc.). Experience using data analytics to support assumptions and develop business cases. Strong communication skills (verbal and written) and interpersonal skills with the ability to translate complex analysis into actionable recommendations. Compelling storytelling and presentation skills. Client centricity, empathy and deep curiosity to find deeper answers to data questions. What will set you apart:Experience working with a wide variety of business data sources. Experience with predictive analytics and data visualizations. Salesforce Administrator experienceNovoEd provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Salary range: The base pay for this role is up to $110k base + bonus. The actual base pay is dependent upon many factors, such as training, skills, work experience, business needs, and location. The base pay range is subject to change and may be modified in the future.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data Analyst Job Description : * Supports and contributes to business analytics projects and processes to provide data-driven insights related to business performance used to advise and develop strategies for operational improvements and future business initiatives. * Uses statistical methods, modeling, analytical methodologies, and data analysis to develop and deploy tools including dashboards, infographics, reports, and models to inform and support decision-making. * Processes, and analyzes internal and external data using KPIs, business results, industry sources, competitor intelligence, and customer information. * Develops a good understanding of the business's model, objectives, issues, and challenges by interacting and collaborating with users and stakeholders. * Typically reports to a supervisor or manager and make sure work is closely managed. * Works on projects/matters of limited complexity in a support role. Qualifications: * Desired a Master's or Bachelor's degree in computer science, information technology, statistics or a quantitative field. * Desired 0-2 years of related experience. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Company Description ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTitle: Data AnalystJob Type: Onsite, Full-time, Hybrid ModelLocation: Irving, TXJob DescriptionFamiliar with Banking Products.Good communications to interact with business clients.Familiar with finance data models data acquisitions.Good in excel Working on collecting and understanding the requirements.Should be well versed on Data Investigation, Data Analysis.Ability to explain functional technical details.Should have good SQL writing capabilities Validate UAT results and identify issue.Should be Independent and resourceful dealing with risks issues and resolving them in a timely manner.About CapgeminiCapgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.Get The Future You Want |\\u202fwww.capgemini.comDisclaimerCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-lawApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Skill/RequirementJob DescriptionNew graduate or individual with 1-2 years of experience with Geographic Information Systems (GIS) tools such as QGIS; basic familiarity with land cover classification methodologies. Knowledge of one or more scripting languages such as Python to automate GIS processing, data analysis and image processing is a plus.ResponsibilitiesJOB Description:Execute manual analytics steps and assist Data Scientists with data and result analysis & quality control for the LandVisor Brazil product. Assess patterns in data acquisition and model output for larger scale workflow improvementsProject scope:-Data analysis support and quality control for consumer-facing product and research projects, particularly QA and editing of data inputs and quality assurance of model outputs. Automation of data acquisition and result delivery.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Minimum Position Qualifications: * 6 - 8 years' experience with IT initiatives * 4 - 5 years as a data analyst for data related projects; data warehouses, data marts, BI reporting, analytics; experience with migrations from on-prem to cloud a big plus * Thorough knowledge and understanding of systems, procedures, and technology/project life cycles. * Excellent communication and presentation skills to effectively communicate information to customers and to all levels within the organization * A working knowledge of IT Service Management practices. * Hands-on technical knowledge including SQL, or ETL platforms * Hands-on exposure to modern cloud solutions (Azure, Snowflake, ...) Company Description Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That's why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure - even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants' experience so far!Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That’s why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure – even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants’ experience so far! https://fusionalliance.com/careers/spotlight/\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are a Direct Mail and Email Marketing company. We acquire database lists and put them in a format for printing and mailing or emailing. We use Altryx and Excel. Company Description TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The data analyst/report technical writer performs highly advanced work related to special education and special populations data collection and reporting activities and projects.Essential FunctionsDevelops and writes data documentation, analytical requirements, business rules, workflows, and data calendar/timelines for existing and new data projects using simple, clear, unambiguous, and concise languageOversees the planning, design, scope, structure, creation, analysis, and maintenance of SAS programs, datasets, data reporting systems, and reportsDevelops and manages extensive quality assurance and quality control checks of SAS programs and workflows to improve existing programs and processes including comprehensive documentationPlans, studies, researches, and evaluates current information and data systems and recommends changes as neededMinimum RequirementsII. CANDIDATE SKILLS AND QUALIFICATIONSCandidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity. Years Required/Preferred Experience 4 Required Experience with SAS programming or similar statistical programming language 3 Required Education: Graduation from an accredited four-year college or university 3 Required Experience working with administrative data 3 Required Experience developing technical documentation 3 Required Experience with MS Office suite, especially Word and Excel 2 Preferred Experience working with education data\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Bachelor's degree in computer or information scienceStrong background in large-scale, shared data environments. Preferable candidate would have experience in Water/Wastewater space include Water Assets, GIS, Workorder and Asset ManagementExcellent technical abilities, strong communication skills, and strong project management and organizational skillsRelevant technical skills or knowledge may include data modeling, SQL programming (SQL Server or Oracle), and Microsoft OfficeEffective analytical abilities in order to examine existing processes/workflows/dataflows and make recommendations for improvements6 to 8 months possibility of extension\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title:ID - DOPL - Data AnalystLocation: Boise, ID Fully ONSITE Position***DescriptionDOPL needs a Data Analyst to assist with the validation of data in the migration of legacy transaction and documentation data from eleven (11) existing systems into one. In addition, the new consolidated data will form a new historical data set for DOPL in the event not all data is migrated into the new license system.DOPL is implementing an enterprise Licensing Information System (LIS) and is required to migrate both application transaction data (OLTP) and business document content from 11 legacy systems. DOPL is seeking a qualified Data Analyst to work within a cross-functional team that includes IT Staff, a Data Architect, Project Coordinators, and Business Users. This individual will play a key role in the identification, transformation, loading and testing of legacy data during the LIS system implementation phase. The ideal candidate will have experience in data validation, data analysis, business systems analysis, requirement documentation, testing, and effectively working with business stakeholders.ResponsibilitiesValidation of all data being moved from original systems into new systemWorking with business stakeholders to observe processing and capture data requirements.Analyzing legacy databases and identifying application data for migration.Documenting key data entities and attributes in legacy database systems.Working with data migration team to test ETL software and loads.Working with system integrator to ensure data loads are complete and accurate.Thanks,N.TEJASWINI NAIDUTechnical recruiterDirect:404-777-9838 | Fax: 866-608-6686Email: tejaswini.n@stiorg.com | Web: www.stiorg.com100 Overlook Center, Suite 200Princeton, NJ 08540.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'At Better Life Partners, We provide what it takes to heal from addiction. Wherever. Whenever.We focus on bringing high quality, accessible and effective tech-enabled care to those with Addiction Disorders, especially those in communities for whom traditional care has been found lacking. We provide evidence-based, scalable, holistic healthcare while working alongside community-based organizations to ensure that our care is accessible, non-punitive and responsive to our communities. We build trusted relationships and healing spaces to nourish Belonging, Love, and Purpose.If you’re passionate about healthcare innovation, low-barrier care, and harm reduction, Better Life Partners is the team for you! Our Headquarters office is seeking a Data Analyst.The ideal candidate will have a deep knowledge of SQL and Python and will be self-motivated with a strong bias for action.Responsibilities include, but are not limited to:Expand and maintain optimal data pipeline architecture.Provide information to teammates that helps increase and optimize member experiences, revenue generation, and other business outcomes.(ad hoc queries, explanations of reports, technical guidance, etc.);Build Tableau dashboards for business usersImplement, integrate and document a variety of software platforms through the REST API frameworkMaintain and upgrade the division’s data warehouse (ETLs, design, dependencies, entity and referential integrity)Qualifications:Bachelor’s Degree in computer science, statistics, mathematics, or related field or equivalent experience. Willingness and eagerness to learn and be flexible.Experience using statistical computer languages (R, Python, SQL) to manipulate and draw insights from data.Extra Points:Knowledge of statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.).Knowledge of some statistical and machine learning techniques (for example, GLM/Regression, Random Forest, clustering, neural networks, k-Nearest Neighbors, Naive Bayes, SVM, etc.) and willingness to learn additional techniques.Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).Experience with TableauProven experience with Time Series Clustering.This is a full-time, exempt position. The starting salary range for this position is $70-90k annually.This position is fully remote (work from home).Work from home requirements:Must have internet service with minimum upload/download ability.Company will provide equipment (laptop, monitor, keyboard, mouse and headset) plus a remote work stipend. Must have a quiet space to speak to members with minimal background noise.Must understand the importance of protected health information and ensure any data/information is not visible to others.Better Life Partners facilitates the treatment of behavioral health conditions including addiction medicine. We offer a full slate of benefits including competitive compensation, medical, dental and vision coverages, four weeks of paid vacation, sick time, wellness days, thirteen paid holidays, a 401(k) plan with company match, parental leave program, learning & development stipend, employee referral bonus, company-issued technology, remote work stipend, paid volunteer time off, stock options for eligible employees, and more!At Better Life Partners, we believe our work directly correlates to the diverse perspectives of our employees. Better Life Partners celebrates inclusion and is a committed Equal Opportunity Employer to all qualified applicants, ensuring individuals will not be discriminated against on the basis of race, color, religion, sex, gender identity, sexual orientation, age, national origin, physical or mental disability, marital or parental status, military or veteran status, or any other protected classification. Persons of color, women, LGBTQ candidates, veterans and individuals with disabilities are encouraged to apply. Better Life Partners is a recovery-friendly workplace.COVID-19 Vaccine RequirementBetter Life Partners has instituted a COVID-19 vaccine mandate for all employees, including remote staff, to remain in full compliance with regulatory bodies. Individuals selected for employment must be able to show proof of vaccination status prior to start date.If you are unable to be vaccinated for medical reasons or religious beliefs, Better Life Partners will consider requests for reasonable accommodation consistent with its policy and if able to do so without undue hardship to the company pursuant to applicable law. Such accommodations must be approved prior to start date. Powered by JazzHRJlsmK7QPZV\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Greetings, Kindly have a look at the below job description and try to share with me your updated resumes at larry@intellectt.comRole: Data Analyst II Location: Sylmar, CA Job DescriptionResponsible for pulling data to support trending of product complaints and medical device reports utilizing data that resides in the complaint handling database for all product lines. This will include detailed data reports (e.g. graphs, charts, tables) prepared for routine trending, senior management reviews, ad-hoc requests, and cross-functional requests as needed (e.g. Regulatory, Quality Engineering, R&D). Will establish and maintain complex reporting formulas and templates using reporting tools such as Excel and other databases (e.g. Business Objects).2 - 4 Years' of experience is required in related field.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Location: Sheetz Corporate - PITTSBURGH, PAPrimary Purpose Of This PositionAssist in creating and driving business value and growth though the effective use of Sheetz’ most valuable resource: Data. Responsible for leading Sheetz’ data and information strategy through data analysis and visualization in order to facilitate and enhance organizational decision-making and data utilization across the company. Provides advanced data analytics support to the Senior Data Analyst while providing mentorship to the Associate Data Analyst around data analytics and information strategy.ESSENTIAL FUNCTIONS: (other duties may be assigned)Cultivate data-driven insights that help support exploitation of strategic and tactical business opportunities, and be a champion for a data-driven, decision-making culture.Support data strategy leadership in the development, assessment, refinement and implementation of corporate strategy through effective use of data analytics.Provide enterprise-wide data science and business intelligence services as well as recommendations to decentralized, embedded data scientists and analysts throughout the business.Assist Senior Data Analysts and management in providing training for departmental and distributed data analysts.Oversee and present robust ad-hoc reports, data models, and deep dive analysis to provide clear observations so that managers can make more informed decisions.Develop and mentor future data-driven, analytical leaders and strategists within the team.Assist with a wide array of analytical tasks and projects requested by other departments.Supports the Senior Data Analyst position with ad-hoc advanced analytics.Assist in the creation of policies and procedures for the access, analysis and visualization of data and associated business insights; partnering with IT and RISC.REQUIREMENTS: (Equivalent combinations of education, licenses, certifications and/or experience may be considered)EducationBachelor’s degree in Economics, Statistics, Mathematics, Actuarial /Data / Computer Science or related field requiredExperienceMinimum 3 years demonstrated experience in data modeling, optimization, and application to business strategies required.Minimum 3 years demonstrated experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required.Thorough understanding of the latest data mining, machine learning and/or artificial intelligence techniques required.In-depth experience with or coursework in designing and implementing information solutions required.Licenses/CertificationsN/ATools & EquipmentN/AAbout SheetzSheetz, Inc. is a fast-growing, family-owned, food/convenience company that has been in business since 1952. Sheetz has over 600 locations in Pennsylvania, Ohio, Virginia, West Virginia, Maryland and North Carolina.Our mission at Sheetz has been to meet the needs of customers on the go. Of course, things have changed over those nearly 70 years. Life is faster and busier, and customers expect us to be there when they need us most. One thing that hasn't changed is our commitment to our customers, our employees and the communities in which we operate. Sheetz donates millions of dollars every year to the charities it holds dear.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionHertz and the Advanced Analytics and Tool Development team is seeking talented individuals with passion for real-world problem solving. The analyst will partner with various functions within the company (Revenue Management, Fleet, Operations) and develop advanced tools and resources to support overall location-level planning and operational decisions. The analyst will be working with large sets of structured and unstructured data to perform analysis, develop tools, and provide actionable insights.What You’ll Be Doing Develop tools for the field for car assignment to optimize upgrade/upsell/booking success.  Develop tools to provide visibility to many of the operational processes.  Conduct analyses to inform stakeholders and help make the most optimal decisions regarding various strategic initiatives.  Code and automate performance reports.  Configure shared PC resources to automate scripts and collect data. What We Expect A Bachelor’s degree; preferably in Data Science, Computer Science, Statistics, Engineering, or another quantitative field.  A demonstrated ability to query and extract findings from large data sets in relational databases such as SQL Server, Teradata, Oracle, etc.  A wide range of data-related technical skills regarding databases, scripts, and web APIs.  Experience with programming/scripting languages like R or Python  Experience with advanced data visualization platforms such as Tableau.  Quick on feet; willingness to discover alternative solutions to technical problems.  A desire to solve complex problems with creative and concise solutions.  Excellent written and oral presentation skills – ability to communicate findings with non-technical stakeholders in concise and simple terms.  An individual who thrives in a collaborative environment. Nice To Haves More than 1 year of work experience in a data driven industry including Rent-A-Car, travel, or service industry  A Master’s degree in a quantitative field  Experience with statistical modeling  Experience with web development languages such as Ruby, PHP, or JavaScript. r work every day represent a significant part of our culture – and our success and reputation as a company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionRole: Data AnalystSalary: $110,000 - $140,000 (plus benefits)Location: Austin, Texas (Hybrid Model)Sponsorship: Not availableI am currently on the lookout for a Data Analysis to join one of the largest U.S. banks based in Austin Texas. Within this position you will be working functionally across the business with Engineering, Finance, Customer success and product to collect, analyze and interpret data related to the bank's commercial lending and business operations.Working on a Hybrid model, if you have a strong curiosity of data and enjoy problem-solving a wide range of topics, who thrives on a fast-paced environment then this would be the perfect role for you!ResponsibilitiesCollect and analyze data related to commercial lending portfolios, including loan performance, risk assessments, and compliance with regulations.Develop and maintain reporting and analytics tools to provide insights into commercial lending and business operations.Work with stakeholders to identify key performance indicators and develop dashboards and reports to monitor them.Generate insights to uncover usage trends to inform product development, drive user adoption and savings (time and/or cost)About YouExperience with data visualization tools such as Tableau or PowerBI.Commercial knowledge working with SQL and programming languages such as Python or R.Strong analytical and problem-solving skills with attention to detail.Knowledge of commercial lending and banking operations is a plus.Our client is an equal opportunity employer committed to creating a diverse and inclusive workplace. They offer a competitive salary, comprehensive benefits package, and opportunities for career growth and development.If you are a data analyst who is passionate about using data to drive business decisions and interested in joining a dynamic team at one of the largest commercial banks in the US, please click to apply!For more information about ITECCO and the opportunities we have to offer follow us on Twitter @ITECCOrecITECCO Ltd is acting as an Employment Agency in relation to this vacancy.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Are you a passionate IT trailblazer - a growth focused, problem solver who takes full ownership of your work, wants to collaborate & co-create with fellow IT experts, innovate, learn new skills, create new solutions & drive your career to the pinnacle of your potential? If so, you will love working with our IT Team - we are constantly innovating to create breakthrough solutions for our client's growth through a vibrant, fun team culture. Read on below to learn more... Featured in CNBC, Digital Journal, Fox News & CIO Review GBSI has been successfully serving the world's top Fortune 500 organizations for the last 18+ years. GBSI IT teams and consultants have delivered more than 568 projects successfully within the automotive, manufacturing, retail & pharmaceutical domains across the world. Headquartered in Moline, IL GBSI's clients and consultants are spread across the US, Canada, Europe & India. Join us to be a part of an ever growing, elite IT team & start building your dream career today! To be a successful Data Analyst you will embody GBSI's core employee characteristics of being passionate about IT, taking full ownership of your work & having a growth mindset. Additionally, you will exhibit strategic vision, thoughtful engagement, strong analytical/process skills, a bias for action, and the ability to partner with senior operational leaders. Work you'll do/Responsibilities: * Develop data strategies * Analyze, interpret and visualize data to deliver insights and solutions * Building relationships with business areas to improve the flow of reporting/explanations and rationale * Working with technology teams, management and/or data scientists to set goals * Mining data from primary and secondary sources * Cleaning and dissecting data to get rid of irrelevant information * Analyzing and interpreting results using statistical tools and techniques * Pinpointing trends and patterns in data sets * Prior experience of working in healthcare domain What qualifications you need: Bachelor's / Master's in IT What will give you an edge: Impeccable written and verbal communication skills in English Passionate, Energetic, Enthusiastic.  Self-Driven, Motivated, Professional, Positive Minded Location Preference: Norfolk, VA Apply today to join us as part of an elite IT team & let GBSI help you build the career of your dreams! We are excited for your growth! Equal Employment Opportunity Statement GeniusBSI is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion, or sexual orientation. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Company Description We are Genius Business Solutions - our clients describe us as a team of passionate IT experts who take full ownership in delivering innovative technology solutions. At GBSI, we exist to simplify technology so that businesses can innovate faster & accelerate growth. With over 18 years of successful IT experience, GBSI is headquartered in Moline, Illinois & has clients and consultants working across the United States, Canada, India & Europe. We help some of the world's top organizations in manufacturing, automotive, software & IT and pharmaceutical domains in implementing software solutions, ensuring IT quality assurance, develop high quality custom applications & AMS support services. GBSI is a certified SAP partner & featured in multiple top publications including CNBC, Fox News, Digital Journal & MarketWatch. ERP Consultants, Developers, Software Engineers and QA experts, we invite you to join our teams & create the best version of you. As IT experts, our teams are committed to developing & delivering highest quality services in: - Technology Consulting - Digital Strategy & IT Modernization - Implementing Global IT Solutions - Next Gen Developments & AMS Support ServicesWe are Genius Business Solutions - our clients describe us as a team of passionate IT experts who take full ownership in delivering innovative technology solutions. At GBSI, we exist to simplify technology so that businesses can innovate faster & accelerate growth. With over 18 years of successful IT experience, GBSI is headquartered in Moline, Illinois & has clients and consultants working across the United States, Canada, India & Europe. We help some of the world's top organizations in manufacturing, automotive, software & IT and pharmaceutical domains in implementing software solutions, ensuring IT quality assurance, develop high quality custom applications & AMS support services. GBSI is a certified SAP partner & featured in multiple top publications including CNBC, Fox News, Digital Journal & MarketWatch. ERP Consultants, Developers, Software Engineers and QA experts, we invite you to join our teams & create the best version of you. As IT experts, our teams are committed to developing & delivering highest quality services in: - Technology Consulting - Digital Strategy & IT Modernization - Implementing Global IT Solutions - Next Gen Developments & AMS Support Services\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Are you a detail-oriented problem solver with a passion for data? We are looking for an Entry Level Data Analyst to join our team remotely in the USA. In this role, you will be responsible for providing insights and recommendations to help drive business decisions. You will be working with a diverse team of analysts, data scientists, and business stakeholders to deliver accurate and actionable data-driven insights.Responsibilities:Analyze large datasets to identify trends, patterns, and insightsBuild dashboards and reports to visualize and communicate data insights to business stakeholdersCollaborate with cross-functional teams to understand business needs and requirementsDevelop and maintain data models and databasesIdentify areas for process improvement and implement solutionsConduct ad-hoc analysis as neededQualifications:Bachelor's degree in Mathematics, Statistics, Economics, Computer Science or a related fieldStrong analytical and problem-solving skillsProficiency in SQL and ExcelExperience with at least one programming language such as Python or RFamiliarity with data visualization tools such as Tableau or Power BIExcellent communication and interpersonal skillsAbility to work independently and in a team environmentStrong attention to detail and accuracyBenefits:Competitive salary and benefits packageWork from anywhere in the USAOpportunities for growth and career developmentCollaborative and supportive team environmentFlexible work hoursIf you are passionate about data and want to work with a dynamic and growing team, we encourage you to apply for this exciting opportunity.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Must be local or from nearby states...Hybrid role 3days/weekDuration: 6+monthVisa: ANy except H1B and CPTMust have a valid LinkedIn profileThis role is in the IVR development team.The project will be improving the IVR experience for the Client's external customers. This role will pull data to help build use cases and 'how to handle' based on those use cases. The work will be done to determine WHY the customer is callingThis role will have to find the needed data in different systems. The manager is building this new role on his team and this role has to hunt/gather the data, then work with the developers to map to the existing systems.Required Skills Kafka, APIs, ETL Jobs, Understanding how to map the data to the billing systems, customer records etc Critical Thinking Skills as it relates to data and locations Basic data analyst skillsNice to Haves PEGA experience\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Primary Duties And ResponsibilitiesResponsible for the day-to-day operations and management of Zoho Recruit.Responsible for monitoring the health of the data, including data cleaning and data security.Responsible for analytics management and monitoring of KPI metrics, reporting, and data visualization. Work with internal team members and external partners to deliver ad hoc, weekly, monthly, and quarterly analyses of progress. Responsible for monitoring the health of user accounts. Engaging with users that have a problem managing their account for the portal.Responsible for preparing reports, collecting, and analyzing information; preparing presentations.Responsible for ensuring the operation of office equipment and troubleshooting malfunctions.Responsible for coordinating the systems set-up and access for new employees.Create and host an internal training series for team members to learn how to effectively use the system to streamline candidate management and client reporting.Develop a Hacks and Help Intranet site to share quick tips, FAQs, and commonly used features across the team.Data Cleaning – update “Dropdown Fields Options” and run periodic reports to find and remove all duplicates.RequirementsBachelor’s degree in computer science, computer engineering, or a related field At least two years of working experience in data management, data analysisExcellent communication skills to translate complex problems using non-technical termsIn-depth understanding of modern database and information technologiesExcellent analytical skillsExcellent time management skills and the ability to work towards meeting multiple deadlines simultaneouslyAbility to compile and organize findings and data retrieved before presenting it to managementThorough understanding of management and data administration duties such as collection, analysis, and distributionSalesforce experience Zoho Recruit knowledgeIntermediate spreadsheet knowledge, including pivot tables, conditional formatting, querying, and KPIs. Data modeling knowledge is preferredPreferred KnowledgeMicrosoft Excel with Power BI Google Sheets with Google Data StudioBenefitsBesides meeting your passion for making a difference in peoples lives and careers advancement, opportunities you may also be offered:Cell phone stipendHybrid Work OpportunitiesFlexible schedule\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Skill/RequirementJob DescriptionNew graduate or individual with 1-2 years of experience with Geographic Information Systems (GIS) tools such as QGIS; basic familiarity with land cover classification methodologies. Knowledge of one or more scripting languages such as Python to automate GIS processing, data analysis and image processing is a plus.ResponsibilitiesJOB Description:Execute manual analytics steps and assist Data Scientists with data and result analysis & quality control for the LandVisor Brazil product. Assess patterns in data acquisition and model output for larger scale workflow improvementsProject scope:-Data analysis support and quality control for consumer-facing product and research projects, particularly QA and editing of data inputs and quality assurance of model outputs. Automation of data acquisition and result delivery.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Juniper is changing what’s possible in networking. We’re going beyond building the networks customers expect — we’re building the networks customers deserve. And the world is taking note. But to continue to excel, we have work to do. Change in our industry is accelerating. To power connections and empower change, we need radical thinkers, eternal optimists, and energized personalities. We need people like you.Success requires big thinking and high-reaching goals. Our culture breeds innovation. Here, you will have the opportunity to take chances and let your ideas grow. You will be supported by thoughtful, inclusive, and accessible leaders. You will have every chance to be a part of the conversation and seize our momentum. Your career will be better for it.At Juniper, we strive to deliver network experiences that transform how people connect, work and live. We Power Connections, Empower Change, and we do that through our core values Being Bold, Building Trust and Delivering Excellence.Do you want to solve complex problems and build systems that will change the Internet? Do you want to be part of a company that is on the cutting edge of technology? Do you want to work with a world-class team of engineers?Title: Customer Support Data AnalystLocation: Westford, MA, USAJuniper Experience and Operations (JXO) organization is incubating a Technology group to transform CX(customer experience) and EX(employee experience). The charter of this group is to discover, evaluate and leverage technology to enhance and simplify the experience of stakeholders. Knowledge and data will be central to this journey of creating a proactive and predictive support experience. The use of automation, AI and other modern technology will enable reduction of time taken to resolve issues or perform tasks.This role involves analyzing existing customer support data to find trends important for driving business objectives, and navigating strategic projects, system/process efficiencies with data driven decisions across functional teams. The role requires influencing business transformation projects using analytical data that cuts across process, systems and tool re-engineering in customer support and services.Roles and Responsibilities:Interpret data, analyze results using statistical techniques and provide ongoing reportsDevelop and implement data collection systems, data analytics and other strategies that optimize statistical efficiency and qualityIdentify, analyze, and interpret trends or patterns in complex data setsWork with management to prioritize business and information needsAnalyze and prepare interpretations of data to use to develop conclusionsLocate and define new process improvement opportunitiesProvide estimates, impact assessments, and give your expert opinion on key strategic initiativesTake existing processes used to support current assets and expanding them to provide new services (tools expertise, training and consulting)Work with cross-functional teams to build data solutions that impact business decisionsDesign Tableau dashboards and advanced data visualizations to effectively communicate findings to both technical and non-technical audiencesConducts and facilitate (and educates and trains on) analysis, issues identification, organizational risk assessment, and decision-making processes.Provides consulting and analytic services to leadership.Provides technical support and mentoring and training to other analysts. Required Experience/Background:Bachelor’s degree in business administration, economics, computer science, management information systems, or related field or equivalent related experienceOverall 10+ years of experience, 5+ years data analyst or related experience, including proficiency with analytical software or equivalent related educationTechnical expertise regarding data models, database design development, data mining and segmentation techniquesStrong knowledge of and experience with reporting packages databases , programming.Knowledge of statistics and experience using statistical packages for analyzing datasets , including pivot tables, chart-making, and manipulation of large data setsProficiency in statistics, data analysis, and research methods Personal Skills:Ability to collaborate cross-functionally in a fast-paced environment and build sound working relationships within all levels of the organizationAbility to handle sensitive information with keen attention to detail and accuracy. Passion for data handling ethics.Ability to solve complex, technical problems with creative solutions while anticipating stakeholder needs and providing assistance to meet or exceed expectationsAble to demonstrate perseverance and resilience to overcome obstacles when presented with a complex problem. Assist in combining large data sets and data analysis to create optimization strategiesComfortable with ambiguity and uncertainty of change when assessing needs for stakeholdersHave effective time management skills which enable you to work successfully across functions in a dynamic and solution-oriented environment while meeting deadlinesSelf-motivated and innovative; confident when working independently, but an excellent team player with a growth-oriented personalityWill be required to routinely or customarily troubleshoot items related to applications that require independent judgement, decision-making, and unique approachesMinimum Salary: $95,700.00Maximum Salary:$146,740.00The pay range for this position is expected to be between $95,700.00 and $146,740.00/year; however, the base pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position also includes medical benefits, 401(k) eligibility, vacation, sick time, and parental leave. Additional details of participation in these benefit plans will be provided if an employee receives an offer of employment.If hired, employee will be in an “at-will position” and the Company reserves the right to modify base salary (as well as any other payment or compensation program) at any time, including for reasons related to individual performance, Company or individual department/team performance, and market factors.Juniper’s pay range data is provided in accordance with local state pay transparency regulations. Juniper may post different minimum wage ranges for permanent residency petitions pursuant to US Department of Labor requirements.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Citeline, is part of the Norstella group of Pharma information solutions, is one of the world's leading providers of data and intelligence on clinical trials, drug treatments, medical devices and what's new in the regulatory and commercial landscape. Relying on us to deliver vital advantage when making critical R&D and commercial decisions, our customers come from over 3000 of the world’s leading pharmaceutical, contract research organizations (CROs), medical technology, biotechnology and healthcare service providers, including the top 10 global pharma and CROs.From drug and device discovery and development to regulatory approval, and from product launch to lifecycle management, we provide the intelligence and insight to help our customers seize opportunities, mitigate risk and make business-critical decisions, faster. As the pharma and healthcare sector faces unparalleled upheaval, customers rely on our independent advice, enabling them to cut through the clutter and make sense of changing drug development, regulatory and competitive landscapes.Job Summary:We are seeking a Data Analyst to join our Real-world data (RWD) team and support our data-driven initiatives. The ideal candidate will have a strong background in SQL, content knowledge of the Life Sciences industry and the drug development lifecycle, and experience querying healthcare databases (claims, lab, EMR, etc).Responsibilities:Design data pipelines and queries and analyze data to support our Life Sciences use cases, particularly claims and lab dataDevelop and optimize database queries and procedures for data processing, transformation, and analysisDevelop advanced algorithms on large-scale healthcare databasesCreate final deliverables in industry standard to share with external clientsWork with cross-functional teams to identify data needs and develop solutions to support business goalsMonitor and troubleshoot data quality issues, and provide timely and effective solutionsStay up-to-date with the latest industry trends and emerging technologies, and make recommendations for data engineering best practices and toolsRequirementsBachelor's degree in Data Science, Computer Science, Engineering, Public Health, Biostatistics, Epidemiology or related field2+ years of experience working with and querying large databasesStrong proficiency in SQLUnderstanding of life sciences industry and drug development lifecycle Experience working with healthcare databases (e.g., claims, EMR, labs, etc.)Basic understanding of concepts used in epidemiological study designAbility to work collaboratively in a team environment, as well as independently with minimal supervisionStrong problem-solving and analytical skills, with attention to detailNorstella is an equal opportunities employer and does not discriminate on the grounds of gender, sexual orientation, marital or civil partner status, pregnancy or maternity, gender reassignment, race, color, nationality, ethnic or national origin, religion or belief, disability or age. Our ethos is to respect and value people’s differences, to help everyone achieve more at work as well as in their personal lives so that they feel proud of the part they play in our success. We believe that all decisions about people at work should be based on the individual’s abilities, skills, performance and behavior and our business requirements. Norstella operates a zero tolerance policy to any form of discrimination, abuse or harassment.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Gauntlet’s mission is to drive adoption and understanding of the financial systems of the future. Gauntlet is the platform for off-chain intelligence that drives on-chain efficiency in Decentralized Finance (DeFi). We work with protocols to manage risk, improve capital efficiency, and manage incentive spend. We also publish cutting-edge research and aim to take a leading role in defining market risk standards across the industry.Gauntlet is building infrastructure that allows us to simulate and stress-test blockchain protocols, contracts, and network interactions at scale over a wide range of market conditions. Our models ingest a wide range of on-chain and off-chain data, and are continuously calibrated to the current crypto market structure so that our recommendations are always up-to-date. These models and infrastructure power our platform that currently manages risk and optimizes incentives for over $40B in assets.You will be working as part of an experienced team to develop industry-leading products and infrastructure that will enable DeFi to achieve greater efficiency and impact.ResponsibilitiesBuild data models and visualizations of public blockchain data and simulation results that provide intuitive analytics to customersAnalyze on-chain transactions to understand user behavior and dynamics within the DeFi ecosystem, and help to operationalize Gauntlet models and ensure that recommendations are always in sync with market conditionsMeasure business performance, develop core metrics and create dashboards to communicate results for both internal and external audiencesWork with engineering and product teams to develop systems to automate and scale impact of insightsQualifications3+ years of relevant work experienceExperience with financial or crypto products is highly desirable*Understanding of statistical concepts and ability to independently plan and execute on analytics projectsExperience working with databases and doing data analysis with SQLExperience with client facing/consumer facing projects and liasing with multiple stakeholdersComfortable scripting in Python or similar languageBenefits and PerksRemote first - work from anywhere!Regular in-person company retreats and cross-country \"office visit\" perk100% paid medical, dental and vision premiums for employeesLaptop, monitor, keyboard and mouse setup provided$1,000 WFH stipend upon joining$100 per month reimbursement for fitness-related expensesMonthly reimbursement for home internet, phone, and cellular dataUnlimited vacation100% paid parental leave of 12 weeksFertility benefitsOpportunity for incentive compensationPlease note at this time our hiring is reserved for potential employees who are able to work within the contiguous United States and Canada. Should you need alternative accommodations, please note that in your application.The national pay range for this role is $135,000 - $200,000 plus additional On Target Earnings potential by level and equity in the company. Our salary ranges are based on paying competitively for a company of our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide. Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'At UnitedHealthcare, we’re simplifying the health care experience, creating healthier communities and removing barriers to quality care. The work you do here impacts the lives of millions of people for the better. Come build the health care system of tomorrow, making it more responsive, affordable and equitable. Ready to make a difference? Join us and start doing your life\\'s best work.(sm)We\\'ll put you in the driver\\'s seat on vital projects that have strategic importance to our mission of helping people lead healthier lives. Yes, we share a mission that inspires. We need your analytical talents and business discipline to help fuel ours.As the Data Analyst 1, you will act as the Analytical expert and will provide analytic leadership to support Government Program operational reporting and analytics, planning, forecasting, machine learning and process improvements. You\\'ll work closely with business leaders to develop innovative analytic solutions, create actionable insights and drive better decisions and performance to help Government Operation fulfill its mission.You’ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges.Primary ResponsibilitiesDevelop innovative analytic solutions, create actionable insights and drive better decisions and performance to help the business achieve its business objectivesSupport operational analytics, machine learning and process improvement data deep dive, identify and execute on new opportunities for increases in efficiencies and performance Support data governance and stewardship work streamsFormulate hypothesis, develop queries and models to evaluate hypothesis and formulate solutions to drive process & performance improvementDevelop visionary and creative analytic solutions to measure business performance; identifies / quantifies drivers, risks and opportunities and defines solutions to mitigate risks and leverage opportunitiesInfluences senior leadership to adopt new ideas, projects and / or approachesCompetenciesSelf-starter and should have solid coding mindset and facilitation skills that will quickly develop relationships across the organization while building a collaborative work environmentSolid business acumen and critical thinking abilitySolid problem-solving skills with the ability to anticipate, identify and diagnose problems and make recommendationsCandidate must be goal-directed, persistent and driven to achieve positive results. Is positive influence on others and deals well with setbacks. Identifies integration issues, removes barriers and tracks project status in order to obtain desired resultsDetail orientation - getting \"into the trenches\" to evaluate all aspects of operations. Pivotal to success will be the ability to take a hands-on approach to getting the information needed and driving effective and lasting changeServe as a solid coach and will foster career development of team members You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.Please review the required qualifications as posted below. To be eligible to apply and be reviewed for the position, the candidate must meet or exceed all posted required qualifications listed. We value your time and interest in this position and thank you again for taking the time to review the job posting.Required QualificationsBachelor’s degree and equivalent combination of education, experience 3+ years of experience utilizing SQL and/or relational database tools3+ years of experience in reporting & analysis, data management & reconciliation 2+ years of experience in Base SAS / Advanced SAS2+ years of experience with Tableau Demonstrated ability with key successes on business solution derived from analysis and deep learningPreferred Qualifications2+ years of experience with machine learning (Python / R, etc.)Experience with Power BI Snowflake experienceProject Management (Agile, Waterfall methodologies) and Operational (claims, call center, etc.) experience Analysis experience within managed care/health insurance industry experience in government programs, and/or finance Careers with UnitedHealthcare. Work with a Fortune 5 organization that’s serving millions of people as we transform health care with bold ideas. Bring your energy for driving change for the better. Help us improve health access and outcomes for everyone, as we work to advance health equity, connecting people with the care they need to feel their best. As an industry leader, our commitment to improving lives is second to none.All employees working remotely will be required to adhere to UnitedHealth Group’s Telecommuter PolicyCalifornia, Colorado, Connecticut, Nevada, New York, Rhode Island, or Washington Residents Only: The salary range for California, Colorado, Connecticut, Nevada, New York, Rhode Island or Washington residents is $56,300 to $110,400. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives.At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone–of every race, gender, sexuality, age, location and income–deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes — an enterprise priority reflected in our mission. Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Summary: The Database Analyst will maintain data storage; assess database design; and gather, organize, and interpret statistical information based on the data in the database. Duties/Responsibilities: Oversees database development and modification efforts Designs and implements secure, efficient, and accurate databases Maintains current and accurate knowledge of data storage and management best practices Ensures that databases are designed to meet specifications and requirements at the lowest possible costs Ensures that database projects are completed on time and within estimated costs Develops and maintains documentation and standards Assists Senior Database Analyst and identifies and resolves production and/or applications development problems related to the use of the database management system software or utilities Gathers, organizes, and interprets statistical data from the database to provide reports to, and answer questions from, upper management Performs other related duties as assigned Required Skills/Abilities: Excellent verbal and written communication skills Proficient in Microsoft Office Suite or related software Tableau, Power BI, SQL, Microsoft Office, Data Verification Excellent organizational skills and attention to detail Understanding of computer languages used within database Understanding of database design and construction Education and Experience: Bachelor's degree in Business Administration, Statistics, Mathematics, Accounting, or Computer Science or equivalent work experience required At least three years in Data Processing, with at least two years of experience with database management systems; OR two years as a development programmer/analyst using database techniques under IMS/DB-DL/1 required Physical Requirements: Prolonged periods sitting at a desk and working on a computer Must be able to lift up to 15 pounds at times Company Description Detroit Chassis, a subsidiary of SPECTRA LLC, produces rolling chassis, complex subassemblies and modules, and complete vehicles for the automotive, RV and commercial truck industries, with one stop design and engineering solutions. Detroit Chassis, a subsidiary of SPECTRA LLC, produces rolling chassis, complex subassemblies and modules, and complete vehicles for the automotive, RV and commercial truck industries, with one stop design and engineering solutions.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Location: Sheetz Corporate - PITTSBURGH, PAPrimary Purpose Of This PositionAssist in creating and driving business value and growth though the effective use of Sheetz’ most valuable resource: Data. Responsible for leading Sheetz’ data and information strategy through data analysis and visualization in order to facilitate and enhance organizational decision-making and data utilization across the company. Provides advanced data analytics support to the Senior Data Analyst while providing mentorship to the Associate Data Analyst around data analytics and information strategy.ESSENTIAL FUNCTIONS: (other duties may be assigned)Cultivate data-driven insights that help support exploitation of strategic and tactical business opportunities, and be a champion for a data-driven, decision-making culture.Support data strategy leadership in the development, assessment, refinement and implementation of corporate strategy through effective use of data analytics.Provide enterprise-wide data science and business intelligence services as well as recommendations to decentralized, embedded data scientists and analysts throughout the business.Assist Senior Data Analysts and management in providing training for departmental and distributed data analysts.Oversee and present robust ad-hoc reports, data models, and deep dive analysis to provide clear observations so that managers can make more informed decisions.Develop and mentor future data-driven, analytical leaders and strategists within the team.Assist with a wide array of analytical tasks and projects requested by other departments.Supports the Senior Data Analyst position with ad-hoc advanced analytics.Assist in the creation of policies and procedures for the access, analysis and visualization of data and associated business insights; partnering with IT and RISC.REQUIREMENTS: (Equivalent combinations of education, licenses, certifications and/or experience may be considered)EducationBachelor’s degree in Economics, Statistics, Mathematics, Actuarial /Data / Computer Science or related field requiredExperienceMinimum 3 years demonstrated experience in data modeling, optimization, and application to business strategies required.Minimum 3 years demonstrated experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required.Thorough understanding of the latest data mining, machine learning and/or artificial intelligence techniques required.In-depth experience with or coursework in designing and implementing information solutions required.Licenses/CertificationsN/ATools & EquipmentN/AAbout SheetzSheetz, Inc. is a fast-growing, family-owned, food/convenience company that has been in business since 1952. Sheetz has over 600 locations in Pennsylvania, Ohio, Virginia, West Virginia, Maryland and North Carolina.Our mission at Sheetz has been to meet the needs of customers on the go. Of course, things have changed over those nearly 70 years. Life is faster and busier, and customers expect us to be there when they need us most. One thing that hasn't changed is our commitment to our customers, our employees and the communities in which we operate. Sheetz donates millions of dollars every year to the charities it holds dear.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"• Onsite 5 Days per week in Tampa, FL • Must be fully vaccinated • W2 - US Citizen/GC Only • 6 Month Contract to Hire • Pay rates: $38-43hr, $80-90K FTE Must-haves 2+ years of experience using Data Analytics and Reporting tools  Experience running reports within PowerBI Understanding of programming Languages such as C++ and HTML (The company's SharePoint is in HTML, so they are seeking someone who can update pages in HTML to help market IT internally)  Experience with cloud technologies, Azure preferred (understanding of how the cloud works, the company is moving to Azure. Understanding software reporting within the cloud)  Experience with Active Directory/Identity Management  Day-to-Day An employer in Tampa, Florida is looking for a Reporting Data Analyst. This person will be sitting ON-SITE in Tampa, Florida and will:  Pull, analyze, interpret, and report on data pertaining to IT Asset Management  Update internal SharePoint using HTML to help market the IT department to the rest of the organization  Utilize Excel/Tableau/PowerBI to pull reports and create presentable models of data found  Work cross-functionally as needed\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job SummaryAt the MBTA, we envision a thriving region enabled by a best-in-class transit system. Our mission is to serve the public by providing safe, reliable, and accessible transportation. MBTA’s core values are built around safety, service, equity, and sustainability and each employee that works for the MBTA performs their role based on our vision, mission, and values. This includes attendance, participation, and contribution to local safety committee meetings as needed.Capital Programs Strategy & Innovations (CPSI) multifaceted scope includes oversight of Capital Program’s Supplier Diversity Program (CPSD), Capital Program’s Safety Assurance (CPSA) and Project Management Information System (PMIS). The Data Analyst/Reporting, CPSI reports to and partners with the Chief of CPSI and the Deputy Chief of CPSI, in supporting the overall analytics and reporting functions related to CPSI’s goals and initiatives. The Data Analyst/Reporting will be responsible for all aspects of reporting and analysis related CPSI portfolio of information produced by its groups as listed.Duties & ResponsibilitiesDevelop reporting solutions that will provide analysis and transparency and areas of opportunity for CPSI efforts.Deliver a structure and cadence of reporting to meet the needs of the various audiences including regularly scheduled reports, such as quarterly and annual reports. As well as on-demand reporting, and ad hoc requestsEnable team and partners to provide data-driven insights and solutions to meet goals of MBTA Capital Programs and CPSI-specific initiatives.Develop relationships with all CPSI groups: PMIS, CPSD, and CPSA to deliver tools/systems solutions.Serve as a central point of contact for all CPSI data requests.With latitude for independent judgment, maintaining relationships with external and MBTA contacts to develop analytical solutions to CPSI issues.Demonstrates MBTA’s organizational values of stewardship, integrity, respect, and teamwork.Perform all other duties and projects that may be assigned.The physical demands and work environment characteristics described here are representative of those an employee encounter while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform essential functions.Available to work all shifts and locations as assigned or directed.Minimum Requirements & QualificationsBachelor’s Degree from an accredited University.Two (2) + years of related experience in business analyst roles with a deep interest in data, metrics, analysis, and trends Ability to maintain confidentiality when working with confidential HR and proprietary data.Project management experience (Agile preferred)Advanced to expert knowledge of the Microsoft Office product suite (Excel, Word, PowerPoint), including a strong ability to visually convey information and insights through graphs, charts, and other means.Ability to identify linkages and insights between multiple datasets from different sources.Proficiency in utilizing reporting tools such as Tableau, Power BI, or Workday Prism.Effective verbal and written communication skills with comfort presenting to management.Excellent verbal and written communications skills, MS Office, and computer skills., including experience communicating and collaborating with senior executives departmental and across many levels of the MBTA.Works well under pressure in a fast-paced environment and exercises sound judgment and discretion.Motivated self-starter; identifying opportunities for improvement and assuming responsibility.Highest level of professionalism, integrity, and strong work ethic.Team-oriented individual with the ability to work well with diverse groups.Preferred Experience And SkillsTwo (2) years of Data Analyst in one or more of the following: Supplier Diversity Programs, Civil Rights, Safety Assurance, Project ManagementExperience with Agile\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job Description Job Title: Data Analyst Location: Pittsburgh, PA or Conshohocken, PA Duration: 10&plus; Months Must Have Experienced Data Analyst Experience in pharmacy claims, health plans and should have good knowledge of industry quality ratios Databricks, Azure, SQL for creating the analytics file Experience in reporting using eithr Pythor or R Operations support\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Who We AreAngel Studios is the home of stories that amplify light. Through its platform, thousands of “Angel” investors choose which titles will be created, funded, and distributed. Angel Studios allows creators and audiences to form passionate communities around their creative projects, making the story behind the story as important as the final project itself. The studios’ first projects—The Chosen and Dry Bar Comedy—have earned billions of views around the world. Learn more at Angel.comWe’re looking for passionate team members who want to build world-class products that will reshape media over the coming decades. Learn more about:Our North StarCompany StrategyTeam PrinciplesJoin us and be part of stories that matter.Job DescriptionSummary/objective:The Data Analyst is responsible for providing insight and drawing conclusions from data to describe, predict, and improve Angel Studios's business performance.Expectations of Team Members at Angel Studios:Amplify light in every actionAs the owner of your outcomes, you are empowered to break down silos and coordinate with any and all people you need in order to reach your goals. You are ultimately responsible for achieving the outcomes while also using resources wisely - whether that be money, people, or timeKnow your customer - it might be our viewers, investors, creators, or internal Angel Teams. Ensure you understand your customer and are providing what THEY need and not just what you want to build. Essential FunctionsCollect, analyze, and present data in clear, easy to digest waysCreate reports for marketing teams and other applicable teamsManage and structure large and small data sets to find usable informationWork with data and operations teams to process information and drive improvementsCollaborate with team members to established streamlined processes and measurements of effectivenessConstantly seek for ways to solve problems creativelyConstantly seeking to improve your craft by taking advantage of advances made in the fieldMust attend and contribute to regularly scheduled staff meetingsProficiency in speaking, reading and writing in the English language required. Additional language proficiency is a plus. Reasonable accommodations may be made to enable individuals with disabilities to perform these essential functions.CompetenciesIn-depth experience and knowledge of data analysis principles, technologies, industry trends and best practicesYou are experienced with BI Visualization tools (Metabase experience preferred)You have a good eye for design and creating reports, dashboards and other visualizations that are appealing and informativeYou are experienced in mathematical and statistical analysis and in compiling and summarizing data around customers, processes, economics and other business intelligence areas using tools like SQL, Python, R, and SASYou have experience working with large data sets and interacting with Data Lakes (Snowflake, BigQuery, etc.)Capable of managing workload and prioritizing tasks in a fast-paced corporate environmentAn exceptional listener with excellent written and verbal communication skillsProficiency with Microsoft Office and Google WorkspaceDetail-oriented perspective and able to pick up on overlooked detailsOrganization and time management. Able to maintain confidentiality of informationMust be able to manage multiple assignments, set priorities, and adapt to changing conditionsResourceful and able to problem-solve and manage tasks with ambiguity. Can take feedback to tasks and assignments positively and create better solutionsA quick study, able to pick up new skills and learn how to use new programsMust participate in setting and achieving regularly scheduled and outlined objectives. Ability to take individual ownership, execute with high energy, share context, insist on candor with positive intentRequired Education And ExperienceBachelor’s Degree or equivalent5+ years of relevant experiencePreferred Education And ExperienceMaster’s DegreeWork environment - When in the main office, expect a comfortable, air-conditioned work environment. Team members are issued their own desks, but the office is an open, shared space and can be fast-paced and occasionally noisy.Physical demands - Will need to be able to sit or stand at a desk for extended periods of time.Position type and expected hours of work - Regular full-time, 40 hours per week.Travel required - Regular out-of-state travel is not anticipated.Perks at Angel: Competitive compensation Stock Option equity package 100% company-paid medical, dental, and vision premiums for employees and dependents Short, and Long Term Disability Insurance paid for employee, with option of additional AD&D insurance Generous Paid Time Off Health Spending Account (HSA) 401(k) investment opportunity with employer match Paid parental leave Professional development reimbursementAngel is an Equal Opportunity Employer:We are actively seeking to create a diverse work environment because teams are stronger with different perspectives and experiences.We value a diverse workplace and encourage women, people of color, LGBTQIA individuals, people with disabilities, members of ethnic minorities, foreign-born residents, older members of society, and others from minority groups and diverse backgrounds to apply. We do not discriminate on the basis of race, gender, religion, color, national origin, sexual orientation, age, marital status, veteran status, or disability status. All employees and contractors of Angel are responsible for maintaining a work culture free from discrimination and harassment by treating others with kindness and respect.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"National Grid Renewables, which includes the renewables development company formerly known as Geronimo Energy, is a leading North American renewable energy company based in Minneapolis, Minnesota, with satellite offices located in the regions where it develops, constructs, and operates renewable energy projects. As a farmer-friendly and community-focused company, National Grid Renewables develops projects for corporations and utilities that seek to repower America’s electricity grid by reigniting local economies and reinvesting in a sustainable future. National Grid Renewables is part of the competitive, unregulated Ventures division of National Grid and has a portfolio of solar, wind, and energy storage projects located throughout the United States in various stages of development, construction, and operation. National Grid Renewables develops high-value, competitive renewable energy projects. Our focus on communities and farmers means it’s not just about projects, but about the people we work with, both outside and inside our organization. National Grid Renewables Team Members embody our foundational culture of being entrepreneurial, creative, and nimble and take pride in supporting National Grid’s vision to be at the heart of a clean, fair, and affordable energy future for all.   National Grid Renewables is seeking a Senior Data Analyst to join our growing IT Operations Team. This role will provide the technical knowledge necessary to drive forward our organization's cloud-based infrastructure initiatives as we align our processes and technologies. RoleReview and validate business critical data as it is collectedOversee the deployment of data to the Microsoft Azure DatalakeManaging and designing the reporting environment, including data sources, security, and metadataSupporting the data warehouse in identifying and revising reporting requirementsDevelop policies and procedures for the collection and analysis of dataCollaborate with IT for data mapping and integration via Microsoft Azure to leverage big data use casesProviding technical expertise in data storage structures, data mining, and data cleansingTroubleshooting the reporting database environment and reportsAnalyze business processes and requirementsIdentify opportunities to improve processes and strategies with technology solutionsIdentify development needs to improve streamline operationsCreate reports for business stakeholders using tools such as Microsoft Power BIMonitor analytics and metrics resultsImplement new data analysis methodologiesReview organizational data to ensure integrity of data collection and utilizationPerform data profiling to identify and understand anomaliesCollaborate with business usersTraining end-users on new reports and dashboards  Background and SkillsBachelor's degree in Management/Computer Information Systems (MIS/CIS), Computer/Electrical Engineering, Computer Science, or related fields.5+ years as a Data AnalystAbility to build strong data models and relational databasesStrong data mining techniquesSQL experiencePower Query, PowerBI and data visualizationStrong understanding DatalakesStrong understanding of DatabricksDatabase management and reportingBusiness administrationMicrosoft Office and ExcelCritical-thinking and problem-solvingStrong Communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Direct ClientPhone/Skype Hire. Onsite from day 1LOCAL Candidates Strongly PreferredLocation: Boise, IDDuration: 12+ monthsNeeds a Data Analyst to assist with the validation of data in the migration of legacy transaction and documentation data from eleven (11) existing systems into one. In addition, the new consolidated data will form a new historical data set in the event not all data is migrated into the new license system.Client is implementing an enterprise Licensing Information System (LIS) and is required to migrate both application transaction data (OLTP) and business document content from 11 legacy systems.Client is seeking a qualified Data Analyst to work within a cross-functional team that includes IT Staff, a Data Architect, Project Coordinators, and Business Users. This individual will play a key role in the identification, transformation, loading and testing of legacy data during the LIS system implementation phase. The ideal candidate will have experience in data validation, data analysis, business systems analysis, requirement documentation, testing, and effectively working with business stakeholders.ResponsibilitiesValidation of all data being moved from original systems into new systemWorking with business stakeholders to observe processing and capture data requirements.Analyzing legacy databases and identifying application data for migration.Documenting key data entities and attributes in legacy database systems.Working with data migration team to test ETL software and loads.Working with system integrator to ensure data loads are complete and accurate.Skills NeededExperience as Data Analyst responsible for data validation in relation to enterprise system(s) migrations Required 2 YearsExperience working with business stakeholders to observe processing and capture data requirements. Required 2 YearsExperience documenting key data entities and attributes in legacy database systems. Required 2 YearsExperience analyzing legacy databases and identifying application data for migration. Required 2 YearsExperience working w/data migration teams to test ETL software and loads (Unit, Component, Integration, Functional, Smoke, Sanity & System testing) Required 2 YearsExperience working with system integrators to ensure data loads are complete and accurate Required 2 YearsComputer skills, including MS Excel, MS Word, and MS Visio Required 2 YearsMicrosoft SQL Server Management Studio or similar tool DesiredKnowledge of Automated Testing Tools Nice to havePython experience Nice to haveQuestion 1 This is a FULLY ONSITE position. Candidates must work full-time ONSITE at the client's location in Boise, Idaho. Remote work WILL NOT be considered. ONLY submit candidates willing to work fully onsite in Boise, ID for his position. LOCAL CANDIDATES will be strongly preferred due to onsite requirements. Please confirm.ThanksVikram Tiwari\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Description Strong SQL technical knowledge to query DBs High level conceptual understanding of Data integration and data warehouse technologies Requirement coordination with business, ETL and DW team Support the DW team in identifying and revising requirements Perform initial analysis to assess the data Provide quality assurance of data, working with quality assurance analysts if necessary Helping develop reports and analysis\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'SUMMARY:  The Lead Data Analyst will focus on analyzing healthcare financial data and building reports that provide insights into the operational and financial health of the business. This is a very technical and data-driven position that will work closely with Business Users, Billing, Finance, and Technology teams. The optimal candidate has a background in financial data analysis related to claims management. RESPONSIBILITIES:Gather and Document business and functional requirements and specificationsAnalyze data, build database tables and stored procedures to optimize reporting performanceBuild and test reports, and work with users to explain the metricsAutomate and streamline the delivery of reports and alertsUnderstand business processes and map them to underlying data elementsIdentify data gaps and issues between Healthcare system and databases and resolve themHelp define key metrics that would provide more insight and gain approval for developmentDocument projects and tasks, escalate issues and communicate progressLead other analysts to ensure consistency, data quality, and establish standard practicesDocument all reports, track usage, and lead effort to consolidate and organizeWork across different business units to identify data dependencies and set up necessary controlsBuild and maintain a strong relationship between different business units to help collaborateAssist with other analysis, development, QA as neededMINIMUM QUALIFICATIONS AND REQUIREMENTS4+ years working with financial data4+ years analyzing data and writing queries/stored procedures in SQL Server3+ years building reports and dashboards in PowerBI1+ years building reports in ExcelAbility to quickly grasp and articulate dependencies between processes and data Strong ability to analyze data and pay attention to detailExcellent communication, organizational and time management skillsTakes initiative and can manage and complete multiple concurrent projects in a timely mannerPREFERRED EXPERIENCEBachelor’s degree or equivalent combinations of education and experienceExperience working in the Healthcare industry – preferably with data related to Healthcare ClaimsExperience leading projects and/or a small teamExperience working with offshore teams\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"ResponsibilitiesAre you passionate about using data to drive business decisions. Do you love diving into complex datasets and uncovering insights that help companies make better decisions. If so, we want you to join our team as a Data Analyst. We're looking for motivated individuals who are excited to learn and grow in a fast-paced environment. This is an entry-level position, so no prior experience is required, but a strong analytical mind and a willingness to learn are a must.Analyze complex datasets and provide insights to stakeholdersBuild and maintain reports and dashboards to track key business metricsWork cross-functionally with other teams to identify opportunities for improvementDevelop and implement data collection processes to ensure accurate and reliable dataIdentify and communicate trends and patterns in data to key stakeholdersParticipate in data-driven decision-making processes to help guide business strategyQualificationsBachelor's degree in a related field (such as Statistics, Mathematics, Economics, or Computer Science)Strong analytical skills and a passion for dataExperience with SQL and/or other programming languagesFamiliarity with data visualization tools such as Tableau, Power BI, or QlikViewExcellent written and verbal communication skillsAbility to work independently and as part of a teamSelf-motivated and able to manage multiple priorities in a fast-paced environmentBenefitsCompetitive salary and benefits packageOpportunity to work with a talented and passionate teamFlexible remote work arrangementsOpportunities for growth and advancement within the companyAccess to cutting-edge technologies and toolsAt our company, we believe that data is the key to success in today's business environment. As a Data Analyst, you will have the opportunity to work with a variety of stakeholders across the organization, using your analytical skills to drive business decisions and help shape our future direction. If you're looking for a challenging and rewarding career in a dynamic and innovative industry, we want to hear from you!PI212034030\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Genesis10 is seeking a JR SQL Data Analyst for a contract to hire with our client in Plano, TX. \\xa0100% Remote.Job Description:Job responsibilities focus on analyzing, querying, and performing quality assurance on data maintained in a complex relational database environment.Responsibilities:Designs and analyzes data utilizing advanced technical experience with SQL Server technologiesAnalyzes Title Insurance rates and related data maintained in complex relational databasesProduces ad hoc reports and queriesDevelops and maintains familiarity with internal, proprietary SQL Server database structuresWorks collaboratively with database developers and business analysts to identify and resolve data issuesDevelops and maintains familiarity with relevant data reporting and State requirementsAssists in updating in-house proprietary software to reflect required changes to data processing and reporting specificationsParticipates in the development and maintenance of data warehousePerforms testing and validation against software application for quality assurance.Regular consistent attendance is required, that could include attendance at after hour Company events.Ability to accept supervision.Ability to foster, develop and maintain professional and collaborative working relationships. Must be able to get along with others, i.e., peers, supervisors, outside customers, and vendors.Ability to interact effectively and professionally with all levels of management, employees and customers by email, phone and in person.Must be personable, positive, and a professional representative of the Company.Perform other duties as assigned by supervisor.Qualifications:Minimum BS or BA, in computer science or related field; preferred2 - 5 years of experience querying relational databases using SQLStrong PC skills required, including proficiency with Microsoft Windows, Excel, and WordExcellent analytic, interpersonal, and communication skills, especially written communication skillsT-SQL stored procedure development, preferred.Microsoft SQL Server Reporting Services design and development, or similar report design and development experience (e.g. Microsoft Access or Crystal Reports)Querying and/or developing Microsoft Analysis Services (or similar) OLAP databasesExcellent verbal and written communication skills.Excellent interpersonal and customer service skills.Ability to prioritize and handle multiple projects.Strong attention to detail and organizational skills.Proficient in Microsoft Office Suite and Outlook.Compensation:Hourly W2 pay rate $30.00 - $33.00We have access to additional contract, contract-to-hire, and direct hire positions with various rate ranges.\\xa0If you have the described qualifications and are interested in this exciting opportunity, apply today!Ranked a Top Staffing Firm in the U.S. by Staffing Industry Analysts for six consecutive years, Genesis10 puts thousands of consultants and employees to work across the United States every year in contract, contract-for-hire, and permanent placement roles. With more than 300 active clients, Genesis10 provides access to many of the Fortune 100 firms and a variety of mid-market organizations across the full spectrum of industry verticals.For contract roles, Genesis10 offers the benefits listed below. If this is a perm-placement opportunity, our recruiter can talk you through the unique benefits offered for that particular client.Benefits of Working with Genesis10:Access to hundreds of clients, most who have been working with Genesis10 for 5-20+ years.The opportunity to have a career-home in Genesis10; many of our consultants have been working exclusively with Genesis10 for years.Access to an experienced, caring recruiting team (more than 7 years of experience, on average.)Behavioral Health PlatformMedical, Dental, VisionHealth Savings AccountVoluntary Hospital Indemnity (Critical Illness & Accident)Voluntary Term Life Insurance401KSick Pay (for applicable states/municipalities)Commuter Benefits (Dallas, NYC, SF)Remote opportunities availableFor multiple years running, Genesis10 has been recognized as a Top Staffing Firm in the U.S., as a Best Company for Work-Life Balance, as a Best Company for Career Growth, for Diversity, and for Leadership, amongst others. To learn more and to view all our available career opportunities, please visit us at our website.Genesis10 is an Equal Opportunity Employer. Candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionHertz and the Advanced Analytics and Tool Development team is seeking talented individuals with passion for real-world problem solving. The analyst will partner with various functions within the company (Revenue Management, Fleet, Operations) and develop advanced tools and resources to support overall location-level planning and operational decisions. The analyst will be working with large sets of structured and unstructured data to perform analysis, develop tools, and provide actionable insights.What You’ll Be Doing Develop tools for the field for car assignment to optimize upgrade/upsell/booking success.  Develop tools to provide visibility to many of the operational processes.  Conduct analyses to inform stakeholders and help make the most optimal decisions regarding various strategic initiatives.  Code and automate performance reports.  Configure shared PC resources to automate scripts and collect data. What We Expect A Bachelor’s degree; preferably in Data Science, Computer Science, Statistics, Engineering, or another quantitative field.  A demonstrated ability to query and extract findings from large data sets in relational databases such as SQL Server, Teradata, Oracle, etc.  A wide range of data-related technical skills regarding databases, scripts, and web APIs.  Experience with programming/scripting languages like R or Python  Experience with advanced data visualization platforms such as Tableau.  Quick on feet; willingness to discover alternative solutions to technical problems.  A desire to solve complex problems with creative and concise solutions.  Excellent written and oral presentation skills – ability to communicate findings with non-technical stakeholders in concise and simple terms.  An individual who thrives in a collaborative environment. Nice To Haves More than 1 year of work experience in a data driven industry including Rent-A-Car, travel, or service industry  A Master’s degree in a quantitative field  Experience with statistical modeling  Experience with web development languages such as Ruby, PHP, or JavaScript. r work every day represent a significant part of our culture – and our success and reputation as a company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'JDC -61 Data Analyst, Tallahassee, FLAbout Syra HealthSyra Health Corp. is a pioneering healthcare technology consulting company that develops outcomes-driven solutions having a direct and quantitative benefits to the healthcare industry. We work with payers, health services companies, and life sciences companies to build solutions that create measurable business value and have a positive impact on the lives of their customers. And we are dedicated to cultivating an inclusive culture of respect, honesty, and integrity by embracing the unknown, recognize the value of diversity, and harness the power of enthusiasm.Job SummarySyra Health, a healthcare organization, is seeking a highly skilled Data Analyst to join our team. The ideal candidate will be responsible for analysing and interpreting complex healthcare data sets, including experience in Medicaid data management. The candidate should have advanced knowledge of SQL, and experience working with large data sets. The candidate will be expected to provide actionable insights to inform decision-making and improve patient outcomes.ResponsibilitiesAnalyse and interpret large and complex healthcare data sets, including experience in Medicaid data management.Develop and maintain databases, data systems, and data analytics tools to support data-driven decision-making.Extract qualitative and quantitative relationships (i.e., patterns, trends) from large amounts of publicly available data using SAS, SQL, R, Python, or other statistical toolsIdentify and interpret trends or patterns in data sets.Prepare reports and visualizations that effectively communicate insights and recommendations to management and stakeholders.Collaborate with other teams, including clinical and operational teams, to develop data-driven solutions that improve patient outcomes and reduce costs.Design and implement experiments to test hypotheses and validate assumptions.Ensure data accuracy and completeness by conducting regular data audits.Stay up to date with industry trends, best practices, and regulations related to healthcare data management.RequirementsMinimum of 3 years of experience in data analysis, preferably in healthcare.Experience creating datasets for CMS programs such as MSSP, DCE, or ACO Advanced knowledge of SQL and experience with relational databases.Experience working with Medicaid data and other healthcare data sets.Strong analytical and problem-solving skills.Ability to work independently and in a team environment.Excellent communication and presentation skills.Strong attention to detail and accuracy.Strong hands-on with data visualization tools, such as Tableau or Power BI, is a plus.Careers At Syra HealthOur objective is to make the world a better place by thinking big and seizing opportunities for ourselves, our clients, and our consumers. We are driven by a passion for health and encourage you to be unique, inquisitive, and bold. And by working together, we can increase your contribution on both your career and the world of healthcare.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'NovoEd builds the next generation of learning technology to offer engaging learning experiences at scale through social collaborative and experiential learning. Our platform is used by enterprise companies including those in the Fortune 500, top universities, training firms, and foundations, around the world to provide experiential and collaborative learning to adult learners. These online learning experiences replicate in-person learning experiences such as workshops that have traditionally been hard to bring online. Social collaboration and peer learning are not only built into our product, but also the DNA of our company. We have a collaborative team with a passion for learning and an amazing culture.The Data Analyst will report to the VP of Product and be a key partner of the R&D, Revenue Operations and Customer Experience teams. The role is expected to provide deep analysis of data and then determine the best way visualize it for customers, business partners and management. This will require solving business problems by customizing the Salesforce and Churn Zero platforms as well as setting up data pipelines using open-source relational database management systems with wysiwyg type tools. The Data Analyst will create metrics and charts using embedded analytics tools, resolve data issues with the quality assurance team, and liaise with the design team on aesthetics and the user experience aspects of dashboards. The Data Analyst will be the owner of the embedded analytics tool, and be responsible for managing the data vendors, including the reporting and resolution of issues.Responsibilities:Manage dashboards, reports and insights for customers as well as the product, sales, marketing, and customer experience teams. Gather requirements, configure changes, design best practice solutions, data governance and reporting for the Salesforce and Churn Zero platforms. Deliver data sources relevant to customer engagement and the use of the NovoEd product into the SaaS product data store; Use APIs or MySQL to bring data in from relevant sources. Design data sets that are performant, can sync data with a lag of at most 30 minutes using a tool like AWS ETL/AWS GLUE. Create metrics and charts using a tool like Tableau, Google and Excel Charts. Generate, evaluate, and improve in-product, problem focused dashboards. Work with Product, Design, Engineering, and Quality Assurance teams to ship dashboards to production systems. Partner with the Product, Revenue Operations, and Customer Success and Support teams to answer specific data questions that are not yet built into the SaaS product. Qualifications:5+ years of experience with MySQL writing complex queries. 3+ years of experience creating and modeling performant data sets as well as deep data analysis. 5+ years of experience building charts and dashboards in tools like Salesforce, Churn Zero and Tableau. Ability to work independently, prioritize workload, and manage cross-functional projects. Advanced technical, analysis and modeling skills in data analytics tools, python and Excel (pivot, VLOOKUP, etc.). Experience using data analytics to support assumptions and develop business cases. Strong communication skills (verbal and written) and interpersonal skills with the ability to translate complex analysis into actionable recommendations. Compelling storytelling and presentation skills. Client centricity, empathy and deep curiosity to find deeper answers to data questions. What will set you apart:Experience working with a wide variety of business data sources. Experience with predictive analytics and data visualizations. Salesforce Administrator experienceNovoEd provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Salary range: The base pay for this role is up to $110k base + bonus. The actual base pay is dependent upon many factors, such as training, skills, work experience, business needs, and location. The base pay range is subject to change and may be modified in the future.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data Analyst Job Description : * Supports and contributes to business analytics projects and processes to provide data-driven insights related to business performance used to advise and develop strategies for operational improvements and future business initiatives. * Uses statistical methods, modeling, analytical methodologies, and data analysis to develop and deploy tools including dashboards, infographics, reports, and models to inform and support decision-making. * Processes, and analyzes internal and external data using KPIs, business results, industry sources, competitor intelligence, and customer information. * Develops a good understanding of the business's model, objectives, issues, and challenges by interacting and collaborating with users and stakeholders. * Typically reports to a supervisor or manager and make sure work is closely managed. * Works on projects/matters of limited complexity in a support role. Qualifications: * Desired a Master's or Bachelor's degree in computer science, information technology, statistics or a quantitative field. * Desired 0-2 years of related experience. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Company Description ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTitle: Data AnalystJob Type: Onsite, Full-time, Hybrid ModelLocation: Irving, TXJob DescriptionFamiliar with Banking Products.Good communications to interact with business clients.Familiar with finance data models data acquisitions.Good in excel Working on collecting and understanding the requirements.Should be well versed on Data Investigation, Data Analysis.Ability to explain functional technical details.Should have good SQL writing capabilities Validate UAT results and identify issue.Should be Independent and resourceful dealing with risks issues and resolving them in a timely manner.About CapgeminiCapgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.Get The Future You Want |\\u202fwww.capgemini.comDisclaimerCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-lawApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Minimum Position Qualifications: * 6 - 8 years' experience with IT initiatives * 4 - 5 years as a data analyst for data related projects; data warehouses, data marts, BI reporting, analytics; experience with migrations from on-prem to cloud a big plus * Thorough knowledge and understanding of systems, procedures, and technology/project life cycles. * Excellent communication and presentation skills to effectively communicate information to customers and to all levels within the organization * A working knowledge of IT Service Management practices. * Hands-on technical knowledge including SQL, or ETL platforms * Hands-on exposure to modern cloud solutions (Azure, Snowflake, ...) Company Description Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That's why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure - even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants' experience so far!Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That’s why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure – even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants’ experience so far! https://fusionalliance.com/careers/spotlight/\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are a Direct Mail and Email Marketing company. We acquire database lists and put them in a format for printing and mailing or emailing. We use Altryx and Excel. Company Description TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The data analyst/report technical writer performs highly advanced work related to special education and special populations data collection and reporting activities and projects.Essential FunctionsDevelops and writes data documentation, analytical requirements, business rules, workflows, and data calendar/timelines for existing and new data projects using simple, clear, unambiguous, and concise languageOversees the planning, design, scope, structure, creation, analysis, and maintenance of SAS programs, datasets, data reporting systems, and reportsDevelops and manages extensive quality assurance and quality control checks of SAS programs and workflows to improve existing programs and processes including comprehensive documentationPlans, studies, researches, and evaluates current information and data systems and recommends changes as neededMinimum RequirementsII. CANDIDATE SKILLS AND QUALIFICATIONSCandidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity. Years Required/Preferred Experience 4 Required Experience with SAS programming or similar statistical programming language 3 Required Education: Graduation from an accredited four-year college or university 3 Required Experience working with administrative data 3 Required Experience developing technical documentation 3 Required Experience with MS Office suite, especially Word and Excel 2 Preferred Experience working with education data\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Bachelor's degree in computer or information scienceStrong background in large-scale, shared data environments. Preferable candidate would have experience in Water/Wastewater space include Water Assets, GIS, Workorder and Asset ManagementExcellent technical abilities, strong communication skills, and strong project management and organizational skillsRelevant technical skills or knowledge may include data modeling, SQL programming (SQL Server or Oracle), and Microsoft OfficeEffective analytical abilities in order to examine existing processes/workflows/dataflows and make recommendations for improvements6 to 8 months possibility of extension\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title:ID - DOPL - Data AnalystLocation: Boise, ID Fully ONSITE Position***DescriptionDOPL needs a Data Analyst to assist with the validation of data in the migration of legacy transaction and documentation data from eleven (11) existing systems into one. In addition, the new consolidated data will form a new historical data set for DOPL in the event not all data is migrated into the new license system.DOPL is implementing an enterprise Licensing Information System (LIS) and is required to migrate both application transaction data (OLTP) and business document content from 11 legacy systems. DOPL is seeking a qualified Data Analyst to work within a cross-functional team that includes IT Staff, a Data Architect, Project Coordinators, and Business Users. This individual will play a key role in the identification, transformation, loading and testing of legacy data during the LIS system implementation phase. The ideal candidate will have experience in data validation, data analysis, business systems analysis, requirement documentation, testing, and effectively working with business stakeholders.ResponsibilitiesValidation of all data being moved from original systems into new systemWorking with business stakeholders to observe processing and capture data requirements.Analyzing legacy databases and identifying application data for migration.Documenting key data entities and attributes in legacy database systems.Working with data migration team to test ETL software and loads.Working with system integrator to ensure data loads are complete and accurate.Thanks,N.TEJASWINI NAIDUTechnical recruiterDirect:404-777-9838 | Fax: 866-608-6686Email: tejaswini.n@stiorg.com | Web: www.stiorg.com100 Overlook Center, Suite 200Princeton, NJ 08540.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Summary / Position Purpose: The primary responsibility of this role is to create consolidated reports, dashboards, and data analysis for the internal customers of ACG. This role will be responsible for the day-to-day support, maintenance, and improvement of our CRM and supporting platforms, as well as excel-heavy data-related projects. Their work will involve collecting and cleaning data from multiple sources, running ad hoc reports, building automated dashboards, investigating, and fixing any potential errors/bugs, and working with the Database Administrator to ensure that the information in our database is error-free for accurate reporting. Essential Duties, Functions and/or Responsibilities: Create, validate, and send daily weekly, and monthly management reports.Assistance with requests for non-standard reports and analysisSupport management reporting by maintaining hierarchical information.Perform business-to-system analysis and troubleshooting analysis of complex management reports and business problems.In the report, development lifecycle support impacts analysis and project requirements definitionTransform client needs into functional requirements.With guidance, collect, analyze, and document business requirements for project proposals including but not limited to process and data flow, user interface, and reporting requirements.Together with managers and/or senior analysts, participate in cross-functional meetings to understand customer needs and identify problems and solutions.Appropriate solutions, develop specifications, analyze, and document business processes, validate testing processes, and train the user community.Gather, clean, and transform large data sets to be used in reports and visualization.Design, develop and implement innovative/effective/strategic fully automated business solutions.Works closely with IT and business to incorporate daily automated data refreshing.Develops and provides a standard set of user-friendly reporting tools to internal business customers.Provides maintenance on deployed tools and dashboards.Assist sales & marketing teams with CRM reports and data management, building and maintaining outreach lists for up to several dozen sales and inside sales colleagues.Other duties as assigned.  Education and/or Work Experience Requirements: EDUCATION: Bachelors/4 Yr. DegreeYEARS OF RELEVANT WORK EXPERIENCE: 1+ yearsSalesforce.com (or equivalent CRM) power-user/admin experienceExpert knowledge of Microsoft Office (especially Excel)Demonstrable excel & CRM familiarity with pivot tables and other similar visual reporting tools to display/reconcile large amounts of data.Strong ability to meet deadlines and manage and prioritize simultaneous requests.Creative and analytical thinker with strong problem-solving skillsMust demonstrate ability to communicate effectively verbally and in writing with all levels of the organization.Ability to critically evaluate and prioritize information gathered from multiple sources and reconcile conflicts.Ability to assess the impact of new requirements on Salesforce and other integrated systems.Ability to safely and successfully perform the essential job functions consistent with ADA and all other applicable federal, state, and local standards, including meeting qualitative and/or quantitative productivity standards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Extend OverviewExtend is a rapidly growing fintech startup in the B2B payments space with a focus on serving banks and their customers. We have built the first virtual card platform of its kind, directly integrated with processors, networks, and the technology that supports banking across the industry. We offer several virtual card products including an app-as-a-service that banks can offer business customers with their existing credit cards, a suite of virtual card APIs for those looking to build custom payment solutions, and we also offer secure connectivity to key banking and payment services that enable 3rd-parties to integrate and embed payments into their software.Founded in 2017 by 3 industry experts with experience at Fortune 500 companies, including American Express and Capital One, Extend is headquartered in Manhattan and has recently raised $40m in venture capital from top fintech investors. Extend was recently voted one of America's best startup employers by Forbes and best payments service platform by Tearsheet.With extreme monthly growth and 85+ mission-driven employees, now is prime time to join our team!For more information visitAbout The RoleWe are looking to add a Business Intelligence Analyst to our growing Business Intelligence team; as part of this team, you will be responsible for data reporting, developing analytics and measurement tools, and driving initiatives that help optimize revenue across multiple business segments. You will own much of the Tableau dashboarding and ad hoc data requests. You will also ensure our data remains clean and accurate. You’ll work with the Business Insights team to gather requirements from departments across the company, design new dashboards, and incorporate feedback. This is a hybrid role, based out of our New York City office, with three days on-site.At Extend, you’ll:Create and maintain data tables and Tableau dashboards that allow key stakeholders to view data in a quick and concise manner, effectively communicating insights through visualizations.Manage and resolve ad hoc Business Intelligence requests, developing new tools to automate repetitive tasks.Design metrics, derive data-driven insights, and communicate findings in a concise manner to key stakeholders to help improve business performance.Maintain the integrity of company data and put checks in place to ensure accuracy. Identify and fix data quality issues before reports are generated.Partner with stakeholders across the long/short business to identify data needs and build reporting to inform business decisions.Design data models, ensure data quality, and automate processes where possible.THE CANDIDATE4+ years of previous experience within data analytics or business intelligenceExcellent data visualization skills (Tableau, PowerBI, or software libraries in R or Python)Mastery of SQL and database conceptsThe ability to synthesize information quickly to provide an independent and objective viewpoint, propose appropriate solutions, and drive meaningful changeThe ability to multitask and prioritize assignments while producing high quality work in a demanding, fast-paced environmentStrong written and verbal communication skills to interpret the data and dashboards for those less technically inclinedStrong attention to detail Data curiosity – When you look at data or a visualization, do you ask yourself if the values make sense, or what could be causing something to stand out?The ability to work independently as well as collaborate with a small team and internal clientsWhat We OfferCompetitive compensation packageEquity for all–our success is your successUnlimited vacation–and we want you to use it401K matchingFlexible work optionsComprehensive health coverage for you and your familyMaternity and paternity leave benefitsReimbursement for gym membershipsReferral bonus program–bring your friends!Work with and learn from functional experts across disciplinesThe salary range for this role is $100,000-$140,000. Your final base salary will be determined based on various factors which may include, but are not limited to location, work experience, skills, knowledge, education and/or certifications. You may be eligible to participate in Extend’s annual bonus plan, based on individual and organizational performance.To all recruitment agencies, Extend does not accept agency resumes. Please do not forward resumes to our jobs alias, Extend employees or any other company location. Extend is not responsible for any fees related to unsolicited resumesExtend is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, citizenship or immigration status, or any other status protected by law.Powered by JazzHRIJ33N9DZnA\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " '12860BRNew JerseyJob DescriptionData Analyst:Location : Onshore. Working with clients and preparing the Prologue Financials database for implementation.  Importing and converting client conversion data into Prologue-friendly format, retaining all meaningful data points. Working with client on how to handle any discrepancies or exceptions.  Posting general ledger journal entries as required to adjust data loaded.  Crafting client financial and validation reports through the Prologue report writer and working with the client to resolve any findings.  Partnering with the Business Consultants, Project Managers and Project Team to craft a solution to fulfill and prioritize the client’s business requirements.  Identifying and implementing solutions to automate, or otherwise build efficiencies for, the various steps required for building out client databases – encouraging an environment of continual improvement. QualificationsGraduateRange of Year Experience-Min Year5Range of Year Experience-Max Year8\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Contract Remote Role: Data AnalystDuration: 6 months contract with possible extensionLocation: Newark/Remote (primarily remote with ability to occasionally go on-site when needed).Job DescriptionThis position will support the clients Clean Energy Jobs Program, which includes following:The use of data and interpreting to develop executive reports and power points.Gather the information and statistics, analyze trends, and then use charts and graphs to present the results.Documentation of various processes by collaborating with client QA/QC team.Develop actionable roadmaps for improving workflows and processes and establish and organize KPIs in line with global directives.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data AnalystLocation: Hackettstown, NJ, 07840Duration: 6+ Months(possible extension)Hybrid (at least 2 days in Hackettstown office, possibly 3)Roles & ResponsibilitiesData Analyst is responsible for physical product audit, product data quality, data issues investigation, and is the primary point of contact on data violations and resolutions from the audit process with cross-functional business partners (Sales, Packaging R&D, Master Data, Food Safety & Quality, and Site Quality Control). The analyst is also responsible for the support of Client North America's largest distributor, customer communications, internal GS1 compliance adherence, and data accuracy in our master data systems.Key ResponsibilitiesPerforming the onsite physical product audit (using audit tools and equipment).Data violations documentation.Collaborating with cross-functional teams to address data violations and their resolution.Process improvement.Product data quality certification status support.Maintenance of data accuracy within master data systems (internal and customer front).GS1 compliance adherence monitoring.Driving internal data compliance improvements and external customer satisfaction.Qualifications Education & Professional Qualification:BA/BS degree in Business Operations Management, Systems Management, Finance or related discipline is preferred.OR 3+ years' experience in one or more of the following business areas: logistics, customer care, finance, or master data management. Knowledge/Experience:Ability to work independently, without constant supervisionAdvanced analytical skills and attention to detailExcellent written and verbal communication skillsStrong interpersonal, negotiating, and influencing skillsIntermediate to advanced Excel and/or Smartsheet skillsCustomer Service experienceAbility to learn and work in multiple systemsContinuous improvement/automation recommendations Additional skills preferred, but not required:GS1 Standards knowledgeKnowledge of GTIN Allocation RulesPrior knowledge of SAP preferredData Synchronization guidelines\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Mb Staffing Services is seeking a qualified Data Analyst to assist our DC Based client with data surrounding the Opioid crisis in our region. This is an interesting role and would require the experienced Data Analyst to Respond to inbound calls in a timely and professional manner and follow identified procedures to respond, document, log, and notify the appropriate persons Ensure that reporting remains current Timely and accurate submission of all reports with an error rate no greater than 5%. Perform descriptive analyses of public health data using statistical software (SAS preferred) and produce daily reports and other analytical reports as needed Ensuring data quality and integrity, perform tasks such as electronic file transfers; listing and tabulation of data for preparation of statistical reports; and electronic file linkages Develop analytic datasets (to include, for example, data extraction, data cleaning, matching/merging, and variable coding) and document processes in codebooks, protocols, and associated guidance documents Design databases and tracking systems and monitor data collection activities for multiple surveillance programs Utilize business analytics tools, such as Tableau, to perform data analysis. Support design and recommend content, format, dissemination methods, etc. Maintain and automate reporting applications and visualizations Monitor quality assurance and quality improvement of applicable surveillance and other data systems and processes Develop strategies for improving data processing efficiency, as well as data completeness and quality. Work hours are Monday through Friday 8:30 a.m. to 5:00 p.m. This position is Hybrid Company Description In an era of constant workforce changes, Mb Staffing Services offers something you can count on: The perfect fit! We continue this with a seamless transition. We listen intently. We think strategically. And we act methodically. We respond with speed and an eye to the future! We are a precision placement, results-oriented firm serving a full spectrum of industries and staffing needs.In an era of constant workforce changes, Mb Staffing Services offers something you can count on: The perfect fit! We continue this with a seamless transition. We listen intently. We think strategically. And we act methodically. We respond with speed and an eye to the future! We are a precision placement, results-oriented firm serving a full spectrum of industries and staffing needs.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'JDC -61 Data Analyst, Tallahassee, FLAbout Syra HealthSyra Health Corp. is a pioneering healthcare technology consulting company that develops outcomes-driven solutions having a direct and quantitative benefits to the healthcare industry. We work with payers, health services companies, and life sciences companies to build solutions that create measurable business value and have a positive impact on the lives of their customers. And we are dedicated to cultivating an inclusive culture of respect, honesty, and integrity by embracing the unknown, recognize the value of diversity, and harness the power of enthusiasm.Job SummarySyra Health, a healthcare organization, is seeking a highly skilled Data Analyst to join our team. The ideal candidate will be responsible for analysing and interpreting complex healthcare data sets, including experience in Medicaid data management. The candidate should have advanced knowledge of SQL, and experience working with large data sets. The candidate will be expected to provide actionable insights to inform decision-making and improve patient outcomes.ResponsibilitiesAnalyse and interpret large and complex healthcare data sets, including experience in Medicaid data management.Develop and maintain databases, data systems, and data analytics tools to support data-driven decision-making.Extract qualitative and quantitative relationships (i.e., patterns, trends) from large amounts of publicly available data using SAS, SQL, R, Python, or other statistical toolsIdentify and interpret trends or patterns in data sets.Prepare reports and visualizations that effectively communicate insights and recommendations to management and stakeholders.Collaborate with other teams, including clinical and operational teams, to develop data-driven solutions that improve patient outcomes and reduce costs.Design and implement experiments to test hypotheses and validate assumptions.Ensure data accuracy and completeness by conducting regular data audits.Stay up to date with industry trends, best practices, and regulations related to healthcare data management.RequirementsMinimum of 3 years of experience in data analysis, preferably in healthcare.Experience creating datasets for CMS programs such as MSSP, DCE, or ACO Advanced knowledge of SQL and experience with relational databases.Experience working with Medicaid data and other healthcare data sets.Strong analytical and problem-solving skills.Ability to work independently and in a team environment.Excellent communication and presentation skills.Strong attention to detail and accuracy.Strong hands-on with data visualization tools, such as Tableau or Power BI, is a plus.Careers At Syra HealthOur objective is to make the world a better place by thinking big and seizing opportunities for ourselves, our clients, and our consumers. We are driven by a passion for health and encourage you to be unique, inquisitive, and bold. And by working together, we can increase your contribution on both your career and the world of healthcare.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Summary / Position Purpose: The primary responsibility of this role is to create consolidated reports, dashboards, and data analysis for the internal customers of ACG. This role will be responsible for the day-to-day support, maintenance, and improvement of our CRM and supporting platforms, as well as excel-heavy data-related projects. Their work will involve collecting and cleaning data from multiple sources, running ad hoc reports, building automated dashboards, investigating, and fixing any potential errors/bugs, and working with the Database Administrator to ensure that the information in our database is error-free for accurate reporting. Essential Duties, Functions and/or Responsibilities: Create, validate, and send daily weekly, and monthly management reports.Assistance with requests for non-standard reports and analysisSupport management reporting by maintaining hierarchical information.Perform business-to-system analysis and troubleshooting analysis of complex management reports and business problems.In the report, development lifecycle support impacts analysis and project requirements definitionTransform client needs into functional requirements.With guidance, collect, analyze, and document business requirements for project proposals including but not limited to process and data flow, user interface, and reporting requirements.Together with managers and/or senior analysts, participate in cross-functional meetings to understand customer needs and identify problems and solutions.Appropriate solutions, develop specifications, analyze, and document business processes, validate testing processes, and train the user community.Gather, clean, and transform large data sets to be used in reports and visualization.Design, develop and implement innovative/effective/strategic fully automated business solutions.Works closely with IT and business to incorporate daily automated data refreshing.Develops and provides a standard set of user-friendly reporting tools to internal business customers.Provides maintenance on deployed tools and dashboards.Assist sales & marketing teams with CRM reports and data management, building and maintaining outreach lists for up to several dozen sales and inside sales colleagues.Other duties as assigned.  Education and/or Work Experience Requirements: EDUCATION: Bachelors/4 Yr. DegreeYEARS OF RELEVANT WORK EXPERIENCE: 1+ yearsSalesforce.com (or equivalent CRM) power-user/admin experienceExpert knowledge of Microsoft Office (especially Excel)Demonstrable excel & CRM familiarity with pivot tables and other similar visual reporting tools to display/reconcile large amounts of data.Strong ability to meet deadlines and manage and prioritize simultaneous requests.Creative and analytical thinker with strong problem-solving skillsMust demonstrate ability to communicate effectively verbally and in writing with all levels of the organization.Ability to critically evaluate and prioritize information gathered from multiple sources and reconcile conflicts.Ability to assess the impact of new requirements on Salesforce and other integrated systems.Ability to safely and successfully perform the essential job functions consistent with ADA and all other applicable federal, state, and local standards, including meeting qualitative and/or quantitative productivity standards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'NovoEd builds the next generation of learning technology to offer engaging learning experiences at scale through social collaborative and experiential learning. Our platform is used by enterprise companies including those in the Fortune 500, top universities, training firms, and foundations, around the world to provide experiential and collaborative learning to adult learners. These online learning experiences replicate in-person learning experiences such as workshops that have traditionally been hard to bring online. Social collaboration and peer learning are not only built into our product, but also the DNA of our company. We have a collaborative team with a passion for learning and an amazing culture.The Data Analyst will report to the VP of Product and be a key partner of the R&D, Revenue Operations and Customer Experience teams. The role is expected to provide deep analysis of data and then determine the best way visualize it for customers, business partners and management. This will require solving business problems by customizing the Salesforce and Churn Zero platforms as well as setting up data pipelines using open-source relational database management systems with wysiwyg type tools. The Data Analyst will create metrics and charts using embedded analytics tools, resolve data issues with the quality assurance team, and liaise with the design team on aesthetics and the user experience aspects of dashboards. The Data Analyst will be the owner of the embedded analytics tool, and be responsible for managing the data vendors, including the reporting and resolution of issues.Responsibilities:Manage dashboards, reports and insights for customers as well as the product, sales, marketing, and customer experience teams. Gather requirements, configure changes, design best practice solutions, data governance and reporting for the Salesforce and Churn Zero platforms. Deliver data sources relevant to customer engagement and the use of the NovoEd product into the SaaS product data store; Use APIs or MySQL to bring data in from relevant sources. Design data sets that are performant, can sync data with a lag of at most 30 minutes using a tool like AWS ETL/AWS GLUE. Create metrics and charts using a tool like Tableau, Google and Excel Charts. Generate, evaluate, and improve in-product, problem focused dashboards. Work with Product, Design, Engineering, and Quality Assurance teams to ship dashboards to production systems. Partner with the Product, Revenue Operations, and Customer Success and Support teams to answer specific data questions that are not yet built into the SaaS product. Qualifications:5+ years of experience with MySQL writing complex queries. 3+ years of experience creating and modeling performant data sets as well as deep data analysis. 5+ years of experience building charts and dashboards in tools like Salesforce, Churn Zero and Tableau. Ability to work independently, prioritize workload, and manage cross-functional projects. Advanced technical, analysis and modeling skills in data analytics tools, python and Excel (pivot, VLOOKUP, etc.). Experience using data analytics to support assumptions and develop business cases. Strong communication skills (verbal and written) and interpersonal skills with the ability to translate complex analysis into actionable recommendations. Compelling storytelling and presentation skills. Client centricity, empathy and deep curiosity to find deeper answers to data questions. What will set you apart:Experience working with a wide variety of business data sources. Experience with predictive analytics and data visualizations. Salesforce Administrator experienceNovoEd provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Salary range: The base pay for this role is up to $110k base + bonus. The actual base pay is dependent upon many factors, such as training, skills, work experience, business needs, and location. The base pay range is subject to change and may be modified in the future.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data Analyst Job Description : * Supports and contributes to business analytics projects and processes to provide data-driven insights related to business performance used to advise and develop strategies for operational improvements and future business initiatives. * Uses statistical methods, modeling, analytical methodologies, and data analysis to develop and deploy tools including dashboards, infographics, reports, and models to inform and support decision-making. * Processes, and analyzes internal and external data using KPIs, business results, industry sources, competitor intelligence, and customer information. * Develops a good understanding of the business's model, objectives, issues, and challenges by interacting and collaborating with users and stakeholders. * Typically reports to a supervisor or manager and make sure work is closely managed. * Works on projects/matters of limited complexity in a support role. Qualifications: * Desired a Master's or Bachelor's degree in computer science, information technology, statistics or a quantitative field. * Desired 0-2 years of related experience. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Company Description ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTitle: Data AnalystJob Type: Onsite, Full-time, Hybrid ModelLocation: Irving, TXJob DescriptionFamiliar with Banking Products.Good communications to interact with business clients.Familiar with finance data models data acquisitions.Good in excel Working on collecting and understanding the requirements.Should be well versed on Data Investigation, Data Analysis.Ability to explain functional technical details.Should have good SQL writing capabilities Validate UAT results and identify issue.Should be Independent and resourceful dealing with risks issues and resolving them in a timely manner.About CapgeminiCapgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.Get The Future You Want |\\u202fwww.capgemini.comDisclaimerCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-lawApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Minimum Position Qualifications: * 6 - 8 years' experience with IT initiatives * 4 - 5 years as a data analyst for data related projects; data warehouses, data marts, BI reporting, analytics; experience with migrations from on-prem to cloud a big plus * Thorough knowledge and understanding of systems, procedures, and technology/project life cycles. * Excellent communication and presentation skills to effectively communicate information to customers and to all levels within the organization * A working knowledge of IT Service Management practices. * Hands-on technical knowledge including SQL, or ETL platforms * Hands-on exposure to modern cloud solutions (Azure, Snowflake, ...) Company Description Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That's why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure - even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants' experience so far!Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That’s why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure – even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants’ experience so far! https://fusionalliance.com/careers/spotlight/\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are a Direct Mail and Email Marketing company. We acquire database lists and put them in a format for printing and mailing or emailing. We use Altryx and Excel. Company Description TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The data analyst/report technical writer performs highly advanced work related to special education and special populations data collection and reporting activities and projects.Essential FunctionsDevelops and writes data documentation, analytical requirements, business rules, workflows, and data calendar/timelines for existing and new data projects using simple, clear, unambiguous, and concise languageOversees the planning, design, scope, structure, creation, analysis, and maintenance of SAS programs, datasets, data reporting systems, and reportsDevelops and manages extensive quality assurance and quality control checks of SAS programs and workflows to improve existing programs and processes including comprehensive documentationPlans, studies, researches, and evaluates current information and data systems and recommends changes as neededMinimum RequirementsII. CANDIDATE SKILLS AND QUALIFICATIONSCandidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity. Years Required/Preferred Experience 4 Required Experience with SAS programming or similar statistical programming language 3 Required Education: Graduation from an accredited four-year college or university 3 Required Experience working with administrative data 3 Required Experience developing technical documentation 3 Required Experience with MS Office suite, especially Word and Excel 2 Preferred Experience working with education data\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"ARE YOU HAPPY? ARE YOU VALUED? ARE YOU IN CHARGE OF YOUR FUTURE?Our Mission is to provide products and services, in an honorable way, that exceed the expectations of each one of our clients. We are not like other HVAC companies, Conditioned Air, “The Comfort People since 1962” Success Depends on Employees Like You, who pride themselves in teamwork, professionalism, knowledge, ability, loyalty, and exceeding customer expectations.We Want Our Employees to Thrive and Grow, in a place where a job is more than a job, It Is a Career! Learn while on the job, always preparing to achieve the next step of personal and professional success. We continually invest in you! Named 2019's “Top 500 Companies on the Gulf Coast” by Business Observer and recognized in Gulfshore Magazine’s “Best in Business” several years in a row. Now is the time to Join Our Growing Team! We are now seeking a Data Analyst to work in either our Fort Myers or Naples location.The position works on multiple projects as a subject matter expert in a fast-paced environment for the support of executive management and other internal clients.PLEASE BE AWARE THAT THIS IS AN ON-SITE POSITION IN SWFL, THERE IS NO OPTION FOR REMOTE WORK. IF YOU LIVE IN SWFL OR ARE PLANNING TO RELOCATE, PLEASE APPLY AND YOU WILL BE CONTACTED.Essential Duties and Responsibilities:Creates, analyzes, and utilizes financial data to create reporting related to revenue, sales, and operating metrics/KPINormalizes financial and operational data to maintain appropriate and accurate financial databasesEnhances and refines databases to improve reporting and analysis capabilitiesTracks, reconciles and analyzes variancesCompletes weekly, monthly, quarterly, annual, and ad-hoc management reports and analysisIs the go-to expert regarding system data and report buildingCreate proactive analyses comparing company results to industry data to evaluate program performance.Participates in project teams, analyzing various new programs, projects, or venturesPrepares reports, presentations, and other documents and presents these materials in meetingsIdentify problematic areas and research to determine the best course of action to correct the dataIdentify and research anomalies and outliers in dataPerforms other related duties as assigned or requestedEducation and Experience:BachelorsRequired- 3+ years of experience working in a Data Analyst or Business Analyst RoleAttention to detailCoding skills (SQL)BI tools (Tableau or PowerBI)MS Office (Excel)Critical thinkingAbility to work with technical and non-technical stakeholdersDesire to learn / Intellectual curiosityWANT COMPETITIVE PAY AND GREAT BENEFITS? Look no more, we offer 8 Paid Holidays, Company Paid Basic Life and Long-Term Disability, PTO, Medical, Dental, Vision, supplemental insurance benefits for Accident, Critical Illness, 401(K) Retirement plan, a bonus plan, and above all, a great atmosphere with on-going training and teamwork. For additional information or assistance please visit www.conditionedair.com.Conditioned Air provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.In compliance with the Drug-Free Workplace Act of 1988, Conditioned Air has a longstanding commitment to providing a safe, quality-oriented, and productive work environment. Alcohol and drug abuse pose a threat to the health and safety of Conditioned Air employees and the security of the company’s equipment and facilities. For these reasons, Conditioned Air is committed to the elimination of drug and alcohol use and abuse in the workplace\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Position: Data AnalystLocation: West Chester, PADuration: 12 monthsThe ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users. As part of the Cyber Recovery program it is vital to measure and document multiple recovery scenarios. This position will assist in gathering, evaluating and transforming recovery time information into a formula which can be re-used across multiple scenarios.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with dataCompile and analyze data related to business' issuesDevelop clear visualizations to convey complicated data in a straightforward fashionQualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience1 - 2 years' Data Analysis experienceProficient in SQL\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The Black Tux is reinventing formal wear so people can show up at their best on the days that matter most. We design and manufacture modern rental suits and tuxedos that actually fit—made of 100% wool, ordered online, and delivered for free.As a member of the Data & Analytics team, you will become the company expert on data. Our data is key to the company’s ability to live up to our mission to provide our customers with concierge level service and you will be an integral part of ensuring we succeed. You will work on a variety of projects from utilizing Zendesk data to help the CX team track and plan staffing, to analyzing trends to help showrooms expand and convert customers, and working with our stakeholders and defining key metrics and visibility for performance management. You will work to mainly support stakeholders in the Customer Experience and Showroom teams to help them make smarter, data driven decisions and inform company-wide strategy as we continue to grow.What You'll DoBuild analytics solutions to monitor the health of our business and solve a wide range of business problems to inform data-driven strategic and operational decisionsWork closely with stakeholders to understand business requirements and translate them into technical solutionsCommunicate directly with stakeholders to understand the business, project requirements, and to better ideate analytical solutionsDefine KPIs, develop and own business intelligence dashboards, and provide ongoing tracking and insights to partnersCollaborate with data engineering to ensure that we have accurate sources of truth data to serve needs across our organizationEngage stakeholders to identify obstacles and implement data analytics and tools to help improve their day-to-day business decisions and operationsWho You AreA problem solver that is excited to take on new challenges and, given context, being self-directed and enthusiastic about owning your work autonomouslyYou use SQL every day to help companies understand their operations and make data-driven decisions, preferably with experience working with warehouse, inventory, and/or customer care dataAn empathetic analyst that thrives as a true partner to business stakeholders and understanding their needs, building strong relationships to achieve the shared goal of using analytics and insights to drive the business forwardA storyteller that can use data visualization to communicate insights effectively to a variety of stakeholdersYou show modesty, kindness and support to your team and the people you work withThe Data Analyst role is remote.The base salary for this position will be $95,000 - $105,000, but the actual compensation may vary based on the candidate’s skills, qualifications, and location. The Black Tux defines compensation plans using market data aligned with comparable companies at a similar stage and size as ours.This position also qualifies incentive based compensation which may include a performance based bonus and/or incentive stock options. The Black Tux also offers unlimited PTO on top of generous company holidays, including a winter break at the end of each year.Our people are the most important asset to us. Our benefits, perks, pay and culture reflect this in every decision we make. If you want to learn more about us, check out our Culture Book.We're an equal opportunity employer to all. We interview and hire applicants of all backgrounds, orientations, expressions, and identities.Notice to California Job Applicants disclosed here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionHertz and the Advanced Analytics and Tool Development team is seeking talented individuals with passion for real-world problem solving. The analyst will partner with various functions within the company (Revenue Management, Fleet, Operations) and develop advanced tools and resources to support overall location-level planning and operational decisions. The analyst will be working with large sets of structured and unstructured data to perform analysis, develop tools, and provide actionable insights.What You’ll Be Doing Develop tools for the field for car assignment to optimize upgrade/upsell/booking success.  Develop tools to provide visibility to many of the operational processes.  Conduct analyses to inform stakeholders and help make the most optimal decisions regarding various strategic initiatives.  Code and automate performance reports.  Configure shared PC resources to automate scripts and collect data. What We Expect A Bachelor’s degree; preferably in Data Science, Computer Science, Statistics, Engineering, or another quantitative field.  A demonstrated ability to query and extract findings from large data sets in relational databases such as SQL Server, Teradata, Oracle, etc.  A wide range of data-related technical skills regarding databases, scripts, and web APIs.  Experience with programming/scripting languages like R or Python  Experience with advanced data visualization platforms such as Tableau.  Quick on feet; willingness to discover alternative solutions to technical problems.  A desire to solve complex problems with creative and concise solutions.  Excellent written and oral presentation skills – ability to communicate findings with non-technical stakeholders in concise and simple terms.  An individual who thrives in a collaborative environment. Nice To Haves More than 1 year of work experience in a data driven industry including Rent-A-Car, travel, or service industry  A Master’s degree in a quantitative field  Experience with statistical modeling  Experience with web development languages such as Ruby, PHP, or JavaScript. r work every day represent a significant part of our culture – and our success and reputation as a company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Extend OverviewExtend is a rapidly growing fintech startup in the B2B payments space with a focus on serving banks and their customers. We have built the first virtual card platform of its kind, directly integrated with processors, networks, and the technology that supports banking across the industry. We offer several virtual card products including an app-as-a-service that banks can offer business customers with their existing credit cards, a suite of virtual card APIs for those looking to build custom payment solutions, and we also offer secure connectivity to key banking and payment services that enable 3rd-parties to integrate and embed payments into their software.Founded in 2017 by 3 industry experts with experience at Fortune 500 companies, including American Express and Capital One, Extend is headquartered in Manhattan and has recently raised $40m in venture capital from top fintech investors. Extend was recently voted one of America's best startup employers by Forbes and best payments service platform by Tearsheet.With extreme monthly growth and 85+ mission-driven employees, now is prime time to join our team!For more information visitAbout The RoleWe are looking to add a Business Intelligence Analyst to our growing Business Intelligence team; as part of this team, you will be responsible for data reporting, developing analytics and measurement tools, and driving initiatives that help optimize revenue across multiple business segments. You will own much of the Tableau dashboarding and ad hoc data requests. You will also ensure our data remains clean and accurate. You’ll work with the Business Insights team to gather requirements from departments across the company, design new dashboards, and incorporate feedback. This is a hybrid role, based out of our New York City office, with three days on-site.At Extend, you’ll:Create and maintain data tables and Tableau dashboards that allow key stakeholders to view data in a quick and concise manner, effectively communicating insights through visualizations.Manage and resolve ad hoc Business Intelligence requests, developing new tools to automate repetitive tasks.Design metrics, derive data-driven insights, and communicate findings in a concise manner to key stakeholders to help improve business performance.Maintain the integrity of company data and put checks in place to ensure accuracy. Identify and fix data quality issues before reports are generated.Partner with stakeholders across the long/short business to identify data needs and build reporting to inform business decisions.Design data models, ensure data quality, and automate processes where possible.THE CANDIDATE4+ years of previous experience within data analytics or business intelligenceExcellent data visualization skills (Tableau, PowerBI, or software libraries in R or Python)Mastery of SQL and database conceptsThe ability to synthesize information quickly to provide an independent and objective viewpoint, propose appropriate solutions, and drive meaningful changeThe ability to multitask and prioritize assignments while producing high quality work in a demanding, fast-paced environmentStrong written and verbal communication skills to interpret the data and dashboards for those less technically inclinedStrong attention to detail Data curiosity – When you look at data or a visualization, do you ask yourself if the values make sense, or what could be causing something to stand out?The ability to work independently as well as collaborate with a small team and internal clientsWhat We OfferCompetitive compensation packageEquity for all–our success is your successUnlimited vacation–and we want you to use it401K matchingFlexible work optionsComprehensive health coverage for you and your familyMaternity and paternity leave benefitsReimbursement for gym membershipsReferral bonus program–bring your friends!Work with and learn from functional experts across disciplinesThe salary range for this role is $100,000-$140,000. Your final base salary will be determined based on various factors which may include, but are not limited to location, work experience, skills, knowledge, education and/or certifications. You may be eligible to participate in Extend’s annual bonus plan, based on individual and organizational performance.To all recruitment agencies, Extend does not accept agency resumes. Please do not forward resumes to our jobs alias, Extend employees or any other company location. Extend is not responsible for any fees related to unsolicited resumesExtend is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, citizenship or immigration status, or any other status protected by law.Powered by JazzHRIJ33N9DZnA\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " '12860BRNew JerseyJob DescriptionData Analyst:Location : Onshore. Working with clients and preparing the Prologue Financials database for implementation.  Importing and converting client conversion data into Prologue-friendly format, retaining all meaningful data points. Working with client on how to handle any discrepancies or exceptions.  Posting general ledger journal entries as required to adjust data loaded.  Crafting client financial and validation reports through the Prologue report writer and working with the client to resolve any findings.  Partnering with the Business Consultants, Project Managers and Project Team to craft a solution to fulfill and prioritize the client’s business requirements.  Identifying and implementing solutions to automate, or otherwise build efficiencies for, the various steps required for building out client databases – encouraging an environment of continual improvement. QualificationsGraduateRange of Year Experience-Min Year5Range of Year Experience-Max Year8\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The position’s main responsibility is to manage a variety of data sources and conduct research initiatives as directed by leadership. This role will work with other researchers in the team on specific data queries, provide periodic updates on key statistics from multiple data sources and perform other activities as needed, including survey development and research paper writing. The Senior Research & Data Analyst will also play a major role in building, improving and updating key data sources used by researchers and serve as go-to claims data expert.RequirementsBachelor's degree in statistics, economics, data analytics, epidemiology, data science, data engineering, computer science, market research or other quantitative discipline.A minimum of 3 years of proven experience in/with building datasets using multiple input files and managing or analyzing claims data or similar large datasets.Excellent communication, analytical and interpersonal skills.The ability to shift between multiple projects, work with different team members, seek feedback and clarification, be detail oriented, and think of creative and innovative ways to improve processes and deliverables.Proficiency in SAS software and Microsoft Office Suite.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Contract Remote Role: Data AnalystDuration: 6 months contract with possible extensionLocation: Newark/Remote (primarily remote with ability to occasionally go on-site when needed).Job DescriptionThis position will support the clients Clean Energy Jobs Program, which includes following:The use of data and interpreting to develop executive reports and power points.Gather the information and statistics, analyze trends, and then use charts and graphs to present the results.Documentation of various processes by collaborating with client QA/QC team.Develop actionable roadmaps for improving workflows and processes and establish and organize KPIs in line with global directives.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Genesis10 is seeking a JR SQL Data Analyst for a contract to hire with our client in Plano, TX. \\xa0100% Remote.Job Description:Job responsibilities focus on analyzing, querying, and performing quality assurance on data maintained in a complex relational database environment.Responsibilities:Designs and analyzes data utilizing advanced technical experience with SQL Server technologiesAnalyzes Title Insurance rates and related data maintained in complex relational databasesProduces ad hoc reports and queriesDevelops and maintains familiarity with internal, proprietary SQL Server database structuresWorks collaboratively with database developers and business analysts to identify and resolve data issuesDevelops and maintains familiarity with relevant data reporting and State requirementsAssists in updating in-house proprietary software to reflect required changes to data processing and reporting specificationsParticipates in the development and maintenance of data warehousePerforms testing and validation against software application for quality assurance.Regular consistent attendance is required, that could include attendance at after hour Company events.Ability to accept supervision.Ability to foster, develop and maintain professional and collaborative working relationships. Must be able to get along with others, i.e., peers, supervisors, outside customers, and vendors.Ability to interact effectively and professionally with all levels of management, employees and customers by email, phone and in person.Must be personable, positive, and a professional representative of the Company.Perform other duties as assigned by supervisor.Qualifications:Minimum BS or BA, in computer science or related field; preferred2 - 5 years of experience querying relational databases using SQLStrong PC skills required, including proficiency with Microsoft Windows, Excel, and WordExcellent analytic, interpersonal, and communication skills, especially written communication skillsT-SQL stored procedure development, preferred.Microsoft SQL Server Reporting Services design and development, or similar report design and development experience (e.g. Microsoft Access or Crystal Reports)Querying and/or developing Microsoft Analysis Services (or similar) OLAP databasesExcellent verbal and written communication skills.Excellent interpersonal and customer service skills.Ability to prioritize and handle multiple projects.Strong attention to detail and organizational skills.Proficient in Microsoft Office Suite and Outlook.Compensation:Hourly W2 pay rate $30.00 - $33.00We have access to additional contract, contract-to-hire, and direct hire positions with various rate ranges.\\xa0If you have the described qualifications and are interested in this exciting opportunity, apply today!Ranked a Top Staffing Firm in the U.S. by Staffing Industry Analysts for six consecutive years, Genesis10 puts thousands of consultants and employees to work across the United States every year in contract, contract-for-hire, and permanent placement roles. With more than 300 active clients, Genesis10 provides access to many of the Fortune 100 firms and a variety of mid-market organizations across the full spectrum of industry verticals.For contract roles, Genesis10 offers the benefits listed below. If this is a perm-placement opportunity, our recruiter can talk you through the unique benefits offered for that particular client.Benefits of Working with Genesis10:Access to hundreds of clients, most who have been working with Genesis10 for 5-20+ years.The opportunity to have a career-home in Genesis10; many of our consultants have been working exclusively with Genesis10 for years.Access to an experienced, caring recruiting team (more than 7 years of experience, on average.)Behavioral Health PlatformMedical, Dental, VisionHealth Savings AccountVoluntary Hospital Indemnity (Critical Illness & Accident)Voluntary Term Life Insurance401KSick Pay (for applicable states/municipalities)Commuter Benefits (Dallas, NYC, SF)Remote opportunities availableFor multiple years running, Genesis10 has been recognized as a Top Staffing Firm in the U.S., as a Best Company for Work-Life Balance, as a Best Company for Career Growth, for Diversity, and for Leadership, amongst others. To learn more and to view all our available career opportunities, please visit us at our website.Genesis10 is an Equal Opportunity Employer. Candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data AnalystLocation: Hackettstown, NJ, 07840Duration: 6+ Months(possible extension)Hybrid (at least 2 days in Hackettstown office, possibly 3)Roles & ResponsibilitiesData Analyst is responsible for physical product audit, product data quality, data issues investigation, and is the primary point of contact on data violations and resolutions from the audit process with cross-functional business partners (Sales, Packaging R&D, Master Data, Food Safety & Quality, and Site Quality Control). The analyst is also responsible for the support of Client North America's largest distributor, customer communications, internal GS1 compliance adherence, and data accuracy in our master data systems.Key ResponsibilitiesPerforming the onsite physical product audit (using audit tools and equipment).Data violations documentation.Collaborating with cross-functional teams to address data violations and their resolution.Process improvement.Product data quality certification status support.Maintenance of data accuracy within master data systems (internal and customer front).GS1 compliance adherence monitoring.Driving internal data compliance improvements and external customer satisfaction.Qualifications Education & Professional Qualification:BA/BS degree in Business Operations Management, Systems Management, Finance or related discipline is preferred.OR 3+ years' experience in one or more of the following business areas: logistics, customer care, finance, or master data management. Knowledge/Experience:Ability to work independently, without constant supervisionAdvanced analytical skills and attention to detailExcellent written and verbal communication skillsStrong interpersonal, negotiating, and influencing skillsIntermediate to advanced Excel and/or Smartsheet skillsCustomer Service experienceAbility to learn and work in multiple systemsContinuous improvement/automation recommendations Additional skills preferred, but not required:GS1 Standards knowledgeKnowledge of GTIN Allocation RulesPrior knowledge of SAP preferredData Synchronization guidelines\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Title: Data Analyst Job Description : * Supports and contributes to business analytics projects and processes to provide data-driven insights related to business performance used to advise and develop strategies for operational improvements and future business initiatives. * Uses statistical methods, modeling, analytical methodologies, and data analysis to develop and deploy tools including dashboards, infographics, reports, and models to inform and support decision-making. * Processes, and analyzes internal and external data using KPIs, business results, industry sources, competitor intelligence, and customer information. * Develops a good understanding of the business's model, objectives, issues, and challenges by interacting and collaborating with users and stakeholders. * Typically reports to a supervisor or manager and make sure work is closely managed. * Works on projects/matters of limited complexity in a support role. Qualifications: * Desired a Master's or Bachelor's degree in computer science, information technology, statistics or a quantitative field. * Desired 0-2 years of related experience. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Company Description ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.ASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. ASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners. Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Key Responsibilities: Analyze data sets to determine data gaps Support the team with data analysis, such as data discovery and data usage viability Partner with team on testing with data verification, completeness, and data quality checks. Participate in data driven initiatives, such as data linage, data quality checks, data migrationQualificationsSkills Required: Bachelor's Degree in Computer Science or similar Strong communication skills, both verbal and written Have strong reasoning skills, logical deduction and apply to data analysis Present and be able to tell a story with the data analysis/reporting ?Experience working in SQL and relational databases Self-motivated individual and creative thinker who will take ownership of tasks assigned Ability to problem solve and have creative solutions in challenging environments Able to thrive in a fast-paced, high energy, demanding and team-orientated environment Good customer service skills. Ability to deal with difficult situations gracefully. Microsoft Office Suite: Word, Excel, and PowerPointSkills Desired: Knowledge of trades data, positions data, reference data. Experience with trade lifecycles and asset classes, Equity, Fixed Income, Options, Futures Understanding of Risk or Compliance Systems, such as Actimize, MANTAS, or SungardRate Range: $45-$50/hrPowered by JazzHRvpkaehKEHR\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Bachelor's degree in computer or information scienceStrong background in large-scale, shared data environments. Preferable candidate would have experience in Water/Wastewater space include Water Assets, GIS, Workorder and Asset ManagementExcellent technical abilities, strong communication skills, and strong project management and organizational skillsRelevant technical skills or knowledge may include data modeling, SQL programming (SQL Server or Oracle), and Microsoft OfficeEffective analytical abilities in order to examine existing processes/workflows/dataflows and make recommendations for improvements6 to 8 months possibility of extension\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title:ID - DOPL - Data AnalystLocation: Boise, ID Fully ONSITE Position***DescriptionDOPL needs a Data Analyst to assist with the validation of data in the migration of legacy transaction and documentation data from eleven (11) existing systems into one. In addition, the new consolidated data will form a new historical data set for DOPL in the event not all data is migrated into the new license system.DOPL is implementing an enterprise Licensing Information System (LIS) and is required to migrate both application transaction data (OLTP) and business document content from 11 legacy systems. DOPL is seeking a qualified Data Analyst to work within a cross-functional team that includes IT Staff, a Data Architect, Project Coordinators, and Business Users. This individual will play a key role in the identification, transformation, loading and testing of legacy data during the LIS system implementation phase. The ideal candidate will have experience in data validation, data analysis, business systems analysis, requirement documentation, testing, and effectively working with business stakeholders.ResponsibilitiesValidation of all data being moved from original systems into new systemWorking with business stakeholders to observe processing and capture data requirements.Analyzing legacy databases and identifying application data for migration.Documenting key data entities and attributes in legacy database systems.Working with data migration team to test ETL software and loads.Working with system integrator to ensure data loads are complete and accurate.Thanks,N.TEJASWINI NAIDUTechnical recruiterDirect:404-777-9838 | Fax: 866-608-6686Email: tejaswini.n@stiorg.com | Web: www.stiorg.com100 Overlook Center, Suite 200Princeton, NJ 08540.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionHertz and the Advanced Analytics and Tool Development team is seeking talented individuals with passion for real-world problem solving. The analyst will partner with various functions within the company (Revenue Management, Fleet, Operations) and develop advanced tools and resources to support overall location-level planning and operational decisions. The analyst will be working with large sets of structured and unstructured data to perform analysis, develop tools, and provide actionable insights.What You’ll Be Doing Develop tools for the field for car assignment to optimize upgrade/upsell/booking success.  Develop tools to provide visibility to many of the operational processes.  Conduct analyses to inform stakeholders and help make the most optimal decisions regarding various strategic initiatives.  Code and automate performance reports.  Configure shared PC resources to automate scripts and collect data. What We Expect A Bachelor’s degree; preferably in Data Science, Computer Science, Statistics, Engineering, or another quantitative field.  A demonstrated ability to query and extract findings from large data sets in relational databases such as SQL Server, Teradata, Oracle, etc.  A wide range of data-related technical skills regarding databases, scripts, and web APIs.  Experience with programming/scripting languages like R or Python  Experience with advanced data visualization platforms such as Tableau.  Quick on feet; willingness to discover alternative solutions to technical problems.  A desire to solve complex problems with creative and concise solutions.  Excellent written and oral presentation skills – ability to communicate findings with non-technical stakeholders in concise and simple terms.  An individual who thrives in a collaborative environment. Nice To Haves More than 1 year of work experience in a data driven industry including Rent-A-Car, travel, or service industry  A Master’s degree in a quantitative field  Experience with statistical modeling  Experience with web development languages such as Ruby, PHP, or JavaScript. r work every day represent a significant part of our culture – and our success and reputation as a company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Are you a passionate IT trailblazer - a growth focused, problem solver who takes full ownership of your work, wants to collaborate & co-create with fellow IT experts, innovate, learn new skills, create new solutions & drive your career to the pinnacle of your potential? If so, you will love working with our IT Team - we are constantly innovating to create breakthrough solutions for our client's growth through a vibrant, fun team culture. Read on below to learn more... Featured in CNBC, Digital Journal, Fox News & CIO Review GBSI has been successfully serving the world's top Fortune 500 organizations for the last 18+ years. GBSI IT teams and consultants have delivered more than 568 projects successfully within the automotive, manufacturing, retail & pharmaceutical domains across the world. Headquartered in Moline, IL GBSI's clients and consultants are spread across the US, Canada, Europe & India. Join us to be a part of an ever growing, elite IT team & start building your dream career today! To be a successful Data Analyst you will embody GBSI's core employee characteristics of being passionate about IT, taking full ownership of your work & having a growth mindset. Additionally, you will exhibit strategic vision, thoughtful engagement, strong analytical/process skills, a bias for action, and the ability to partner with senior operational leaders. Work you'll do/Responsibilities: * Develop data strategies * Analyze, interpret and visualize data to deliver insights and solutions * Building relationships with business areas to improve the flow of reporting/explanations and rationale * Working with technology teams, management and/or data scientists to set goals * Mining data from primary and secondary sources * Cleaning and dissecting data to get rid of irrelevant information * Analyzing and interpreting results using statistical tools and techniques * Pinpointing trends and patterns in data sets * Prior experience of working in healthcare domain What qualifications you need: Bachelor's / Master's in IT What will give you an edge: Impeccable written and verbal communication skills in English Passionate, Energetic, Enthusiastic.  Self-Driven, Motivated, Professional, Positive Minded Location Preference: Norfolk, VA Apply today to join us as part of an elite IT team & let GBSI help you build the career of your dreams! We are excited for your growth! Equal Employment Opportunity Statement GeniusBSI is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion, or sexual orientation. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Company Description We are Genius Business Solutions - our clients describe us as a team of passionate IT experts who take full ownership in delivering innovative technology solutions. At GBSI, we exist to simplify technology so that businesses can innovate faster & accelerate growth. With over 18 years of successful IT experience, GBSI is headquartered in Moline, Illinois & has clients and consultants working across the United States, Canada, India & Europe. We help some of the world's top organizations in manufacturing, automotive, software & IT and pharmaceutical domains in implementing software solutions, ensuring IT quality assurance, develop high quality custom applications & AMS support services. GBSI is a certified SAP partner & featured in multiple top publications including CNBC, Fox News, Digital Journal & MarketWatch. ERP Consultants, Developers, Software Engineers and QA experts, we invite you to join our teams & create the best version of you. As IT experts, our teams are committed to developing & delivering highest quality services in: - Technology Consulting - Digital Strategy & IT Modernization - Implementing Global IT Solutions - Next Gen Developments & AMS Support ServicesWe are Genius Business Solutions - our clients describe us as a team of passionate IT experts who take full ownership in delivering innovative technology solutions. At GBSI, we exist to simplify technology so that businesses can innovate faster & accelerate growth. With over 18 years of successful IT experience, GBSI is headquartered in Moline, Illinois & has clients and consultants working across the United States, Canada, India & Europe. We help some of the world's top organizations in manufacturing, automotive, software & IT and pharmaceutical domains in implementing software solutions, ensuring IT quality assurance, develop high quality custom applications & AMS support services. GBSI is a certified SAP partner & featured in multiple top publications including CNBC, Fox News, Digital Journal & MarketWatch. ERP Consultants, Developers, Software Engineers and QA experts, we invite you to join our teams & create the best version of you. As IT experts, our teams are committed to developing & delivering highest quality services in: - Technology Consulting - Digital Strategy & IT Modernization - Implementing Global IT Solutions - Next Gen Developments & AMS Support Services\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Extend OverviewExtend is a rapidly growing fintech startup in the B2B payments space with a focus on serving banks and their customers. We have built the first virtual card platform of its kind, directly integrated with processors, networks, and the technology that supports banking across the industry. We offer several virtual card products including an app-as-a-service that banks can offer business customers with their existing credit cards, a suite of virtual card APIs for those looking to build custom payment solutions, and we also offer secure connectivity to key banking and payment services that enable 3rd-parties to integrate and embed payments into their software.Founded in 2017 by 3 industry experts with experience at Fortune 500 companies, including American Express and Capital One, Extend is headquartered in Manhattan and has recently raised $40m in venture capital from top fintech investors. Extend was recently voted one of America's best startup employers by Forbes and best payments service platform by Tearsheet.With extreme monthly growth and 85+ mission-driven employees, now is prime time to join our team!For more information visitAbout The RoleWe are looking to add a Business Intelligence Analyst to our growing Business Intelligence team; as part of this team, you will be responsible for data reporting, developing analytics and measurement tools, and driving initiatives that help optimize revenue across multiple business segments. You will own much of the Tableau dashboarding and ad hoc data requests. You will also ensure our data remains clean and accurate. You’ll work with the Business Insights team to gather requirements from departments across the company, design new dashboards, and incorporate feedback. This is a hybrid role, based out of our New York City office, with three days on-site.At Extend, you’ll:Create and maintain data tables and Tableau dashboards that allow key stakeholders to view data in a quick and concise manner, effectively communicating insights through visualizations.Manage and resolve ad hoc Business Intelligence requests, developing new tools to automate repetitive tasks.Design metrics, derive data-driven insights, and communicate findings in a concise manner to key stakeholders to help improve business performance.Maintain the integrity of company data and put checks in place to ensure accuracy. Identify and fix data quality issues before reports are generated.Partner with stakeholders across the long/short business to identify data needs and build reporting to inform business decisions.Design data models, ensure data quality, and automate processes where possible.THE CANDIDATE4+ years of previous experience within data analytics or business intelligenceExcellent data visualization skills (Tableau, PowerBI, or software libraries in R or Python)Mastery of SQL and database conceptsThe ability to synthesize information quickly to provide an independent and objective viewpoint, propose appropriate solutions, and drive meaningful changeThe ability to multitask and prioritize assignments while producing high quality work in a demanding, fast-paced environmentStrong written and verbal communication skills to interpret the data and dashboards for those less technically inclinedStrong attention to detail Data curiosity – When you look at data or a visualization, do you ask yourself if the values make sense, or what could be causing something to stand out?The ability to work independently as well as collaborate with a small team and internal clientsWhat We OfferCompetitive compensation packageEquity for all–our success is your successUnlimited vacation–and we want you to use it401K matchingFlexible work optionsComprehensive health coverage for you and your familyMaternity and paternity leave benefitsReimbursement for gym membershipsReferral bonus program–bring your friends!Work with and learn from functional experts across disciplinesThe salary range for this role is $100,000-$140,000. Your final base salary will be determined based on various factors which may include, but are not limited to location, work experience, skills, knowledge, education and/or certifications. You may be eligible to participate in Extend’s annual bonus plan, based on individual and organizational performance.To all recruitment agencies, Extend does not accept agency resumes. Please do not forward resumes to our jobs alias, Extend employees or any other company location. Extend is not responsible for any fees related to unsolicited resumesExtend is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, citizenship or immigration status, or any other status protected by law.Powered by JazzHRIJ33N9DZnA\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " '12860BRNew JerseyJob DescriptionData Analyst:Location : Onshore. Working with clients and preparing the Prologue Financials database for implementation.  Importing and converting client conversion data into Prologue-friendly format, retaining all meaningful data points. Working with client on how to handle any discrepancies or exceptions.  Posting general ledger journal entries as required to adjust data loaded.  Crafting client financial and validation reports through the Prologue report writer and working with the client to resolve any findings.  Partnering with the Business Consultants, Project Managers and Project Team to craft a solution to fulfill and prioritize the client’s business requirements.  Identifying and implementing solutions to automate, or otherwise build efficiencies for, the various steps required for building out client databases – encouraging an environment of continual improvement. QualificationsGraduateRange of Year Experience-Min Year5Range of Year Experience-Max Year8\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Genesis10 is seeking a JR SQL Data Analyst for a contract to hire with our client in Plano, TX. \\xa0100% Remote.Job Description:Job responsibilities focus on analyzing, querying, and performing quality assurance on data maintained in a complex relational database environment.Responsibilities:Designs and analyzes data utilizing advanced technical experience with SQL Server technologiesAnalyzes Title Insurance rates and related data maintained in complex relational databasesProduces ad hoc reports and queriesDevelops and maintains familiarity with internal, proprietary SQL Server database structuresWorks collaboratively with database developers and business analysts to identify and resolve data issuesDevelops and maintains familiarity with relevant data reporting and State requirementsAssists in updating in-house proprietary software to reflect required changes to data processing and reporting specificationsParticipates in the development and maintenance of data warehousePerforms testing and validation against software application for quality assurance.Regular consistent attendance is required, that could include attendance at after hour Company events.Ability to accept supervision.Ability to foster, develop and maintain professional and collaborative working relationships. Must be able to get along with others, i.e., peers, supervisors, outside customers, and vendors.Ability to interact effectively and professionally with all levels of management, employees and customers by email, phone and in person.Must be personable, positive, and a professional representative of the Company.Perform other duties as assigned by supervisor.Qualifications:Minimum BS or BA, in computer science or related field; preferred2 - 5 years of experience querying relational databases using SQLStrong PC skills required, including proficiency with Microsoft Windows, Excel, and WordExcellent analytic, interpersonal, and communication skills, especially written communication skillsT-SQL stored procedure development, preferred.Microsoft SQL Server Reporting Services design and development, or similar report design and development experience (e.g. Microsoft Access or Crystal Reports)Querying and/or developing Microsoft Analysis Services (or similar) OLAP databasesExcellent verbal and written communication skills.Excellent interpersonal and customer service skills.Ability to prioritize and handle multiple projects.Strong attention to detail and organizational skills.Proficient in Microsoft Office Suite and Outlook.Compensation:Hourly W2 pay rate $30.00 - $33.00We have access to additional contract, contract-to-hire, and direct hire positions with various rate ranges.\\xa0If you have the described qualifications and are interested in this exciting opportunity, apply today!Ranked a Top Staffing Firm in the U.S. by Staffing Industry Analysts for six consecutive years, Genesis10 puts thousands of consultants and employees to work across the United States every year in contract, contract-for-hire, and permanent placement roles. With more than 300 active clients, Genesis10 provides access to many of the Fortune 100 firms and a variety of mid-market organizations across the full spectrum of industry verticals.For contract roles, Genesis10 offers the benefits listed below. If this is a perm-placement opportunity, our recruiter can talk you through the unique benefits offered for that particular client.Benefits of Working with Genesis10:Access to hundreds of clients, most who have been working with Genesis10 for 5-20+ years.The opportunity to have a career-home in Genesis10; many of our consultants have been working exclusively with Genesis10 for years.Access to an experienced, caring recruiting team (more than 7 years of experience, on average.)Behavioral Health PlatformMedical, Dental, VisionHealth Savings AccountVoluntary Hospital Indemnity (Critical Illness & Accident)Voluntary Term Life Insurance401KSick Pay (for applicable states/municipalities)Commuter Benefits (Dallas, NYC, SF)Remote opportunities availableFor multiple years running, Genesis10 has been recognized as a Top Staffing Firm in the U.S., as a Best Company for Work-Life Balance, as a Best Company for Career Growth, for Diversity, and for Leadership, amongst others. To learn more and to view all our available career opportunities, please visit us at our website.Genesis10 is an Equal Opportunity Employer. Candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'We have an excellent contract opportunity for a Junior Data Analyst in New York City! If you want to have a big client\\'s name on your resume, this is your opportunity! The AMI Meter Installation Issues Group (MIIG) of our Client is looking for a temporary resource to support the team in reviewing a large data set of meter installation issues and being able to channel the work in and out of our client\\'s database. Excel is the primary application used by various work groups for tracking the progress of the installation.  Basic training in the use of Excel will not be provided as the applicant is expected to be proficient. Other responsibilities are:The Consultant must be proficient in analyzing and reviewing large data sets in Excel and demonstrate proficiency in using formulas (such as and not limited to Vlookup, Pivot Tables, Graphs, and Charts) to efficiently manipulate the data so that it can be imported into the database Will review and process large sets of data in the various Client databases and must be proficient in using Excel, PowerPoint, Access database, SQL, and TableauWill work independently as well as on a team - Must be self-motivatedThe Consultant will learn the functions of AMI and the Legacy applications used by the team with proper training and be able to communicate with end-user customers to resolve issues, and gaps, and collect dataWill be interacting with other vendors on the MIIG team and will be managing the database that is used to issue escalation work for the team to review and be able to receive the data in return and update the databaseThe Consultant must be flexible and able to work onsite for the first few weeks for onboarding and training. After the onboarding, we can consider transiting to a hybrid work schedule (3 days in the office and 2 days remote)The Consultant will be responsible for managing the database for tracking legacy meters to upgrade and the tracking of work for the different work streamsThe Consultant will be also responsible for managing the work of other MIIG analysts by issuing work from the database and importing reviews completed by the MIIG analyst into the databaseDevelop and deliver PowerPoint presentations to communicate status, work scope, and workflow This is an hourly position with opportunity for overtime.All Candidates Must be Authorized to Legally Work in the US Without Sponsorship**Mandatory Qualifications: (Please read carefully. They MUST be shown on your resume)Must be proficient in Access database, PowerPoint, SQL, and Tableau, Must be proficient in Excel working with Vlookup, Pivot Tables, Graphs, and ChartsMust have strong communication skills with all stakeholders (verbal and written)Must have the ability to draft documentsMust have the ability to clearly communicate technical issues and potential resolution pathsBachelor\\'s degree and 2 years of relevant work experience OR, Associates Degree and 5 years of relevant work experienceProduce high-quality work and check work frequentlyAgile, self-motivatedMust be able to work in a team and as an individual contributorExperience developing and delivering PowerPoint presentations to communicate status, work scope, and workflowPreferably with Legacy Experience $500 Referral Fee Program Earn extra cash while helping your friends!VTS3 will pay you up to $500.00 for each person you refer to us and we place into a contract or full-time position. If you know someone who\\'s a good candidate for any of our openings, use the \"Refer a friend\" button on this page and earn extra cash.The rules are simple:The referral must be made by using the \"Refer a friend\" button on this pageThe person you refer must be placed within 90 days of being referredThe person you refer must complete 480 billable hoursCannot be someone we already have on our team or are currently working withPowered by JazzHRHi7bfAh9Zp\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data AnalystLocation: Hackettstown, NJ, 07840Duration: 6+ Months(possible extension)Hybrid (at least 2 days in Hackettstown office, possibly 3)Roles & ResponsibilitiesData Analyst is responsible for physical product audit, product data quality, data issues investigation, and is the primary point of contact on data violations and resolutions from the audit process with cross-functional business partners (Sales, Packaging R&D, Master Data, Food Safety & Quality, and Site Quality Control). The analyst is also responsible for the support of Client North America's largest distributor, customer communications, internal GS1 compliance adherence, and data accuracy in our master data systems.Key ResponsibilitiesPerforming the onsite physical product audit (using audit tools and equipment).Data violations documentation.Collaborating with cross-functional teams to address data violations and their resolution.Process improvement.Product data quality certification status support.Maintenance of data accuracy within master data systems (internal and customer front).GS1 compliance adherence monitoring.Driving internal data compliance improvements and external customer satisfaction.Qualifications Education & Professional Qualification:BA/BS degree in Business Operations Management, Systems Management, Finance or related discipline is preferred.OR 3+ years' experience in one or more of the following business areas: logistics, customer care, finance, or master data management. Knowledge/Experience:Ability to work independently, without constant supervisionAdvanced analytical skills and attention to detailExcellent written and verbal communication skillsStrong interpersonal, negotiating, and influencing skillsIntermediate to advanced Excel and/or Smartsheet skillsCustomer Service experienceAbility to learn and work in multiple systemsContinuous improvement/automation recommendations Additional skills preferred, but not required:GS1 Standards knowledgeKnowledge of GTIN Allocation RulesPrior knowledge of SAP preferredData Synchronization guidelines\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About UsWho We AreSitting at the intersection of social networking and gaming, we empower creativity and connection in a digital world. Our mission is to build deep, rich virtual worlds where everyone belongs.We have been working towards this mission for a decade. We are the creators of Highrise, the first virtual world on mobile, which has seen extraordinary growth over the last few years and now boasts over 20 million users across iOS and Android. Every day, the citizens of Highrise come together to hangout, explore, create, collect, and trade in our metaverse, and we are on the precipice of making history once again with our expansion into Highrise World.Our PurposeTo build creative worlds where you belong.About This RoleThis is a cross-functional role and you will be reporting to Anton Bernstein, CEO. (Please note that if you reach out to Anton, they may not reply due to the volume of messages received.)In this role, you will build out marketing and product reports, analyze data, learn and establish data best practices, as well as collaborate with artists to generate high-performing live operations and marketing creatives.This is an analytical role that requires a passion for data analysis and reporting. You must have strong knowledge of SQL and Python. You will be working collaboratively with various teams including Live Operations, Marketing and Product.Your MissionThe mission of this role is to deliver key reports and interpret data to provide valuable insights into Highrise features and player behavior. This data will help us make decisions around in-game content releases, marketing performance, feature development, and more.Key Indicators of SuccessYou will be the go-to person for data analytics questions from the Live Operations, Marketing, Product and Art teams. You will provide timely and easy-to-understand insights to different stakeholdersYou will turn raw data into actionable insight and recommendations that will be crucial to Highrise's features, tools, and overall business successYou will leverage tools like Amplitude, Looker, Periscope and more in order to create insightful dashboards for different teamsWhat You Will DoYou will build, design, and maintain reports and dashboardsYou will work with data and perform “deep dive” analyses on various topics such as player journeys, live events, user acquisition, etcYou will work closely with product and marketing teams to review data and extract storylines & trends aligned to Highrise growthYou will identify trends and behaviors that influence performance and player engagementWhat You Can Expect in the First 90 Days30 Days: In the first 30 days, you'll become familiar with the scope of work of the different teams: product, live operations, marketing, and art. Additionally, you'll get to know the analytics infrastructure60 Days: In the first 60 days, you’ll start building dashboards and reporting based on team needs. You will begin working with live operations and marketing to craft questions and answer them with data90 Days: In the first 90 days, you will take ownership of analytical insight. You will use data proactively and present your findings to the teamWho You AreYou have the ability to collect, clean, and analyze data, and turn it into meaningful insights and recommendationsYou have excellent written and oral communication skills with the ability to explain complex data clearlyYou have the ambition to own the reporting and analysis functions for the Highrise metaverseYou have an entrepreneurial mindsetMust Have'sA university degree in Computer Science, Math, Economics, Statistics, or other quantitative fields2+ years of hands-on experience in quantitative analysis and a proven track record of significantly impacting product growth by providing data findingsExtensive knowledge of relational databases, SQL, Python and working with large datasetsExperience with data analytics for mobile apps, gaming products, or e-commerceNice to Have'sYou are familiar with technologies such as Amplitude, AWS, and Redshift to build and optimize production data pipelinesYou have an understanding of machine learning and data scienceBenefitsMeaningful equity in an extremely fast-growing startupEquipment allowance so you can choose whatever you need to work comfortablyCompany-sponsored medical and dental insuranceUnlimited Vacation policy. We know how important taking time off is and we encourage it. Our team takes about 20 days off on average every yearEducation stipend. We deeply believe in learning and self-improvement. We've set aside a budget for every employee to learn additional skills and growMonthly Fitness Allowance to stay active and take care of your physical healthPerksWorking with a diverse team of people in over 15 countriesYou have a voice! We love hearing ideas and want to embrace you for themExtremely low turnover environment. Over 20% of our team has been here for over 3 years!Coworking space stipend in whichever location you wantMonthly team building budget to get to know your teamTeam retreats to meet face-to-face and deepen connectionBring your pet to work everyday! We love seeing your furry loved onesA Highrise Admin badge for your avatarCompensation PhilosophyAs a fully remote company, we strive to have an equitable compensation philosophy that allows us to take good care of our people, no matter where they are in the world. At the moment, our philosophy is composed of multiple factors such as market pay, location, performance, and other rewards. Our compensation philosophy is meant to support our organization’s strategic plan and operating objectives — as we continue to grow as a company, so will our approach to compensation.The salary range for this role is $75,000 -$120,000 in US and Canada. Salary will be adjusted based on your location.What its Really Like to Work HereOur CultureWe are a global team of nearly 100 people right now and rapidly growing. We feel a sense of ownership over our work and take great pride in what we do. We are not afraid to make, and most importantly, admit our mistakes — that allows us to show up authentically and build relationships of trust across the board. We are the scrappy kind, so we try to do more with less, and we love that! If you were to ask our team to describe our culture, they would probably say we are a passionate group of peeps trying to impact the next revolution of the internet.Our ValuesDream big, then make it real.Be an owner, make a difference.Build with humility.Fast is better than slow.Keep it scrappy.Always be learning.Read more about our values here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About the Company:Built by the number-one sales trainer in the world, Cardone Training Technologies has become one of the most trusted names in the sales industry. For over thirty years, Grant Cardone has helped companies expand sales, increase transaction profitability, and reduce turnover all by disrupting the status quo by implementing his proven, industry-leading processes, through management, and training technology. Founded and led by CEO, Grant Cardone, a New York Times bestselling author, international social media influencer, renowned speaker, trainer and coach to fortune 500 companies as well as a real estate mogul, Cardone Training Technologies takes a cutting-edge, disruptive approach to sales, marketing, social media and consulting to give businesses an opportunity to increase their revenue and expand their market share.Event Data Analyst Responsibilities:Manage, monitor, track and report on all eventsPerform event registration maintenance in our proprietary ticketing system including responding to attendee’s questions, making registration changes and providing updates to team members and clientsSet registration rules/parameters (early bird rates and dates, etc.) based on experience and past year’s registration data analysisProvide analysis and new ideas/testing using this information to upper managementCommunicate with clients and partners in a professional mannerCommunicate all necessary automations with the web team to streamline processesProvide reports to help increase sales and tacticsTransform data into a digestible and presentable story based on ticketed, redeemed and confirmed attendees and confidently / effectively communicate that information with the Executive TeamProactively drive responsibilities and self-manage to the highest quality standardsBe available for occasional work travel and weekend workExperience, Competencies and Education:Advanced Excel and Google Sheets skills including pivot tables, V-lookups, ability to build complex formulasExcellent written and verbal communication skillsStrong analytical and data interpretation skills and the ability to interact with all levels of the organizationExperience in Shopify and Hubspot - desired but not requiredExceptional attention to detail and excellent coordination and organization skills, with the ability to manage multiple inputs and to organize data effectivelyYou have demonstrated the ability to work in a global and fast paced environment and remain calm in times of pressure This is full-time Monday to Friday 9am to 6pm, with additional hours/times as needed Cardone Enterprises is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"At DDC (www.ddcpublicaffairs.com) we provide public affairs solutions that enable our clients to identify, manage and communicate with their political assets and advocates around the globe. Through a unique blend of professional services and technology solutions, we establish rich connections with targeted audiences and empower our clients to win on their public policy campaigns.Currently, we are looking for a Data Analyst to join our downtown, Washington, DC office.About The RoleAs a Data Analyst working at DDC, you'll work alongside our internal teams and support our clients, both in an ad-hoc/on-demand manner, and by managing existing frameworks within our ecosystem. In this role, you will have the ability to work well and collaborate within a team and excel in a fast-paced, client intensive environment.What You'll Be DoingDesign and implementation of SQL queriesCreation and editing of SSRS reportsDesign, creation, and execution of automated and manual SSIS packagesManipulation and transformation of client data using various SQL toolsTroubleshoot and resolve data related issuesAbout YouYou are an initiative-taker and can work independently as necessary.You possess a drive to make things better and the aptitude to do so.Relational Database (specifically MS-SQL) experience, SSIS, SSRS, T-SQLExperience with data validation, data file manipulation, report creation, data extraction (ETL/ELT)Strong communication and organizational skillsCollege degree strongly preferred, or you have equivalent professional experienceProgramming background, Crystal Reports experience, and Geo-Spatial (mapping) experience is a plusAbout DDCSince our founding in 1996, DDC has grown to become the largest full-service Public Affairs agency in the country. Through our unique blend of professional services and technology solutions, we establish rich connections with targeted audiences and empower our clients to build the relationships necessary to win on their public policy campaigns. We are committed to ensuring each member of our team is a key contributor, and support that by fostering a collaborative work environment and entrepreneurial spirit throughout the organization.DDC is proud to be part of the Omnicom Group Inc. (www.omnicomgroup.com). Omnicom is a leading global marketing and corporate communications company. Omnicom’s branded networks and numerous specialty firms provide advertising, strategic media planning and buying, digital and interactive marketing, direct and promotional marketing, public relations, and other specialty communications services to over 5,000 clients in more than 100 countries.Agency Information And Submission RequirementsDDC has offered a hybrid work environment for many years. This position will be based in our downtown Washington, D.C.The anticipated salary range for this position is $60,000 – $85,000 per year.Salary is based on a range of factors that include relevant experience, knowledge, skills, other job-related qualifications, and geography. A range of medical, dental, vision, 401(k) matching, paid time off, and/or other benefits also are available. Employees from diverse or underrepresented backgrounds are encouraged to apply.DDC is an Equal Opportunity Employer M/F/Disability/ProtectedVet EEO Statement DDC Public Affairs is committed to equal employment opportunity and affirmative action. DDC Public Affairs does not discriminate in any aspect of employment on the basis of race, color, religion, national origin, ancestry, gender, sex, sexual orientation, gender identity and/or expression, age, veteran status, disability, or any other characteristic protected by federal, state, or local employment discrimination laws where DDC Public Affairs does business. Our policy is to employ, advance, and reasonably accommodate all qualified employees and applicants. Any person who feels that he or she has been subjected to discrimination should immediately report the matter to Talent Development or to a supervisor.Any reported incident will be investigated. Retaliation against an employee or applicant who makes a good-faith claim of discrimination is prohibited. Employees and applicants may bring good-faith complaints, ask questions, and raise concerns without fear of reprisal or retaliation.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job Summary: The Database Analyst will maintain data storage; assess database design; and gather, organize, and interpret statistical information based on the data in the database. Duties/Responsibilities: Oversees database development and modification efforts Designs and implements secure, efficient, and accurate databases Maintains current and accurate knowledge of data storage and management best practices Ensures that databases are designed to meet specifications and requirements at the lowest possible costs Ensures that database projects are completed on time and within estimated costs Develops and maintains documentation and standards Assists Senior Database Analyst and identifies and resolves production and/or applications development problems related to the use of the database management system software or utilities Gathers, organizes, and interprets statistical data from the database to provide reports to, and answer questions from, upper management Performs other related duties as assigned Required Skills/Abilities: Excellent verbal and written communication skills Proficient in Microsoft Office Suite or related software Tableau, Power BI, SQL, Microsoft Office, Data Verification Excellent organizational skills and attention to detail Understanding of computer languages used within database Understanding of database design and construction Education and Experience: Bachelor's degree in Business Administration, Statistics, Mathematics, Accounting, or Computer Science or equivalent work experience required At least three years in Data Processing, with at least two years of experience with database management systems; OR two years as a development programmer/analyst using database techniques under IMS/DB-DL/1 required Physical Requirements: Prolonged periods sitting at a desk and working on a computer Must be able to lift up to 15 pounds at times Company Description Detroit Chassis, a subsidiary of SPECTRA LLC, produces rolling chassis, complex subassemblies and modules, and complete vehicles for the automotive, RV and commercial truck industries, with one stop design and engineering solutions. Detroit Chassis, a subsidiary of SPECTRA LLC, produces rolling chassis, complex subassemblies and modules, and complete vehicles for the automotive, RV and commercial truck industries, with one stop design and engineering solutions.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"National Grid Renewables, which includes the renewables development company formerly known as Geronimo Energy, is a leading North American renewable energy company based in Minneapolis, Minnesota, with satellite offices located in the regions where it develops, constructs, and operates renewable energy projects. As a farmer-friendly and community-focused company, National Grid Renewables develops projects for corporations and utilities that seek to repower America’s electricity grid by reigniting local economies and reinvesting in a sustainable future. National Grid Renewables is part of the competitive, unregulated Ventures division of National Grid and has a portfolio of solar, wind, and energy storage projects located throughout the United States in various stages of development, construction, and operation. National Grid Renewables develops high-value, competitive renewable energy projects. Our focus on communities and farmers means it’s not just about projects, but about the people we work with, both outside and inside our organization. National Grid Renewables Team Members embody our foundational culture of being entrepreneurial, creative, and nimble and take pride in supporting National Grid’s vision to be at the heart of a clean, fair, and affordable energy future for all.   National Grid Renewables is seeking a Senior Data Analyst to join our growing IT Operations Team. This role will provide the technical knowledge necessary to drive forward our organization's cloud-based infrastructure initiatives as we align our processes and technologies. RoleReview and validate business critical data as it is collectedOversee the deployment of data to the Microsoft Azure DatalakeManaging and designing the reporting environment, including data sources, security, and metadataSupporting the data warehouse in identifying and revising reporting requirementsDevelop policies and procedures for the collection and analysis of dataCollaborate with IT for data mapping and integration via Microsoft Azure to leverage big data use casesProviding technical expertise in data storage structures, data mining, and data cleansingTroubleshooting the reporting database environment and reportsAnalyze business processes and requirementsIdentify opportunities to improve processes and strategies with technology solutionsIdentify development needs to improve streamline operationsCreate reports for business stakeholders using tools such as Microsoft Power BIMonitor analytics and metrics resultsImplement new data analysis methodologiesReview organizational data to ensure integrity of data collection and utilizationPerform data profiling to identify and understand anomaliesCollaborate with business usersTraining end-users on new reports and dashboards  Background and SkillsBachelor's degree in Management/Computer Information Systems (MIS/CIS), Computer/Electrical Engineering, Computer Science, or related fields.5+ years as a Data AnalystAbility to build strong data models and relational databasesStrong data mining techniquesSQL experiencePower Query, PowerBI and data visualizationStrong understanding DatalakesStrong understanding of DatabricksDatabase management and reportingBusiness administrationMicrosoft Office and ExcelCritical-thinking and problem-solvingStrong Communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Position:\\u202fSenior Data Analyst\\u202fLocation:\\u202f\\u202fRemoteAbout Us:\\u202f\\u202fFIA Tech is a dynamic and growing Software-as-a-Service technology company which supports over 8,000 global finance and trading firms. Our customers depend on our solutions which connect the global futures and derivatives industry for trade processing and regulatory compliance needs.\\u202fPosition Description:\\u202f\\u202fWe are looking for an experienced Senior Data Analyst to join our team. The Senior Data Analyst will be responsible for analyzing large datasets, creating reports to support business decisions, and maintaining operational processes. The Senior Data Analyst will also be involved in developing and maintaining data pipelines, ensuring data accuracy, and providing insights to stakeholders. The main role will focus on day-to-day quality assurance and management of our reference data\\u202fproducts\\u202falong with overseeing our offshore counterpart.\\u202f Outside of day-to-day operations, this role will have the dual responsibility of\\u202fassisting on\\u202fkey projects related to the firm’s reference data initiatives. Responsibilities:Monitor global derivatives exchanges and financial regulatory authority sites for current and upcoming events affecting globally listed exchange listed derivative products.Track and help manage team’s daily workflow. Identify and communicate high priority items to onshore team, and assure data is validated and quality checked for time-sensitive tasks.\\u202fExecute data analysis plans, monitoring data accuracy and integrity, to support firm wide business objectives.\\u202fAssist in the design, development and maintenance of ETL processes to ensure data accuracy and integrity.Create reports to communicate data quality status, working cross functionally to maintain high level data standards.Qualifications/ Preferred Experience:3-4\\u202fyears of experience in Financial Services and/or Banking Operations. Experience\\u202fand subject matter expertise\\u202fwith\\u202ffinancial derivative\\u202fproducts\\u202fis\\u202fpreferred.Knowledge of data quality and ETL best practicesAbility to communicate complex technical concepts to a variety of audiences.Attention to detail and excellent organizational skills.Proficiency in Microsoft Office Products.Experience with SQL, Python preferred.\\u202fBachelor's\\u202fdegree in Business, Economics, Finance, Accounting or related field\\u202fCompensation $80,000 - 90,000 - bonus eligible\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Skill/RequirementJob DescriptionNew graduate or individual with 1-2 years of experience with Geographic Information Systems (GIS) tools such as QGIS; basic familiarity with land cover classification methodologies. Knowledge of one or more scripting languages such as Python to automate GIS processing, data analysis and image processing is a plus.ResponsibilitiesJOB Description:Execute manual analytics steps and assist Data Scientists with data and result analysis & quality control for the LandVisor Brazil product. Assess patterns in data acquisition and model output for larger scale workflow improvementsProject scope:-Data analysis support and quality control for consumer-facing product and research projects, particularly QA and editing of data inputs and quality assurance of model outputs. Automation of data acquisition and result delivery.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionTitle: Data AnalystJob Type: Onsite, Full-time, Hybrid ModelLocation: Irving, TXJob DescriptionFamiliar with Banking Products.Good communications to interact with business clients.Familiar with finance data models data acquisitions.Good in excel Working on collecting and understanding the requirements.Should be well versed on Data Investigation, Data Analysis.Ability to explain functional technical details.Should have good SQL writing capabilities Validate UAT results and identify issue.Should be Independent and resourceful dealing with risks issues and resolving them in a timely manner.About CapgeminiCapgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.Get The Future You Want |\\u202fwww.capgemini.comDisclaimerCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-lawApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Must be onsite from day 1- Must be based in EST zone.Duration: 6-12+ monthVisa: GC/USC/GC-EAD/H4EADMust have a valid LinkedIn profileThe project will be improving the IVR experience for the client external customers. This role will pull data to help build use cases and 'how to handle' based on those use cases. The work will be done to determine WHY the customer is callingThis role will have to find the needed data in different systems in Charter. The manager is building this new role on his team and this role has to hunt/gather the data, then work with the developers to map to the existing systems.Required Skills Kafka, APIs, ETL Jobs, Understanding how to map the data to the billing systems, customer records etc Critical Thinking Skills as it relates to data and locations Basic data analyst skillsNice to Haves experience with billing systems and customer records PEGA experience\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The Best Players Need the Best People.This position will be working on projects supporting Golf Course Properties, KornFerry, Finance, Digital, and Golf Technologies. Here responsibilities will include the following. This position will has a keen understanding and experience with reporting metrics, analytics, data management platforms, and ad servers.QualificationsBachelor’s degree in business, Statistics, Analytics, or related field of study; Master’s degree preferredMinimum 2 years’ experience in data science, analytics, or marketingStrong analytical and problem-solving skillsExcellent quantitative, communication, follow through, and interpersonal skillsAdvanced Microsoft Excel skills and experience with data visualization toolsMust have strong attention to detail, flexibility, and strategic thinkingMust maintain have ability to manage multiple projects and deadlines in a professional manner Golf knowledge/background a plusREPONSIBILITIES/DUTIESDevelop BI reports (Quicksight, Tableau, Qlik, etc.) highlighting analytics and data patternsAssist with data programing and modeling using (R, Python, NumPy, Pandas, SQL, KNIME, Jupyter Notebook, etc.)Implement best practices for report developmentSupport the analysis, design, development, and implementation of new reporting requirements and KPIsDocument technical specifications, data models, process flows, requirements, and solutionsWork with data architects and engineers to define report performanceCollaborate with delivery and technical team members on design and development of solutionsUnderstand business processes, underlying data and reporting needsConduct data analysis in support of ETL development and other activitiesWork with management to prioritize business and information needsSpecial Projects or other duties as assigned\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are seeking a motivated and customer-oriented Data Analyst to support our US Courts client.The customer is looking to consolidate and integrate existing data warehouses, data marts, and applications into an Integrated Enterprise Data Warehouse. The Data Analyst will perform analyses of data and data source characteristics, relationships, and logic necessary for effective implementation of information systems.Duties And Responsibilities IncludeIdentifies and documents problems traced to both original data quality issues and system outputs and recommends solutions. Combines domain knowledge and knowledge of system performance requirements in supporting system development and performance testing processes.Required QualificationsThree (3) or more years of experience in data analysis and the identification and documentation of data characteristics and entity relationships.Prefer experience with R programming language and PowerBI.Education Requirement: Bachelor's degree in computer science, information systems, engineering, or business management.Clearance Requirement: Ability to obtain and maintain a Public Trust.This position is contingent upon contract award to Gunnison Consulting.Why Join Gunnison?Gunnison takes on ambitious projects. We target fun, challenging work that requires creative thinking and innovation. Quality is our top priority.Gunnison employee benefits meet or exceed what other companies in the Washington, D.C. metropolitan area offer.There is a great sense of camaraderie at Gunnison. This is an atmosphere we will maintain as we continue to grow.We are growing rapidly and the opportunity for individual professional growth with Gunnison is outstanding. We hire for careers at Gunnison, not to fill a position.Employee BenefitsGunnison employee benefits meet or beat other companies in the Washington, D.C. metropolitan area, including:Bonuses AND profit-sharing!401k MatchingCertifications and training allowance $2,500/year3 weeks of personal leave your first year (160 hours can roll over every year)Equal Opportunity/Affirmative Action Employer. Must be eligible for employment in the United States. We are unable to sponsor candidates at this timeIn 1994 Gunnison Consulting Group began serving the greater Washington, D.C. metro area, focused on tackling our customers' most ambitious technology projects. By creating a culture dedicated to enabling our customers and employees to achieve more than they ever thought they could, the company has thrived for 25 years.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"SummaryS&S Activewear has an opportunity for a new HRIS & Data Specialist to join our team. In this role, you will be responsible for day-to-day support, maintenance, and data integrity within our Human Resource Information System (HRIS), including but not limited to data management, reporting, compliance, analysis, training, and process improvement, acting as Super User. This role will also partner with the HRIS Manager on improvements to achieve short-term and long-term objectives working with business related departments including but not limited to finance, information technology and other partners as identified. Schedule Monday-Friday 8AM-5PM, Exempt Base location for this role is flexible - working remotely or from one of our Warehouse locations.Duties and ResponsibilitiesMaintain optimal functions to HR systems which may include installation, customization, development, maintenance and upgrade to applications, systems, modules, and software.Provide technical support, troubleshooting to HRIS users.Collaborate with HRIS Manager and business partners to identify system improvements enhancements while recommending and implementing viable solutions.Manage permissions, access, personalization and similar system operations and settings for HRIS users.Compile and assist with the acquisition of data reports and summaries for leadership and team members.Conduct regular assessments including quality assurance testing, system audits, data cleanup and corrections.Develop a variety of user procedures, guides, manuals, and instructional tools.Assist/train end users with inputting, updating, analyzing, and maintaining accurate data for new hires, transfers, terminations, pay location changes, salary changes, address changes, etc. to meet entity needs.Maintain high standards of confidentiality and in compliance with data privacy guidelines.Perform additional duties as assigned.Required Education, Skills, Abilities and ExperienceDegree or diploma in systems or HR related field.Experience in HRIS setup/design, support, data management and reporting.Experience in ADP Workforce Now strongly preferred.Advanced knowledge of Microsoft Excel required.Possess knowledge of human resources practices.Data analysis and Implementation of technical effective solutions; creative problem solver.Project management experience and innovative thinking skills.Process orientated and action-orientation with excellent follow-through skills.Ability to prioritize workload and provide timely follow-up and resolution to meet tight deadlines.Excellent customer service skills, with excellent verbal and written communication skills.Demonstrated high level of accountability, integrity, discretion and confidentiality.Proven ability to collaborate and work in a cross-functional team environment.Able to develop various types of end-user written training materials/manuals/guides.Strong interpersonal and customer relations skills.Working EnvironmentThis job operates in a professional office environment. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines. Reasonable accommodations may be made to enable people with disabilities to perform the essential functions. Physical DemandsThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. While performing the duties of this job, the employee is regularly required to talk or hear. S&S conducts its business without regard to sex, race, creed, color, religion, marital status, national origin, citizenship status, age, pregnancy, sexual orientation, gender identity or expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. S&S's policy is to recruit, hire, train, promote, assign, transfer and terminate employees based on their own ability, achievement, experience and conduct and other legitimate business reasons. S&S participates in E-Verify and will provide the federal government with your Form I-9 information to confirm you are authorized to work in the U.S. This job offer is contingent upon the completion of a satisfactory background check.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Location: Onsite. San Antonio, TXDuration: 6 months contractPay Term: Up to $44/hr on W2Our Investment and Financial Servicing client in San Antonio TX is looking for a Data Analyst.The Data Analyst partners closely with business, functional and technical resources to ensure only quality deliverables are put into production and also provides ongoing support of solutions.ResponsibilitiesActs as a primary project resource with a focus on data cleanup and data governancePossesses a clear understanding of pipelines and data schemasPartners with business and functional resources to obtain a better understanding of current data issues and pain points.Develops a plan that alleviates pain points and improves the ability for the business to record and utilize data within Salesforce.com.Ensures that IT partners are building the solution in accordance with business needs.Influences the development of solutions which will aid in the data capture, data cleansing, data monitoring, and reporting of customer data (dealers and financial advisors) and/or product data (mutual funds).Manages and coordinates data development activities and projects.Collaborates with IT partners to resolve production and data quality issues.Applies validation and enrichment concepts to improve the quality and completeness of data.Develops and implements standard data quality and governance procedures, which may include deliverables such as: Data quality standards; Introduction of appropriate reporting and transparency capabilities required to understand and manage the quality, storage and usage of informationA Successful Candidate:Exercises good judgment when applying business and procedural knowledge in a complex environmentHas good knowledge of database structures and schemasDemonstrates strong analytical and problem solving skills; ability to distill complex information into key pointsPossesses familiarity with cloud migration work, such as AWSDemonstrates the ability to work in a team environment; initiative to work and learn independently and proactively contribute to department goals; and ability to lead others while maintaining effective business relationships with associates throughout the organizationDemonstrates strong detail orientation, organizational, and multi-tasking skills; ability to effectively manage an unpredictable workload and meet established deadlinesDemonstrates strong written and verbal communication skills with a diverse group of associates; strong presentation skills; strong inter-personal skillsDemonstrates strong computer skills, especially a strong command in the Microsoft suite including Excel, PowerPoint, Word, and VisioRequirements:Minimum Of 5 Years Of Relatable ExperienceRequires a Bachelor's degreeGeneral knowledge of mutual funds or experience in the investment management industry is preferred but not requiredBenefitsWe put our Ambassadors first. When it comes down to it, we know we can't fulfill our Promise to our business customers without your commitment. You represent our organization while on assignment. In return, we do our best to show our commitment to you. Our Ambassador Benefits package includes: Medical, dental and vision coverage. It also includes 401k, sick time, holiday and much more. We are an equal opportunity employer.We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance. - provided by Dice\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Extend OverviewExtend is a rapidly growing fintech startup in the B2B payments space with a focus on serving banks and their customers. We have built the first virtual card platform of its kind, directly integrated with processors, networks, and the technology that supports banking across the industry. We offer several virtual card products including an app-as-a-service that banks can offer business customers with their existing credit cards, a suite of virtual card APIs for those looking to build custom payment solutions, and we also offer secure connectivity to key banking and payment services that enable 3rd-parties to integrate and embed payments into their software.Founded in 2017 by 3 industry experts with experience at Fortune 500 companies, including American Express and Capital One, Extend is headquartered in Manhattan and has recently raised $40m in venture capital from top fintech investors. Extend was recently voted one of America's best startup employers by Forbes and best payments service platform by Tearsheet.With extreme monthly growth and 85+ mission-driven employees, now is prime time to join our team!For more information visitAbout The RoleWe are looking to add a Business Intelligence Analyst to our growing Business Intelligence team; as part of this team, you will be responsible for data reporting, developing analytics and measurement tools, and driving initiatives that help optimize revenue across multiple business segments. You will own much of the Tableau dashboarding and ad hoc data requests. You will also ensure our data remains clean and accurate. You’ll work with the Business Insights team to gather requirements from departments across the company, design new dashboards, and incorporate feedback. This is a hybrid role, based out of our New York City office, with three days on-site.At Extend, you’ll:Create and maintain data tables and Tableau dashboards that allow key stakeholders to view data in a quick and concise manner, effectively communicating insights through visualizations.Manage and resolve ad hoc Business Intelligence requests, developing new tools to automate repetitive tasks.Design metrics, derive data-driven insights, and communicate findings in a concise manner to key stakeholders to help improve business performance.Maintain the integrity of company data and put checks in place to ensure accuracy. Identify and fix data quality issues before reports are generated.Partner with stakeholders across the long/short business to identify data needs and build reporting to inform business decisions.Design data models, ensure data quality, and automate processes where possible.THE CANDIDATE4+ years of previous experience within data analytics or business intelligenceExcellent data visualization skills (Tableau, PowerBI, or software libraries in R or Python)Mastery of SQL and database conceptsThe ability to synthesize information quickly to provide an independent and objective viewpoint, propose appropriate solutions, and drive meaningful changeThe ability to multitask and prioritize assignments while producing high quality work in a demanding, fast-paced environmentStrong written and verbal communication skills to interpret the data and dashboards for those less technically inclinedStrong attention to detail Data curiosity – When you look at data or a visualization, do you ask yourself if the values make sense, or what could be causing something to stand out?The ability to work independently as well as collaborate with a small team and internal clientsWhat We OfferCompetitive compensation packageEquity for all–our success is your successUnlimited vacation–and we want you to use it401K matchingFlexible work optionsComprehensive health coverage for you and your familyMaternity and paternity leave benefitsReimbursement for gym membershipsReferral bonus program–bring your friends!Work with and learn from functional experts across disciplinesThe salary range for this role is $100,000-$140,000. Your final base salary will be determined based on various factors which may include, but are not limited to location, work experience, skills, knowledge, education and/or certifications. You may be eligible to participate in Extend’s annual bonus plan, based on individual and organizational performance.To all recruitment agencies, Extend does not accept agency resumes. Please do not forward resumes to our jobs alias, Extend employees or any other company location. Extend is not responsible for any fees related to unsolicited resumesExtend is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, citizenship or immigration status, or any other status protected by law.Powered by JazzHRIJ33N9DZnA\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Ideally, we are looking for someone with knowledge and/or experience with NIBRS. This is a national database that keeps track of police/incident reports, so this person will be working with another member of the Records Management team and go through all of the data in police and incident reports and gather data for the national database. The data may include: age, race, weapon/no weapon, type of weapon, etc Experience with NIBRS, or industry experience (i.e., public safety, law enforcement, etc.). (NIBRS captures detailed data about the characteristics of criminal incidents , including: a broad array of offenses. types and amount of property lost. demographic information about victims, offenders, and persons arrested. what type of weapon, if any, was used in the incident)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Description Job Summary  : Under the direction of the Associate Professor in Advanced Research in Obstetrics at the Office of Population Health at the University of Texas Health Science Center at Tyler (UTHSCT) and officed at The University of Texas System Population Health in Austin, the Research Data Analyst will help coordinate and monitor data activities related to multiple grant funded projects. They will primarily work on the Texas Collaborative for Healthy Mothers and Babies (TCHMB) and contribute to the design and analysis of projects using primary and secondary data to inform the work. TCHMB is the Texas statewide perinatal quality collaborative (www.tchmb.org). TCHMB’s mission is to advance health care quality, equity and patient safety for all Texas mothers and babies through the collaboration of health and community stakeholders as informed by the voices of the patients we serve. TCHMB is funded by the Texas Department of State Health Services and is staffed by the UTHSCT.This position will be based in Austin, Texas. In-state travel may be required for this position (1-2 days/month) to assist project sites in implementation of quality improvement or to attend project-related meetings, and potential for out of state travel to present findings at scientific conferences depending on availability of funds. The Research Data Analyst will be involved with developing grants focused on improving birth outcomes in Texas. The position is funded through a 2-year contract with potential for further extension.Major Responsibilities / Duties / Critical Tasks The Research Data Analyst will work closely with the Associate Professor in Advanced Research in Obstetrics who is also the TCHMB Research Director and other TCHMB leadership to develop and standardize data collection and research protocols.  Conduct quantitative analyses with large datasets.  Maintain active data use agreements and IRB approvals.  Prepare reports designed for various audiences as needed.  The Research Data Analyst will work closely with the Research Director and other department staff to design research and identify data needs.  They will also maintain documentation and relevant literature for the projects and research studies.  The Research Data Analyst will be assisting with writeups of reports and peer-reviewed publications.  They may also be required to manage collaborative projects and to coordinate activities and deliverables with stakeholders and participating hospitals/clinics.  They may assist with the Research Director to recruit, oversee, and mentor graduate research students assisting with projects.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job Title: Data Entry AnalystJob Location: Southlake HQEmployment Type: Full timeJob DescriptionAFS is looking for Data Entry Analyst to join our growing team! As a Data Entry Analyst, you will be responsible for the onboarding and maintenance of data of our customers in various systems. This will require the ability to accurate key data from paper or electronic documents into our systems. This is a fast paced environment with opportunity to advance.Job Bullet PointsMaintains database by entering new and updated customer and account information.Review and identify errors made by other and correct, as needed.Manages competing priorities to ensure work is completed on time.The right candidate must have strong organizational skills, with attention to detail and accuracy. They will need to have excellent typing skills and be proficient in Microsoft Office programs. We are looing for someone with good communication skills and the ability to work independently. Benefits PackageFull 401K, Medical, Dental, Life, and Vision Options AvailablePaid Vacation and Sick TimeCompensation Range: $19.00 to $22.00 per hour\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Classification Title: IT Business Data AnalystCollege/Division: Division of DevelopmentDepartment: DEV Advancement ServicesAdvertised Salary Range: $51,586 - commensurate with qualificationsAdvertised Job SummaryUnder general supervision, reporting to the Senior Director of Analytics & Client Solutions (Senior Director), the Junior Data Analyst supports the success of major gift development efforts at the University of South Carolina (UofSC) by providing data and performing analysis of annual, major and planned gift donors, prospects and alumni. Serves as a point of contact for assigned fundraising units to effectively translate reporting objectives and business requirements into technical specifications, report design and code and utilize Tableau, QlikView, and/or Microsoft Power BI and various other applications to document, design, develop, test and implement analysis, dashboards, extracts and other solutions in accordance with project plans, business requirements and specifications. Works closely with the Senior Director and team members to understand the needs of the organization, utilize system functionalities and perform continuous data quality improvements that allow for the implementation of sophisticated BI and performance management solutions that supports the fundraising efforts individually, at Campus, Colleges, Unit level and within the University system. Provides assistance as needed to those participating in efforts to investigate, identify, and fulfill internal and external reporting needs.Advertised Minimum QualificationsBachelor's degree in Information Technology Systems or related field and 1 year related experience in computer systems development and modifications; or equivalency.Ability to work evenings and weekends when needed and travel overnight for professional development conferences.Full/Part Time: Full Time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Are you a passionate leader looking for autonomy and exciting career possibilities?Do you take an energetic and resourceful approach to problem-solving while bringing innovative ideas and analytics to life on behalf of your team and your customers?Do you enjoy effectively translating requirements into an efficient process and/or system solution? If so, DHL Supply Chain has the opportunity for you.Job DescriptionTo apply knowledge and analytics to develop and communicate timely, accurate, and actionable insight to the business through the use of modeling, visualization, and optimization. Responsible for the reporting, analyzing, and predicting of operational processes, performance, and Key Performance Indicators. Communication with site leadership, operations, and finance on efficiency, customer requirements, account specific issues, and insight into to the business, operations, and customer.Applies hindsight, insight, and foresight techniques to communicate complex findings and recommendations to influence others to take actionUses knowledge of business and data structure to discover and/or anticipate problems where data can be used to solve the problemUses spreadsheets, databases, and relevant software to provide ongoing analysis of operational activitiesApplies data visualization for discovery and timely insights to decrease Cycle Time to Action (CTA)Assists site operations in identifying areas for improving service levels, reducing operational costs, and providing other operational enhancementsSupports account start-up analysis and/or report implementation as neededDevelop standardized and ad hoc site and/or customer reportingStreamlines and/or automates internal and external reportingMay investigate and recommend new technologies and information systemsMay conduct feasibility analyses on various processes and equipment to increase efficiency of operationsPartners with Finance to develop financial models to analyze productivity and payroll; calculates cost benefits and business impact and proposes solutionsDevelops predictive models to help drive decision makingDesigns, develops, and implements data gathering and reporting methods and procedures for OperationsResponsible for tracking, planning, analysis, and forecasting of storage capacities, inventory levels, equipment and/or labor requirementsCoordinates with Operations Systems group to ensure technical issues and problems are being identified, addressed, and resolved in a timely mannerMay coordinate with ILD group on issues related to modeling customer solutions, including providing data and relevant insight for customer pursuitsResponsible for assisting finance and senior leadership in modeling yearly labor budget based on operational and profile changesRequired Education And ExperienceUndergraduate degree in business, logistics, mathematics, statistics, related field, or equivalent experience, required1+ years of analytics experience, requiredOur Organization has a business casual environment and focuses on teamwork, associate development, training, and continuous improvement. We offer competitive wages, excellent affordable insurance benefits (including health, dental, vision and life), 401K plan, paid vacation and holidays.Our Organization is an equal opportunity employer.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Doximity is transforming the healthcare industry. Join our mission to help every physician be more productive and provide better care for their patients. As medicine's largest network in the United States, there's an elevated level of responsibility in everything we do. We don't take that responsibility lightly and are committed to building diverse teams with an inclusive culture that can make a direct impact on the healthcare system.One of Doximity's core values is stretching ourselves. Even if you don't check off all the boxes below we encourage you to apply. Doximity is full of exceptional people who bring their own unique experiences to work everyday and make us all better for it!As a Data Analyst, you'll work within cross-functional delivery teams alongside other analysts, engineers, and product managers in discovering data insights to help improve healthcare.This role can be filled in our San Francisco headquarters OR remotely in the U.S.About UsHere are some of the ways we bring value to doctorsHere is an introduction to our tech stack We use UNIX command-line interface and standard programming tools (vim/emacs, git, etc.) and have over 350 private repositories in Github containing our applications, forks of gems, our own internal gems, and open-source projectsWe have worked as a distributed team for a long time; we're currently about 65% distributedFind out more information on the Doximity engineering blogOur company core valuesOur recruiting processOur product development cycleOur on-boarding & mentorship processHere's How You Will Make An ImpactLeverage Doximity's extensive datasets to identify and classify behavioral patterns of medical professionals on our platform. Play a key role in creating both product and client-facing analytics. Inform data team strategy by working with the product leaders and managers. Actively participate in execution and some planning of organizational data team strategy. Collaborate with a team of product managers, analysts, and other developers to define and lead data projects from data ingestion to analysis to recommendations. About YouAt least 2 years of professional experience as a data analyst or a data scientist. Knowledge of statistical concepts, especially exploratory data analysis techniques, and probability theory. Excellent SQL skills to create and evaluate complex statements involving numerous tables and data relationships. Excellent visualization and storytelling skills to explain your results and solutions to the stakeholders, clearly and compellingly. Proficient in using Python data analysis libraries such as Pandas and Numpy. Also has a basic understanding of the object-oriented programming concepts as it relates to Python. Prior exposure to distributed data processing concepts and execution (e.g., working with column stores, leveraging spark, etc.)Fast learner; curiosity about and passion for data. CompensationThe US total compensation range for this full-time position is $110,000 - $150,000 (inclusive of salary + equity) Our ranges are determined by role and level. The range displayed on each job posting reflects the approximate total target compensation for the position across the US. Within the range, individual pay is determined by factors including relevant skills, experience, and education/training. Please note that the compensation listed does not include benefits.BenefitsDoximity is proud to offer industry-leading benefits. Some of our offerings include:Medical, dental, vision offerings for you and your family401k with matching programEmployee stock purchase planFamily planning support, Childcare FSA, and parental leaveLife, AD&D, and DisabilityGenerous time off, holidays and paid company tripsWellness benefits…plus many more!More info on DoximityFor the past decade, it's been our mission to help every physician be more productive so they can provide better care for their patients. We believe that when doctors are connected, the healthcare system works better and patients benefit. Doximity enables our verified clinician members to collaborate with colleagues, stay up-to-date with the latest medical news and research, manage their careers, and conduct virtual patient visits. Today, Doximity is the leading digital platform for U.S. medical professionals, with over 80% of physicians, 50% of all nurse practitioners and physician assistants, and 90% of graduating medical students as members.Joining Doximity means being part of an incredibly talented and humble team passionate about improving inefficiencies in our $4.3 trillion U.S. healthcare system. We are a team of doers who solve problems everyday by treating obstacles like an adventure, and we love creating technology that has a real, meaningful impact on people's lives. Doxers are committed to working towards a more equitable world both within and beyond our office walls. This starts by fostering an inclusive and diverse work environment where differences are valued and all employees are encouraged to bring their full, authentic selves to work daily. To learn more about our team, culture, and users, check out our careers page, company blog, and engineering blog. We're growing fast, and there's plenty of opportunity for you to make an impact—join us! For more information, visit Doximity.com.____________________________________________EEOC StatementDoximity is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Technology Data Analyst3 days on site in NYC, NYLong Term Consulting Opportunity Seeking a Technology Data Analyst (with Finance Domain experience) who will be responsible for the analysis, governance and management of data that is sourced into the shared data platforms that are used across LCG. This includes understanding of requested datasets, the rationalization of the data (future and current) that we source and store, coordination with upstream data providers and consumers to gather requirements, analyze and understand data, work with developers to source and actively maintain data catalog / system dictionaries. In addition, you will be responsible for the governance of centrally managed datasets, including cataloging attributes, upstream and downstream systems, defining and monitoring data quality controls, managing data related issues and managing coordination and relation with data providers and consumers. You will also be responsible for managing multiple data projects and contribute to define governance for data and central data platforms.KEY RESPONSIBILITIES:Work with data consumers to understand and document data requirements.Liaison between upstream data providers, data consumers and developers to source and manage data.Assist and provide guidance to data consumers during the QA & UAT phases to quickly confirm the validity of potential issues and determine the root cause and best resolution of verified issues.Independently plan, manage and track multiple data projects and provide regular status reports to stakeholders.Work with Data Governance team and Data Owners to catalog datasets and manage data and system dictionaries.Define and monitor data quality controls using firm approved tools.Develop data analytics and visualization using Tableau.Liaison with Production Management team and provide support of data feeds in productionSKILLS / QUALIFICATIONSBachelor’s degree in Computer Science, Software Engineering, Information Technology, or related field.10+ years of work experience in Information Technology and 5+ years working as Data Analyst.Strong SQL experience and ability to write ad-hoc and complex queries to perform data analysisAbility to understanding Entity Relations and Data models (conceptual, logical, and physical)Ability to understand data warehouse concepts (Fact-less Fact Tables, Temporal \\\\ BI-Temporal models, etc.)Experience in highly complex data environments with large data volumes.Strong analytical skills, including a thorough understanding of how to interpret customer business requirements and translate them into technical designs and solutionsStrong project management experience with Agile or other methodologiesStrong communication skills both verbal and written. Capable of collaborating effectively across a variety of IT and Business groups, across regions, roles and able to interact effectively with all levels.Self-starter. Proven ability to manage multiple, concurrent projects with minimal supervision. Can manage a complex, ever changing priority list and resolve conflicts to competing priorities.Strong problem-solving skills. Ability to identify where focus is needed and bring clarity to business objectives, requirements, and priorities.Experience with the development of data analytics and visualizations using Tableau.DAExperience with data governance and quality, using tools like Collibra will be plus.Experience with Cloud data platforms (Azure, Snowflake) will be a plus.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'At Level, we believe using your benefits should be as easy as buying a cup of coffee. We’re unlocking the full value of compensation by rebuilding benefits as a simple payments experience — fast, flexible, and transparent. Our mission is to empower people to build better financial futures, and we’re accomplishing that by transforming the status quo of benefits.Level is a B2B2C fintech company comprised of a diverse team from industry-leading companies like Square, Oscar, Google, Uber, and Airbnb. Together, we’re creating a new payments tech stack to help employers offer more accessible and personalized benefits for their teams — and this is just the beginning.At Level, collaboration is our superpower. By leveraging each other’s strengths and curiosity, we’ve been able to build a best-in-class product, culture, and business. Plus, our employee benefits are so awesome that we let our customers buy them too.What You’ll Do:Become a subject matter expert on our data and its capabilitiesDetermine what data we need and procure and develop high-impact data layers, user interfaces and other tools to enable self-service analyticsAssist with the infrastructure that allows us to scale by defining analytic requirements, developing analysis plans, and ensuring data quality standardsDevelop and own critical reporting and dashboards that provide transparency into the organizationCollaborate with our business-focused colleagues, our data scientist to inform data and client related decisions, and uncover trends, patterns and insights for benefit administratorsWho You Are:5-8+ years of prior experience in an analytics role or equivalent skillsetBachelor’s degree in a quantitative disciplineSolid grasp of probability and statistical concepts and ability to apply those concepts confidently to dataHigh level of SQL competence and some experience in programming in Python or RThe ability to think creatively, solve unexpected issues and work independently to meet deadlines.Ability to juggle and prioritize multiple projects, and adjust work accordinglyClear and effective communication styleA passion for working in high performing teams and helping people make better decisions around their healthcareOur Technologies:These are some of the technologies we use today. You don’t need to be familiar with all of these—many people on our team learned them with us. During our interview process, you’re welcome to use any language you’re most comfortable with.Google Cloud Platform (GCP): BigQuery, Vertex AILookerPython: scikit-learn, pandas, NLP librariesAmazon Web Services (AWS): SagemakerKubernetesProtobuf / gRPCElasticSearchGolangWhat We Offer:Competitive salary and equityRemote first, with an office in NYC as an option to come in100% paid medical for you and 80% for your dependents, 100% covered dental and vision through Level for you and your dependentsFlexible paid time off: take the time you need when you need it! Plus, get up to 10 days of paid sick leave per yearFully paid parental leave: up to 14 weeks for primary and 8 weeks for secondary caregiversFood, wellness, and office funds via our own Level productQuarterly company sponsored eventsInternal learning and development programsHave the chance to work at a leading innovator and trailblazer in the world of benefits and paymentsThis position has a minimum base salary of $145,000 and a midpoint base salary of $160,000. The base pay may vary depending on job-related knowledge, skills, and experience. In addition to a competitive base salary this position is also eligible for equity awards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"About ObieObie is an insurance technology company, hyper-focused on driving value for the modern real estate investor and the partners they work with every day. Whether an owner, lender, agent, or property manager, Obie’s mission is to build technology and insurance products that drive efficiency and fundamentally change the way insurance is bought and sold.As the industry leader in embedded and instant insurance products, Obie was recently honored as Business Insurance Best Places to Work and one of Inc Magazine's Fastest Growing Companies for 2022. Obie is one of a small number of companies that are both a Y-Combinator and NAR REACH accelerator alum.To date, Obie has raised $13.7 million from leading proptech investors including Battery Ventures, Thomvest Ventures, MetaProp, Second Century Ventures, and Funders Club. The company has two offices, one in Chicago, IL and the other in Sarasota, FL, but also offers employees the option to work remotely.Brief Summary of RoleWe are seeking an individual to join the growing data analytics team at Obie. Those successful in this role will have a broad mix of business and analytical skills, with depth in at least one of these areas. Those successful will also have strong interpersonal skills and be comfortable communicating with a wide range of individuals in different disciplines and levels.Although reporting within the broader Risk team, we work in a matrixed environment. The ability to collaborate and build trust with customers within and outside the Risk department is critical. This role will require the skill to complete intermediate tasks with some guidance from your leader.What You'll Do:Create critical data visualizations that incorporate best practices to support business needs and provide insights for both internal teams and external partnersBecome an expert within Obie’s data visualization tool and train business users on how to use itComplete priority reporting within Excel, until it can be built within data visualization toolComplete ad-hoc reports and analysis that provides meaningful insights into the business; work with business leaders to identify opportunities for improvementAssist with the creation of business glossaries and data dictionaries, including (1) defining key metrics and dimensions used to evaluate the business and (2) maintenance of data metadata and lineageWhat You'll Bring:2+ years of experience in data analytics or data science, ideally within the Property and Casualty insurance industryExperience using a data visualization business intelligence toolStrong experience using ExcelBasic experience using SQL to query data within SQL databasesTechnical writing skillsAbility to meet deadlines and manage competing demandsInterview ProcessWe want you at your best, and won't be giving you any gotcha-style questions - we aren't like that. We want to get to know you, hear about what you're interested in, and learn about what you hope to do in the future.You should familiarize yourself with these resources before continuing: Our company’s blog to learn more about the space we’re working in and where we write about landlord insurance Check out our Twitter andLinkedIn to get a glimpse of how people interact with our brand and product Some posts with and about us around the web (Inc 5000, Estate Innovation, Geek Estate Blog, Business Wire, Innovate State) Podcast appearances: (The Ryan Hanley Show, REM #22) Meet us and learn about ObieYou'll first talk to Kara on a 30 minute call; you won't need to prepare anything in advance. The goal of this conversation is to get to know you and mutually explore if we might be a good fit for each other. You'll learn more about Obie and have a chance to ask any questions about our company, team, culture, and product. Meet the hiring managerYou'll get to have a 45 minute video interview with the hiring manager for this role, Jeff White. This discussion will be more technical in nature to ensure you have the skills needed to be successful in the role. Project exerciseThis role requires strong Excel skills, so we’ll present you with a challenge to provide you a chance to flex those muscles. You will be able to review the challenge and prep in advance of the live interview with the hiring manager where you'll work through the exercise. We'll be looking to see your Excel, analysis and critical thinking skills - more on this when you get there! Meet the teamSince you'll be joining a close-knit team, we'll ask you to meet other people in the company so we get to know each other a bit better.Obie has you coveredBeing in the insurance industry, we understand the importance of comprehensive benefits for you and your family. These are just some of the benefits and perks we provide:Competitive salaryFlexible time off with an encouraged minimum time away to support a healthy work-life balance12 weeks of Paid Parental LeaveGreat health, dental and vision coverageLife InsuranceFlexible Spending & Health Savings AccountsStock Options401k matchPet Insurance ReimbursementEquipment budget - everything you need to do your best workProfessional development supportSummer hours\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Job SummaryThe Data Analyst will work with a team to provide high-quality service to our customer by applying analysis techniques to determine solutions based on client requirements with an IT services/solutions-based scope. They will review, analyze, map and reverse engineer business and technical artifacts such as spreadsheets, programs, data models, data catalogs, design documentation and interfaces to capture, store and maintain relevant metadata for the systems within the portfolioYou Will Do Job Duties and Responsibilities:  Decipher data elements from various domain sources (programs, data dictionaries, interfaces) and map/cross-walk to financial terms  Able to understand complex system environments using non-standardized data domains  Able to provide data collection of disparate data sources into common data categorizations  Decipher complex financial descriptions and work through a process/protocol to see if terms can be matched in 9+ internal catalog source files  Update Data Dictionaries  Create and work with matrixed excel files to track mapped data elements  Able to piece together data entities from large non-normalized data sets  Able to understand how data is linked to other data  Collects and analyzes data and associated system artifacts  Understand DODAF documents/images and data architectures  Understand data attributes and how they can be used to assist with data mapping efforts  Data Mining, Data Mapping, Data Modeling, Data Preparation  Retrieve data using SQL, PowerShell or other common tools  Provides support in mission requirements determination, conceptualization, design, development, testing, verification and validation, documentation, and implementation of system application data  Performs analysis to determine how data is used within the application  Other duties as assigned  Understand and convey to leadership topics related to data management, data governance, and data maturity  Reverse engineer data models and other design or build artifacts to extract relevant business and technical metadata  Map data in system tables to compliance items  Creates plans to achieve performance-based objectives  Review data to detect data quality problems and anomalies  Help the organization correct data: both current and historical Job Requirements (Education/Skills/Experience)You'll need to have: Ability to obtain an active DoD Secret Clearance  Bachelor's degree in Computer Science or equivalent 3 to 5 years of experience  Experience using SQL for data analysis, data quality, and data profiling  Experience in one or more scripting languages  Experience working with data sets in enterprise-level data  Experience creating data mapping documentation for databases, interfaces and applications  Experience with Agile development methodologies and roles Even Better If You Have Experience with AF Logistics systems and data  Experience in requirements elicitation  DOD data background  SFIS background  Advanced excel skills  Knowledge of PowerShell and MS Project  A good problem solver  Understanding of older database technologies and programming languages (ADABAS, COBOL, Natural, Focus, etc.)  Data standards experience/knowledge  Data interface experience/knowledge\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About the Company:Built by the number-one sales trainer in the world, Cardone Training Technologies has become one of the most trusted names in the sales industry. For over thirty years, Grant Cardone has helped companies expand sales, increase transaction profitability, and reduce turnover all by disrupting the status quo by implementing his proven, industry-leading processes, through management, and training technology. Founded and led by CEO, Grant Cardone, a New York Times bestselling author, international social media influencer, renowned speaker, trainer and coach to fortune 500 companies as well as a real estate mogul, Cardone Training Technologies takes a cutting-edge, disruptive approach to sales, marketing, social media and consulting to give businesses an opportunity to increase their revenue and expand their market share.Event Data Analyst Responsibilities:Manage, monitor, track and report on all eventsPerform event registration maintenance in our proprietary ticketing system including responding to attendee’s questions, making registration changes and providing updates to team members and clientsSet registration rules/parameters (early bird rates and dates, etc.) based on experience and past year’s registration data analysisProvide analysis and new ideas/testing using this information to upper managementCommunicate with clients and partners in a professional mannerCommunicate all necessary automations with the web team to streamline processesProvide reports to help increase sales and tacticsTransform data into a digestible and presentable story based on ticketed, redeemed and confirmed attendees and confidently / effectively communicate that information with the Executive TeamProactively drive responsibilities and self-manage to the highest quality standardsBe available for occasional work travel and weekend workExperience, Competencies and Education:Advanced Excel and Google Sheets skills including pivot tables, V-lookups, ability to build complex formulasExcellent written and verbal communication skillsStrong analytical and data interpretation skills and the ability to interact with all levels of the organizationExperience in Shopify and Hubspot - desired but not requiredExceptional attention to detail and excellent coordination and organization skills, with the ability to manage multiple inputs and to organize data effectivelyYou have demonstrated the ability to work in a global and fast paced environment and remain calm in times of pressure This is full-time Monday to Friday 9am to 6pm, with additional hours/times as needed Cardone Enterprises is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " '12860BRNew JerseyJob DescriptionData Analyst:Location : Onshore. Working with clients and preparing the Prologue Financials database for implementation.  Importing and converting client conversion data into Prologue-friendly format, retaining all meaningful data points. Working with client on how to handle any discrepancies or exceptions.  Posting general ledger journal entries as required to adjust data loaded.  Crafting client financial and validation reports through the Prologue report writer and working with the client to resolve any findings.  Partnering with the Business Consultants, Project Managers and Project Team to craft a solution to fulfill and prioritize the client’s business requirements.  Identifying and implementing solutions to automate, or otherwise build efficiencies for, the various steps required for building out client databases – encouraging an environment of continual improvement. QualificationsGraduateRange of Year Experience-Min Year5Range of Year Experience-Max Year8\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'On-Board PMO is hiring a Data Analysis in Front Royal, VA!   For immediate consideration please send your resume to    resumes@onboardusa.com      Subject Line: Position Title and State you are Located     About Us:   On-Board PMO, Incorporated, is an on-site contract service provider for a local manufacturing entity providing full-time positions to our employees. We offer benefits, paid time off, paid holidays and 401k after a probationary time.    Position Details:   Position Title: Data Analysis   Job Location: Front Royal, VA   Shift: Daylight M-F 7:30am-4pm   Benefits: Paid time off, Paid Holidays and Health benefits: Medical, Dental, Vision, 401K and Life Insurance   Compensation: $28/Hour     Primary duties include:    Serve as the liaison between various operational areas via business data    Support operations by monitoring and analyzing master data, key data, and master relationship data within the organization    Provide user community and management with reports as needed    Work with business user and project leads to assemble necessary project data    Manages and analyzes data initiative issues to meet internal customer requirements    Defines, designs, and builds databases to meet business needs     Required Experience and Skills:    SAP experience, previous manufacturing experience is desired    Proficient in SAP preferred    Demonstrated proficiency in Microsoft Office, particularly in Excel and PowerPoint    Understanding of SAP transactions and tables to pull the data for validation preferred    Strong data analysis, query experience with large amounts of data    Well organized, ability to work independently and as part of a team - results driven    Must have a Valid Drivers License    Must be able to pass a pre-employment background check, drug test and physical     Additional Skills:    Strong quantitative, analytical, and critical thinking skills    Good analytical and problem-solving skills    Experience working with software products to support sound business recommendations    Excellent written, verbal, and presentation skills    Close attention to detail     Education:    Bachelor’s degree is preferred    High School and equivalent combination of education and experience     Apply Today!      www.onboardusa.com        On-Board was founded in 1976 by Robert L. Wilson to provide Engineering and Design services to the chemical manufacturing industry. Today, On-Board is a thriving privately held family of companies with services Consulting, Professional Engineering, Industrial Maintenance and Facility Management, Contracted Manufacturing and Production Services, as well as Temporary Staffing and Recruiting throughout North America.    The On-Board Family of Companies conducts operations through its Corporate Headquarters located in East Windsor, NJ along with Regional Offices in New Castle, DE and Wake Forest, NC. On-Board’s Mission is to provide “Flexible Service by applying the talents of our people, work processes and technology to meet our clients’ expectations in a Safe, Responsible and Dependable manner.”    On-Board Companies provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, religion, sex, national origin, age, disability or genetics.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This role is onsite in Plano, TX. (Local candidates will be given first consideration) No Corp to Corp or sponsorship being considered.About the jobJOB PURPOSE:The Data Analyst is focused on supplying analytics, reporting, and modeling around key risk factors across the enterprise. Expertise with database tools and resources will be key to develop novel solutions to business questions and challenges. The analyst will distill underlying insights by leveraging analytics and risk modeling techniques, ultimately crafting compelling dashboards and presentations for executive consumption.KEY RESPONSIBILITIES:Conduct deep dive risk analytics and present findings in a compelling and comprehensive story, highlighting key risk factors and trendsPerform data gathering and cleansing, reporting, and analysis in support of the risk officeDevelops, produces, and streamlines periodic reporting to ensure comprehensive visibility across organizational risk driversConducts complex ad-hoc analysis to provide actionable insight to leadership to drive informed and successful decision makingDevelop thorough risk models to evaluate the impact of various risk strategies and factorsLeverages databases (Oracle and PostgreSQL), reporting tools (Excel, PowerBI, and Periscope), and other technology to complete tasks effectively, precisely, and sustainablyServes as the subject matter expert during strategy meetings, providing appropriate and concise recommendations, and adds value during team discussions and brainstorm sessionsSupports team members across the organization during ongoing business decisions or initiatives, providing pragmatic guidanceExplore and develop new opportunities to add value to the organization and teamJOB REQUIREMENTS:5+ years' work experience in analytics, data science, and/or risk managementMUST HAVE Experience in big retail, financial services, banking, or wealth management industryBachelor's Degree or equivalent combination of education and experiencePreferred field of study: mathematics, statistics, analytics, data science, or financeExcellent interpersonal skills and robust verbal and written communication skillsExpert level Microsoft Excel skills: ability to effectively use pivot tables, v-lookups, logical and nested formulas, macros, and other elementsExperience writing queries in SQL; experience with PythonProven ability to connect data from multiple sources, summarize and suggest next stepsDemonstrates sound business acumen in selecting techniques for obtaining solutionsAbility to multi-task demonstrating flexibility to easily adapt to changing business prioritiesCan work independently or within a team environment“Applicants must be currently authorized to work in the U.S. on a full-time basis. No sponsorship is available for this position or work transfers.”\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"• Onsite 5 Days per week in Tampa, FL • Must be fully vaccinated • W2 - US Citizen/GC Only • 6 Month Contract to Hire • Pay rates: $38-43hr, $80-90K FTE Must-haves 2+ years of experience using Data Analytics and Reporting tools  Experience running reports within PowerBI Understanding of programming Languages such as C++ and HTML (The company's SharePoint is in HTML, so they are seeking someone who can update pages in HTML to help market IT internally)  Experience with cloud technologies, Azure preferred (understanding of how the cloud works, the company is moving to Azure. Understanding software reporting within the cloud)  Experience with Active Directory/Identity Management  Day-to-Day An employer in Tampa, Florida is looking for a Reporting Data Analyst. This person will be sitting ON-SITE in Tampa, Florida and will:  Pull, analyze, interpret, and report on data pertaining to IT Asset Management  Update internal SharePoint using HTML to help market the IT department to the rest of the organization  Utilize Excel/Tableau/PowerBI to pull reports and create presentable models of data found  Work cross-functionally as needed\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTitle: Data AnalystJob Type: Onsite, Full-time, Hybrid ModelLocation: Irving, TXJob DescriptionFamiliar with Banking Products.Good communications to interact with business clients.Familiar with finance data models data acquisitions.Good in excel Working on collecting and understanding the requirements.Should be well versed on Data Investigation, Data Analysis.Ability to explain functional technical details.Should have good SQL writing capabilities Validate UAT results and identify issue.Should be Independent and resourceful dealing with risks issues and resolving them in a timely manner.About CapgeminiCapgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.Get The Future You Want |\\u202fwww.capgemini.comDisclaimerCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-lawApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Skill/RequirementJob DescriptionNew graduate or individual with 1-2 years of experience with Geographic Information Systems (GIS) tools such as QGIS; basic familiarity with land cover classification methodologies. Knowledge of one or more scripting languages such as Python to automate GIS processing, data analysis and image processing is a plus.ResponsibilitiesJOB Description:Execute manual analytics steps and assist Data Scientists with data and result analysis & quality control for the LandVisor Brazil product. Assess patterns in data acquisition and model output for larger scale workflow improvementsProject scope:-Data analysis support and quality control for consumer-facing product and research projects, particularly QA and editing of data inputs and quality assurance of model outputs. Automation of data acquisition and result delivery.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Minimum Position Qualifications: * 6 - 8 years' experience with IT initiatives * 4 - 5 years as a data analyst for data related projects; data warehouses, data marts, BI reporting, analytics; experience with migrations from on-prem to cloud a big plus * Thorough knowledge and understanding of systems, procedures, and technology/project life cycles. * Excellent communication and presentation skills to effectively communicate information to customers and to all levels within the organization * A working knowledge of IT Service Management practices. * Hands-on technical knowledge including SQL, or ETL platforms * Hands-on exposure to modern cloud solutions (Azure, Snowflake, ...) Company Description Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That's why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure - even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants' experience so far!Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That’s why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure – even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants’ experience so far! https://fusionalliance.com/careers/spotlight/\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are a Direct Mail and Email Marketing company. We acquire database lists and put them in a format for printing and mailing or emailing. We use Altryx and Excel. Company Description TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The data analyst/report technical writer performs highly advanced work related to special education and special populations data collection and reporting activities and projects.Essential FunctionsDevelops and writes data documentation, analytical requirements, business rules, workflows, and data calendar/timelines for existing and new data projects using simple, clear, unambiguous, and concise languageOversees the planning, design, scope, structure, creation, analysis, and maintenance of SAS programs, datasets, data reporting systems, and reportsDevelops and manages extensive quality assurance and quality control checks of SAS programs and workflows to improve existing programs and processes including comprehensive documentationPlans, studies, researches, and evaluates current information and data systems and recommends changes as neededMinimum RequirementsII. CANDIDATE SKILLS AND QUALIFICATIONSCandidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity. Years Required/Preferred Experience 4 Required Experience with SAS programming or similar statistical programming language 3 Required Education: Graduation from an accredited four-year college or university 3 Required Experience working with administrative data 3 Required Experience developing technical documentation 3 Required Experience with MS Office suite, especially Word and Excel 2 Preferred Experience working with education data\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Summary / Position Purpose: The primary responsibility of this role is to create consolidated reports, dashboards, and data analysis for the internal customers of ACG. This role will be responsible for the day-to-day support, maintenance, and improvement of our CRM and supporting platforms, as well as excel-heavy data-related projects. Their work will involve collecting and cleaning data from multiple sources, running ad hoc reports, building automated dashboards, investigating, and fixing any potential errors/bugs, and working with the Database Administrator to ensure that the information in our database is error-free for accurate reporting. Essential Duties, Functions and/or Responsibilities: Create, validate, and send daily weekly, and monthly management reports.Assistance with requests for non-standard reports and analysisSupport management reporting by maintaining hierarchical information.Perform business-to-system analysis and troubleshooting analysis of complex management reports and business problems.In the report, development lifecycle support impacts analysis and project requirements definitionTransform client needs into functional requirements.With guidance, collect, analyze, and document business requirements for project proposals including but not limited to process and data flow, user interface, and reporting requirements.Together with managers and/or senior analysts, participate in cross-functional meetings to understand customer needs and identify problems and solutions.Appropriate solutions, develop specifications, analyze, and document business processes, validate testing processes, and train the user community.Gather, clean, and transform large data sets to be used in reports and visualization.Design, develop and implement innovative/effective/strategic fully automated business solutions.Works closely with IT and business to incorporate daily automated data refreshing.Develops and provides a standard set of user-friendly reporting tools to internal business customers.Provides maintenance on deployed tools and dashboards.Assist sales & marketing teams with CRM reports and data management, building and maintaining outreach lists for up to several dozen sales and inside sales colleagues.Other duties as assigned.  Education and/or Work Experience Requirements: EDUCATION: Bachelors/4 Yr. DegreeYEARS OF RELEVANT WORK EXPERIENCE: 1+ yearsSalesforce.com (or equivalent CRM) power-user/admin experienceExpert knowledge of Microsoft Office (especially Excel)Demonstrable excel & CRM familiarity with pivot tables and other similar visual reporting tools to display/reconcile large amounts of data.Strong ability to meet deadlines and manage and prioritize simultaneous requests.Creative and analytical thinker with strong problem-solving skillsMust demonstrate ability to communicate effectively verbally and in writing with all levels of the organization.Ability to critically evaluate and prioritize information gathered from multiple sources and reconcile conflicts.Ability to assess the impact of new requirements on Salesforce and other integrated systems.Ability to safely and successfully perform the essential job functions consistent with ADA and all other applicable federal, state, and local standards, including meeting qualitative and/or quantitative productivity standards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Bachelor's degree in computer or information scienceStrong background in large-scale, shared data environments. Preferable candidate would have experience in Water/Wastewater space include Water Assets, GIS, Workorder and Asset ManagementExcellent technical abilities, strong communication skills, and strong project management and organizational skillsRelevant technical skills or knowledge may include data modeling, SQL programming (SQL Server or Oracle), and Microsoft OfficeEffective analytical abilities in order to examine existing processes/workflows/dataflows and make recommendations for improvements6 to 8 months possibility of extension\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job Title:ID - DOPL - Data AnalystLocation: Boise, ID Fully ONSITE Position***DescriptionDOPL needs a Data Analyst to assist with the validation of data in the migration of legacy transaction and documentation data from eleven (11) existing systems into one. In addition, the new consolidated data will form a new historical data set for DOPL in the event not all data is migrated into the new license system.DOPL is implementing an enterprise Licensing Information System (LIS) and is required to migrate both application transaction data (OLTP) and business document content from 11 legacy systems. DOPL is seeking a qualified Data Analyst to work within a cross-functional team that includes IT Staff, a Data Architect, Project Coordinators, and Business Users. This individual will play a key role in the identification, transformation, loading and testing of legacy data during the LIS system implementation phase. The ideal candidate will have experience in data validation, data analysis, business systems analysis, requirement documentation, testing, and effectively working with business stakeholders.ResponsibilitiesValidation of all data being moved from original systems into new systemWorking with business stakeholders to observe processing and capture data requirements.Analyzing legacy databases and identifying application data for migration.Documenting key data entities and attributes in legacy database systems.Working with data migration team to test ETL software and loads.Working with system integrator to ensure data loads are complete and accurate.Thanks,N.TEJASWINI NAIDUTechnical recruiterDirect:404-777-9838 | Fax: 866-608-6686Email: tejaswini.n@stiorg.com | Web: www.stiorg.com100 Overlook Center, Suite 200Princeton, NJ 08540.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'At Better Life Partners, We provide what it takes to heal from addiction. Wherever. Whenever.We focus on bringing high quality, accessible and effective tech-enabled care to those with Addiction Disorders, especially those in communities for whom traditional care has been found lacking. We provide evidence-based, scalable, holistic healthcare while working alongside community-based organizations to ensure that our care is accessible, non-punitive and responsive to our communities. We build trusted relationships and healing spaces to nourish Belonging, Love, and Purpose.If you’re passionate about healthcare innovation, low-barrier care, and harm reduction, Better Life Partners is the team for you! Our Headquarters office is seeking a Data Analyst.The ideal candidate will have a deep knowledge of SQL and Python and will be self-motivated with a strong bias for action.Responsibilities include, but are not limited to:Expand and maintain optimal data pipeline architecture.Provide information to teammates that helps increase and optimize member experiences, revenue generation, and other business outcomes.(ad hoc queries, explanations of reports, technical guidance, etc.);Build Tableau dashboards for business usersImplement, integrate and document a variety of software platforms through the REST API frameworkMaintain and upgrade the division’s data warehouse (ETLs, design, dependencies, entity and referential integrity)Qualifications:Bachelor’s Degree in computer science, statistics, mathematics, or related field or equivalent experience. Willingness and eagerness to learn and be flexible.Experience using statistical computer languages (R, Python, SQL) to manipulate and draw insights from data.Extra Points:Knowledge of statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.).Knowledge of some statistical and machine learning techniques (for example, GLM/Regression, Random Forest, clustering, neural networks, k-Nearest Neighbors, Naive Bayes, SVM, etc.) and willingness to learn additional techniques.Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).Experience with TableauProven experience with Time Series Clustering.This is a full-time, exempt position. The starting salary range for this position is $70-90k annually.This position is fully remote (work from home).Work from home requirements:Must have internet service with minimum upload/download ability.Company will provide equipment (laptop, monitor, keyboard, mouse and headset) plus a remote work stipend. Must have a quiet space to speak to members with minimal background noise.Must understand the importance of protected health information and ensure any data/information is not visible to others.Better Life Partners facilitates the treatment of behavioral health conditions including addiction medicine. We offer a full slate of benefits including competitive compensation, medical, dental and vision coverages, four weeks of paid vacation, sick time, wellness days, thirteen paid holidays, a 401(k) plan with company match, parental leave program, learning & development stipend, employee referral bonus, company-issued technology, remote work stipend, paid volunteer time off, stock options for eligible employees, and more!At Better Life Partners, we believe our work directly correlates to the diverse perspectives of our employees. Better Life Partners celebrates inclusion and is a committed Equal Opportunity Employer to all qualified applicants, ensuring individuals will not be discriminated against on the basis of race, color, religion, sex, gender identity, sexual orientation, age, national origin, physical or mental disability, marital or parental status, military or veteran status, or any other protected classification. Persons of color, women, LGBTQ candidates, veterans and individuals with disabilities are encouraged to apply. Better Life Partners is a recovery-friendly workplace.COVID-19 Vaccine RequirementBetter Life Partners has instituted a COVID-19 vaccine mandate for all employees, including remote staff, to remain in full compliance with regulatory bodies. Individuals selected for employment must be able to show proof of vaccination status prior to start date.If you are unable to be vaccinated for medical reasons or religious beliefs, Better Life Partners will consider requests for reasonable accommodation consistent with its policy and if able to do so without undue hardship to the company pursuant to applicable law. Such accommodations must be approved prior to start date. Powered by JazzHRJlsmK7QPZV\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Greetings, Kindly have a look at the below job description and try to share with me your updated resumes at larry@intellectt.comRole: Data Analyst II Location: Sylmar, CA Job DescriptionResponsible for pulling data to support trending of product complaints and medical device reports utilizing data that resides in the complaint handling database for all product lines. This will include detailed data reports (e.g. graphs, charts, tables) prepared for routine trending, senior management reviews, ad-hoc requests, and cross-functional requests as needed (e.g. Regulatory, Quality Engineering, R&D). Will establish and maintain complex reporting formulas and templates using reporting tools such as Excel and other databases (e.g. Business Objects).2 - 4 Years' of experience is required in related field.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Location: Sheetz Corporate - PITTSBURGH, PAPrimary Purpose Of This PositionAssist in creating and driving business value and growth though the effective use of Sheetz’ most valuable resource: Data. Responsible for leading Sheetz’ data and information strategy through data analysis and visualization in order to facilitate and enhance organizational decision-making and data utilization across the company. Provides advanced data analytics support to the Senior Data Analyst while providing mentorship to the Associate Data Analyst around data analytics and information strategy.ESSENTIAL FUNCTIONS: (other duties may be assigned)Cultivate data-driven insights that help support exploitation of strategic and tactical business opportunities, and be a champion for a data-driven, decision-making culture.Support data strategy leadership in the development, assessment, refinement and implementation of corporate strategy through effective use of data analytics.Provide enterprise-wide data science and business intelligence services as well as recommendations to decentralized, embedded data scientists and analysts throughout the business.Assist Senior Data Analysts and management in providing training for departmental and distributed data analysts.Oversee and present robust ad-hoc reports, data models, and deep dive analysis to provide clear observations so that managers can make more informed decisions.Develop and mentor future data-driven, analytical leaders and strategists within the team.Assist with a wide array of analytical tasks and projects requested by other departments.Supports the Senior Data Analyst position with ad-hoc advanced analytics.Assist in the creation of policies and procedures for the access, analysis and visualization of data and associated business insights; partnering with IT and RISC.REQUIREMENTS: (Equivalent combinations of education, licenses, certifications and/or experience may be considered)EducationBachelor’s degree in Economics, Statistics, Mathematics, Actuarial /Data / Computer Science or related field requiredExperienceMinimum 3 years demonstrated experience in data modeling, optimization, and application to business strategies required.Minimum 3 years demonstrated experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required.Thorough understanding of the latest data mining, machine learning and/or artificial intelligence techniques required.In-depth experience with or coursework in designing and implementing information solutions required.Licenses/CertificationsN/ATools & EquipmentN/AAbout SheetzSheetz, Inc. is a fast-growing, family-owned, food/convenience company that has been in business since 1952. Sheetz has over 600 locations in Pennsylvania, Ohio, Virginia, West Virginia, Maryland and North Carolina.Our mission at Sheetz has been to meet the needs of customers on the go. Of course, things have changed over those nearly 70 years. Life is faster and busier, and customers expect us to be there when they need us most. One thing that hasn't changed is our commitment to our customers, our employees and the communities in which we operate. Sheetz donates millions of dollars every year to the charities it holds dear.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionHertz and the Advanced Analytics and Tool Development team is seeking talented individuals with passion for real-world problem solving. The analyst will partner with various functions within the company (Revenue Management, Fleet, Operations) and develop advanced tools and resources to support overall location-level planning and operational decisions. The analyst will be working with large sets of structured and unstructured data to perform analysis, develop tools, and provide actionable insights.What You’ll Be Doing Develop tools for the field for car assignment to optimize upgrade/upsell/booking success.  Develop tools to provide visibility to many of the operational processes.  Conduct analyses to inform stakeholders and help make the most optimal decisions regarding various strategic initiatives.  Code and automate performance reports.  Configure shared PC resources to automate scripts and collect data. What We Expect A Bachelor’s degree; preferably in Data Science, Computer Science, Statistics, Engineering, or another quantitative field.  A demonstrated ability to query and extract findings from large data sets in relational databases such as SQL Server, Teradata, Oracle, etc.  A wide range of data-related technical skills regarding databases, scripts, and web APIs.  Experience with programming/scripting languages like R or Python  Experience with advanced data visualization platforms such as Tableau.  Quick on feet; willingness to discover alternative solutions to technical problems.  A desire to solve complex problems with creative and concise solutions.  Excellent written and oral presentation skills – ability to communicate findings with non-technical stakeholders in concise and simple terms.  An individual who thrives in a collaborative environment. Nice To Haves More than 1 year of work experience in a data driven industry including Rent-A-Car, travel, or service industry  A Master’s degree in a quantitative field  Experience with statistical modeling  Experience with web development languages such as Ruby, PHP, or JavaScript. r work every day represent a significant part of our culture – and our success and reputation as a company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job DescriptionRole: Data AnalystSalary: $110,000 - $140,000 (plus benefits)Location: Austin, Texas (Hybrid Model)Sponsorship: Not availableI am currently on the lookout for a Data Analysis to join one of the largest U.S. banks based in Austin Texas. Within this position you will be working functionally across the business with Engineering, Finance, Customer success and product to collect, analyze and interpret data related to the bank's commercial lending and business operations.Working on a Hybrid model, if you have a strong curiosity of data and enjoy problem-solving a wide range of topics, who thrives on a fast-paced environment then this would be the perfect role for you!ResponsibilitiesCollect and analyze data related to commercial lending portfolios, including loan performance, risk assessments, and compliance with regulations.Develop and maintain reporting and analytics tools to provide insights into commercial lending and business operations.Work with stakeholders to identify key performance indicators and develop dashboards and reports to monitor them.Generate insights to uncover usage trends to inform product development, drive user adoption and savings (time and/or cost)About YouExperience with data visualization tools such as Tableau or PowerBI.Commercial knowledge working with SQL and programming languages such as Python or R.Strong analytical and problem-solving skills with attention to detail.Knowledge of commercial lending and banking operations is a plus.Our client is an equal opportunity employer committed to creating a diverse and inclusive workplace. They offer a competitive salary, comprehensive benefits package, and opportunities for career growth and development.If you are a data analyst who is passionate about using data to drive business decisions and interested in joining a dynamic team at one of the largest commercial banks in the US, please click to apply!For more information about ITECCO and the opportunities we have to offer follow us on Twitter @ITECCOrecITECCO Ltd is acting as an Employment Agency in relation to this vacancy.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Are you a passionate IT trailblazer - a growth focused, problem solver who takes full ownership of your work, wants to collaborate & co-create with fellow IT experts, innovate, learn new skills, create new solutions & drive your career to the pinnacle of your potential? If so, you will love working with our IT Team - we are constantly innovating to create breakthrough solutions for our client's growth through a vibrant, fun team culture. Read on below to learn more... Featured in CNBC, Digital Journal, Fox News & CIO Review GBSI has been successfully serving the world's top Fortune 500 organizations for the last 18+ years. GBSI IT teams and consultants have delivered more than 568 projects successfully within the automotive, manufacturing, retail & pharmaceutical domains across the world. Headquartered in Moline, IL GBSI's clients and consultants are spread across the US, Canada, Europe & India. Join us to be a part of an ever growing, elite IT team & start building your dream career today! To be a successful Data Analyst you will embody GBSI's core employee characteristics of being passionate about IT, taking full ownership of your work & having a growth mindset. Additionally, you will exhibit strategic vision, thoughtful engagement, strong analytical/process skills, a bias for action, and the ability to partner with senior operational leaders. Work you'll do/Responsibilities: * Develop data strategies * Analyze, interpret and visualize data to deliver insights and solutions * Building relationships with business areas to improve the flow of reporting/explanations and rationale * Working with technology teams, management and/or data scientists to set goals * Mining data from primary and secondary sources * Cleaning and dissecting data to get rid of irrelevant information * Analyzing and interpreting results using statistical tools and techniques * Pinpointing trends and patterns in data sets * Prior experience of working in healthcare domain What qualifications you need: Bachelor's / Master's in IT What will give you an edge: Impeccable written and verbal communication skills in English Passionate, Energetic, Enthusiastic.  Self-Driven, Motivated, Professional, Positive Minded Location Preference: Norfolk, VA Apply today to join us as part of an elite IT team & let GBSI help you build the career of your dreams! We are excited for your growth! Equal Employment Opportunity Statement GeniusBSI is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion, or sexual orientation. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Company Description We are Genius Business Solutions - our clients describe us as a team of passionate IT experts who take full ownership in delivering innovative technology solutions. At GBSI, we exist to simplify technology so that businesses can innovate faster & accelerate growth. With over 18 years of successful IT experience, GBSI is headquartered in Moline, Illinois & has clients and consultants working across the United States, Canada, India & Europe. We help some of the world's top organizations in manufacturing, automotive, software & IT and pharmaceutical domains in implementing software solutions, ensuring IT quality assurance, develop high quality custom applications & AMS support services. GBSI is a certified SAP partner & featured in multiple top publications including CNBC, Fox News, Digital Journal & MarketWatch. ERP Consultants, Developers, Software Engineers and QA experts, we invite you to join our teams & create the best version of you. As IT experts, our teams are committed to developing & delivering highest quality services in: - Technology Consulting - Digital Strategy & IT Modernization - Implementing Global IT Solutions - Next Gen Developments & AMS Support ServicesWe are Genius Business Solutions - our clients describe us as a team of passionate IT experts who take full ownership in delivering innovative technology solutions. At GBSI, we exist to simplify technology so that businesses can innovate faster & accelerate growth. With over 18 years of successful IT experience, GBSI is headquartered in Moline, Illinois & has clients and consultants working across the United States, Canada, India & Europe. We help some of the world's top organizations in manufacturing, automotive, software & IT and pharmaceutical domains in implementing software solutions, ensuring IT quality assurance, develop high quality custom applications & AMS support services. GBSI is a certified SAP partner & featured in multiple top publications including CNBC, Fox News, Digital Journal & MarketWatch. ERP Consultants, Developers, Software Engineers and QA experts, we invite you to join our teams & create the best version of you. As IT experts, our teams are committed to developing & delivering highest quality services in: - Technology Consulting - Digital Strategy & IT Modernization - Implementing Global IT Solutions - Next Gen Developments & AMS Support Services\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The position’s main responsibility is to manage a variety of data sources and conduct research initiatives as directed by leadership. This role will work with other researchers in the team on specific data queries, provide periodic updates on key statistics from multiple data sources and perform other activities as needed, including survey development and research paper writing. The Senior Research & Data Analyst will also play a major role in building, improving and updating key data sources used by researchers and serve as go-to claims data expert.RequirementsBachelor's degree in statistics, economics, data analytics, epidemiology, data science, data engineering, computer science, market research or other quantitative discipline.A minimum of 3 years of proven experience in/with building datasets using multiple input files and managing or analyzing claims data or similar large datasets.Excellent communication, analytical and interpersonal skills.The ability to shift between multiple projects, work with different team members, seek feedback and clarification, be detail oriented, and think of creative and innovative ways to improve processes and deliverables.Proficiency in SAS software and Microsoft Office Suite.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionClientSolv Technologies is an IT solution firm with over a decade of experience serving Fortune 1000 companies, public sector and small to medium sized companies. ClientSolv Technologies is a woman-owned and operated company that is certified as a WMBE, 8a firm by the Federal government's Small Business Administration.Job DescriptionWe are seeking a Data Analyst for a 3-month contract-to-hire in Littleton, CO.  This role will be onsite/in the office during regular business hours, Monday-Friday (no remote options). Upon permanent hire, this role will offer a salary of $125,000 per year (with flexibility depending on experience) and benefits to include health/dental/vision insurance, ESPP, 401K with match, and paid time off. In this role, you will: Nurture and enhance relationships with subject matter experts, leveraging both quantitative and qualitative insights from data sources across the enterpriseCollect, model, analyze, report, and present large amounts of data with meticulous attention to detail. Garner key insights from data and communicate these findings to key stakeholders to help make data-driven decisions. Key technologies include Druid SQL, Python, R, and Google suite of tools. Employ creativity and critical thinking in problem-solving and achieving business goals, using statistical techniques, advanced approaches, and/or new technologies. Develop and deliver recommendations for continuous improvement to internal. Conduct long-term and short-term time series data analysis focusing on increasing accuracy.  Qualifications4+ years experience with SQL, Python, R, Tableau, and Excel in a business environment requiredExperience in understanding and summarizing complex business processes into key performance indicators. Experience creating and maintaining documentation of business processes. Experience manipulating large datasets in a business environment requiredExperience translating data to actionable insights requiredExcellent facilitation skills; Strong desire to communicate in all settingsAdditional InformationThis 3-month contract-to-hire role will be located in Littleton, CO. This role will be onsite/in the office during normal business hours, Monday-Friday (no remote options). Upon permanent hire, this role will offer a salary of $125,000 per year (with flexibility depending on experience) and benefits to include health/dental/vision insurance, ESPP, 401K with match, and paid time off.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Citeline, is part of the Norstella group of Pharma information solutions, is one of the world's leading providers of data and intelligence on clinical trials, drug treatments, medical devices and what's new in the regulatory and commercial landscape. Relying on us to deliver vital advantage when making critical R&D and commercial decisions, our customers come from over 3000 of the world’s leading pharmaceutical, contract research organizations (CROs), medical technology, biotechnology and healthcare service providers, including the top 10 global pharma and CROs.From drug and device discovery and development to regulatory approval, and from product launch to lifecycle management, we provide the intelligence and insight to help our customers seize opportunities, mitigate risk and make business-critical decisions, faster. As the pharma and healthcare sector faces unparalleled upheaval, customers rely on our independent advice, enabling them to cut through the clutter and make sense of changing drug development, regulatory and competitive landscapes.Job Summary:We are seeking a Data Analyst to join our Real-world data (RWD) team and support our data-driven initiatives. The ideal candidate will have a strong background in SQL, content knowledge of the Life Sciences industry and the drug development lifecycle, and experience querying healthcare databases (claims, lab, EMR, etc).Responsibilities:Design data pipelines and queries and analyze data to support our Life Sciences use cases, particularly claims and lab dataDevelop and optimize database queries and procedures for data processing, transformation, and analysisDevelop advanced algorithms on large-scale healthcare databasesCreate final deliverables in industry standard to share with external clientsWork with cross-functional teams to identify data needs and develop solutions to support business goalsMonitor and troubleshoot data quality issues, and provide timely and effective solutionsStay up-to-date with the latest industry trends and emerging technologies, and make recommendations for data engineering best practices and toolsRequirementsBachelor's degree in Data Science, Computer Science, Engineering, Public Health, Biostatistics, Epidemiology or related field2+ years of experience working with and querying large databasesStrong proficiency in SQLUnderstanding of life sciences industry and drug development lifecycle Experience working with healthcare databases (e.g., claims, EMR, labs, etc.)Basic understanding of concepts used in epidemiological study designAbility to work collaboratively in a team environment, as well as independently with minimal supervisionStrong problem-solving and analytical skills, with attention to detailNorstella is an equal opportunities employer and does not discriminate on the grounds of gender, sexual orientation, marital or civil partner status, pregnancy or maternity, gender reassignment, race, color, nationality, ethnic or national origin, religion or belief, disability or age. Our ethos is to respect and value people’s differences, to help everyone achieve more at work as well as in their personal lives so that they feel proud of the part they play in our success. We believe that all decisions about people at work should be based on the individual’s abilities, skills, performance and behavior and our business requirements. Norstella operates a zero tolerance policy to any form of discrimination, abuse or harassment.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About the Company:Built by the number-one sales trainer in the world, Cardone Training Technologies has become one of the most trusted names in the sales industry. For over thirty years, Grant Cardone has helped companies expand sales, increase transaction profitability, and reduce turnover all by disrupting the status quo by implementing his proven, industry-leading processes, through management, and training technology. Founded and led by CEO, Grant Cardone, a New York Times bestselling author, international social media influencer, renowned speaker, trainer and coach to fortune 500 companies as well as a real estate mogul, Cardone Training Technologies takes a cutting-edge, disruptive approach to sales, marketing, social media and consulting to give businesses an opportunity to increase their revenue and expand their market share.Event Data Analyst Responsibilities:Manage, monitor, track and report on all eventsPerform event registration maintenance in our proprietary ticketing system including responding to attendee’s questions, making registration changes and providing updates to team members and clientsSet registration rules/parameters (early bird rates and dates, etc.) based on experience and past year’s registration data analysisProvide analysis and new ideas/testing using this information to upper managementCommunicate with clients and partners in a professional mannerCommunicate all necessary automations with the web team to streamline processesProvide reports to help increase sales and tacticsTransform data into a digestible and presentable story based on ticketed, redeemed and confirmed attendees and confidently / effectively communicate that information with the Executive TeamProactively drive responsibilities and self-manage to the highest quality standardsBe available for occasional work travel and weekend workExperience, Competencies and Education:Advanced Excel and Google Sheets skills including pivot tables, V-lookups, ability to build complex formulasExcellent written and verbal communication skillsStrong analytical and data interpretation skills and the ability to interact with all levels of the organizationExperience in Shopify and Hubspot - desired but not requiredExceptional attention to detail and excellent coordination and organization skills, with the ability to manage multiple inputs and to organize data effectivelyYou have demonstrated the ability to work in a global and fast paced environment and remain calm in times of pressure This is full-time Monday to Friday 9am to 6pm, with additional hours/times as needed Cardone Enterprises is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Journera has developed the first software platform for travel-related companies to craft more seamless, more personalized journeys for their customers. We work with some of the biggest travel brands in the world, operate at massive scale (over 1 billion data events processed to date!) and are backed by elite investors including Andreessen Horowitz, B Capital, the Boston Consulting Group, PAR Capital, and Pritzker Group Venture Capital.As a Data Analyst you'll help analyze and visualize data, and help build tooling to help non-analysts do the same. You'll work closely with our data scientists to build optimized and insightful views of Journera data, and will work closely with our commercial team to understand how to extract value from our large and rich data set for our ever-growing customer base.Diversity is one of our core company values. We are committed to fostering an inclusive, equitable, and supportive working and learning environment for all our employees. We believe the diverse experiences of our employees enrich the way we identify and overcome challenges, as well as design and deliver clever solutions.We're Looking For Someone Who...Will use a visualization tool, build live dashboards to provide travel providers meaningful insights about their data and customers (we use Looker, but that's not a hard prerequisite). Will identify and analyze patterns of travel data, ad hoc, to find business value. Can create and execute SQL queries to aid in the troubleshooting process of potential data anomalies. This role will aid in the testing and validation of the Journera algorithms. Assist with regular agile process activities, including daily standups, sprint and release planning, sprint open, close and retrospective; lead those activities when necessary. Has strong analytical and problem solving skills and a high attention to detail. Can tell stories with data and visualization. Strong intellectual curiosity. Will work across teams to build shared procedures and understandings of data. Journera also values experiences that demonstrate a commitment to diversity, inclusion, and community involvement. Please feel free to include your involvement with clubs, meetups, ERGs, non-profits, your community, etc on your resume or cover letter and ask us what we do at Journera.We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"BICP, a leader in the delivery of innovative cloud ecosystems & advanced analytics data products for large enterprise customers, is looking to hire three (3) Business Data Analyst to join our Data Product Delivery team embedded at a Fortune 100 retailer in support of a multi-year enterprise data analytics remediation effort. We're sun setting legacy reports and building net new data analytics products for the business on the client’s data foundation. The data sets will be primarily Finance & Supply Chain related. The ideal candidate will have strong Excel and data mapping skills. Any SQL and data visualization skills are a plus. Prior experience delivering data products in an Agile environment is a nice to have.The initial scope will be 4-6 months with possible extensions. We are open to W2 hourly and/or contractors. Our team is embedded with the client’s business, and we are on-site in Beaverton Tue - Thu and remote Mon + Friday.What you will support:This position is to help expand the reporting capabilities and portfolio of the team by working closely with the end business users to identify their needs and determine how best to meet those needs.Drafting, editing, and maintaining documentationResponsible for applying advanced concepts, theories, principles, and practices in a professional and technical discipline that is analytical, creative, evaluative and advisory in nature.Conducts work requiring substantial independent facilitation, judgment, and devises new approaches to unique problems.Develops conclusions and makes recommendations on a wide variety of complex issues.Describe the Key Projects/Deliverables associated with this role: Responsible for creating Business Requirement Documents (BRDs) in partnership with the business to capture information and detailed reporting needs.Ask leading questions and secure stakeholder buy-in to ensure solutions provide maximum adoption and benefit cross-functionally.Facilitate a broad range of projects from kick off through deployment and transition management.Track projects against established timelines and budgetWork closely with stakeholders, and various teams to access information and transform the data into information the business can use more readily and effectively.Advocates for a project through developing ROI and business benefit/impact/criticality narrativesCollaborates with business to translate goals and objectives into projects and timelines with associated deliverables.Consults on issue resolution, triage, and troubleshooting.What you bring to the table:Extensive MS Excel expertiseExcellent written and verbal communicationAbility to prioritize and effectively communicate impacts based on cost-time-quality considerations with stakeholders, including senior leadership tier.High profile communication; able to speak to various levels of the business community in non-technical terms.Facilitates subject matter expert (SME) discussions across department level or single business unit.Knowledge in the areas of Supply Chain and FinanceAbout BICPBICP is a consulting firm focused on delivering innovative Analytics + Hyperscale platform solutions to our customers. With deep experience across a diverse ecosystem analytical products and cloud-based platforms we have the required product ambiguity and expertise to deliver best-in-breed solutions tailored to our client’s critical business data needs.BICP is an Equal Opportunity Employer and does not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Job DescriptionTitle: Data AnalystJob Type: Onsite, Full-time, Hybrid ModelLocation: Irving, TXJob DescriptionFamiliar with Banking Products.Good communications to interact with business clients.Familiar with finance data models data acquisitions.Good in excel Working on collecting and understanding the requirements.Should be well versed on Data Investigation, Data Analysis.Ability to explain functional technical details.Should have good SQL writing capabilities Validate UAT results and identify issue.Should be Independent and resourceful dealing with risks issues and resolving them in a timely manner.About CapgeminiCapgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.Get The Future You Want |\\u202fwww.capgemini.comDisclaimerCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-lawApplicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Minimum Position Qualifications: * 6 - 8 years' experience with IT initiatives * 4 - 5 years as a data analyst for data related projects; data warehouses, data marts, BI reporting, analytics; experience with migrations from on-prem to cloud a big plus * Thorough knowledge and understanding of systems, procedures, and technology/project life cycles. * Excellent communication and presentation skills to effectively communicate information to customers and to all levels within the organization * A working knowledge of IT Service Management practices. * Hands-on technical knowledge including SQL, or ETL platforms * Hands-on exposure to modern cloud solutions (Azure, Snowflake, ...) Company Description Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That's why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure - even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants' experience so far!Established in 1994 in Indianapolis, Indiana, Fusion Alliance is highly regarded as an enterprise solution provider, delivering practical insights, engaging customer experiences, and human-driven technologies that transform the way our clients do business. That’s why over 450 clients across more than 100 companies trust us. They know that the solutions we build alongside them are robust, scalable, usable, and secure – even in the most challenging, dynamic, and highly regulated environments. We have deep experience in delivering solutions to companies within life sciences and healthcare, banking and insurance, manufacturing, energy and utilities, and more. Copy and paste the link to learn a little more about our consultants’ experience so far! https://fusionalliance.com/careers/spotlight/\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Company DescriptionKGS TECHNOLOGY GROUP, head quartered in Alpharetta, Georgia; is a leading multinational IT Consulting company that has successfully served the business community for over five years in onshore and over Ten years in Offshore. KGS in to software service, Customized Software development, Business consulting, Manpower staffing and outsourcing in various verticals like Banking, Business Services, Financial, Insurance, Manufacturing, Pharmaceuticals, Retail, Transportation, and Utilities including small-midsize ISV (Independent Software Vendors).QualificationsOPT OR HAVING 1 TO 3 YEARS OF EXPERIENCEAdditional InformationAll your information will be kept confidential according to EEO guidelines.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"We are a Direct Mail and Email Marketing company. We acquire database lists and put them in a format for printing and mailing or emailing. We use Altryx and Excel. Company Description TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.TaCito Direct is the Nation's Expert in Direct Response Advertising. You will join a team with a 40+ year history of proven products and services in the automotive industry.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Company DescriptionIntegriChain is the data and application backbone for market access departments of Life Sciences manufacturers. We deliver the data, the applications, and the business process infrastructure for patient access and therapy commercialization. More than 250 manufacturers rely on our ICyte Platform to orchestrate their commercial and government payer contracting, patient services, and distribution channels. ICyte is the first and only platform that unites the financial, operational, and commercial data sets required to support therapy access in the era of specialty and precision medicine. With ICyte, Life Sciences innovators can digitalize their market access operations, freeing up resources to focus on more data-driven decision support. With ICyte, Life Sciences innovators are digitalizing labor-intensive processes – freeing up their best talent to identify and resolve coverage and availability hurdles and to manage pricing and forecasting complexity.We are headquartered in Philadelphia, PA (USA), with offices in: Ambler, PA (USA); Pune, India; and Medellín, Colombia. For more information, visit www.integrichain.com, or follow us on Twitter @IntegriChain and LinkedIn.Job DescriptionLet’s break down the basics:Location: RemoteManager: Sr Manager, Data Analysis and DeliveryYour mission at IntegriChain:IntegriChain is seeking a data-savvy, detail-oriented professional to support the execution and ongoing quality of the company’s Inventory Analytic product offering, which utilizes manufacturer channel data to develop a comprehensive and detailed picture of product sales and key customer dynamics.Reporting to the Sr Manager, Data Analysis and Delivery, this individual will be responsible for data analysis, QA, and product support for our customers in adherence with our service-level agreements (SLAs), and will support multiple customer data deliverables simultaneously. This role regularly collaborates across several groups (Product Management, Engineering, Data Science and Customer Engagement), working with various resources to escalate and resolve issues when they arise.The position is ideal for a candidate looking to leverage their existing analytical skills and gain additional experience, using sound judgment and attention to detail to improve customer data deliverables.What this role entails: Responsible for onboarding and maintaining recurring Inventory Analytics deliverablesResponsible for maintaining a deep familiarity with customer data sets, and understanding distribution networks, and channel data-related issues that could potentially impact Inventory AnalyticsResponsible for owning and providing oversight for ongoing quality assurance and quality control processes related to Inventory Analytics, including the identification, implementation, and documentation of new processes and toolsProvide front-line support to customers to fully support the Inventory Analytic product offeringResponsible for timely execution of daily activities related to the Inventory Analytics production processAssist with data investigations and working with internal stakeholders. Support Development and Data Science Inventory Analytics methodology enhancements through the design, development, and test statesCross-train with Product Management Team to assist in identifying product improvements and enhancementsPartner with Enriched Data Analytics to develop understanding of reporting interaction between the two departments, analyze reports to solve internal questionsCollaborate cross-functionally with Customer Engagement to present and share findings with customers onsite and virtuallyAssist with other ad-hoc project work and custom extractsPropose process improvements that eliminate toil within the departmentWhat success looks like in this role:Assist in ownership of weekly production of Inventory Analytic deliverablesUnderstand all Inventory Analytics code and processes (primarily Python, Spotfire, and SQL) and MethodologySupport explanations of Inventory Analystics methodology in internal conversations and with customers; prepare materials (files and data visualizations) for customer presentationsUnderstand Enriched Data and support the Enriched Data team efforts for Inventory Analytics clientsWhat you’ll need to thrive in this role:Strong ability to identify, investigate, and resolve data anomaliesProven ability to work independently and take initiativeExcellent verbal and written communication skillsStrong analytical, problem solving, organizational, and administrative skillsAbility to work independently, as well as a team member, in a dynamic, fast-paced, and deadline-oriented environmentWillingness to work with all levels of the organizationExcellent problem solving and troubleshooting skills to perform root cause analysis QualificationsWhat you’ll bring to the table: 1+ years of work experience in a quantitative and analytical discipline1+ years of work experience in a customer facing roleWork experience in the pharmaceutical industry; Channel data experience a plusBachelor’s degree required; Master’s degree a plus. Background in Analytics, Mathematics/statistics, and/or Finance preferred. Python and SQL experience, requiredAdditional InformationWhat does IntegriChain have to offer?Mission driven: Work with the purpose of helping to improve patients' lives! Excellent and affordable medical benefits + non-medical perks including Flexible Paid Time Off, 401(k) Plan with a Company Match to prepare for your future, Parental Leave, Student Loan Reimbursement and much more!Robust Learning & Development opportunities including over 700+ development courses free to all employees. IntegriChain is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. IntegriChain is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.Our policy on visa sponsorship for US based positions: Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by IntegriChain.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The data analyst/report technical writer performs highly advanced work related to special education and special populations data collection and reporting activities and projects.Essential FunctionsDevelops and writes data documentation, analytical requirements, business rules, workflows, and data calendar/timelines for existing and new data projects using simple, clear, unambiguous, and concise languageOversees the planning, design, scope, structure, creation, analysis, and maintenance of SAS programs, datasets, data reporting systems, and reportsDevelops and manages extensive quality assurance and quality control checks of SAS programs and workflows to improve existing programs and processes including comprehensive documentationPlans, studies, researches, and evaluates current information and data systems and recommends changes as neededMinimum RequirementsII. CANDIDATE SKILLS AND QUALIFICATIONSCandidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity. Years Required/Preferred Experience 4 Required Experience with SAS programming or similar statistical programming language 3 Required Education: Graduation from an accredited four-year college or university 3 Required Experience working with administrative data 3 Required Experience developing technical documentation 3 Required Experience with MS Office suite, especially Word and Excel 2 Preferred Experience working with education data\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"ARE YOU HAPPY? ARE YOU VALUED? ARE YOU IN CHARGE OF YOUR FUTURE?Our Mission is to provide products and services, in an honorable way, that exceed the expectations of each one of our clients. We are not like other HVAC companies, Conditioned Air, “The Comfort People since 1962” Success Depends on Employees Like You, who pride themselves in teamwork, professionalism, knowledge, ability, loyalty, and exceeding customer expectations.We Want Our Employees to Thrive and Grow, in a place where a job is more than a job, It Is a Career! Learn while on the job, always preparing to achieve the next step of personal and professional success. We continually invest in you! Named 2019's “Top 500 Companies on the Gulf Coast” by Business Observer and recognized in Gulfshore Magazine’s “Best in Business” several years in a row. Now is the time to Join Our Growing Team! We are now seeking a Data Analyst to work in either our Fort Myers or Naples location.The position works on multiple projects as a subject matter expert in a fast-paced environment for the support of executive management and other internal clients.PLEASE BE AWARE THAT THIS IS AN ON-SITE POSITION IN SWFL, THERE IS NO OPTION FOR REMOTE WORK. IF YOU LIVE IN SWFL OR ARE PLANNING TO RELOCATE, PLEASE APPLY AND YOU WILL BE CONTACTED.Essential Duties and Responsibilities:Creates, analyzes, and utilizes financial data to create reporting related to revenue, sales, and operating metrics/KPINormalizes financial and operational data to maintain appropriate and accurate financial databasesEnhances and refines databases to improve reporting and analysis capabilitiesTracks, reconciles and analyzes variancesCompletes weekly, monthly, quarterly, annual, and ad-hoc management reports and analysisIs the go-to expert regarding system data and report buildingCreate proactive analyses comparing company results to industry data to evaluate program performance.Participates in project teams, analyzing various new programs, projects, or venturesPrepares reports, presentations, and other documents and presents these materials in meetingsIdentify problematic areas and research to determine the best course of action to correct the dataIdentify and research anomalies and outliers in dataPerforms other related duties as assigned or requestedEducation and Experience:BachelorsRequired- 3+ years of experience working in a Data Analyst or Business Analyst RoleAttention to detailCoding skills (SQL)BI tools (Tableau or PowerBI)MS Office (Excel)Critical thinkingAbility to work with technical and non-technical stakeholdersDesire to learn / Intellectual curiosityWANT COMPETITIVE PAY AND GREAT BENEFITS? Look no more, we offer 8 Paid Holidays, Company Paid Basic Life and Long-Term Disability, PTO, Medical, Dental, Vision, supplemental insurance benefits for Accident, Critical Illness, 401(K) Retirement plan, a bonus plan, and above all, a great atmosphere with on-going training and teamwork. For additional information or assistance please visit www.conditionedair.com.Conditioned Air provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.In compliance with the Drug-Free Workplace Act of 1988, Conditioned Air has a longstanding commitment to providing a safe, quality-oriented, and productive work environment. Alcohol and drug abuse pose a threat to the health and safety of Conditioned Air employees and the security of the company’s equipment and facilities. For these reasons, Conditioned Air is committed to the elimination of drug and alcohol use and abuse in the workplace\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Position: Data AnalystLocation: West Chester, PADuration: 12 monthsThe ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users. As part of the Cyber Recovery program it is vital to measure and document multiple recovery scenarios. This position will assist in gathering, evaluating and transforming recovery time information into a formula which can be re-used across multiple scenarios.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with dataCompile and analyze data related to business' issuesDevelop clear visualizations to convey complicated data in a straightforward fashionQualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience1 - 2 years' Data Analysis experienceProficient in SQL\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'BPI is looking for a Data Analyst to join our team in our Sioux Falls office. The Data Analyst is responsible for managing our master data set and developing respective reports/visualizations.The ideal person for this position has an exceptional eye for detail, and a solid understanding of popular data analysis tools. This individual will partner with our Procurement team to manage the back end data entry and analytics of our ERP system. Responsibilities:Manage data – Own the master data and all that it contains. Review and report all findings to appropriate parties. Explain the testing of data and the ability to import and process anything confidential according to the guidelines given. Create reports for the customer and internal users that can provide clarity trends as well as areas for improvement.Support data – Support the data warehouse in identifying and revising reporting requirements as well as initiatives for data integrity and normalization. Make recommendations for improvements and suggest ways to generate sales of our existing products by analyzing all trends. Compile business intelligence and trends to support actionable recommendations.Requirements:Associates degree in business, information technology, or data preferred or experience in lieu of degreeAbility to understand business needs and relay into easy to understand, non-technical languageHigh-level written and verbal communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'RaptorTech is looking for a Junior Data Analyst to join our team. As a data analyst, you will play a crucial role in analysing complex data sets, developing insights, and making data-driven decisions. You will be responsible for gathering, interpreting, and analysing data from various sources to create reports, dashboards, and visualizations that can be understood by stakeholders.You will ideally have experience in Mining data sets - specifically Fleet Management systems and have conducted productivity and data integrity analysis to identify improvement opportunities.Key Responsibilities Collect and analyse large, complex data sets from multiple sources Use statistical methods to identify trends and patterns in data to help make business decisions Develop insightful reports and dashboards that clearly communicate data insights Communicate technical information and data interpretation to non-technical stakeholders Collaborate with internal and external stakeholders to understand business requirements, goals, and objectives Advise on data quality improvements and optimization of data modelsQualifications Bachelor’s or master’s degree in Statistics, Mathematics, Computer Science or a related field 2+ years of work experience in a data analyst role Experience in the mining industry will be viewed favourably. Strong analytical, problem-solving skills and ability to translate analysis into recommendations. Proficiency in data analysis, visualization, and reporting tools such as SQL, Excel, Tableau Experience in project management Experience with data modelling, data profiling, and data warehousing Excellent communication, interpersonal and organizational skills Ability to manage multiple tasks and projects simultaneously High attention to detail and accuracyBenefits Opportunities for career advancement and growth Ongoing training and developmentIf you are a creative problem solver with a passion for data analysis, we would like to hear from you. This is an excellent opportunity for a talented and driven professional to work in a challenging and rewarding environment.Please submit your CV and covering letter outlining your qualifications and experience.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Summary / Position Purpose: The primary responsibility of this role is to create consolidated reports, dashboards, and data analysis for the internal customers of ACG. This role will be responsible for the day-to-day support, maintenance, and improvement of our CRM and supporting platforms, as well as excel-heavy data-related projects. Their work will involve collecting and cleaning data from multiple sources, running ad hoc reports, building automated dashboards, investigating, and fixing any potential errors/bugs, and working with the Database Administrator to ensure that the information in our database is error-free for accurate reporting. Essential Duties, Functions and/or Responsibilities: Create, validate, and send daily weekly, and monthly management reports.Assistance with requests for non-standard reports and analysisSupport management reporting by maintaining hierarchical information.Perform business-to-system analysis and troubleshooting analysis of complex management reports and business problems.In the report, development lifecycle support impacts analysis and project requirements definitionTransform client needs into functional requirements.With guidance, collect, analyze, and document business requirements for project proposals including but not limited to process and data flow, user interface, and reporting requirements.Together with managers and/or senior analysts, participate in cross-functional meetings to understand customer needs and identify problems and solutions.Appropriate solutions, develop specifications, analyze, and document business processes, validate testing processes, and train the user community.Gather, clean, and transform large data sets to be used in reports and visualization.Design, develop and implement innovative/effective/strategic fully automated business solutions.Works closely with IT and business to incorporate daily automated data refreshing.Develops and provides a standard set of user-friendly reporting tools to internal business customers.Provides maintenance on deployed tools and dashboards.Assist sales & marketing teams with CRM reports and data management, building and maintaining outreach lists for up to several dozen sales and inside sales colleagues.Other duties as assigned.  Education and/or Work Experience Requirements: EDUCATION: Bachelors/4 Yr. DegreeYEARS OF RELEVANT WORK EXPERIENCE: 1+ yearsSalesforce.com (or equivalent CRM) power-user/admin experienceExpert knowledge of Microsoft Office (especially Excel)Demonstrable excel & CRM familiarity with pivot tables and other similar visual reporting tools to display/reconcile large amounts of data.Strong ability to meet deadlines and manage and prioritize simultaneous requests.Creative and analytical thinker with strong problem-solving skillsMust demonstrate ability to communicate effectively verbally and in writing with all levels of the organization.Ability to critically evaluate and prioritize information gathered from multiple sources and reconcile conflicts.Ability to assess the impact of new requirements on Salesforce and other integrated systems.Ability to safely and successfully perform the essential job functions consistent with ADA and all other applicable federal, state, and local standards, including meeting qualitative and/or quantitative productivity standards.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Job DescriptionHertz and the Advanced Analytics and Tool Development team is seeking talented individuals with passion for real-world problem solving. The analyst will partner with various functions within the company (Revenue Management, Fleet, Operations) and develop advanced tools and resources to support overall location-level planning and operational decisions. The analyst will be working with large sets of structured and unstructured data to perform analysis, develop tools, and provide actionable insights.What You’ll Be Doing Develop tools for the field for car assignment to optimize upgrade/upsell/booking success.  Develop tools to provide visibility to many of the operational processes.  Conduct analyses to inform stakeholders and help make the most optimal decisions regarding various strategic initiatives.  Code and automate performance reports.  Configure shared PC resources to automate scripts and collect data. What We Expect A Bachelor’s degree; preferably in Data Science, Computer Science, Statistics, Engineering, or another quantitative field.  A demonstrated ability to query and extract findings from large data sets in relational databases such as SQL Server, Teradata, Oracle, etc.  A wide range of data-related technical skills regarding databases, scripts, and web APIs.  Experience with programming/scripting languages like R or Python  Experience with advanced data visualization platforms such as Tableau.  Quick on feet; willingness to discover alternative solutions to technical problems.  A desire to solve complex problems with creative and concise solutions.  Excellent written and oral presentation skills – ability to communicate findings with non-technical stakeholders in concise and simple terms.  An individual who thrives in a collaborative environment. Nice To Haves More than 1 year of work experience in a data driven industry including Rent-A-Car, travel, or service industry  A Master’s degree in a quantitative field  Experience with statistical modeling  Experience with web development languages such as Ruby, PHP, or JavaScript. r work every day represent a significant part of our culture – and our success and reputation as a company.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Extend OverviewExtend is a rapidly growing fintech startup in the B2B payments space with a focus on serving banks and their customers. We have built the first virtual card platform of its kind, directly integrated with processors, networks, and the technology that supports banking across the industry. We offer several virtual card products including an app-as-a-service that banks can offer business customers with their existing credit cards, a suite of virtual card APIs for those looking to build custom payment solutions, and we also offer secure connectivity to key banking and payment services that enable 3rd-parties to integrate and embed payments into their software.Founded in 2017 by 3 industry experts with experience at Fortune 500 companies, including American Express and Capital One, Extend is headquartered in Manhattan and has recently raised $40m in venture capital from top fintech investors. Extend was recently voted one of America's best startup employers by Forbes and best payments service platform by Tearsheet.With extreme monthly growth and 85+ mission-driven employees, now is prime time to join our team!For more information visitAbout The RoleWe are looking to add a Business Intelligence Analyst to our growing Business Intelligence team; as part of this team, you will be responsible for data reporting, developing analytics and measurement tools, and driving initiatives that help optimize revenue across multiple business segments. You will own much of the Tableau dashboarding and ad hoc data requests. You will also ensure our data remains clean and accurate. You’ll work with the Business Insights team to gather requirements from departments across the company, design new dashboards, and incorporate feedback. This is a hybrid role, based out of our New York City office, with three days on-site.At Extend, you’ll:Create and maintain data tables and Tableau dashboards that allow key stakeholders to view data in a quick and concise manner, effectively communicating insights through visualizations.Manage and resolve ad hoc Business Intelligence requests, developing new tools to automate repetitive tasks.Design metrics, derive data-driven insights, and communicate findings in a concise manner to key stakeholders to help improve business performance.Maintain the integrity of company data and put checks in place to ensure accuracy. Identify and fix data quality issues before reports are generated.Partner with stakeholders across the long/short business to identify data needs and build reporting to inform business decisions.Design data models, ensure data quality, and automate processes where possible.THE CANDIDATE4+ years of previous experience within data analytics or business intelligenceExcellent data visualization skills (Tableau, PowerBI, or software libraries in R or Python)Mastery of SQL and database conceptsThe ability to synthesize information quickly to provide an independent and objective viewpoint, propose appropriate solutions, and drive meaningful changeThe ability to multitask and prioritize assignments while producing high quality work in a demanding, fast-paced environmentStrong written and verbal communication skills to interpret the data and dashboards for those less technically inclinedStrong attention to detail Data curiosity – When you look at data or a visualization, do you ask yourself if the values make sense, or what could be causing something to stand out?The ability to work independently as well as collaborate with a small team and internal clientsWhat We OfferCompetitive compensation packageEquity for all–our success is your successUnlimited vacation–and we want you to use it401K matchingFlexible work optionsComprehensive health coverage for you and your familyMaternity and paternity leave benefitsReimbursement for gym membershipsReferral bonus program–bring your friends!Work with and learn from functional experts across disciplinesThe salary range for this role is $100,000-$140,000. Your final base salary will be determined based on various factors which may include, but are not limited to location, work experience, skills, knowledge, education and/or certifications. You may be eligible to participate in Extend’s annual bonus plan, based on individual and organizational performance.To all recruitment agencies, Extend does not accept agency resumes. Please do not forward resumes to our jobs alias, Extend employees or any other company location. Extend is not responsible for any fees related to unsolicited resumesExtend is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, citizenship or immigration status, or any other status protected by law.Powered by JazzHRIJ33N9DZnA\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " '12860BRNew JerseyJob DescriptionData Analyst:Location : Onshore. Working with clients and preparing the Prologue Financials database for implementation.  Importing and converting client conversion data into Prologue-friendly format, retaining all meaningful data points. Working with client on how to handle any discrepancies or exceptions.  Posting general ledger journal entries as required to adjust data loaded.  Crafting client financial and validation reports through the Prologue report writer and working with the client to resolve any findings.  Partnering with the Business Consultants, Project Managers and Project Team to craft a solution to fulfill and prioritize the client’s business requirements.  Identifying and implementing solutions to automate, or otherwise build efficiencies for, the various steps required for building out client databases – encouraging an environment of continual improvement. QualificationsGraduateRange of Year Experience-Min Year5Range of Year Experience-Max Year8\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"The position’s main responsibility is to manage a variety of data sources and conduct research initiatives as directed by leadership. This role will work with other researchers in the team on specific data queries, provide periodic updates on key statistics from multiple data sources and perform other activities as needed, including survey development and research paper writing. The Senior Research & Data Analyst will also play a major role in building, improving and updating key data sources used by researchers and serve as go-to claims data expert.RequirementsBachelor's degree in statistics, economics, data analytics, epidemiology, data science, data engineering, computer science, market research or other quantitative discipline.A minimum of 3 years of proven experience in/with building datasets using multiple input files and managing or analyzing claims data or similar large datasets.Excellent communication, analytical and interpersonal skills.The ability to shift between multiple projects, work with different team members, seek feedback and clarification, be detail oriented, and think of creative and innovative ways to improve processes and deliverables.Proficiency in SAS software and Microsoft Office Suite.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Contract Remote Role: Data AnalystDuration: 6 months contract with possible extensionLocation: Newark/Remote (primarily remote with ability to occasionally go on-site when needed).Job DescriptionThis position will support the clients Clean Energy Jobs Program, which includes following:The use of data and interpreting to develop executive reports and power points.Gather the information and statistics, analyze trends, and then use charts and graphs to present the results.Documentation of various processes by collaborating with client QA/QC team.Develop actionable roadmaps for improving workflows and processes and establish and organize KPIs in line with global directives.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Genesis10 is seeking a JR SQL Data Analyst for a contract to hire with our client in Plano, TX. \\xa0100% Remote.Job Description:Job responsibilities focus on analyzing, querying, and performing quality assurance on data maintained in a complex relational database environment.Responsibilities:Designs and analyzes data utilizing advanced technical experience with SQL Server technologiesAnalyzes Title Insurance rates and related data maintained in complex relational databasesProduces ad hoc reports and queriesDevelops and maintains familiarity with internal, proprietary SQL Server database structuresWorks collaboratively with database developers and business analysts to identify and resolve data issuesDevelops and maintains familiarity with relevant data reporting and State requirementsAssists in updating in-house proprietary software to reflect required changes to data processing and reporting specificationsParticipates in the development and maintenance of data warehousePerforms testing and validation against software application for quality assurance.Regular consistent attendance is required, that could include attendance at after hour Company events.Ability to accept supervision.Ability to foster, develop and maintain professional and collaborative working relationships. Must be able to get along with others, i.e., peers, supervisors, outside customers, and vendors.Ability to interact effectively and professionally with all levels of management, employees and customers by email, phone and in person.Must be personable, positive, and a professional representative of the Company.Perform other duties as assigned by supervisor.Qualifications:Minimum BS or BA, in computer science or related field; preferred2 - 5 years of experience querying relational databases using SQLStrong PC skills required, including proficiency with Microsoft Windows, Excel, and WordExcellent analytic, interpersonal, and communication skills, especially written communication skillsT-SQL stored procedure development, preferred.Microsoft SQL Server Reporting Services design and development, or similar report design and development experience (e.g. Microsoft Access or Crystal Reports)Querying and/or developing Microsoft Analysis Services (or similar) OLAP databasesExcellent verbal and written communication skills.Excellent interpersonal and customer service skills.Ability to prioritize and handle multiple projects.Strong attention to detail and organizational skills.Proficient in Microsoft Office Suite and Outlook.Compensation:Hourly W2 pay rate $30.00 - $33.00We have access to additional contract, contract-to-hire, and direct hire positions with various rate ranges.\\xa0If you have the described qualifications and are interested in this exciting opportunity, apply today!Ranked a Top Staffing Firm in the U.S. by Staffing Industry Analysts for six consecutive years, Genesis10 puts thousands of consultants and employees to work across the United States every year in contract, contract-for-hire, and permanent placement roles. With more than 300 active clients, Genesis10 provides access to many of the Fortune 100 firms and a variety of mid-market organizations across the full spectrum of industry verticals.For contract roles, Genesis10 offers the benefits listed below. If this is a perm-placement opportunity, our recruiter can talk you through the unique benefits offered for that particular client.Benefits of Working with Genesis10:Access to hundreds of clients, most who have been working with Genesis10 for 5-20+ years.The opportunity to have a career-home in Genesis10; many of our consultants have been working exclusively with Genesis10 for years.Access to an experienced, caring recruiting team (more than 7 years of experience, on average.)Behavioral Health PlatformMedical, Dental, VisionHealth Savings AccountVoluntary Hospital Indemnity (Critical Illness & Accident)Voluntary Term Life Insurance401KSick Pay (for applicable states/municipalities)Commuter Benefits (Dallas, NYC, SF)Remote opportunities availableFor multiple years running, Genesis10 has been recognized as a Top Staffing Firm in the U.S., as a Best Company for Work-Life Balance, as a Best Company for Career Growth, for Diversity, and for Leadership, amongst others. To learn more and to view all our available career opportunities, please visit us at our website.Genesis10 is an Equal Opportunity Employer. Candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Job Title: Data AnalystLocation: Hackettstown, NJ, 07840Duration: 6+ Months(possible extension)Hybrid (at least 2 days in Hackettstown office, possibly 3)Roles & ResponsibilitiesData Analyst is responsible for physical product audit, product data quality, data issues investigation, and is the primary point of contact on data violations and resolutions from the audit process with cross-functional business partners (Sales, Packaging R&D, Master Data, Food Safety & Quality, and Site Quality Control). The analyst is also responsible for the support of Client North America's largest distributor, customer communications, internal GS1 compliance adherence, and data accuracy in our master data systems.Key ResponsibilitiesPerforming the onsite physical product audit (using audit tools and equipment).Data violations documentation.Collaborating with cross-functional teams to address data violations and their resolution.Process improvement.Product data quality certification status support.Maintenance of data accuracy within master data systems (internal and customer front).GS1 compliance adherence monitoring.Driving internal data compliance improvements and external customer satisfaction.Qualifications Education & Professional Qualification:BA/BS degree in Business Operations Management, Systems Management, Finance or related discipline is preferred.OR 3+ years' experience in one or more of the following business areas: logistics, customer care, finance, or master data management. Knowledge/Experience:Ability to work independently, without constant supervisionAdvanced analytical skills and attention to detailExcellent written and verbal communication skillsStrong interpersonal, negotiating, and influencing skillsIntermediate to advanced Excel and/or Smartsheet skillsCustomer Service experienceAbility to learn and work in multiple systemsContinuous improvement/automation recommendations Additional skills preferred, but not required:GS1 Standards knowledgeKnowledge of GTIN Allocation RulesPrior knowledge of SAP preferredData Synchronization guidelines\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"About UsWho We AreSitting at the intersection of social networking and gaming, we empower creativity and connection in a digital world. Our mission is to build deep, rich virtual worlds where everyone belongs.We have been working towards this mission for a decade. We are the creators of Highrise, the first virtual world on mobile, which has seen extraordinary growth over the last few years and now boasts over 20 million users across iOS and Android. Every day, the citizens of Highrise come together to hangout, explore, create, collect, and trade in our metaverse, and we are on the precipice of making history once again with our expansion into Highrise World.Our PurposeTo build creative worlds where you belong.About This RoleThis is a cross-functional role and you will be reporting to Anton Bernstein, CEO. (Please note that if you reach out to Anton, they may not reply due to the volume of messages received.)In this role, you will build out marketing and product reports, analyze data, learn and establish data best practices, as well as collaborate with artists to generate high-performing live operations and marketing creatives.This is an analytical role that requires a passion for data analysis and reporting. You must have strong knowledge of SQL and Python. You will be working collaboratively with various teams including Live Operations, Marketing and Product.Your MissionThe mission of this role is to deliver key reports and interpret data to provide valuable insights into Highrise features and player behavior. This data will help us make decisions around in-game content releases, marketing performance, feature development, and more.Key Indicators of SuccessYou will be the go-to person for data analytics questions from the Live Operations, Marketing, Product and Art teams. You will provide timely and easy-to-understand insights to different stakeholdersYou will turn raw data into actionable insight and recommendations that will be crucial to Highrise's features, tools, and overall business successYou will leverage tools like Amplitude, Looker, Periscope and more in order to create insightful dashboards for different teamsWhat You Will DoYou will build, design, and maintain reports and dashboardsYou will work with data and perform “deep dive” analyses on various topics such as player journeys, live events, user acquisition, etcYou will work closely with product and marketing teams to review data and extract storylines & trends aligned to Highrise growthYou will identify trends and behaviors that influence performance and player engagementWhat You Can Expect in the First 90 Days30 Days: In the first 30 days, you'll become familiar with the scope of work of the different teams: product, live operations, marketing, and art. Additionally, you'll get to know the analytics infrastructure60 Days: In the first 60 days, you’ll start building dashboards and reporting based on team needs. You will begin working with live operations and marketing to craft questions and answer them with data90 Days: In the first 90 days, you will take ownership of analytical insight. You will use data proactively and present your findings to the teamWho You AreYou have the ability to collect, clean, and analyze data, and turn it into meaningful insights and recommendationsYou have excellent written and oral communication skills with the ability to explain complex data clearlyYou have the ambition to own the reporting and analysis functions for the Highrise metaverseYou have an entrepreneurial mindsetMust Have'sA university degree in Computer Science, Math, Economics, Statistics, or other quantitative fields2+ years of hands-on experience in quantitative analysis and a proven track record of significantly impacting product growth by providing data findingsExtensive knowledge of relational databases, SQL, Python and working with large datasetsExperience with data analytics for mobile apps, gaming products, or e-commerceNice to Have'sYou are familiar with technologies such as Amplitude, AWS, and Redshift to build and optimize production data pipelinesYou have an understanding of machine learning and data scienceBenefitsMeaningful equity in an extremely fast-growing startupEquipment allowance so you can choose whatever you need to work comfortablyCompany-sponsored medical and dental insuranceUnlimited Vacation policy. We know how important taking time off is and we encourage it. Our team takes about 20 days off on average every yearEducation stipend. We deeply believe in learning and self-improvement. We've set aside a budget for every employee to learn additional skills and growMonthly Fitness Allowance to stay active and take care of your physical healthPerksWorking with a diverse team of people in over 15 countriesYou have a voice! We love hearing ideas and want to embrace you for themExtremely low turnover environment. Over 20% of our team has been here for over 3 years!Coworking space stipend in whichever location you wantMonthly team building budget to get to know your teamTeam retreats to meet face-to-face and deepen connectionBring your pet to work everyday! We love seeing your furry loved onesA Highrise Admin badge for your avatarCompensation PhilosophyAs a fully remote company, we strive to have an equitable compensation philosophy that allows us to take good care of our people, no matter where they are in the world. At the moment, our philosophy is composed of multiple factors such as market pay, location, performance, and other rewards. Our compensation philosophy is meant to support our organization’s strategic plan and operating objectives — as we continue to grow as a company, so will our approach to compensation.The salary range for this role is $75,000 -$120,000 in US and Canada. Salary will be adjusted based on your location.What its Really Like to Work HereOur CultureWe are a global team of nearly 100 people right now and rapidly growing. We feel a sense of ownership over our work and take great pride in what we do. We are not afraid to make, and most importantly, admit our mistakes — that allows us to show up authentically and build relationships of trust across the board. We are the scrappy kind, so we try to do more with less, and we love that! If you were to ask our team to describe our culture, they would probably say we are a passionate group of peeps trying to impact the next revolution of the internet.Our ValuesDream big, then make it real.Be an owner, make a difference.Build with humility.Fast is better than slow.Keep it scrappy.Always be learning.Read more about our values here.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About the Company:Built by the number-one sales trainer in the world, Cardone Training Technologies has become one of the most trusted names in the sales industry. For over thirty years, Grant Cardone has helped companies expand sales, increase transaction profitability, and reduce turnover all by disrupting the status quo by implementing his proven, industry-leading processes, through management, and training technology. Founded and led by CEO, Grant Cardone, a New York Times bestselling author, international social media influencer, renowned speaker, trainer and coach to fortune 500 companies as well as a real estate mogul, Cardone Training Technologies takes a cutting-edge, disruptive approach to sales, marketing, social media and consulting to give businesses an opportunity to increase their revenue and expand their market share.Event Data Analyst Responsibilities:Manage, monitor, track and report on all eventsPerform event registration maintenance in our proprietary ticketing system including responding to attendee’s questions, making registration changes and providing updates to team members and clientsSet registration rules/parameters (early bird rates and dates, etc.) based on experience and past year’s registration data analysisProvide analysis and new ideas/testing using this information to upper managementCommunicate with clients and partners in a professional mannerCommunicate all necessary automations with the web team to streamline processesProvide reports to help increase sales and tacticsTransform data into a digestible and presentable story based on ticketed, redeemed and confirmed attendees and confidently / effectively communicate that information with the Executive TeamProactively drive responsibilities and self-manage to the highest quality standardsBe available for occasional work travel and weekend workExperience, Competencies and Education:Advanced Excel and Google Sheets skills including pivot tables, V-lookups, ability to build complex formulasExcellent written and verbal communication skillsStrong analytical and data interpretation skills and the ability to interact with all levels of the organizationExperience in Shopify and Hubspot - desired but not requiredExceptional attention to detail and excellent coordination and organization skills, with the ability to manage multiple inputs and to organize data effectivelyYou have demonstrated the ability to work in a global and fast paced environment and remain calm in times of pressure This is full-time Monday to Friday 9am to 6pm, with additional hours/times as needed Cardone Enterprises is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"At DDC (www.ddcpublicaffairs.com) we provide public affairs solutions that enable our clients to identify, manage and communicate with their political assets and advocates around the globe. Through a unique blend of professional services and technology solutions, we establish rich connections with targeted audiences and empower our clients to win on their public policy campaigns.Currently, we are looking for a Data Analyst to join our downtown, Washington, DC office.About The RoleAs a Data Analyst working at DDC, you'll work alongside our internal teams and support our clients, both in an ad-hoc/on-demand manner, and by managing existing frameworks within our ecosystem. In this role, you will have the ability to work well and collaborate within a team and excel in a fast-paced, client intensive environment.What You'll Be DoingDesign and implementation of SQL queriesCreation and editing of SSRS reportsDesign, creation, and execution of automated and manual SSIS packagesManipulation and transformation of client data using various SQL toolsTroubleshoot and resolve data related issuesAbout YouYou are an initiative-taker and can work independently as necessary.You possess a drive to make things better and the aptitude to do so.Relational Database (specifically MS-SQL) experience, SSIS, SSRS, T-SQLExperience with data validation, data file manipulation, report creation, data extraction (ETL/ELT)Strong communication and organizational skillsCollege degree strongly preferred, or you have equivalent professional experienceProgramming background, Crystal Reports experience, and Geo-Spatial (mapping) experience is a plusAbout DDCSince our founding in 1996, DDC has grown to become the largest full-service Public Affairs agency in the country. Through our unique blend of professional services and technology solutions, we establish rich connections with targeted audiences and empower our clients to build the relationships necessary to win on their public policy campaigns. We are committed to ensuring each member of our team is a key contributor, and support that by fostering a collaborative work environment and entrepreneurial spirit throughout the organization.DDC is proud to be part of the Omnicom Group Inc. (www.omnicomgroup.com). Omnicom is a leading global marketing and corporate communications company. Omnicom’s branded networks and numerous specialty firms provide advertising, strategic media planning and buying, digital and interactive marketing, direct and promotional marketing, public relations, and other specialty communications services to over 5,000 clients in more than 100 countries.Agency Information And Submission RequirementsDDC has offered a hybrid work environment for many years. This position will be based in our downtown Washington, D.C.The anticipated salary range for this position is $60,000 – $85,000 per year.Salary is based on a range of factors that include relevant experience, knowledge, skills, other job-related qualifications, and geography. A range of medical, dental, vision, 401(k) matching, paid time off, and/or other benefits also are available. Employees from diverse or underrepresented backgrounds are encouraged to apply.DDC is an Equal Opportunity Employer M/F/Disability/ProtectedVet EEO Statement DDC Public Affairs is committed to equal employment opportunity and affirmative action. DDC Public Affairs does not discriminate in any aspect of employment on the basis of race, color, religion, national origin, ancestry, gender, sex, sexual orientation, gender identity and/or expression, age, veteran status, disability, or any other characteristic protected by federal, state, or local employment discrimination laws where DDC Public Affairs does business. Our policy is to employ, advance, and reasonably accommodate all qualified employees and applicants. Any person who feels that he or she has been subjected to discrimination should immediately report the matter to Talent Development or to a supervisor.Any reported incident will be investigated. Retaliation against an employee or applicant who makes a good-faith claim of discrimination is prohibited. Employees and applicants may bring good-faith complaints, ask questions, and raise concerns without fear of reprisal or retaliation.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"National Grid Renewables, which includes the renewables development company formerly known as Geronimo Energy, is a leading North American renewable energy company based in Minneapolis, Minnesota, with satellite offices located in the regions where it develops, constructs, and operates renewable energy projects. As a farmer-friendly and community-focused company, National Grid Renewables develops projects for corporations and utilities that seek to repower America’s electricity grid by reigniting local economies and reinvesting in a sustainable future. National Grid Renewables is part of the competitive, unregulated Ventures division of National Grid and has a portfolio of solar, wind, and energy storage projects located throughout the United States in various stages of development, construction, and operation. National Grid Renewables develops high-value, competitive renewable energy projects. Our focus on communities and farmers means it’s not just about projects, but about the people we work with, both outside and inside our organization. National Grid Renewables Team Members embody our foundational culture of being entrepreneurial, creative, and nimble and take pride in supporting National Grid’s vision to be at the heart of a clean, fair, and affordable energy future for all.   National Grid Renewables is seeking a Senior Data Analyst to join our growing IT Operations Team. This role will provide the technical knowledge necessary to drive forward our organization's cloud-based infrastructure initiatives as we align our processes and technologies. RoleReview and validate business critical data as it is collectedOversee the deployment of data to the Microsoft Azure DatalakeManaging and designing the reporting environment, including data sources, security, and metadataSupporting the data warehouse in identifying and revising reporting requirementsDevelop policies and procedures for the collection and analysis of dataCollaborate with IT for data mapping and integration via Microsoft Azure to leverage big data use casesProviding technical expertise in data storage structures, data mining, and data cleansingTroubleshooting the reporting database environment and reportsAnalyze business processes and requirementsIdentify opportunities to improve processes and strategies with technology solutionsIdentify development needs to improve streamline operationsCreate reports for business stakeholders using tools such as Microsoft Power BIMonitor analytics and metrics resultsImplement new data analysis methodologiesReview organizational data to ensure integrity of data collection and utilizationPerform data profiling to identify and understand anomaliesCollaborate with business usersTraining end-users on new reports and dashboards  Background and SkillsBachelor's degree in Management/Computer Information Systems (MIS/CIS), Computer/Electrical Engineering, Computer Science, or related fields.5+ years as a Data AnalystAbility to build strong data models and relational databasesStrong data mining techniquesSQL experiencePower Query, PowerBI and data visualizationStrong understanding DatalakesStrong understanding of DatabricksDatabase management and reportingBusiness administrationMicrosoft Office and ExcelCritical-thinking and problem-solvingStrong Communication skills\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'DescriptionThe newly formed Cancer Data Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson Comprehensive Cancer Center is seeking a programmer/analyst with research and development experience. This position will be working with a broad team of Data Scientists, developing new quantitative strategies to improve our understanding and ability to treat cancer. Our team is passionate about applying their knowledge of software-development and design to improve scientific research. We develop scalable and distributed software solutions that maximize utilization of both local high-performance computer infrastructure and a growing set of cloud-based assets. Our datasets comprise hundreds of terrabytes, and are growing rapidly, creating fascinating problems in storage, access, parallelization, distributability, optimization, containerization and core algorithm design. This requires a strong background in computer science, providing a platform for technical leadership, but linked to strong personal communication and leadership skills, to help ensure insights are broadly adopted. The successful candidate will be helping us perform research that will transform the lives of cancer patients. Your responsibilities will be to use your design, analysis and programming skills to create Data Science software, optimize existing code and improve its quality and improve distributability boost productivity of the entire team. You may have experience in data-intensive software-development or research, or you may be experienced with software-engineering in an enterprise environment. You will help drive professional-level design and development practices throughout the entire team, and serve as a local point of expertise for workflow optimization and containerization. You will be rewsponsible for one major and several minor projects at any point in time. We are in a rapid growth-phase, and the successful candidate will be involved in hiring of new team members. Beyond your strong inter-personal skills and computer science background, you will have experience with either systems software, databases or algorithms, linked to implementation skills at least one of C++, R, Perl or Python. You will be comfortable in UNIX/Linux environments and using continuous integration and CASE tools. Salary Range: $5525-$10925 Monthly\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning engineer to work closely with our product and research teams to develop SOTA deep learning software. This person will work closely with our technical and research teams to develop training and deployment pipelines, implement model compression algorithms, and productize deep learning research. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to build machine learning productsPrototype and implement appropriate ML algorithms, tools, and pipelinesCreate and manage training and deployment pipelinesCollaborate with a cross-functional team about market requirements and best practicesKeep abreast of developments in the fieldRequirementsProven experience as a machine learning engineer or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityBachelor's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Scientist (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job RequirementsM.S. or PhD in Data Science/Electrical Engineering/Computer ScienceExperience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlySpecial Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"WHO ARE WE?Our team is the first in the world to use autonomous vehicles on public roads using end-to-end deep learning, computer vision and reinforcement learning. Leveraging our multi-national world-class research team we're focusing on using less data to learn more intelligent algorithms to bring autonomy for everyone, everywhere. We aim to be the future of self-driving cars, not vehicles that are told how to drive through hand-coded rules and maps, but ones which learn from experience and data.WHERE YOU'LL HAVE AN IMPACTWe're looking for bold, talented and creative people to join our journey in developing next-generation autonomous vehicles. We're a growing start-up, building our first cohort of engineers and you can be at the heart of this!We are looking for ML Engineers to help productionize an end-to-end self driving neural network for autonomous driving. You'll be working closely with Platform and Research teams to integrate, test and scale ML features for production. Productionizing and scaling our ML models by working across Data, Validation, Platform and Research is a core component of this role and why we need you!What You'll Bring To WayveExperience in shipping ML features and in applied researchPassion to take research ideas to productionGood grasp of machine learning literatureExperience in working in platform teams and working with research teamsGood insight into the training, validation, testing and metrics for deep learning features/modelsAbility to write high quality, well-structured and tested Python codeSolid experience working with concurrent, parallel and distributed computingComfortable working with and visualising huge data setsKnowledge of computing fundamentals - what makes code fast, secure and reliableBS or MS in Machine Learning, Computer Science, Engineering, or a related technical discipline or equivalent experienceWhat We Offer YouAttractive compensation with salary and equityImmersion in a team of world-class researchers, engineers and entrepreneursA unique position to shape the future of autonomous driving and to tackle the biggest challenge of our timeBespoke learning and development opportunitiesRelocation support with visa sponsorshipFlexible working hours - we trust you to do your job well, at times that suit you and your teamPrivate on-site chef, in-house bar, lots of socials, and more!Wayve is built by people from all walks of life. We believe that it is our differences that make us stronger, and our unique perspectives and backgrounds that allow us to build something different. We are proud to be an equal opportunities workplace, where we don't just embrace diversity but nurture it - so that we all thrive and grow.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'LVIS is a leader in cutting edge neural information analysis technology that decodes brain networks and provides visualizations assisting neurological disease diagnosis. LVIS owns patented technologies and our team includes leaders with strong expertise in neuroscience and engineering. LVIS has been selected to be a member of the Stanford StartX community and the NVIDIA inception program. We are an international team with our headquarter located in Palo Alto, California, USA and an office in Gangnam, Seoul, South Korea. We are looking for talented individuals to join us in transforming the neurology health care industry.ResponsibilitiesDeep learning model deployment for medical web applications.Machine learning system stability testing and optimization.Model compression with pruning, quantization and distillation.Collaborate with data scientists and software engineers to optimize deep learning model performance.RequirementsMinimum Required QualificationsMS or PHD in Computer Science, Statistics, Electrical Engineering, Applied Math, and other similar fields.Deep understanding of the machine learning algorithms and systems, especially convolutional neural networks.Proficient in python and python machine learning packages, such as numpy, scikit learn, pytorch, keras, etc.Preferred To HaveHands-on experience of model deployment in the cloud (AWS, Azure or GCP).Experience of model compression techniques.Experiences in medical image/signal processing and data analysis.Other InformationJob type: Full-time.U.S. citizens, green card holders, and those authorized to work in the U.S. for any employer will be considered.Willing to work onsite at our Palo Alto location.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Machine Learning Engineer , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job Requirements2 years of experience, or an advanced degree (MSc).Experience in applied Deep Learning (DL) and Computer Vision (CV) concepts including but are not limited to: CNNs, RNNs, Autoencoders, Transfer Learning.Hands-on experience (academic and/or industrial) in 3D Pose Estimation and Motion reconstruction from images and videosProficiency in general purpose programming languages: Python, and C++.Experience with ML frameworks such as: PyTorch, Tensorflow, etc.The ideal candidate would be very well acquainted with Computer Graphics techniques, Neural Rendering, and Numerical Optimization(Optional) Knowledge of 3D packages such as Blender, Maya, or any game engine technologyBSc in Computer Science, Mathematics, Electrical Engineering, or related technical field.Ability to speak and write in English fluently and idiomatically.Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatment.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'ML - Handson Tensorflow Dev -ML pipeline and process -Strong python coding skills -Experience in deploying models -API development -Flask or Django experience\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Description:By bringing together people that use their passion for purposeful innovation, at Lockheed Martin we keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work.With our employees as our priority, we provide diverse career opportunities designed to propel development and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work.At Lockheed Martin, we place an emphasis on empowering our employees by fostering innovation, integrity, and exemplifying the epitome of corporate responsibility.Your Mission is Ours.The coolest jobs on this planet… or any other… are with Lockheed Martin Space.Lockheed Martin Space in Littleton, CO is seeking a full-time Early Career Software Engineer. Consolidated Analysis Orchestration Services (CAOS) is the preeminent Geospatial-Intelligence program in the world – over 10,000 intelligence analysts and decision-makers worldwide daily rely on CAOS for critical intelligence and geospatial data management. In addition to meeting today’s critical intelligence mission needs, we are working on evolving exciting future automation and artificial intelligence solutions for the National Geospatial-Intelligence Agency (NGA). We need the best engineers on our team to ensure mission success! Think you have the skills, come join the CAOS Team that builds software for the next generation of geospatial intelligence.Must be a US Citizen ; this position will require a government security clearance. This position is located at a facility that requires special access.Basic Qualifications Acceptable bachelors degree programs will include only science and technology (STEM) related programs such as Computer Science, Systems Engineering, Electrical Engineering, Computer Engineering, Physics, Mathematics etc. Must be a US Citizen ; this position will require a government security clearance. This position is located at a facility that requires special access.Desired SkillsProficiency with one or more of the following software languages: Java, C++, C#. Candidate will have knowledge of basic software practices such as coding standards, unit testing and configuration management, database and System administration. Good communication skills. Strong team player. Candidate will work in a team environment utilizing software methodologies and processes. Familiarity with Agile Development Process a plus. Strong communication skills a results oriented team player, creative thinker and problem-solver and follow all ethical standards of the Lockheed Martin Corporation.Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.Clearance Level: TS/SCIOther Important Information You Should KnowExpression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.Ability to Work Remotely: Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.Schedule for this Position: 9x80 every other Friday offPay RateThe annual base salary range for this position in Colorado or Washington is $57,800 - $110,800. Please note that the salary information is a general guideline only. Lockheed Martin considers factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience, education/ training, key skills as well as market and business considerations when extending an offer.Benefits offered: Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Flexible Spending Accounts, EAP, Education Assistance, Parental Leave, Paid time off, and Holidays.(Washington state applicants only) Non-represented full time employees: accrue 10 hours per month of Paid Time Off (PTO); receive 40 hours of Granted PTO annually for incidental absences; receive at least 90 hours for holidays. Represented full time employees accrue 6.67 hours of PTO per month; accrue up to 52 hours of sick leave annually; receive at least 96 hours for holidays. PTO is prorated based on hours worked and start date during the calendar year.This position is incentive plan eligible.Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.Experience Level: 4 yr and up CollegeBusiness Unit: SPACERelocation Available: PossibleCareer Area: Software EngineeringType: Full-TimeShift: First\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'Holy Grail developed a direct air carbon capture technology that uses electrons to capture CO2 from the atmosphere. We are looking for proactive candidates who are ready to take ownership and are passionate about creating a sustainable solution to removing excess CO2 from the atmosphere. The ultimate goal of Holy Grail is to contribute to the long-term sustainability of life on Earth.We are looking for a data machine learning engineer to join our team and help bring our modular CO2 scrubbers to market.This role will be located in Mountain View, CA.Requirements: Detail-oriented with a creative approach to science and engineering A high degree of autonomy and independence Intrinsic motivation with a fundamental love of science Ability to learn and adapt quickly Advanced skills with Tensorflow and/or Pytorch Experience with probabilistic models like Gaussian processes and BNNs Experience with active learning for Design of Experiments Experience with different active learning sampling methods Experience in building regression models in large combinatorial spacesResponsibilities: Design and build models for Design of Experiments Design and build multi-target regression models for research and engineering optimization Design and build hyperparameter tuning pipelines for machine learning and deep learning models Collaborate with mechanical engineers, chemical engineers, and design engineers to optimize manufacturing methodsNice to have: Advanced degree in data science or equivalent experience Data engineering experience Computational chemistry and atomistic simulations experience Bioinformatics experience Experience with TensorFlow probability and Pyro Experience with building active learning sampling methods from scratchWhat we offer:You will join a team that is passionate about having an impact on climate change. We care about the optimal way to solve a problem and nurture a culture of creativity and collaboration. We care about quick iterations, minimizing assumptions, and we use emojis to label our chemicals. We work on interesting technical problems and provide support and resources to tackle them.Impact: your contribution will directly impact our technical milestones and you will have full ownership of your projects. We don’t micromanageNo politics: we give you the resources to test all your wildest ideas in hours or days, not months. If there is a chance that something will advance our progress we will test it as soon as possibleOwnership: not only you will own your projects you will also own part of the companyAutonomy: we welcome your independent perspective and encourage you to set and manage your time to achieve our shared goalsFlexibility: we cultivate an informal environment that is more fun and less rigid compared to academia and larger companies\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Data Scientist , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job RequirementsM.S. or PhD in Data Science/Electrical Engineering/Computer ScienceExperience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlySpecial Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This is a fully remote opportunity at Blackbird.AI. You will not be required to relocate.The Company:What has been the effect of disinformation on the world?Blackbird.AI creates leading-edge AI software to provide critical real-time insights to provide our clients with a deep understanding of ongoing disruptive narratives, their motives, and overall digital noise. We are united by our dedication to our mission. We believe that we have a responsibility to society and that our service is vitally needed by organizations and individuals to create an empowered and critical thinking society.If this mission resonates with you, we'd love to hear from you.The Opportunity:We are looking for a Machine Learning Engineer with expertise in NLP who can join our AI research and development efforts with a direct impact on our core platform. You will work with both engineering and business teams to best understand design requirements. Then, your role is to design and build practical high performance machine learning solutions.In this role, you will work on some of the latest cutting edge applications of machine learning applied to critical problems that affect businesses, governments and society. You will directly work with top management and key stakeholders to define solutions to critical problems that will have immediate impact and value at the platform and client levels. If you are passionate to work on massive, unstructured problems that can be solved using data, we are looking for you.RESPONSIBILITIES:Contribute to research and development focusing on the following areas: information extraction, multilingual NLP, automated summarization and graph network analysis.Manage the collection and annotation of large custom datasets for text classification, unsupervised pre-training, translation, tagging, and other related problems.Capable of understanding and implementing state-of-the-art methods based on research papers and/or open source libraries, and push beyond the state-of-the-art.Experience with implementing efficient and scalable software systems in Python. Ability to integrate implemented software components into a fully functional software pipeline, and provide verification and validation against requirements.Knowledge of machine learning evaluation techniques, failure modes, and limitations.RequirementsMust Have:Minimum 2 years of professional experience working in Natural Language Processing or closely related field, with demonstration of successful delivery of novel research and/or product offerings.Masters degree or PhD from an accredited college/university in Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields (strong mathematical/static background with ability to understand algorithms and methods from a mathematical and intuitive viewpoint). Some exceptions can be made depending on exceptional past accomplishments/references. Experience with command-line scripting, data structures and algorithms, and the ability to work in a Linux environment, processing large amounts of data in a cloud environment.Highly skilled in Python development, as well as: Tensorflow, Pytorch, Keras and Scikit-Learn.Able to communicate scientific concepts to both technical and non-technical audiences.Nice to Have:Working knowledge of AWS and other cloud services.Experience creating novel datasets for scientific analysis or benchmarking.Capability to contribute at the system architecture level to enhance scalability, testability, robustness.Experience with generative models of fake text or images.Experience and top performances in online competitions / hackathons, such as, kaggle.Published research in areas related to machine learning, NLP, or its applications.Record of contributions to open-source machine learning projects, or related endeavors.Experience writing detailed documentation of machine learning systems.BenefitsHealth Care Plan (Medical, Dental & Vision)Paid Time Off (Vacation, Sick & Public Holidays)Work From HomeStock Option PlanExciting career development prospects, to grow into leadership rolesTake note - due to the high volume of applicants, only shortlisted candidates will be notified. Thank you for taking the time to apply for the role at Blackbird.AI.Ll-Remote\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Who are we?X1 is building the smartest credit card ever made. We power over $800M in annualized spending and are rapidly growing.We have been featured in publications like Business Insider, Fast Company, Forbes, Inc., Money, CNBC, CNET, Nasdaq, TechCrunch and Wired.We have raised over $60M from some of the most iconic investors in Silicon Valley, who founded Google Analytics, Y Combinator Continuity, PayPal, Affirm, Box, Yelp, and more. These include David Sacks, Max Levchin, Wesley Chan, CEOs of Yelp, Box, and Y Combinator Continuity, The Chainsmokers, and Jared Leto.What will you do?Build world class consumer finance software to serve X1's customers.Who will you work with?An elite engineering team with alumni from Affirm, Stripe, Google, Pinterest, Y Combinator, Stanford, MIT, and more.What will you work on?As a frontend-focused product engineer, you will build features that no other credit card has offered before. You will gain experience across the entire stack by deep diving into React and React Native, designing GraphQL API interfaces, and adding functionality to core processing infrastructure.Who are you? An undergraduate or graduate computer science degree (or a related field) Strong computer science fundamentals Strong programming experience with any one language Good communication skills Hungry to learn and grow alongside a growing businessAs an early team member at X1 you will be a critical voice and have significant influence over the direction of the company. We will compensate you well, invest deeply in your development, and ensure this is the single best work experience of your life. If you think you’d be a good fit, we’d love to hear from you.How can you reach us?To learn more, see https://x1.co/\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At MNTN, we've built a culture based on quality, trust, ambition, and accountability – but most importantly, we really enjoy working here. We pride ourselves on our self-service platform and are constantly seeking to improve the user experience for our customers and scale for efficiency. Our startup spirit powers our growth mindset and supports our teammates as they build the future of ConnectedTV. We're looking for people who naturally want to do more, own more, and make an impact in their careers – and we're seeking someone to be part of our next stage of growth.As a Machine Learning Engineer on our Attribution team, you will ideate, train, test, deploy, evaluate and monitor matching systems in a large scale production environment to maximize advertiser goals while respecting consumer privacy. As a core contributor to how we best match ads, you will work with data science, software engineers, product managers, infrastructure teams, and data teams. Relevant experience includes propensity modeling, ranking, predictive modeling, spam detection, clustering, segmentation, and similar.What You'll Do:Use MNTN proprietary and third party data sources to conceive and lead machine learning projects that maximize goals for advertising marketers while protecting consumer privacy. Be a hands-on builder of needed components in software and infrastructure. Become the end to end expert on matching ad opportunities to potential audiences in an ambiguous and privacy-focused ecosphere. Identify opportunities and gaps in data and insights for both internal and external stakeholders. Work with product and engineering teams to create and evaluate your model designs. Lead discussions with other technical and non-technical functions. Investigate critical incidents and provide insights to data ambiguity. What You'll Bring:1-3 years of experience of real-world problem solving related to developing and using machine learning models on large scale data. Advanced degrees in Computer Science, Mathematics, Electrical Engineering, Statistics or similar may be substituted for some years of experience. Experience in SQL, Python, Spark, R, or similar languages. Experience in machine learning libraries and platforms such as scikit-learn, tensorflow, sagemaker, or similar. Written and verbal communication skills to convey complex technical topics to a variety of audiences. MNTN Perks100% remote Open-ended vacation policy with an annual vacation allowanceThree-day weekend every month of the yearCompetitive compensation100% healthcare coverage401k planFlexible Spending Account (FSA) for dependent, medical, and dental careAccess to coaching, therapy, and professional developmentAbout MNTN:MNTN provides advertising software for brands to reach their audience across Connected TV, web, and mobile. MNTN Performance TV has redefined what it means to advertise on television, transforming Connected TV into a direct-response, performance marketing channel. Our web retargeting has been leveraged by thousands of top brands for over a decade, driving billions of dollars in revenue.Our solutions give advertisers total transparency and complete control over their campaigns – all with the fastest go-live in the industry. As a result, thousands of top brands have partnered with MNTN, including, Petsmart, Build with Ferguson Master, Simplisafe, Yieldstreet and National University.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The software engineer I position will design, develop and debug desktop/web applications that function in a hybrid environment.Participate in all aspects of the application development life cycle, includingBusiness requirements translationTechnical designTest case creation (unit test)Coding/developmentUnit testingDebug/troubleshootingPeer-reviewDeploymentPost-deploy supportCreate clear and accurate technical documentationStrong discipline of accountability and task managementRequired SkillsWorking knowledge of one or more object-oriented languagesBe motivated to continue to learn new skillsHave strong interpersonal skills to facilitate working within a team Effective verbal and written communication skillsEffective time management skillsQualificationsBachelor’s degree in Software Engineering, Computer Science or related degreeExperience with PHP, HTML5, CSS, Javascript, Java, C#, SQL/TSQLExperience developing stateless web applications, RESTful web services and APIsExperience with AWS environments and SDKs including S3, SNS, SQS, SES, ElasticCache, Lambda, CloudSearchUnderstanding of source control practices with TFS and GitExperience with databases, including working knowledge of MS SQL, PostgreSQL and MongoDBExperience with transactional web development, RESTFul APIs, ecommerce or related applicationsExcellent communication skillsMINIMUM 3+ years of software development experienceEqual Opportunity and Non-DiscriminationTranscat is an equal-opportunity employer and prohibits discrimination on the basis of any protected status. All qualified applicants will receive consideration for employment without regard to age, color, creed, disability, domestic violence victim status, gender identity, genetic predisposition or carrier status, marital status, national origin, pregnancy, race, religion, sex, sexual orientation, status as a protected veteran or as a member of any other protected group or activity.We will make reasonable accommodations for personnel with disabilities to enable them to perform the essential functions of this position unless doing so poses an undue hardship on the company or a direct threat to health or safety.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'About Rose AIRose AI is a cutting-edge cloud data platform that leverages generative AI to help users find, visualize, and share data. By combining powerful natural language processing and state-of-the-art open-source LLMs, we empower knowledge workers to research at the speed of thought, starting with the finance industry. Our platform simplifies the process of accessing, manipulating, and visualizing data, providing a single source of truth that is fully auditable and easy to use.Job DescriptionWe are seeking a talented and experienced Senior ML/AI Engineer to join our team at Rose AI. You will be responsible for designing, implementing, and optimizing advanced machine learning models to drive the next generation of our platform. You will work alongside a team of passionate engineers and researchers dedicated to transforming the way data is accessed, visualized, and shared.ResponsibilitiesDevelop and implement cutting-edge machine learning and AI algorithms to improve the platform’s performance, scalability, and user experienceCollaborate with cross-functional teams to define and prioritize product requirements, scope, and timelineConduct research to stay up-to-date with the latest ML/AI technologies and industry trendsOptimize existing models and algorithms to enhance performance and efficiencyDevelop and maintain a robust ML/AI pipeline, including data preprocessing, feature extraction, model training, and evaluationEnsure high-quality code by following best practices and conducting thorough code reviewsWork closely with the data team to understand data sources and implement data ingestion and processing solutionsMentor and support junior team members to foster a culture of continuous learning and growthQualificationsBS, MS, or PhD in Computer Science, Engineering, Statistics, or a related field5+ years of experience in machine learning, AI, or a related fieldStrong programming skills in Python and experience with ML/AI frameworks (e.g., TensorFlow, PyTorch, or similar)Expertise in natural language processing, deep learning, and generative modelsFamiliarity with cloud platforms and services (e.g., AWS, GCP, Azure)Experience with data processing tools and libraries (e.g., Pandas, NumPy, Dask)Strong problem-solving skills and the ability to work independently and collaborativelyExcellent communication and interpersonal skillsPreferred Qualifications:Experience in the finance industry and familiarity with financial data sourcesExperience working with large-scale, distributed systemsA proven track record of published research in ML/AI or related fieldsExperience with data visualization tools and libraries (e.g., D3.js, Plotly, or similar)BenefitsCompetitive salary and equity packageComprehensive health, dental, and vision insuranceGenerous vacation and holiday policyProfessional development and growth opportunitiesCollaborative and inclusive work environmentHow To ApplyIf you are a talented and driven individual with a passion for revolutionizing the way data is accessed and visualized, we would love to hear from you. To apply, please submit your resume, a cover letter detailing your relevant experience, and any links to your GitHub, research publications, or other examples of your work.Rose AI is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.Please note that this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to create thriving communities. Show up. Change lives.Our benefits include:Flexible Paid Time Off16 weeks of paid family leave + option for additional unpaid leave15 Company holidaysMonthly wellness stipendAnnual learning and development budget401K with employer matchEvery year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.What you'll do:You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:Use machine learning to improve Meetup's search, recommendation, and notification systemsDevelop, optimize, and maintain machine learning systems through their entire product lifecycleCollaborate with product and design to leverage data and algorithms to improve user experienceRecruit and present on behalf of Meetup at technical conferences and Meetup eventsYou have:Bachelor's degree in Computer Science, Engineering, Statistics or related STEM field3+ years of work/educational experience with NLP, recommendations, or predictionsContributed to a large codebase in Python, Scala, or JavaHands-on experience using machine learning frameworks to robustly build, validate, test, and monitor search models (ElasticSearch, LogStash, Kibana)Implement machine learning algorithms in cloud (AWS) and horizontally scalable environments (MapReduce, Hadoop, Spark)Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIsMeetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community; a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.The pay range for this position is between $95,000 - $115,000/year; however, base pay offered may vary depending on job-related knowledge, skills, candidate location, and experience. This role can be located anywhere in the US and Canada.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'About Rose AIRose AI is a cutting-edge cloud data platform that leverages generative AI to help users find, visualize, and share data. By combining powerful natural language processing and state-of-the-art open-source LLMs, we empower knowledge workers to research at the speed of thought, starting with the finance industry. Our platform simplifies the process of accessing, manipulating, and visualizing data, providing a single source of truth that is fully auditable and easy to use.Job DescriptionWe are seeking a talented and experienced Senior ML/AI Engineer to join our team at Rose AI. You will be responsible for designing, implementing, and optimizing advanced machine learning models to drive the next generation of our platform. You will work alongside a team of passionate engineers and researchers dedicated to transforming the way data is accessed, visualized, and shared.ResponsibilitiesDevelop and implement cutting-edge machine learning and AI algorithms to improve the platform’s performance, scalability, and user experienceCollaborate with cross-functional teams to define and prioritize product requirements, scope, and timelineConduct research to stay up-to-date with the latest ML/AI technologies and industry trendsOptimize existing models and algorithms to enhance performance and efficiencyDevelop and maintain a robust ML/AI pipeline, including data preprocessing, feature extraction, model training, and evaluationEnsure high-quality code by following best practices and conducting thorough code reviewsWork closely with the data team to understand data sources and implement data ingestion and processing solutionsMentor and support junior team members to foster a culture of continuous learning and growthQualificationsBS, MS, or PhD in Computer Science, Engineering, Statistics, or a related field5+ years of experience in machine learning, AI, or a related fieldStrong programming skills in Python and experience with ML/AI frameworks (e.g., TensorFlow, PyTorch, or similar)Expertise in natural language processing, deep learning, and generative modelsFamiliarity with cloud platforms and services (e.g., AWS, GCP, Azure)Experience with data processing tools and libraries (e.g., Pandas, NumPy, Dask)Strong problem-solving skills and the ability to work independently and collaborativelyExcellent communication and interpersonal skillsPreferred Qualifications:Experience in the finance industry and familiarity with financial data sourcesExperience working with large-scale, distributed systemsA proven track record of published research in ML/AI or related fieldsExperience with data visualization tools and libraries (e.g., D3.js, Plotly, or similar)BenefitsCompetitive salary and equity packageComprehensive health, dental, and vision insuranceGenerous vacation and holiday policyProfessional development and growth opportunitiesCollaborative and inclusive work environmentHow To ApplyIf you are a talented and driven individual with a passion for revolutionizing the way data is accessed and visualized, we would love to hear from you. To apply, please submit your resume, a cover letter detailing your relevant experience, and any links to your GitHub, research publications, or other examples of your work.Rose AI is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.Please note that this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning engineer to work closely with our product and research teams to develop SOTA deep learning software. This person will work closely with our technical and research teams to develop training and deployment pipelines, implement model compression algorithms, and productize deep learning research. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to build machine learning productsPrototype and implement appropriate ML algorithms, tools, and pipelinesCreate and manage training and deployment pipelinesCollaborate with a cross-functional team about market requirements and best practicesKeep abreast of developments in the fieldRequirementsProven experience as a machine learning engineer or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityBachelor's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Neural Magic is an early-stage AI software company democratizing high performance for deep learning models. Our goal is to reduce the cost and increase the performance of end-users deploying deep learning applications. Based on decades of research at MIT, Neural Magic has developed a software platform that allows developers to sparsify deep learning models to minimize footprint and run on CPUs at GPU speeds. Please look through our website and GitHub repos to get a feel of what we are about.Founded by an award-winning team of computer scientists and researchers out of MIT, we are a venture-backed company headquartered in Davis Square, Somerville, MA. Our investors include Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, and Pillar VC.We are seeking a machine learning research engineer to work closely with our research team implementing deep learning research and using model compression techniques. This person identify, report on, and create new algorithms and models within the deep learning field. If you are someone who wants to contribute to solving challenging technical problems at the forefront of deep learning, this is the role for you!ResponsibilitiesUse your understanding of machine learning to tackle meaningful technical problemsCollaborate with research and product development teams to transform research ideas into product solutionsResearch and implement appropriate ML algorithms and toolsRun machine learning tests and experiments while optimizing hyperparametersPerform statistical analysis and fine-tuning using test resultsKeep abreast of developments in the fieldRequirementsProven experience as a machine learning researcher, engineer, or similar roleSolid knowledge of machine learning and deep learning fundamentals with experience in one or more of computer vision, NLP, speech, reinforcement learning, generative models, etcKnowledge of common ML frameworks (like PyTorch or Keras) and libraries (like NumPy and scikit-learn)Strong programming skills with proven experience implementing Python-based machine learning solutionsAbility to interpret and implement research ideas and algorithmsCreative, collaborative, and innovation-focusedStrong sense of project ownership and personal responsibilityMaster's in Computer Science, Mathematics or similar fieldBenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)Short Term & Long Term DisabilityTraining & DevelopmentWork From HomeFree Food & SnacksWellness ResourcesStock Option PlanWe are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Scientist (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job RequirementsM.S. or PhD in Data Science/Electrical Engineering/Computer ScienceExperience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlySpecial Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'LVIS is a leader in cutting edge neural information analysis technology that decodes brain networks and provides visualizations assisting neurological disease diagnosis. LVIS owns patented technologies and our team includes leaders with strong expertise in neuroscience and engineering. LVIS has been selected to be a member of the Stanford StartX community and the NVIDIA inception program. We are an international team with our headquarter located in Palo Alto, California, USA and an office in Gangnam, Seoul, South Korea. We are looking for talented individuals to join us in transforming the neurology health care industry.ResponsibilitiesDeep learning model deployment for medical web applications.Machine learning system stability testing and optimization.Model compression with pruning, quantization and distillation.Collaborate with data scientists and software engineers to optimize deep learning model performance.RequirementsMinimum Required QualificationsMS or PHD in Computer Science, Statistics, Electrical Engineering, Applied Math, and other similar fields.Deep understanding of the machine learning algorithms and systems, especially convolutional neural networks.Proficient in python and python machine learning packages, such as numpy, scikit learn, pytorch, keras, etc.Preferred To HaveHands-on experience of model deployment in the cloud (AWS, Azure or GCP).Experience of model compression techniques.Experiences in medical image/signal processing and data analysis.Other InformationJob type: Full-time.U.S. citizens, green card holders, and those authorized to work in the U.S. for any employer will be considered.Willing to work onsite at our Palo Alto location.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Do you want to be part of the core team for building the next one-of-a-kind tech companies that can potentially change your career's trajectory?! We are striving to build the future of decision-making at Verneek. Come join us!If you are fed up with how little impact you are making at your current job despite all the hard work, if you are bored with your job where you cannot learn or innovate anymore, Verneek could be a perfect opportunity for you: a new deep-tech AI startup, where you'd get to learn, innovate, and leave your mark every single day.We are looking for a stellar & highly ambitious machine learning engineer as one of the first employees to help build complex AI/NLP models supporting the Verneek AI platform! You'll get to work on fundamental AI research problems, but all grounded within the scope of our particular AI platform. It'll be all much more rewarding and influential than working on narrow AI benchmarks! :)Every day, you'll get to solve very unique, highly complex, and socially impactful problems. This is an early-stage startup, so we'll be moving super-fast and there will be no legacy obstacles on your way to make a significant impact. Whatever you do every hour of every day counts!!ResponsibilitiesImplement, scale, and maintain complex AI/NLP models supporting the Verneek AI platformRequirementsMINIMUM QUALIFICATIONS BSc. degree in Computer Science or related fields3+ years of experience with Python3+ years hands-on experience developing architectures with machine learning frameworks such as Tensorflow/PyTorchDemonstrated AI/NLP engineering skillset through having deployed largescale AI/NLP systems to productionWork authorization in the USA at the time of hireContinuing work authorization during employment can be sponsored by VerneekPreferred QualificationsMSc. degree in Computer Science or related fieldsExperience in Natural Language Understanding, Dialogue Systems, Semantic Parsing, Transfer Learning and learning with limited dataBenefitsMedical, dental, vision, disability, and life insurance401K matching contributionsFlexible PTOCareer growth support through sponsoring learning opportunities and mentorshipAbout VerneekVerneek is an early-stage deep-tech AI startup, based in NYC, founded by a team of leading AI research scientists and backed by a group of world-renowned business and AI leaders. Verneek recently closed its first round of financing and is now hiring its first ten employees, with tremendous growth & leadership opportunities.Verneek MissionQuintillion bytes of data get generated every day!! Leveraging this data for data-informed decision-making for societal, personal, and business matters is more viable and crucial than ever. Verneek's mission is to enable anyone to make data-informed decisions, be personal or business, without needing to have any technical background.Verneek CultureYou can get a visual sense of our culture here: https://www.verneek.com/culture.It’s often hard to put “culture” into words. We all absolutely love what we do, care about each other, share all sorts of meals together, celebrate all kinds of events together, and work tirelessly with the excitement of making a difference through technical innovation. We are enjoying the journey, and going through all the ups and downs together.We are building a truly different kind of a company where we put the well-being, career growth, and overall happiness of our team as our north star, through which we can deliver on our highly ambitious mission. We are determined to make sure that every individual’s career and life goals will be well aligned with their role at Verneek. We are striving to hit a balance between each employees’ personal growth and their productivity in their role. We firmly believe that everyone can hit their productivity stride when they are learning and growing every single day, working towards meaningful goals; which is the case at Verneek.We are just getting started! The initial core Verneek team will be playing a crucial role in shaping the culture of the company moving forward. We are looking for highly ambitious individuals who can take the lead in driving various aspects of the company, and help us shape its lasting culture.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'We’re looking for people who want to build for the future of Web3. You’ll be building customer-facing products that help shape the way intellectual property is processed and handled.ResponsibilitiesTrain and deploy deep learning models to power Yakoa’s intellectual property tracing capabilities.Own the implementation of capabilities by taking responsibility from inception to deployment.Uphold our high engineering standards by bringing consistency and repeatability to the training, evaluation, and deployment processes.Mentor software engineers while serving as technical lead, contributing to and directing the execution of complex projectRequirements5+ years working as a machine learning engineer or researcher.Experience managing model deployment pipelines on cloud services like AWS.Familiarity with state-of-the-art deep learning models across computer vision and natural language processing.Proficiency in Python, and PyTorch.Exceptional candidates also haveExperience with Web3 toolingB2B software design experienceBenefitsUnlimited PTO.Competitive compensation packages.Remote friendly & flexible hours.Wellness packages for mental and physical health.No crypto or Web3 experience? No problem! We’ll help coach you and cover any costs for educational materials for your growth.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Chemix is seeking a highly-motivated graduate-level machine learning research engineer intern to help develop and expand our internal AI capabilities for battery materials discovery. Our AI platform is the core of Chemix. Though data is first and foremost in any application of AI, it is typically very scarce in materials development. We've designed our entire R&D operation to generate battery materials datasets of unprecedented size and quality. As a machine learning research engineer intern at Chemix, your mission is to work with our machine learning scientists to (i) suggest, prototype, and test new algorithms, and (ii) design and build the machine learning pipelines that turn our data into actionable results. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond.As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of the ML and data software stack, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation.Responsibilities:Suggest, prototype, and test new ML algorithms based on our large materials datasetsDiscover and introduce new ML models, statistical methods, software frameworks, and libraries Contribute code to Chemix's internal codebase (Python)Interface with our data scientists, data/software engineers, and battery engineers Implement best practices for code development and ML-ops, experiment tracking, etcInform the optimization of the R&D process that generates our dataRequirementsIn-progress, or recently completed, MS or PhD in applied machine learning or adjacent field.Experience with core data science, machine learning, and statistics conceptsExperience with the python data ML stack: pandas, numpy, sklearn, pytorch / tensorflowExperience with the fundamentals of ML and software ops: git, testing, CI/CD, experiment tracking, cloud computingClear communication and good people skillsStrong organization and ability to manage parallel projectsNice to have:Previous battery data experienceFamiliarity with experimental chemistry/materials scienceBenefitsStock Option PlanHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k)Paid Time Off (Vacation, Sick & Public Holidays)Family Leave (Maternity, Paternity)\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Machine Learning Engineer , FULL-TIME, Salary $90K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job Requirements2 years of experience, or an advanced degree (MSc).Experience in applied Deep Learning (DL) and Computer Vision (CV) concepts including but are not limited to: CNNs, RNNs, Autoencoders, Transfer Learning.Hands-on experience (academic and/or industrial) in 3D Pose Estimation and Motion reconstruction from images and videosProficiency in general purpose programming languages: Python, and C++.Experience with ML frameworks such as: PyTorch, Tensorflow, etc.The ideal candidate would be very well acquainted with Computer Graphics techniques, Neural Rendering, and Numerical Optimization(Optional) Knowledge of 3D packages such as Blender, Maya, or any game engine technologyBSc in Computer Science, Mathematics, Electrical Engineering, or related technical field.Ability to speak and write in English fluently and idiomatically.Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insuranceOptional supplemental insurance policies for things like accidents, injuries, hospitalizations, or cancer diagnosis and treatment.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'ML - Handson Tensorflow Dev -ML pipeline and process -Strong python coding skills -Experience in deploying models -API development -Flask or Django experience\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"Description:By bringing together people that use their passion for purposeful innovation, at Lockheed Martin we keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work.With our employees as our priority, we provide diverse career opportunities designed to propel development and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work.At Lockheed Martin, we place an emphasis on empowering our employees by fostering innovation, integrity, and exemplifying the epitome of corporate responsibility.Your Mission is Ours.The coolest jobs on this planet… or any other… are with Lockheed Martin Space.Lockheed Martin Space in Littleton, CO is seeking a full-time Early Career Software Engineer. Consolidated Analysis Orchestration Services (CAOS) is the preeminent Geospatial-Intelligence program in the world – over 10,000 intelligence analysts and decision-makers worldwide daily rely on CAOS for critical intelligence and geospatial data management. In addition to meeting today’s critical intelligence mission needs, we are working on evolving exciting future automation and artificial intelligence solutions for the National Geospatial-Intelligence Agency (NGA). We need the best engineers on our team to ensure mission success! Think you have the skills, come join the CAOS Team that builds software for the next generation of geospatial intelligence.Must be a US Citizen ; this position will require a government security clearance. This position is located at a facility that requires special access.Basic Qualifications Acceptable bachelors degree programs will include only science and technology (STEM) related programs such as Computer Science, Systems Engineering, Electrical Engineering, Computer Engineering, Physics, Mathematics etc. Must be a US Citizen ; this position will require a government security clearance. This position is located at a facility that requires special access.Desired SkillsProficiency with one or more of the following software languages: Java, C++, C#. Candidate will have knowledge of basic software practices such as coding standards, unit testing and configuration management, database and System administration. Good communication skills. Strong team player. Candidate will work in a team environment utilizing software methodologies and processes. Familiarity with Agile Development Process a plus. Strong communication skills a results oriented team player, creative thinker and problem-solver and follow all ethical standards of the Lockheed Martin Corporation.Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.Clearance Level: TS/SCIOther Important Information You Should KnowExpression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.Ability to Work Remotely: Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.Schedule for this Position: 9x80 every other Friday offPay RateThe annual base salary range for this position in Colorado or Washington is $57,800 - $110,800. Please note that the salary information is a general guideline only. Lockheed Martin considers factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience, education/ training, key skills as well as market and business considerations when extending an offer.Benefits offered: Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Flexible Spending Accounts, EAP, Education Assistance, Parental Leave, Paid time off, and Holidays.(Washington state applicants only) Non-represented full time employees: accrue 10 hours per month of Paid Time Off (PTO); receive 40 hours of Granted PTO annually for incidental absences; receive at least 90 hours for holidays. Represented full time employees accrue 6.67 hours of PTO per month; accrue up to 52 hours of sick leave annually; receive at least 96 hours for holidays. PTO is prorated based on hours worked and start date during the calendar year.This position is incentive plan eligible.Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.Experience Level: 4 yr and up CollegeBusiness Unit: SPACERelocation Available: PossibleCareer Area: Software EngineeringType: Full-TimeShift: First\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"The AI age is upon us and high performance computing is the underlying platform powering everything from Large Language Models (LLM) to Image synthesis from text. However, with the demise of Moore’s law and Dennard scaling we are at an inflection point. At Lightmatter, we are leading the transition of computing from traditional electronic transistors to photonic technologies which can operate at mind blowing efficiency and throughput.In this role, you will support all the activities of the ML team as it guides the development of a new class of computing infrastructure. This includes fine tuning LLMs, enablement of new models on custom architectures, evaluating the performance of models at scale, developing abstract models of the hardware for evaluating accuracy and throughput and help co-design novel hardware in a new paradigm of computing. Working in a small team of highly talented engineers, you will be able to move fast and develop well architected solutions.If you are passionate about advanced AI technology and would like to develop scalable algorithms, hardware and ML techniques, join us!ResponsibilitiesDevelop software for evaluating accuracy and throughput of models on a custom hardware.Develop performance models for a novel class of hardware.Develop scalable algorithms for large scale inference and trainingTrain LLMs and other models on a large cluster of GPUs.Support ML researchers as they explore accuracy on a wide variety of models on custom hardware.Publish and present new research at premier ML/CS conferences.RequirementsMS in Computer Science or related fields; PhD strongly preferredMinimum of 8 years of related experience with a Bachelor’s degree; or 6 years and a Master’s degreeExperience with developing and shipping ML/HPC software Understanding of deep learning, parallel computing, compilers and/or hardware architecture.Experience with developing and modifying machine learning models for scalability.Experience or understanding of low precision training and inference.Technical expertiseExperience with scalable frameworks such as MPI, PyTorch distributed, CUDA, and NCCL.Highly proficient in deep learning programming languages and frameworks, e.g. Python, C++, CUDA, Tensorflow, PyTorch, JAX.Experience with practical problem solving with innovative algorithmic solutions.Preferred QualificationsUnderstanding of advanced techniques used in parallel computing, deep learning and HPC.Ability to model complex workloads on different architecture proposals.Understanding of parallel computing architectures.Experience contributing first hand to important software or ML algorithms deployed in the industry.You are enthusiastic about new technologies, algorithms, and mathematics.BenefitsComprehensive Health Care Plan (Medical, Dental & Vision)401k matchingLife Insurance (Basic, Voluntary & AD&D)Generous Time Off (Vacation, Sick & Public Holidays)Paid Family LeaveShort Term & Long Term DisabilityTraining & DevelopmentFlexible, hybrid workplace modelStock Option PlanBase Compensation Range: $200,000 to $230,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.Lightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Junior Data Scientist , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The Job RequirementsM.S. or PhD in Data Science/Electrical Engineering/Computer ScienceExperience in machine learning, data science or similar rolesExperience with version control systems, collaborative coding frameworks and scalable engineering tools such as DockerSolid understanding of the theory and practice of machine learning algorithmsExperience building functional prototypes and/or products in PythonDSP or/and timeseries analysis an advantageKnowledge of human physiology and bioelectric or optical sensing techniques is a nice bonusCollaborative approach with strong written and verbal communication skillsEfficient, creative and able to manage multiple projects concurrentlySpecial Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Holy Grail developed a direct air carbon capture technology that uses electrons to capture CO2 from the atmosphere. We are looking for proactive candidates who are ready to take ownership and are passionate about creating a sustainable solution to removing excess CO2 from the atmosphere. The ultimate goal of Holy Grail is to contribute to the long-term sustainability of life on Earth.We are looking for a data machine learning engineer to join our team and help bring our modular CO2 scrubbers to market.This role will be located in Mountain View, CA.Requirements: Detail-oriented with a creative approach to science and engineering A high degree of autonomy and independence Intrinsic motivation with a fundamental love of science Ability to learn and adapt quickly Advanced skills with Tensorflow and/or Pytorch Experience with probabilistic models like Gaussian processes and BNNs Experience with active learning for Design of Experiments Experience with different active learning sampling methods Experience in building regression models in large combinatorial spacesResponsibilities: Design and build models for Design of Experiments Design and build multi-target regression models for research and engineering optimization Design and build hyperparameter tuning pipelines for machine learning and deep learning models Collaborate with mechanical engineers, chemical engineers, and design engineers to optimize manufacturing methodsNice to have: Advanced degree in data science or equivalent experience Data engineering experience Computational chemistry and atomistic simulations experience Bioinformatics experience Experience with TensorFlow probability and Pyro Experience with building active learning sampling methods from scratchWhat we offer:You will join a team that is passionate about having an impact on climate change. We care about the optimal way to solve a problem and nurture a culture of creativity and collaboration. We care about quick iterations, minimizing assumptions, and we use emojis to label our chemicals. We work on interesting technical problems and provide support and resources to tackle them.Impact: your contribution will directly impact our technical milestones and you will have full ownership of your projects. We don’t micromanageNo politics: we give you the resources to test all your wildest ideas in hours or days, not months. If there is a chance that something will advance our progress we will test it as soon as possibleOwnership: not only you will own your projects you will also own part of the companyAutonomy: we welcome your independent perspective and encourage you to set and manage your time to achieve our shared goalsFlexibility: we cultivate an informal environment that is more fun and less rigid compared to academia and larger companies\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Tech Firefly is teaming up with a national financial services company to hire a Machine Learning Engineer. If you have experience building out Machine Learning projects as an engineer, please apply today.This position will require you to work on-site in Austin, TXLong Term Contract PositionPay: $60/hour on W2Requirements Bachelor of Science in Computer Science or a related field Proven experience building out ML projects as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java or R Experience with machine learning frameworks and libraries such as Tensorflow, Pandas, NumPy, Matplotlib or similar Working knowledge of Agile, Iterative development process is essential Preferred Experience in NLU/NLP or large language models Experience working in GCP or AWS clouds Demonstrated ability to work well under pressure in a fast-paced environment Exposure to a regulatory environment (like Banking & Finance or Health care etc.) domain is a plus Hands on experience with DevOps and Continuous Integration tools (Jenkins/Bamboo/GIT etc.) is preferredBenefitsSick DaysFree Life InsuranceMedical Insurance Options\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " 'Allozymes is a deep tech company based in Singapore. We are revolutionising the way industry uses enzymes for manufacturing chemicals and natural compounds. Our rapid discovery and evolution of custom-designed enzymes enables breakthrough developments for sustainable production of ingredients for pharmaceuticals, cosmetics, chemical, food and beverages.We’re hiring a highly capable Machine Learning Engineer into our Data team. This team is responsible for developing and implementing state-of-the-art approaches for evolving enzymes and microbes to enhance the production of chemicals and natural compounds. The engineer will integrate the development of our cloud-based artificial intelligence platform for enhancing Allozymes’ enzyme optimization capabilities. Working in a highly collaborative and dynamic environment, this role has the opportunity to interact with other scientists, automation and process engineers to achieve these goals. Responsibilities:Contribute to the design and improvement of Allozymes cloud-based AI platform.Scope project requirements, assess data quality, process data and perform feature engineering.Build, train and deploy ML/DL models, using state-of-the-art technologies and proprietary data to accurately perform predictions and generate new, high performing, enzymes.Perform model evaluation and statistical analysis to improve model quality.Enhance the performance and deployment environment of implemented solutions.Qualifications:MS or PhD in mathematics, statistics, computer science, engineering or a related quantitative field with a focus on AI and Machine Learning.2+ years of relevant industry experience.Expertise in building, training and deploying Machine and Deep Learning models.Proficiency in Python.Expertise in using ML/DS specific python libraries (Pandas, Numpy, Scipy, Scikit-learn, PyTorch, Keras).Experience with ML life-cycle management and code/data version control tools.Familiarity working with Cloud computing.Ability to work in a fast-paced, collaborative and cross-functional environment and communicate results effectively to management.Experience with supervised and unsupervised learning algorithms, clustering, feature selection methods, evaluation, dimensionality reduction, Bayesian inference, hyper-parameter tuning and model optimization is a plusExperience with Language models, Encoders, Transformers, Attention, Generative models and GANs is a plusExperience in biology, bioinformatics or computational biology.Experience using AWS/SageMaker is a plusExperience with containers and container orchestration tools is a plusExperience writing production-ready code (version-controlled, scalable, well-documented, testable, deployment-ready) is a plusNumber of Vacancies: 1\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"This is a fully remote opportunity at Blackbird.AI. You will not be required to relocate.The Company:What has been the effect of disinformation on the world?Blackbird.AI creates leading-edge AI software to provide critical real-time insights to provide our clients with a deep understanding of ongoing disruptive narratives, their motives, and overall digital noise. We are united by our dedication to our mission. We believe that we have a responsibility to society and that our service is vitally needed by organizations and individuals to create an empowered and critical thinking society.If this mission resonates with you, we'd love to hear from you.The Opportunity:We are looking for a Machine Learning Engineer with expertise in NLP who can join our AI research and development efforts with a direct impact on our core platform. You will work with both engineering and business teams to best understand design requirements. Then, your role is to design and build practical high performance machine learning solutions.In this role, you will work on some of the latest cutting edge applications of machine learning applied to critical problems that affect businesses, governments and society. You will directly work with top management and key stakeholders to define solutions to critical problems that will have immediate impact and value at the platform and client levels. If you are passionate to work on massive, unstructured problems that can be solved using data, we are looking for you.RESPONSIBILITIES:Contribute to research and development focusing on the following areas: information extraction, multilingual NLP, automated summarization and graph network analysis.Manage the collection and annotation of large custom datasets for text classification, unsupervised pre-training, translation, tagging, and other related problems.Capable of understanding and implementing state-of-the-art methods based on research papers and/or open source libraries, and push beyond the state-of-the-art.Experience with implementing efficient and scalable software systems in Python. Ability to integrate implemented software components into a fully functional software pipeline, and provide verification and validation against requirements.Knowledge of machine learning evaluation techniques, failure modes, and limitations.RequirementsMust Have:Minimum 2 years of professional experience working in Natural Language Processing or closely related field, with demonstration of successful delivery of novel research and/or product offerings.Masters degree or PhD from an accredited college/university in Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields (strong mathematical/static background with ability to understand algorithms and methods from a mathematical and intuitive viewpoint). Some exceptions can be made depending on exceptional past accomplishments/references. Experience with command-line scripting, data structures and algorithms, and the ability to work in a Linux environment, processing large amounts of data in a cloud environment.Highly skilled in Python development, as well as: Tensorflow, Pytorch, Keras and Scikit-Learn.Able to communicate scientific concepts to both technical and non-technical audiences.Nice to Have:Working knowledge of AWS and other cloud services.Experience creating novel datasets for scientific analysis or benchmarking.Capability to contribute at the system architecture level to enhance scalability, testability, robustness.Experience with generative models of fake text or images.Experience and top performances in online competitions / hackathons, such as, kaggle.Published research in areas related to machine learning, NLP, or its applications.Record of contributions to open-source machine learning projects, or related endeavors.Experience writing detailed documentation of machine learning systems.BenefitsHealth Care Plan (Medical, Dental & Vision)Paid Time Off (Vacation, Sick & Public Holidays)Work From HomeStock Option PlanExciting career development prospects, to grow into leadership rolesTake note - due to the high volume of applicants, only shortlisted candidates will be notified. Thank you for taking the time to apply for the role at Blackbird.AI.Ll-Remote\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Welcome to Hayden AI, where the future is ours to make. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future.Led by experts in AI, computer vision, data science, transportation, and government technology, Hayden AI is pioneering real world problem solving powered by AI and machine learning.Our mobile perception platform is currently utilized by New York City's MTA for automated bus lane enforcement. We recently raised $20 million in Series A funding and have been featured in Bloomberg CityLab, Forbes, Smart Cities Dive, and Politico.Come join us, and help us build a vision-based data platform for smart enforcement and smart cities with our six core values in mind:Customer FocusPassionCollaborationEmpowermentTransparencyIntegrityMachine Learning EngineerSummary Of ResponsibilitiesThis role will work with the data generated from perception algorithms to create insights and fine tune our perception system. You will access databases to create local datasets. Analyze the data to understand the performance and problems with the current solutions Develop custom data models and algorithms to apply to improve our decision making pipelines. Coordinate with different functional teams (cloud /device) to implement models and monitor outcomes. Present findings to the company so that insights can be acted on across the company to improve performanceUse data visualization tools to present findings in easy to understand ways to make improvements to the current system. Summary of Qualifications:Strong data science and traditional ML skills (SVM, Random Forest etc.)Strong problem solving skills with an emphasis on product development. Self led and excited to dig into the data to find issues and insights. Python, Pandas (C++ or Go experience is a bonus). Understanding of computer vision and deep learning. SQL/Database access experience. Experience working with geospatial data is a plus. Compensation89,000-200,000 Base Salary Considerable equity package Extensive wide ranging health benefits Company wide bonus program401k with match programThere are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more)!Just a few of our perks include:Options for 100% company paid medical, dental, and vision coverage for employees and dependents (for US employees)Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)Life, AD&D, Short and Long Term Disability InsuranceAflac Critical Illness, Accident Insurance & Hospital Indemnity InsuranceMetLife Legal Plan(s) & Pet InsuranceFarmers GroupSelect Auto & Home Insurance401(k) with 3% company matchingProfessional development reimbursementWellness stipendsUnlimited PTORemote work opportunitiesHome office & technology reimbursementDaily catered lunches in our Oakland officeHayden AI is committed to creating a diverse and inclusive environment that fosters learning from each other. We celebrate people of diverse backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and are committed to providing a work environment free of harassment and discrimination. Hayden AI is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.To all recruitment agencies: Hayden AI does not accept agency resumes. Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.Privacy Policy\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"Who are we?X1 is building the smartest credit card ever made. We power over $800M in annualized spending and are rapidly growing.We have been featured in publications like Business Insider, Fast Company, Forbes, Inc., Money, CNBC, CNET, Nasdaq, TechCrunch and Wired.We have raised over $60M from some of the most iconic investors in Silicon Valley, who founded Google Analytics, Y Combinator Continuity, PayPal, Affirm, Box, Yelp, and more. These include David Sacks, Max Levchin, Wesley Chan, CEOs of Yelp, Box, and Y Combinator Continuity, The Chainsmokers, and Jared Leto.What will you do?Build world class consumer finance software to serve X1's customers.Who will you work with?An elite engineering team with alumni from Affirm, Stripe, Google, Pinterest, Y Combinator, Stanford, MIT, and more.What will you work on?As a frontend-focused product engineer, you will build features that no other credit card has offered before. You will gain experience across the entire stack by deep diving into React and React Native, designing GraphQL API interfaces, and adding functionality to core processing infrastructure.Who are you? An undergraduate or graduate computer science degree (or a related field) Strong computer science fundamentals Strong programming experience with any one language Good communication skills Hungry to learn and grow alongside a growing businessAs an early team member at X1 you will be a critical voice and have significant influence over the direction of the company. We will compensate you well, invest deeply in your development, and ensure this is the single best work experience of your life. If you think you’d be a good fit, we’d love to hear from you.How can you reach us?To learn more, see https://x1.co/\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " \"At Skyways we are building a new form of air transportation. Some people call it the flying car. We believe fully autonomous unmanned aerial vehicles represent a unique opportunity to move things and ultimately people in new, more efficient ways. Our strategy to get there is completely different than the rest of the industry.Skyways is a startup based in Austin TX. We are backed by some of the most respected investors in Silicon Valley including YCombinator. Although we consider ourselves early-stage, we already have vehicles in production and in the hands of paying customers. Come join us and work on a transportation revolution to advance our civilization!Note: most of our jobs are local in Austin TX, with the notable exception of software related roles.We are growing and looking for a ML/CV/AI Software Engineer to join our team.Having a solid math/science foundation is critical for the role, since you'll need to understand and work with flight dynamics and also help support mechanical engineers by writing software for hardware test stands.We are also looking for a candidate who is excited about things that fly, not afraid of tough engineering challenges, and eager and able to learn quickly and work in an extremely fast-paced startup environment.STUDENTS/NEW GRADUATES: This job requires 3 years post graduation experience, new grad/internship openings are posted separately and applying here may misdirect your application for the roles you are qualified for!Responsibilitieswork with more senior engineers to build new ML training pipelines, add features to existing systems, and fix bugs (Python)write software for CV inference at the edge (C++ mostly)go through design review processreason about your decisions based on data (experiments, math/science)maintain a clean codebase by doing code reviews, writing tests, utilizing continuous integrationlearn and promote software engineering best practicesship software to production (i.e. our aircraft but also network-based applications)maintain production systemswork with flight ops to test your software and iterate/improve at high speedRequirementseducation in Computer Science, Computer Engineering or a related field -- a formal education isn't required but you'll be expected to know backend and low-level fundamentals2+ years of experience in ML (CV preferred)familiarity with PyTorch or TensorFlow and training ML modelsfamiliarity with inference (C++ preferred) and performance optimization at the edgeinterest in aerospaceability and willingness to learn a thousand things in a hundred daysbe an awesome and friendly individualbe open minded to learn more about both software best practices and our field (your code will fly, it's a big deal)bonus points if you have experience with software running onboard a vehicle/robotbonus points if you have experience with flight controls / control theory\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'REMOTE (US/Canada Residing people only, with work permit)Patterned Learning – Data Engineer (Entry Level ) , FULL-TIME, Salary $100K - $130K a year.About us: The Future of AI is Patterned, a stealth-mode technology startup. Top investors include Sequoia and Anderson Horowitz, founders from Google, DeepMind, and NASA and we’re hiring for almost everything!About The JobRequired Skills and Experience:Experience in writing cloud-based softwareExpertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.Experience delivering software products built using PythonExperience using professional software development practices, including: Agile processes, CI/CD, etc)Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)Special Benefits You Will LoveFlexible vacation, paid holidays, and paid sick days401(k) with up to 2% employer match (no match)Health, vision, and dental insurance.Schedule: 8 hour shift, Monday to Friday , Time: Flexible, Job Type: Full-time\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " \"At MNTN, we've built a culture based on quality, trust, ambition, and accountability – but most importantly, we really enjoy working here. We pride ourselves on our self-service platform and are constantly seeking to improve the user experience for our customers and scale for efficiency. Our startup spirit powers our growth mindset and supports our teammates as they build the future of ConnectedTV. We're looking for people who naturally want to do more, own more, and make an impact in their careers – and we're seeking someone to be part of our next stage of growth.As a Machine Learning Engineer on our Attribution team, you will ideate, train, test, deploy, evaluate and monitor matching systems in a large scale production environment to maximize advertiser goals while respecting consumer privacy. As a core contributor to how we best match ads, you will work with data science, software engineers, product managers, infrastructure teams, and data teams. Relevant experience includes propensity modeling, ranking, predictive modeling, spam detection, clustering, segmentation, and similar.What You'll Do:Use MNTN proprietary and third party data sources to conceive and lead machine learning projects that maximize goals for advertising marketers while protecting consumer privacy. Be a hands-on builder of needed components in software and infrastructure. Become the end to end expert on matching ad opportunities to potential audiences in an ambiguous and privacy-focused ecosphere. Identify opportunities and gaps in data and insights for both internal and external stakeholders. Work with product and engineering teams to create and evaluate your model designs. Lead discussions with other technical and non-technical functions. Investigate critical incidents and provide insights to data ambiguity. What You'll Bring:1-3 years of experience of real-world problem solving related to developing and using machine learning models on large scale data. Advanced degrees in Computer Science, Mathematics, Electrical Engineering, Statistics or similar may be substituted for some years of experience. Experience in SQL, Python, Spark, R, or similar languages. Experience in machine learning libraries and platforms such as scikit-learn, tensorflow, sagemaker, or similar. Written and verbal communication skills to convey complex technical topics to a variety of audiences. MNTN Perks100% remote Open-ended vacation policy with an annual vacation allowanceThree-day weekend every month of the yearCompetitive compensation100% healthcare coverage401k planFlexible Spending Account (FSA) for dependent, medical, and dental careAccess to coaching, therapy, and professional developmentAbout MNTN:MNTN provides advertising software for brands to reach their audience across Connected TV, web, and mobile. MNTN Performance TV has redefined what it means to advertise on television, transforming Connected TV into a direct-response, performance marketing channel. Our web retargeting has been leveraged by thousands of top brands for over a decade, driving billions of dollars in revenue.Our solutions give advertisers total transparency and complete control over their campaigns – all with the fastest go-live in the industry. As a result, thousands of top brands have partnered with MNTN, including, Petsmart, Build with Ferguson Master, Simplisafe, Yieldstreet and National University.\\n\\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\",\n",
              " 'The software engineer I position will design, develop and debug desktop/web applications that function in a hybrid environment.Participate in all aspects of the application development life cycle, includingBusiness requirements translationTechnical designTest case creation (unit test)Coding/developmentUnit testingDebug/troubleshootingPeer-reviewDeploymentPost-deploy supportCreate clear and accurate technical documentationStrong discipline of accountability and task managementRequired SkillsWorking knowledge of one or more object-oriented languagesBe motivated to continue to learn new skillsHave strong interpersonal skills to facilitate working within a team Effective verbal and written communication skillsEffective time management skillsQualificationsBachelor’s degree in Software Engineering, Computer Science or related degreeExperience with PHP, HTML5, CSS, Javascript, Java, C#, SQL/TSQLExperience developing stateless web applications, RESTful web services and APIsExperience with AWS environments and SDKs including S3, SNS, SQS, SES, ElasticCache, Lambda, CloudSearchUnderstanding of source control practices with TFS and GitExperience with databases, including working knowledge of MS SQL, PostgreSQL and MongoDBExperience with transactional web development, RESTFul APIs, ecommerce or related applicationsExcellent communication skillsMINIMUM 3+ years of software development experienceEqual Opportunity and Non-DiscriminationTranscat is an equal-opportunity employer and prohibits discrimination on the basis of any protected status. All qualified applicants will receive consideration for employment without regard to age, color, creed, disability, domestic violence victim status, gender identity, genetic predisposition or carrier status, marital status, national origin, pregnancy, race, religion, sex, sexual orientation, status as a protected veteran or as a member of any other protected group or activity.We will make reasonable accommodations for personnel with disabilities to enable them to perform the essential functions of this position unless doing so poses an undue hardship on the company or a direct threat to health or safety.\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less',\n",
              " ...]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job_descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUmPcbZ5br8i",
        "outputId": "69dae724-8c87-4124-daae-46e799f6cb47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The cosine similarity score between the resume and job description is: 0.39858739994341824\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.5003790978018228\n",
            "The cosine similarity score between the resume and job description is: 0.4705807125986845\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.4398054376891351\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.35834468731623315\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.4154786799185604\n",
            "The cosine similarity score between the resume and job description is: 0.49094002416618243\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.4710208378009734\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5341289962837813\n",
            "The cosine similarity score between the resume and job description is: 0.43683280225411625\n",
            "The cosine similarity score between the resume and job description is: 0.4734935629317173\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.39858739994341824\n",
            "The cosine similarity score between the resume and job description is: 0.5481958104358354\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.5003790978018228\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.4596452291417429\n",
            "The cosine similarity score between the resume and job description is: 0.4814445606038157\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4959748898019245\n",
            "The cosine similarity score between the resume and job description is: 0.49094002416618243\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.5079055228309398\n",
            "The cosine similarity score between the resume and job description is: 0.4710208378009734\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.49598104979066915\n",
            "The cosine similarity score between the resume and job description is: 0.5003790978018228\n",
            "The cosine similarity score between the resume and job description is: 0.4705807125986845\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.4398054376891351\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.35834468731623315\n",
            "The cosine similarity score between the resume and job description is: 0.4154786799185604\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.5079055228309398\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.4710208378009734\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.43683280225411625\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.2860241840753149\n",
            "The cosine similarity score between the resume and job description is: 0.5541738101369418\n",
            "The cosine similarity score between the resume and job description is: 0.45824765940249546\n",
            "The cosine similarity score between the resume and job description is: 0.4615663313770509\n",
            "The cosine similarity score between the resume and job description is: 0.4948829164003021\n",
            "The cosine similarity score between the resume and job description is: 0.4154786799185604\n",
            "The cosine similarity score between the resume and job description is: 0.4856660755334708\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.49507176443231315\n",
            "The cosine similarity score between the resume and job description is: 0.5475032842838782\n",
            "The cosine similarity score between the resume and job description is: 0.4626852653410969\n",
            "The cosine similarity score between the resume and job description is: 0.4474629295317247\n",
            "The cosine similarity score between the resume and job description is: 0.4734935629317173\n",
            "The cosine similarity score between the resume and job description is: 0.49284667047860126\n",
            "The cosine similarity score between the resume and job description is: 0.4103393574191724\n",
            "The cosine similarity score between the resume and job description is: 0.5149363255670016\n",
            "The cosine similarity score between the resume and job description is: 0.45078989961462246\n",
            "The cosine similarity score between the resume and job description is: 0.49016445998966035\n",
            "The cosine similarity score between the resume and job description is: 0.5481958104358354\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.5264397302215236\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.4427568375595623\n",
            "The cosine similarity score between the resume and job description is: 0.5253791030773006\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.4398054376891351\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.35834468731623315\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.49094002416618243\n",
            "The cosine similarity score between the resume and job description is: 0.4154786799185604\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.5341289962837813\n",
            "The cosine similarity score between the resume and job description is: 0.4734935629317173\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.43683280225411625\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.5541738101369418\n",
            "The cosine similarity score between the resume and job description is: 0.4862987625796375\n",
            "The cosine similarity score between the resume and job description is: 0.4705807125986845\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.4398054376891351\n",
            "The cosine similarity score between the resume and job description is: 0.4596452291417429\n",
            "The cosine similarity score between the resume and job description is: 0.4814445606038157\n",
            "The cosine similarity score between the resume and job description is: 0.5001015538482332\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4154786799185604\n",
            "The cosine similarity score between the resume and job description is: 0.49094002416618243\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.4710208378009734\n",
            "The cosine similarity score between the resume and job description is: 0.5079055228309398\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.49598104979066915\n",
            "The cosine similarity score between the resume and job description is: 0.5539207899669027\n",
            "The cosine similarity score between the resume and job description is: 0.5341289962837813\n",
            "The cosine similarity score between the resume and job description is: 0.4734935629317173\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.4398054376891351\n",
            "The cosine similarity score between the resume and job description is: 0.4596452291417429\n",
            "The cosine similarity score between the resume and job description is: 0.4814445606038157\n",
            "The cosine similarity score between the resume and job description is: 0.5001015538482332\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4154786799185604\n",
            "The cosine similarity score between the resume and job description is: 0.49094002416618243\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.5079055228309398\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5539207899669027\n",
            "The cosine similarity score between the resume and job description is: 0.5341289962837813\n",
            "The cosine similarity score between the resume and job description is: 0.4734935629317173\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.5541738101369418\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.49094002416618243\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.4950352158708142\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.5541738101369418\n",
            "The cosine similarity score between the resume and job description is: 0.3544427645713001\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.4518950211374005\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.4060517809103758\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.35834468731623315\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.4710208378009734\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5341289962837813\n",
            "The cosine similarity score between the resume and job description is: 0.43683280225411625\n",
            "The cosine similarity score between the resume and job description is: 0.4734935629317173\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.5541738101369418\n",
            "The cosine similarity score between the resume and job description is: 0.4862987625796375\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.5253791030773006\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.48400477022680627\n",
            "The cosine similarity score between the resume and job description is: 0.5622062649986229\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.5447049907489416\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.49016445998966035\n",
            "The cosine similarity score between the resume and job description is: 0.45078989961462246\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.5772646106817982\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.5395515257216098\n",
            "The cosine similarity score between the resume and job description is: 0.529870622773982\n",
            "The cosine similarity score between the resume and job description is: 0.4367049454782844\n",
            "The cosine similarity score between the resume and job description is: 0.4241548801958943\n",
            "The cosine similarity score between the resume and job description is: 0.5447502082646807\n",
            "The cosine similarity score between the resume and job description is: 0.4834190917352399\n",
            "The cosine similarity score between the resume and job description is: 0.5001015538482332\n",
            "The cosine similarity score between the resume and job description is: 0.5139621314502164\n",
            "The cosine similarity score between the resume and job description is: 0.4484803682711993\n",
            "The cosine similarity score between the resume and job description is: 0.547752892986012\n",
            "The cosine similarity score between the resume and job description is: 0.4792060649219761\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.39766103046938917\n",
            "The cosine similarity score between the resume and job description is: 0.38559673772809294\n",
            "The cosine similarity score between the resume and job description is: 0.4856660755334708\n",
            "The cosine similarity score between the resume and job description is: 0.4171181303468688\n",
            "The cosine similarity score between the resume and job description is: 0.4834190917352399\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.45223376886555644\n",
            "The cosine similarity score between the resume and job description is: 0.4154786799185604\n",
            "The cosine similarity score between the resume and job description is: 0.49094002416618243\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.4710208378009734\n",
            "The cosine similarity score between the resume and job description is: 0.5079055228309398\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.4734935629317173\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.5541738101369418\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.3544427645713001\n",
            "The cosine similarity score between the resume and job description is: 0.5253791030773006\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.5001015538482332\n",
            "The cosine similarity score between the resume and job description is: 0.49598104979066915\n",
            "The cosine similarity score between the resume and job description is: 0.5452006500774037\n",
            "The cosine similarity score between the resume and job description is: 0.487805470866604\n",
            "The cosine similarity score between the resume and job description is: 0.47067340052396106\n",
            "The cosine similarity score between the resume and job description is: 0.4305586219689222\n",
            "The cosine similarity score between the resume and job description is: 0.5049203486137667\n",
            "The cosine similarity score between the resume and job description is: 0.5231851400808775\n",
            "The cosine similarity score between the resume and job description is: 0.5725730780322633\n",
            "The cosine similarity score between the resume and job description is: 0.4735662772920773\n",
            "The cosine similarity score between the resume and job description is: 0.5458842825210535\n",
            "The cosine similarity score between the resume and job description is: 0.4857705112130109\n",
            "The cosine similarity score between the resume and job description is: 0.5729235923516679\n",
            "The cosine similarity score between the resume and job description is: 0.44273424540732437\n",
            "The cosine similarity score between the resume and job description is: 0.5203157748403289\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.3915017061498123\n",
            "The cosine similarity score between the resume and job description is: 0.441081422004555\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.3261804545886715\n",
            "The cosine similarity score between the resume and job description is: 0.38547703854541815\n",
            "The cosine similarity score between the resume and job description is: 0.5595632156004755\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.42866683555923235\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.5438666103662073\n",
            "The cosine similarity score between the resume and job description is: 0.4804347510925644\n",
            "The cosine similarity score between the resume and job description is: 0.4857705112130109\n",
            "The cosine similarity score between the resume and job description is: 0.5458842825210535\n",
            "The cosine similarity score between the resume and job description is: 0.3261804545886715\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.47067340052396106\n",
            "The cosine similarity score between the resume and job description is: 0.5595632156004755\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.42866683555923235\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.5438666103662073\n",
            "The cosine similarity score between the resume and job description is: 0.5157156210736407\n",
            "The cosine similarity score between the resume and job description is: 0.522381495567888\n",
            "The cosine similarity score between the resume and job description is: 0.5431506048992122\n",
            "The cosine similarity score between the resume and job description is: 0.4503430951073363\n",
            "The cosine similarity score between the resume and job description is: 0.5196475276392453\n",
            "The cosine similarity score between the resume and job description is: 0.512600540415159\n",
            "The cosine similarity score between the resume and job description is: 0.5049203486137667\n",
            "The cosine similarity score between the resume and job description is: 0.4857705112130109\n",
            "The cosine similarity score between the resume and job description is: 0.5725730780322633\n",
            "The cosine similarity score between the resume and job description is: 0.4735662772920773\n",
            "The cosine similarity score between the resume and job description is: 0.5458842825210535\n",
            "The cosine similarity score between the resume and job description is: 0.5729235923516679\n",
            "The cosine similarity score between the resume and job description is: 0.44273424540732437\n",
            "The cosine similarity score between the resume and job description is: 0.4305586219689222\n",
            "The cosine similarity score between the resume and job description is: 0.3261804545886715\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.47067340052396106\n",
            "The cosine similarity score between the resume and job description is: 0.5595632156004755\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.42866683555923235\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.5438666103662073\n",
            "The cosine similarity score between the resume and job description is: 0.5157156210736407\n",
            "The cosine similarity score between the resume and job description is: 0.522381495567888\n",
            "The cosine similarity score between the resume and job description is: 0.5431506048992122\n",
            "The cosine similarity score between the resume and job description is: 0.4503430951073363\n",
            "The cosine similarity score between the resume and job description is: 0.5196475276392453\n",
            "The cosine similarity score between the resume and job description is: 0.512600540415159\n",
            "The cosine similarity score between the resume and job description is: 0.5231851400808775\n",
            "The cosine similarity score between the resume and job description is: 0.5231851400808775\n",
            "The cosine similarity score between the resume and job description is: 0.5725730780322633\n",
            "The cosine similarity score between the resume and job description is: 0.4735662772920773\n",
            "The cosine similarity score between the resume and job description is: 0.5458842825210535\n",
            "The cosine similarity score between the resume and job description is: 0.4857705112130109\n",
            "The cosine similarity score between the resume and job description is: 0.5729235923516679\n",
            "The cosine similarity score between the resume and job description is: 0.44273424540732437\n",
            "The cosine similarity score between the resume and job description is: 0.5203157748403289\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.3915017061498123\n",
            "The cosine similarity score between the resume and job description is: 0.441081422004555\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.3261804545886715\n",
            "The cosine similarity score between the resume and job description is: 0.38547703854541815\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.3172934369490661\n",
            "The cosine similarity score between the resume and job description is: 0.4793111756871171\n",
            "The cosine similarity score between the resume and job description is: 0.4804347510925644\n",
            "The cosine similarity score between the resume and job description is: 0.3814301780355789\n",
            "The cosine similarity score between the resume and job description is: 0.5441116677668215\n",
            "The cosine similarity score between the resume and job description is: 0.5157156210736407\n",
            "The cosine similarity score between the resume and job description is: 0.522381495567888\n",
            "The cosine similarity score between the resume and job description is: 0.45070383414766757\n",
            "The cosine similarity score between the resume and job description is: 0.4770599615316209\n",
            "The cosine similarity score between the resume and job description is: 0.4569101342724628\n",
            "The cosine similarity score between the resume and job description is: 0.5111910990413683\n",
            "The cosine similarity score between the resume and job description is: 0.3915017061498123\n",
            "The cosine similarity score between the resume and job description is: 0.5453653912439271\n",
            "The cosine similarity score between the resume and job description is: 0.5457837621768629\n",
            "The cosine similarity score between the resume and job description is: 0.5082821959935837\n",
            "The cosine similarity score between the resume and job description is: 0.5297991398385021\n",
            "The cosine similarity score between the resume and job description is: 0.4578393052715551\n",
            "The cosine similarity score between the resume and job description is: 0.5441116677668215\n",
            "The cosine similarity score between the resume and job description is: 0.47563363508543566\n",
            "The cosine similarity score between the resume and job description is: 0.5461227007529279\n",
            "The cosine similarity score between the resume and job description is: 0.23472626340651007\n",
            "The cosine similarity score between the resume and job description is: 0.538971844705568\n",
            "The cosine similarity score between the resume and job description is: 0.5092571500163202\n",
            "The cosine similarity score between the resume and job description is: 0.5046658288813689\n",
            "The cosine similarity score between the resume and job description is: 0.39719999601425615\n",
            "The cosine similarity score between the resume and job description is: 0.48519203709789394\n",
            "The cosine similarity score between the resume and job description is: 0.5048952195748687\n",
            "The cosine similarity score between the resume and job description is: 0.512600540415159\n",
            "The cosine similarity score between the resume and job description is: 0.5157156210736407\n",
            "The cosine similarity score between the resume and job description is: 0.5458842825210535\n",
            "The cosine similarity score between the resume and job description is: 0.5729235923516679\n",
            "The cosine similarity score between the resume and job description is: 0.44273424540732437\n",
            "The cosine similarity score between the resume and job description is: 0.5203157748403289\n",
            "The cosine similarity score between the resume and job description is: 0.441081422004555\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.3261804545886715\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.38547703854541815\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.3172934369490661\n",
            "The cosine similarity score between the resume and job description is: 0.4793111756871171\n",
            "The cosine similarity score between the resume and job description is: 0.4857705112130109\n",
            "The cosine similarity score between the resume and job description is: 0.5431506048992122\n",
            "The cosine similarity score between the resume and job description is: 0.4503430951073363\n",
            "The cosine similarity score between the resume and job description is: 0.4305586219689222\n",
            "The cosine similarity score between the resume and job description is: 0.4554525989113072\n",
            "The cosine similarity score between the resume and job description is: 0.4735662772920773\n",
            "The cosine similarity score between the resume and job description is: 0.5458842825210535\n",
            "The cosine similarity score between the resume and job description is: 0.4857705112130109\n",
            "The cosine similarity score between the resume and job description is: 0.5729235923516679\n",
            "The cosine similarity score between the resume and job description is: 0.44273424540732437\n",
            "The cosine similarity score between the resume and job description is: 0.5203157748403289\n",
            "The cosine similarity score between the resume and job description is: 0.441081422004555\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.3261804545886715\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.38547703854541815\n",
            "The cosine similarity score between the resume and job description is: 0.5595632156004755\n",
            "The cosine similarity score between the resume and job description is: 0.42866683555923235\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.5438666103662073\n",
            "The cosine similarity score between the resume and job description is: 0.5157156210736407\n",
            "The cosine similarity score between the resume and job description is: 0.5431506048992122\n",
            "The cosine similarity score between the resume and job description is: 0.4503430951073363\n",
            "The cosine similarity score between the resume and job description is: 0.5129316356588159\n",
            "The cosine similarity score between the resume and job description is: 0.4305586219689222\n",
            "The cosine similarity score between the resume and job description is: 0.512600540415159\n",
            "The cosine similarity score between the resume and job description is: 0.4554525989113072\n",
            "The cosine similarity score between the resume and job description is: 0.44273424540732437\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.47067340052396106\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.3172934369490661\n",
            "The cosine similarity score between the resume and job description is: 0.4793111756871171\n",
            "The cosine similarity score between the resume and job description is: 0.5157156210736407\n",
            "The cosine similarity score between the resume and job description is: 0.45070383414766757\n",
            "The cosine similarity score between the resume and job description is: 0.5431506048992122\n",
            "The cosine similarity score between the resume and job description is: 0.4503430951073363\n",
            "The cosine similarity score between the resume and job description is: 0.512600540415159\n",
            "The cosine similarity score between the resume and job description is: 0.5231851400808775\n",
            "The cosine similarity score between the resume and job description is: 0.4554525989113072\n",
            "The cosine similarity score between the resume and job description is: 0.5480318587390622\n",
            "The cosine similarity score between the resume and job description is: 0.5440712123642748\n",
            "The cosine similarity score between the resume and job description is: 0.49563064264606904\n",
            "The cosine similarity score between the resume and job description is: 0.4578393052715551\n",
            "The cosine similarity score between the resume and job description is: 0.5092571500163202\n",
            "The cosine similarity score between the resume and job description is: 0.5313892549917111\n",
            "The cosine similarity score between the resume and job description is: 0.3915017061498123\n",
            "The cosine similarity score between the resume and job description is: 0.5203157748403289\n",
            "The cosine similarity score between the resume and job description is: 0.45866032474058943\n",
            "The cosine similarity score between the resume and job description is: 0.45826524133648544\n",
            "The cosine similarity score between the resume and job description is: 0.4961304765356669\n",
            "The cosine similarity score between the resume and job description is: 0.5196475276392453\n",
            "The cosine similarity score between the resume and job description is: 0.5452672018314022\n",
            "The cosine similarity score between the resume and job description is: 0.5431506048992122\n",
            "The cosine similarity score between the resume and job description is: 0.4029027554227081\n",
            "The cosine similarity score between the resume and job description is: 0.5376091144852849\n",
            "The cosine similarity score between the resume and job description is: 0.4848776560232114\n",
            "The cosine similarity score between the resume and job description is: 0.5160796520376465\n",
            "The cosine similarity score between the resume and job description is: 0.45670718836470753\n",
            "The cosine similarity score between the resume and job description is: 0.5536219029101098\n",
            "The cosine similarity score between the resume and job description is: 0.5080873989996975\n",
            "The cosine similarity score between the resume and job description is: 0.5187391244330738\n",
            "The cosine similarity score between the resume and job description is: 0.5398525790400083\n",
            "The cosine similarity score between the resume and job description is: 0.47948703038051244\n",
            "The cosine similarity score between the resume and job description is: 0.5440712123642748\n",
            "The cosine similarity score between the resume and job description is: 0.4503430951073363\n",
            "The cosine similarity score between the resume and job description is: 0.5180156438924063\n",
            "The cosine similarity score between the resume and job description is: 0.5046209770807469\n",
            "The cosine similarity score between the resume and job description is: 0.47563363508543566\n",
            "The cosine similarity score between the resume and job description is: 0.5203157748403289\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.3915017061498123\n",
            "The cosine similarity score between the resume and job description is: 0.441081422004555\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.3261804545886715\n",
            "The cosine similarity score between the resume and job description is: 0.38547703854541815\n",
            "The cosine similarity score between the resume and job description is: 0.4857705112130109\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.3172934369490661\n",
            "The cosine similarity score between the resume and job description is: 0.4793111756871171\n",
            "The cosine similarity score between the resume and job description is: 0.4804347510925644\n",
            "The cosine similarity score between the resume and job description is: 0.3814301780355789\n",
            "The cosine similarity score between the resume and job description is: 0.5441116677668215\n",
            "The cosine similarity score between the resume and job description is: 0.5157156210736407\n",
            "The cosine similarity score between the resume and job description is: 0.522381495567888\n",
            "The cosine similarity score between the resume and job description is: 0.45070383414766757\n",
            "The cosine similarity score between the resume and job description is: 0.5129316356588159\n",
            "The cosine similarity score between the resume and job description is: 0.49352797244845475\n",
            "The cosine similarity score between the resume and job description is: 0.5457837621768629\n",
            "The cosine similarity score between the resume and job description is: 0.5440712123642748\n",
            "The cosine similarity score between the resume and job description is: 0.5142630306932776\n",
            "The cosine similarity score between the resume and job description is: 0.5446409066495088\n",
            "The cosine similarity score between the resume and job description is: 0.5203157748403289\n",
            "The cosine similarity score between the resume and job description is: 0.441081422004555\n",
            "The cosine similarity score between the resume and job description is: 0.2987577586391815\n",
            "The cosine similarity score between the resume and job description is: 0.3261804545886715\n",
            "The cosine similarity score between the resume and job description is: 0.5558635900621319\n",
            "The cosine similarity score between the resume and job description is: 0.38547703854541815\n",
            "The cosine similarity score between the resume and job description is: 0.5595632156004755\n",
            "The cosine similarity score between the resume and job description is: 0.42866683555923235\n",
            "The cosine similarity score between the resume and job description is: 0.5235681891666943\n",
            "The cosine similarity score between the resume and job description is: 0.48797617422936795\n",
            "The cosine similarity score between the resume and job description is: 0.4857705112130109\n",
            "The cosine similarity score between the resume and job description is: 0.5157156210736407\n",
            "The cosine similarity score between the resume and job description is: 0.5431506048992122\n",
            "The cosine similarity score between the resume and job description is: 0.4503430951073363\n",
            "The cosine similarity score between the resume and job description is: 0.5129316356588159\n",
            "The cosine similarity score between the resume and job description is: 0.4305586219689222\n",
            "The cosine similarity score between the resume and job description is: 0.512600540415159\n",
            "The cosine similarity score between the resume and job description is: 0.4554525989113072\n",
            "The cosine similarity score between the resume and job description is: 0.5480318587390622\n",
            "The cosine similarity score between the resume and job description is: 0.5440712123642748\n",
            "The cosine similarity score between the resume and job description is: 0.49563064264606904\n",
            "The cosine similarity score between the resume and job description is: 0.5092571500163202\n",
            "The cosine similarity score between the resume and job description is: 0.555504967499605\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.5128224480616359\n",
            "The cosine similarity score between the resume and job description is: 0.5462439865700482\n",
            "The cosine similarity score between the resume and job description is: 0.32281466710242607\n",
            "The cosine similarity score between the resume and job description is: 0.4884379736508462\n",
            "The cosine similarity score between the resume and job description is: 0.47557937023418717\n",
            "The cosine similarity score between the resume and job description is: 0.5472418561170869\n",
            "The cosine similarity score between the resume and job description is: 0.5030706085308198\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.56862308939364\n",
            "The cosine similarity score between the resume and job description is: 0.5330722658054903\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.535460837750508\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5186408413678072\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5524914135898226\n",
            "The cosine similarity score between the resume and job description is: 0.5377587526082935\n",
            "The cosine similarity score between the resume and job description is: 0.4331969234286931\n",
            "The cosine similarity score between the resume and job description is: 0.3697694422950913\n",
            "The cosine similarity score between the resume and job description is: 0.2572827465046133\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5128224480616359\n",
            "The cosine similarity score between the resume and job description is: 0.555504967499605\n",
            "The cosine similarity score between the resume and job description is: 0.5462439865700482\n",
            "The cosine similarity score between the resume and job description is: 0.32281466710242607\n",
            "The cosine similarity score between the resume and job description is: 0.4884379736508462\n",
            "The cosine similarity score between the resume and job description is: 0.47557937023418717\n",
            "The cosine similarity score between the resume and job description is: 0.5472418561170869\n",
            "The cosine similarity score between the resume and job description is: 0.5030706085308198\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.5330722658054903\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.535460837750508\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5186408413678072\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5524914135898226\n",
            "The cosine similarity score between the resume and job description is: 0.5377587526082935\n",
            "The cosine similarity score between the resume and job description is: 0.4331969234286931\n",
            "The cosine similarity score between the resume and job description is: 0.3697694422950913\n",
            "The cosine similarity score between the resume and job description is: 0.5128224480616359\n",
            "The cosine similarity score between the resume and job description is: 0.5462439865700482\n",
            "The cosine similarity score between the resume and job description is: 0.32281466710242607\n",
            "The cosine similarity score between the resume and job description is: 0.4884379736508462\n",
            "The cosine similarity score between the resume and job description is: 0.47557937023418717\n",
            "The cosine similarity score between the resume and job description is: 0.5472418561170869\n",
            "The cosine similarity score between the resume and job description is: 0.5030706085308198\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.5330722658054903\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.535460837750508\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5524914135898226\n",
            "The cosine similarity score between the resume and job description is: 0.5377587526082935\n",
            "The cosine similarity score between the resume and job description is: 0.4331969234286931\n",
            "The cosine similarity score between the resume and job description is: 0.3697694422950913\n",
            "The cosine similarity score between the resume and job description is: 0.2572827465046133\n",
            "The cosine similarity score between the resume and job description is: 0.5313851994482349\n",
            "The cosine similarity score between the resume and job description is: 0.48345800421358726\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.32281466710242607\n",
            "The cosine similarity score between the resume and job description is: 0.5340075302170758\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.5128224480616359\n",
            "The cosine similarity score between the resume and job description is: 0.555504967499605\n",
            "The cosine similarity score between the resume and job description is: 0.5303090055147789\n",
            "The cosine similarity score between the resume and job description is: 0.5462439865700482\n",
            "The cosine similarity score between the resume and job description is: 0.51605129834963\n",
            "The cosine similarity score between the resume and job description is: 0.48345800421358726\n",
            "The cosine similarity score between the resume and job description is: 0.4884379736508462\n",
            "The cosine similarity score between the resume and job description is: 0.5472418561170869\n",
            "The cosine similarity score between the resume and job description is: 0.4738835985765466\n",
            "The cosine similarity score between the resume and job description is: 0.5030706085308198\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.49163773102500025\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.32281466710242607\n",
            "The cosine similarity score between the resume and job description is: 0.4884379736508462\n",
            "The cosine similarity score between the resume and job description is: 0.47557937023418717\n",
            "The cosine similarity score between the resume and job description is: 0.5472418561170869\n",
            "The cosine similarity score between the resume and job description is: 0.5030706085308198\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.56862308939364\n",
            "The cosine similarity score between the resume and job description is: 0.5330722658054903\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.535460837750508\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5186408413678072\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5524914135898226\n",
            "The cosine similarity score between the resume and job description is: 0.5377587526082935\n",
            "The cosine similarity score between the resume and job description is: 0.4331969234286931\n",
            "The cosine similarity score between the resume and job description is: 0.3697694422950913\n",
            "The cosine similarity score between the resume and job description is: 0.2572827465046133\n",
            "The cosine similarity score between the resume and job description is: 0.5313851994482349\n",
            "The cosine similarity score between the resume and job description is: 0.48345800421358726\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.43450492328126383\n",
            "The cosine similarity score between the resume and job description is: 0.4884379736508462\n",
            "The cosine similarity score between the resume and job description is: 0.5472418561170869\n",
            "The cosine similarity score between the resume and job description is: 0.5030706085308198\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5377587526082935\n",
            "The cosine similarity score between the resume and job description is: 0.2572827465046133\n",
            "The cosine similarity score between the resume and job description is: 0.5313851994482349\n",
            "The cosine similarity score between the resume and job description is: 0.48345800421358726\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.43450492328126383\n",
            "The cosine similarity score between the resume and job description is: 0.46543365897389344\n",
            "The cosine similarity score between the resume and job description is: 0.49005986657739836\n",
            "The cosine similarity score between the resume and job description is: 0.47882608968040513\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.5365680214018085\n",
            "The cosine similarity score between the resume and job description is: 0.5190068047775499\n",
            "The cosine similarity score between the resume and job description is: 0.5462439865700482\n",
            "The cosine similarity score between the resume and job description is: 0.32281466710242607\n",
            "The cosine similarity score between the resume and job description is: 0.4884379736508462\n",
            "The cosine similarity score between the resume and job description is: 0.5472418561170869\n",
            "The cosine similarity score between the resume and job description is: 0.5030706085308198\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5186408413678072\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.4331969234286931\n",
            "The cosine similarity score between the resume and job description is: 0.5313851994482349\n",
            "The cosine similarity score between the resume and job description is: 0.43450492328126383\n",
            "The cosine similarity score between the resume and job description is: 0.46543365897389344\n",
            "The cosine similarity score between the resume and job description is: 0.49005986657739836\n",
            "The cosine similarity score between the resume and job description is: 0.5365680214018085\n",
            "The cosine similarity score between the resume and job description is: 0.5190068047775499\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.5128224480616359\n",
            "The cosine similarity score between the resume and job description is: 0.555504967499605\n",
            "The cosine similarity score between the resume and job description is: 0.5303090055147789\n",
            "The cosine similarity score between the resume and job description is: 0.5462439865700482\n",
            "The cosine similarity score between the resume and job description is: 0.51605129834963\n",
            "The cosine similarity score between the resume and job description is: 0.48345800421358726\n",
            "The cosine similarity score between the resume and job description is: 0.4884379736508462\n",
            "The cosine similarity score between the resume and job description is: 0.47557937023418717\n",
            "The cosine similarity score between the resume and job description is: 0.5472418561170869\n",
            "The cosine similarity score between the resume and job description is: 0.4738835985765466\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.56862308939364\n",
            "The cosine similarity score between the resume and job description is: 0.5330722658054903\n",
            "The cosine similarity score between the resume and job description is: 0.535460837750508\n",
            "The cosine similarity score between the resume and job description is: 0.5460015710016316\n",
            "The cosine similarity score between the resume and job description is: 0.31390549427706194\n",
            "The cosine similarity score between the resume and job description is: 0.49163773102500025\n",
            "The cosine similarity score between the resume and job description is: 0.5186408413678072\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5030706085308198\n",
            "The cosine similarity score between the resume and job description is: 0.47193618061502923\n",
            "The cosine similarity score between the resume and job description is: 0.56862308939364\n",
            "The cosine similarity score between the resume and job description is: 0.5330722658054903\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.535460837750508\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5186408413678072\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5524914135898226\n",
            "The cosine similarity score between the resume and job description is: 0.5377587526082935\n",
            "The cosine similarity score between the resume and job description is: 0.4331969234286931\n",
            "The cosine similarity score between the resume and job description is: 0.3697694422950913\n",
            "The cosine similarity score between the resume and job description is: 0.2572827465046133\n",
            "The cosine similarity score between the resume and job description is: 0.5313851994482349\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.43450492328126383\n",
            "The cosine similarity score between the resume and job description is: 0.49005986657739836\n",
            "The cosine similarity score between the resume and job description is: 0.47557937023418717\n",
            "The cosine similarity score between the resume and job description is: 0.5330722658054903\n",
            "The cosine similarity score between the resume and job description is: 0.56862308939364\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.535460837750508\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5186408413678072\n",
            "The cosine similarity score between the resume and job description is: 0.5408661412557535\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5524914135898226\n",
            "The cosine similarity score between the resume and job description is: 0.5377587526082935\n",
            "The cosine similarity score between the resume and job description is: 0.3697694422950913\n",
            "The cosine similarity score between the resume and job description is: 0.2572827465046133\n",
            "The cosine similarity score between the resume and job description is: 0.5313851994482349\n",
            "The cosine similarity score between the resume and job description is: 0.48345800421358726\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.43450492328126383\n",
            "The cosine similarity score between the resume and job description is: 0.46543365897389344\n",
            "The cosine similarity score between the resume and job description is: 0.49005986657739836\n",
            "The cosine similarity score between the resume and job description is: 0.5365680214018085\n",
            "The cosine similarity score between the resume and job description is: 0.56862308939364\n",
            "The cosine similarity score between the resume and job description is: 0.5330722658054903\n",
            "The cosine similarity score between the resume and job description is: 0.45836948323463694\n",
            "The cosine similarity score between the resume and job description is: 0.535460837750508\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5090095152047985\n",
            "The cosine similarity score between the resume and job description is: 0.3836334562718443\n",
            "The cosine similarity score between the resume and job description is: 0.5186408413678072\n",
            "The cosine similarity score between the resume and job description is: 0.5132864257974594\n",
            "The cosine similarity score between the resume and job description is: 0.5524914135898226\n",
            "The cosine similarity score between the resume and job description is: 0.5377587526082935\n",
            "The cosine similarity score between the resume and job description is: 0.4331969234286931\n",
            "The cosine similarity score between the resume and job description is: 0.3697694422950913\n",
            "The cosine similarity score between the resume and job description is: 0.2572827465046133\n",
            "The cosine similarity score between the resume and job description is: 0.5313851994482349\n",
            "The cosine similarity score between the resume and job description is: 0.48345800421358726\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.5365680214018085\n",
            "The cosine similarity score between the resume and job description is: 0.49017562666919595\n",
            "The cosine similarity score between the resume and job description is: 0.11779902227217269\n",
            "The cosine similarity score between the resume and job description is: 0.4230913294148065\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.46910577248670515\n",
            "The cosine similarity score between the resume and job description is: 0.5619042101767673\n",
            "The cosine similarity score between the resume and job description is: 0.4900179155441352\n",
            "The cosine similarity score between the resume and job description is: 0.3736211194577081\n",
            "The cosine similarity score between the resume and job description is: 0.48086427409449395\n",
            "The cosine similarity score between the resume and job description is: 0.34742213204128963\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.5650772024282118\n",
            "The cosine similarity score between the resume and job description is: 0.42125139622882574\n",
            "The cosine similarity score between the resume and job description is: 0.4785752259331572\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.5043463716773016\n",
            "The cosine similarity score between the resume and job description is: 0.5497696382779181\n",
            "The cosine similarity score between the resume and job description is: 0.5454437438785944\n",
            "The cosine similarity score between the resume and job description is: 0.4692941305639549\n",
            "The cosine similarity score between the resume and job description is: 0.5470009204070038\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.20671088945747612\n",
            "The cosine similarity score between the resume and job description is: 0.5920939389876495\n",
            "The cosine similarity score between the resume and job description is: 0.5165569993604355\n",
            "The cosine similarity score between the resume and job description is: 0.5476787645011651\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.5619042101767673\n",
            "The cosine similarity score between the resume and job description is: 0.47149999482387517\n",
            "The cosine similarity score between the resume and job description is: 0.11779902227217269\n",
            "The cosine similarity score between the resume and job description is: 0.3736211194577081\n",
            "The cosine similarity score between the resume and job description is: 0.48086427409449395\n",
            "The cosine similarity score between the resume and job description is: 0.34742213204128963\n",
            "The cosine similarity score between the resume and job description is: 0.5274793303145897\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.44841545915405623\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.5165569993604355\n",
            "The cosine similarity score between the resume and job description is: 0.46910577248670515\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.46910577248670515\n",
            "The cosine similarity score between the resume and job description is: 0.5619042101767673\n",
            "The cosine similarity score between the resume and job description is: 0.34742213204128963\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.4785752259331572\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.42125139622882574\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.5497696382779181\n",
            "The cosine similarity score between the resume and job description is: 0.48895907553456686\n",
            "The cosine similarity score between the resume and job description is: 0.4692941305639549\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.44841545915405623\n",
            "The cosine similarity score between the resume and job description is: 0.5470009204070038\n",
            "The cosine similarity score between the resume and job description is: 0.20671088945747612\n",
            "The cosine similarity score between the resume and job description is: 0.5920939389876495\n",
            "The cosine similarity score between the resume and job description is: 0.5165569993604355\n",
            "The cosine similarity score between the resume and job description is: 0.5049808819125179\n",
            "The cosine similarity score between the resume and job description is: 0.5619042101767673\n",
            "The cosine similarity score between the resume and job description is: 0.47149999482387517\n",
            "The cosine similarity score between the resume and job description is: 0.11779902227217269\n",
            "The cosine similarity score between the resume and job description is: 0.3736211194577081\n",
            "The cosine similarity score between the resume and job description is: 0.48086427409449395\n",
            "The cosine similarity score between the resume and job description is: 0.34742213204128963\n",
            "The cosine similarity score between the resume and job description is: 0.5134814882798345\n",
            "The cosine similarity score between the resume and job description is: 0.5497696382779181\n",
            "The cosine similarity score between the resume and job description is: 0.5274793303145897\n",
            "The cosine similarity score between the resume and job description is: 0.4785752259331572\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.44841545915405623\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.46910577248670515\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.4880401887597888\n",
            "The cosine similarity score between the resume and job description is: 0.47149999482387517\n",
            "The cosine similarity score between the resume and job description is: 0.48086427409449395\n",
            "The cosine similarity score between the resume and job description is: 0.34742213204128963\n",
            "The cosine similarity score between the resume and job description is: 0.5134814882798345\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.4785752259331572\n",
            "The cosine similarity score between the resume and job description is: 0.5650772024282118\n",
            "The cosine similarity score between the resume and job description is: 0.5274793303145897\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.42125139622882574\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.5497696382779181\n",
            "The cosine similarity score between the resume and job description is: 0.5043463716773016\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.48895907553456686\n",
            "The cosine similarity score between the resume and job description is: 0.4692941305639549\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.44841545915405623\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.3736211194577081\n",
            "The cosine similarity score between the resume and job description is: 0.48086427409449395\n",
            "The cosine similarity score between the resume and job description is: 0.5134814882798345\n",
            "The cosine similarity score between the resume and job description is: 0.5274793303145897\n",
            "The cosine similarity score between the resume and job description is: 0.4785752259331572\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.44841545915405623\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.5165569993604355\n",
            "The cosine similarity score between the resume and job description is: 0.46910577248670515\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.4880401887597888\n",
            "The cosine similarity score between the resume and job description is: 0.5351047506902974\n",
            "The cosine similarity score between the resume and job description is: 0.4060517809103758\n",
            "The cosine similarity score between the resume and job description is: 0.4937319147166794\n",
            "The cosine similarity score between the resume and job description is: 0.34742213204128963\n",
            "The cosine similarity score between the resume and job description is: 0.5497696382779181\n",
            "The cosine similarity score between the resume and job description is: 0.4785752259331572\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.20671088945747612\n",
            "The cosine similarity score between the resume and job description is: 0.5165569993604355\n",
            "The cosine similarity score between the resume and job description is: 0.46910577248670515\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.4880401887597888\n",
            "The cosine similarity score between the resume and job description is: 0.5351047506902974\n",
            "The cosine similarity score between the resume and job description is: 0.13360853142453696\n",
            "The cosine similarity score between the resume and job description is: 0.4060517809103758\n",
            "The cosine similarity score between the resume and job description is: 0.46341136055158727\n",
            "The cosine similarity score between the resume and job description is: 0.5662770657445093\n",
            "The cosine similarity score between the resume and job description is: 0.4613719871796785\n",
            "The cosine similarity score between the resume and job description is: 0.46944537046995594\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.4785752259331572\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.44841545915405623\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.20671088945747612\n",
            "The cosine similarity score between the resume and job description is: 0.5165569993604355\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.4880401887597888\n",
            "The cosine similarity score between the resume and job description is: 0.5351047506902974\n",
            "The cosine similarity score between the resume and job description is: 0.13360853142453696\n",
            "The cosine similarity score between the resume and job description is: 0.4060517809103758\n",
            "The cosine similarity score between the resume and job description is: 0.4937319147166794\n",
            "The cosine similarity score between the resume and job description is: 0.46341136055158727\n",
            "The cosine similarity score between the resume and job description is: 0.5662770657445093\n",
            "The cosine similarity score between the resume and job description is: 0.4613719871796785\n",
            "The cosine similarity score between the resume and job description is: 0.46944537046995594\n",
            "The cosine similarity score between the resume and job description is: 0.4987358286262202\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.5506172281944145\n",
            "The cosine similarity score between the resume and job description is: 0.34742213204128963\n",
            "The cosine similarity score between the resume and job description is: 0.5134814882798345\n",
            "The cosine similarity score between the resume and job description is: 0.5497696382779181\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.44841545915405623\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.4880401887597888\n",
            "The cosine similarity score between the resume and job description is: 0.5351047506902974\n",
            "The cosine similarity score between the resume and job description is: 0.4060517809103758\n",
            "The cosine similarity score between the resume and job description is: 0.4937319147166794\n",
            "The cosine similarity score between the resume and job description is: 0.46349840313750484\n",
            "The cosine similarity score between the resume and job description is: 0.46341136055158727\n",
            "The cosine similarity score between the resume and job description is: 0.5662770657445093\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.44841545915405623\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.20671088945747612\n",
            "The cosine similarity score between the resume and job description is: 0.5165569993604355\n",
            "The cosine similarity score between the resume and job description is: 0.46910577248670515\n",
            "The cosine similarity score between the resume and job description is: 0.4622514330984665\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.4880401887597888\n",
            "The cosine similarity score between the resume and job description is: 0.5351047506902974\n",
            "The cosine similarity score between the resume and job description is: 0.46341136055158727\n",
            "The cosine similarity score between the resume and job description is: 0.5662770657445093\n",
            "The cosine similarity score between the resume and job description is: 0.4613719871796785\n",
            "The cosine similarity score between the resume and job description is: 0.46944537046995594\n",
            "The cosine similarity score between the resume and job description is: 0.4987358286262202\n",
            "The cosine similarity score between the resume and job description is: 0.5506172281944145\n",
            "The cosine similarity score between the resume and job description is: 0.5662770657445093\n",
            "The cosine similarity score between the resume and job description is: 0.5134814882798345\n",
            "The cosine similarity score between the resume and job description is: 0.4719491824640831\n",
            "The cosine similarity score between the resume and job description is: 0.40731715221448184\n",
            "The cosine similarity score between the resume and job description is: 0.5650772024282118\n",
            "The cosine similarity score between the resume and job description is: 0.5274793303145897\n",
            "The cosine similarity score between the resume and job description is: 0.42125139622882574\n",
            "The cosine similarity score between the resume and job description is: 0.4785752259331572\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.5043463716773016\n",
            "The cosine similarity score between the resume and job description is: 0.5497696382779181\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.5589298701501484\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.5454437438785944\n",
            "The cosine similarity score between the resume and job description is: 0.4692941305639549\n",
            "The cosine similarity score between the resume and job description is: 0.5470009204070038\n",
            "The cosine similarity score between the resume and job description is: 0.4090658088412366\n",
            "The cosine similarity score between the resume and job description is: 0.5920939389876495\n",
            "The cosine similarity score between the resume and job description is: 0.4613719871796785\n",
            "The cosine similarity score between the resume and job description is: 0.5351047506902974\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.4705807125986845\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.4230913294148065\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.4474629295317247\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.5624104662901636\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.36128089908034244\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.4103393574191724\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.4705807125986845\n",
            "The cosine similarity score between the resume and job description is: 0.4698388262507255\n",
            "The cosine similarity score between the resume and job description is: 0.4230913294148065\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.4474629295317247\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.5624104662901636\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.36128089908034244\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.4103393574191724\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5624104662901636\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.36128089908034244\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.4060517809103758\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.4031504445744519\n",
            "The cosine similarity score between the resume and job description is: 0.49975872015379735\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.3544427645713001\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.4230913294148065\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.5624104662901636\n",
            "The cosine similarity score between the resume and job description is: 0.4060517809103758\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.4031504445744519\n",
            "The cosine similarity score between the resume and job description is: 0.49975872015379735\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.3544427645713001\n",
            "The cosine similarity score between the resume and job description is: 0.520625798727861\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.4474629295317247\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5624104662901636\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.4103393574191724\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.5106365965237261\n",
            "The cosine similarity score between the resume and job description is: 0.48400477022680627\n",
            "The cosine similarity score between the resume and job description is: 0.5622062649986229\n",
            "The cosine similarity score between the resume and job description is: 0.519527463006409\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.4328792881469491\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.4474629295317247\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5624104662901636\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.36128089908034244\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.4103393574191724\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.5622062649986229\n",
            "The cosine similarity score between the resume and job description is: 0.4518950211374005\n",
            "The cosine similarity score between the resume and job description is: 0.46637699750662837\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.4474629295317247\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.5624104662901636\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.36128089908034244\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.4103393574191724\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.5106365965237261\n",
            "The cosine similarity score between the resume and job description is: 0.5622062649986229\n",
            "The cosine similarity score between the resume and job description is: 0.4518950211374005\n",
            "The cosine similarity score between the resume and job description is: 0.3440583357690859\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.463019727476313\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.23488808780588136\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.4060517809103758\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.4031504445744519\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.3544427645713001\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.48400477022680627\n",
            "The cosine similarity score between the resume and job description is: 0.5106365965237261\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.517473598959246\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.4474629295317247\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.5106365965237261\n",
            "The cosine similarity score between the resume and job description is: 0.48400477022680627\n",
            "The cosine similarity score between the resume and job description is: 0.5622062649986229\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.4518950211374005\n",
            "The cosine similarity score between the resume and job description is: 0.3440583357690859\n",
            "The cosine similarity score between the resume and job description is: 0.518005221596739\n",
            "The cosine similarity score between the resume and job description is: 0.42202512485434424\n",
            "The cosine similarity score between the resume and job description is: 0.13655289896181635\n",
            "The cosine similarity score between the resume and job description is: 0.13001762580621712\n",
            "The cosine similarity score between the resume and job description is: 0.4474629295317247\n",
            "The cosine similarity score between the resume and job description is: 0.4884679785086614\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.46215692042518786\n",
            "The cosine similarity score between the resume and job description is: 0.3650190163947509\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.36128089908034244\n",
            "The cosine similarity score between the resume and job description is: 0.4742242097731149\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.4103393574191724\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.5106365965237261\n",
            "The cosine similarity score between the resume and job description is: 0.5622062649986229\n",
            "The cosine similarity score between the resume and job description is: 0.3440583357690859\n",
            "The cosine similarity score between the resume and job description is: 0.518005221596739\n",
            "The cosine similarity score between the resume and job description is: 0.42360200109062673\n",
            "The cosine similarity score between the resume and job description is: 0.5048212051048826\n",
            "The cosine similarity score between the resume and job description is: 0.5184780149240722\n",
            "The cosine similarity score between the resume and job description is: 0.36128089908034244\n",
            "The cosine similarity score between the resume and job description is: 0.32150994012888023\n",
            "The cosine similarity score between the resume and job description is: 0.5191028771767585\n",
            "The cosine similarity score between the resume and job description is: 0.4103393574191724\n",
            "The cosine similarity score between the resume and job description is: 0.5023201727574078\n",
            "The cosine similarity score between the resume and job description is: 0.5304762673948158\n",
            "The cosine similarity score between the resume and job description is: 0.5106365965237261\n",
            "The cosine similarity score between the resume and job description is: 0.48400477022680627\n",
            "The cosine similarity score between the resume and job description is: 0.3440583357690859\n",
            "The cosine similarity score between the resume and job description is: 0.46910577248670515\n",
            "The cosine similarity score between the resume and job description is: 0.32281466710242607\n",
            "The cosine similarity score between the resume and job description is: 0.5054062461201797\n",
            "The cosine similarity score between the resume and job description is: 0.5138408322557945\n",
            "The cosine similarity score between the resume and job description is: 0.5541738101369418\n",
            "The cosine similarity score between the resume and job description is: 0.5726032155240295\n",
            "The cosine similarity score between the resume and job description is: 0.5052560032899355\n",
            "The cosine similarity score between the resume and job description is: 0.3544427645713001\n",
            "The cosine similarity score between the resume and job description is: 0.44902736757012685\n",
            "The cosine similarity score between the resume and job description is: 0.4656881901696046\n",
            "The cosine similarity score between the resume and job description is: 0.4622982912900172\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from statistics import mean\n",
        "similarity={}\n",
        "resume_text= \"PROFESSIONAL EXPERIENCE Universiti Teknologi PETRONAS, Perak, Malaysia June 2021 - March 2022 Research Intern (Data Science) - Python, Pandas, NumPy, Scikit-learn, TensorFlow, TF-Lite, Keras, RPi. • Designed a novel Artificial Neural Network (ANN) architecture to fabricate a Motor Bearing Non-Invasive Fault Testing Rig (MOBIT) which improves plant efficiency by 25% and decreases replacement costs by over 35%.• Fabricated a computationally light image classification algorithm to analyze Park Vector images of IM motors.• Researched with real-world induction motor data provided by Petronas, to implement predictive maintenance in industrial plants. Achieved 98.7% accuracy in fault prediction and deployed predictive model in RPi. Biosthra, Chennai, India March 2021 - December 2021 IoT Engineer and Data Analyst - Flutter, Python, Pandas, NumPy TensorFlow, Keras, Time Series, DoE.• Architected the IoT system of an automated compost pit to monitor key parameters such as pH values and temperature.• Enabled visualization of all key metrics in a live mobile dashboard using ThingSpeak. Further, built the framework tocontrol working of the compost pit via a custom flutter application, thus reducing compost time by 33%.• Developed a machine learning algorithm to predict heat produced by the compost pit at different time stamps, compostconsistencies and reduce its reliance on sensors which are bound to fail in hostile conditions.Saint Louis University, St. Louis, Missouri (Virtual) October 2021 - November 2021 Data Analyst intern - Tableau, R (Rshiny), MS Office suite.• Analyzed real-world data from client industry Ad-campaigns to decide upon the best performers.• Took charge as intern project lead and orchestrated working of the team in visualization of important metrics.• Undertook responsibility to present conclusions and visualizations from the trained model.\"\n",
        "jobs=[\"CVE\",\"DA\",\"DE\",\"DS\",\"MLE\"]\n",
        "for job in jobs:\n",
        "  df=pd.read_csv('linkedinjobs'+job+'.csv')\n",
        "  df=df.dropna()\n",
        "  sim=[]\n",
        "  for x in df[\"job-description\"].tolist():\n",
        "    job_description =x\n",
        "    data = pd.DataFrame({'text': [resume_text, job_description]})\n",
        "    vectorizer = CountVectorizer().fit_transform(data['text'])\n",
        "    cos_sim = cosine_similarity(vectorizer[0], vectorizer[1])[0][0]\n",
        "    sim.append(cos_sim)\n",
        "    print(\"The cosine similarity score between the resume and job description is:\", cos_sim)\n",
        "  similarity[job]=mean(sim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mtzlI0pd9QJ",
        "outputId": "53ae2640-ee56-435e-c9ee-e52bc5fb8572"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'CVE': 0.466225762491494,\n",
              " 'DA': 0.4799135645044779,\n",
              " 'DE': 0.47239386795199606,\n",
              " 'DS': 0.46118747809029575,\n",
              " 'MLE': 0.43631016998630634}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "FRQx0D7tchLK",
        "outputId": "444ff681-116b-4ad5-8aed-c0145adcfac5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "x=[\"Computer Vision Engineer\",\"Data Analyst\",\"Data Engineer\",\"Data Scientist\",\"Machine Learning Engineer\"]\n",
        "y=list(similarity.values())\n",
        "# creating the bar plot\n",
        "plt.bar(x, y, color ='green',\n",
        "        width = 0.4)\n",
        "plt.yticks(np.arange(0, 0.5, step=0.05))\n",
        "plt.xlabel(\"Job Title\")\n",
        "plt.ylabel(\"Fit Percentage\")\n",
        "plt.title(\"Fit percentage of resume for job titles\")\n",
        "for i in range(len(x)):\n",
        "     plt.text(i, y[i], round(y[i],3), ha = 'center')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
